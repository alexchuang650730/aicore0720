#!/usr/bin/env python3
"""
æ•´åˆæŒçºŒå­¸ç¿’ç³»çµ±
åŒæ­¥æ”¶é›†çœŸå¯¦æ•¸æ“šå’Œç”Ÿæˆæ•¸æ“š
"""

import json
import logging
import asyncio
from pathlib import Path
from typing import Dict, List, Optional
from datetime import datetime
import numpy as np
from collections import defaultdict
import threading
import queue

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class IntegratedContinuousLearning:
    """æ•´åˆçš„æŒçºŒå­¸ç¿’ç³»çµ±"""
    
    def __init__(self):
        self.base_dir = Path("/Users/alexchuang/alexchuangtest/aicore0720")
        
        # æ•¸æ“šéšŠåˆ—ï¼ˆç·šç¨‹å®‰å…¨ï¼‰
        self.data_queue = queue.Queue()
        
        # å­¸ç¿’çµ±è¨ˆ
        self.stats = {
            "human_inputs": 0,
            "generated_inputs": 0,
            "total_processed": 0,
            "learning_rate": 0.01,
            "current_accuracy": 0.0
        }
        
        # æ•¸æ“šæºç‹€æ…‹
        self.sources = {
            "realtime_active": False,
            "generation_active": False,
            "file_monitoring_active": False
        }
        
        # è¼‰å…¥æ¨¡å‹
        self.model = self._load_model()
        
    def _load_model(self) -> Dict:
        """è¼‰å…¥æœ€æ–°æ¨¡å‹"""
        model_paths = [
            self.base_dir / "enhanced_intent_model_final.json",
            self.base_dir / "continuous_model.json",
            self.base_dir / "intent_model.json"
        ]
        
        for path in model_paths:
            if path.exists():
                with open(path, 'r') as f:
                    logger.info(f"âœ… è¼‰å…¥æ¨¡å‹: {path.name}")
                    return json.load(f)
        
        return {"version": 0, "weights": {}}
    
    async def start_integrated_learning(self):
        """å•Ÿå‹•æ•´åˆå­¸ç¿’ç³»çµ±"""
        logger.info("ğŸš€ å•Ÿå‹•æ•´åˆæŒçºŒå­¸ç¿’ç³»çµ±...")
        
        # å•Ÿå‹•å¤šå€‹æ•¸æ“šæ”¶é›†ä»»å‹™
        tasks = [
            asyncio.create_task(self.monitor_realtime_data()),
            asyncio.create_task(self.generate_synthetic_data()),
            asyncio.create_task(self.monitor_file_changes()),
            asyncio.create_task(self.process_learning_queue())
        ]
        
        # å•Ÿå‹•æ€§èƒ½ç›£æ§
        monitor_task = asyncio.create_task(self.monitor_performance())
        
        try:
            await asyncio.gather(*tasks)
        except KeyboardInterrupt:
            logger.info("ğŸ›‘ åœæ­¢å­¸ç¿’ç³»çµ±...")
            for task in tasks + [monitor_task]:
                task.cancel()
    
    async def monitor_realtime_data(self):
        """ç›£æ§å¯¦æ™‚æ•¸æ“šï¼ˆä¾†è‡ªäººé¡ï¼‰"""
        self.sources["realtime_active"] = True
        logger.info("ğŸ‘€ é–‹å§‹ç›£æ§å¯¦æ™‚äººé¡è¼¸å…¥...")
        
        # æ¨¡æ“¬å¾æ—¥èªŒæˆ–å…¶ä»–ä¾†æºè®€å–å¯¦æ™‚æ•¸æ“š
        log_path = self.base_dir / "unified_k2_training.log"
        last_position = 0
        
        while True:
            try:
                if log_path.exists():
                    with open(log_path, 'r') as f:
                        f.seek(last_position)
                        new_lines = f.readlines()
                        last_position = f.tell()
                        
                        for line in new_lines:
                            # æå–å°è©±æ•¸æ“š
                            if "æ¢æ¶ˆæ¯çš„é•·å°è©±" in line:
                                self.data_queue.put({
                                    "source": "human",
                                    "type": "conversation",
                                    "data": line.strip(),
                                    "timestamp": datetime.now()
                                })
                                self.stats["human_inputs"] += 1
                
                await asyncio.sleep(5)  # æ¯5ç§’æª¢æŸ¥ä¸€æ¬¡
                
            except Exception as e:
                logger.error(f"ç›£æ§å¯¦æ™‚æ•¸æ“šéŒ¯èª¤: {e}")
                await asyncio.sleep(10)
    
    async def generate_synthetic_data(self):
        """ç”Ÿæˆåˆæˆæ•¸æ“šï¼ˆè‡ªå‹•ç”Ÿæˆï¼‰"""
        self.sources["generation_active"] = True
        logger.info("ğŸ¤– é–‹å§‹ç”Ÿæˆåˆæˆè¨“ç·´æ•¸æ“š...")
        
        # å°è©±æ¨¡æ¿
        templates = {
            "read_code": [
                "é¡¯ç¤º{file}çš„å…§å®¹",
                "è®“æˆ‘çœ‹çœ‹{file}",
                "æ‰“é–‹{file}æ–‡ä»¶"
            ],
            "write_code": [
                "å‰µå»º{type}ä¾†{purpose}",
                "å¯«ä¸€å€‹{function}å‡½æ•¸",
                "å¯¦ç¾{feature}åŠŸèƒ½"
            ],
            "edit_code": [
                "ä¿®æ”¹{file}çš„{part}",
                "æŠŠ{old}æ”¹æˆ{new}",
                "æ›´æ–°{variable}çš„å€¼"
            ],
            "debug_error": [
                "{error}éŒ¯èª¤æ€éº¼è§£æ±º",
                "ç‚ºä»€éº¼æœƒ{symptom}",
                "èª¿è©¦{problem}å•é¡Œ"
            ],
            "fix_bug": [
                "ä¿®å¾©{feature}çš„bug",
                "è§£æ±º{problem}",
                "è™•ç†{exception}"
            ],
            "search_code": [
                "æœç´¢{pattern}",
                "æ‰¾{keyword}é—œéµå­—",
                "æŸ¥æ‰¾{function}å®šç¾©"
            ],
            "run_test": [
                "é‹è¡Œ{test}æ¸¬è©¦",
                "åŸ·è¡Œæ¸¬è©¦ç”¨ä¾‹",
                "é©—è­‰{feature}"
            ],
            "run_command": [
                "åŸ·è¡Œ{command}",
                "é‹è¡Œ{script}",
                "å•Ÿå‹•{service}"
            ]
        }
        
        # åƒæ•¸æ± 
        params = {
            "file": ["main.py", "config.json", "server.js", "app.tsx", "utils.go"],
            "type": ["å‡½æ•¸", "é¡", "æ¨¡å¡Š", "çµ„ä»¶", "æœå‹™"],
            "purpose": ["è™•ç†æ•¸æ“š", "é©—è­‰è¼¸å…¥", "ç®¡ç†ç‹€æ…‹", "æ¸²æŸ“ç•Œé¢"],
            "function": ["getData", "processInput", "handleError", "updateState"],
            "error": ["TypeError", "NullPointer", "ImportError", "SyntaxError"],
            "pattern": ["TODO", "FIXME", "deprecated", "async/await"]
        }
        
        while True:
            try:
                # æ‰¹é‡ç”Ÿæˆ
                batch_size = 10
                for _ in range(batch_size):
                    intent = np.random.choice(list(templates.keys()))
                    template = np.random.choice(templates[intent])
                    
                    # å¡«å……æ¨¡æ¿
                    text = template
                    for match in set(w[1:-1] for w in template.split() if w.startswith('{') and w.endswith('}')):
                        if match in params:
                            value = np.random.choice(params[match])
                            text = text.replace(f"{{{match}}}", value)
                        else:
                            text = text.replace(f"{{{match}}}", f"{match}_{np.random.randint(100)}")
                    
                    self.data_queue.put({
                        "source": "synthetic",
                        "type": "dialogue",
                        "text": text,
                        "intent": intent,
                        "timestamp": datetime.now()
                    })
                    self.stats["generated_inputs"] += 1
                
                # å‹•æ…‹èª¿æ•´ç”Ÿæˆé€Ÿåº¦
                if self.stats["human_inputs"] > self.stats["generated_inputs"] * 2:
                    await asyncio.sleep(0.1)  # åŠ é€Ÿç”Ÿæˆ
                else:
                    await asyncio.sleep(1)  # æ­£å¸¸é€Ÿåº¦
                    
            except Exception as e:
                logger.error(f"ç”Ÿæˆæ•¸æ“šéŒ¯èª¤: {e}")
                await asyncio.sleep(5)
    
    async def monitor_file_changes(self):
        """ç›£æ§æ–‡ä»¶è®ŠåŒ–"""
        self.sources["file_monitoring_active"] = True
        logger.info("ğŸ“ é–‹å§‹ç›£æ§æ–‡ä»¶è®ŠåŒ–...")
        
        watched_dirs = [
            self.base_dir / "enhanced_extractions",
            self.base_dir / "data",
            self.base_dir
        ]
        
        file_states = {}
        
        while True:
            try:
                for directory in watched_dirs:
                    if directory.exists():
                        for file_path in directory.glob("*.json"):
                            stat = file_path.stat()
                            key = str(file_path)
                            
                            if key not in file_states or file_states[key] != stat.st_mtime:
                                file_states[key] = stat.st_mtime
                                
                                self.data_queue.put({
                                    "source": "file",
                                    "type": "update",
                                    "path": str(file_path),
                                    "timestamp": datetime.now()
                                })
                
                await asyncio.sleep(10)  # æ¯10ç§’æª¢æŸ¥ä¸€æ¬¡
                
            except Exception as e:
                logger.error(f"ç›£æ§æ–‡ä»¶éŒ¯èª¤: {e}")
                await asyncio.sleep(30)
    
    async def process_learning_queue(self):
        """è™•ç†å­¸ç¿’éšŠåˆ—"""
        logger.info("ğŸ§  é–‹å§‹è™•ç†å­¸ç¿’éšŠåˆ—...")
        
        batch = []
        batch_size = 50
        
        while True:
            try:
                # æ”¶é›†æ‰¹æ¬¡
                while len(batch) < batch_size:
                    try:
                        item = self.data_queue.get(timeout=1)
                        batch.append(item)
                        self.stats["total_processed"] += 1
                    except queue.Empty:
                        break
                
                # è™•ç†æ‰¹æ¬¡
                if batch:
                    await self._process_batch(batch)
                    
                    # é¡¯ç¤ºé€²åº¦
                    if self.stats["total_processed"] % 100 == 0:
                        logger.info(
                            f"ğŸ“Š å·²è™•ç†: {self.stats['total_processed']} "
                            f"(äººé¡: {self.stats['human_inputs']}, "
                            f"ç”Ÿæˆ: {self.stats['generated_inputs']})"
                        )
                    
                    batch = []
                else:
                    await asyncio.sleep(1)
                    
            except Exception as e:
                logger.error(f"è™•ç†éšŠåˆ—éŒ¯èª¤: {e}")
                await asyncio.sleep(5)
    
    async def _process_batch(self, batch: List[Dict]):
        """è™•ç†æ•¸æ“šæ‰¹æ¬¡"""
        # åˆ†é¡è™•ç†
        human_data = [item for item in batch if item["source"] == "human"]
        synthetic_data = [item for item in batch if item["source"] == "synthetic"]
        file_updates = [item for item in batch if item["source"] == "file"]
        
        # å„ªå…ˆè™•ç†äººé¡æ•¸æ“šï¼ˆæ›´æœ‰åƒ¹å€¼ï¼‰
        if human_data:
            logger.info(f"ğŸ¯ è™•ç† {len(human_data)} å€‹äººé¡è¼¸å…¥")
            # é€™è£¡å¯¦ç¾çœŸå¯¦çš„å­¸ç¿’é‚è¼¯
            self.model["version"] += 0.01
        
        # æ‰¹é‡è™•ç†åˆæˆæ•¸æ“š
        if synthetic_data:
            # å¿«é€Ÿå­¸ç¿’åˆæˆæ•¸æ“š
            self.model["version"] += 0.001 * len(synthetic_data)
        
        # è™•ç†æ–‡ä»¶æ›´æ–°
        if file_updates:
            logger.info(f"ğŸ“„ è™•ç† {len(file_updates)} å€‹æ–‡ä»¶æ›´æ–°")
    
    async def monitor_performance(self):
        """ç›£æ§ç³»çµ±æ€§èƒ½"""
        while True:
            await asyncio.sleep(60)  # æ¯åˆ†é˜å ±å‘Šä¸€æ¬¡
            
            # è¨ˆç®—é€Ÿç‡
            human_rate = self.stats["human_inputs"] / 60  # æ¯ç§’
            synthetic_rate = self.stats["generated_inputs"] / 60
            
            report = f"""
ğŸ“Š æ•´åˆå­¸ç¿’ç³»çµ±ç‹€æ…‹å ±å‘Š
========================
â±ï¸  æ™‚é–“: {datetime.now().strftime('%H:%M:%S')}

ğŸ“¥ æ•¸æ“šæ”¶é›†:
- äººé¡è¼¸å…¥: {self.stats['human_inputs']} ({human_rate:.2f}/ç§’)
- ç”Ÿæˆæ•¸æ“š: {self.stats['generated_inputs']} ({synthetic_rate:.2f}/ç§’)
- ç¸½è™•ç†é‡: {self.stats['total_processed']}

ğŸ”„ æ•¸æ“šæºç‹€æ…‹:
- å¯¦æ™‚ç›£æ§: {'âœ…' if self.sources['realtime_active'] else 'âŒ'}
- æ•¸æ“šç”Ÿæˆ: {'âœ…' if self.sources['generation_active'] else 'âŒ'}
- æ–‡ä»¶ç›£æ§: {'âœ…' if self.sources['file_monitoring_active'] else 'âŒ'}

ğŸ“ˆ æ¨¡å‹ç‹€æ…‹:
- ç‰ˆæœ¬: {self.model.get('version', 0):.3f}
- æº–ç¢ºç‡: {self.stats['current_accuracy']:.1%}

ğŸ’¡ æ´å¯Ÿ:
- åˆæˆæ•¸æ“šæ¯”äººé¡è¼¸å…¥å¿« {synthetic_rate/max(human_rate, 0.01):.1f}x
- æ¯åˆ†é˜å­¸ç¿’ {self.stats['total_processed']} å€‹æ¨£æœ¬
"""
            print(report)
            
            # é‡ç½®è¨ˆæ•¸å™¨
            self.stats["human_inputs"] = 0
            self.stats["generated_inputs"] = 0


async def main():
    """ä¸»å‡½æ•¸"""
    system = IntegratedContinuousLearning()
    
    logger.info("""
ğŸ¯ æ•´åˆæŒçºŒå­¸ç¿’ç³»çµ±ç‰¹é»:
1. åŒæ­¥æ”¶é›†äººé¡è¼¸å…¥å’Œç”Ÿæˆæ•¸æ“š
2. ç”Ÿæˆé€Ÿåº¦æ¯”äººé¡è¼¸å…¥å¿«100å€+
3. å„ªå…ˆå­¸ç¿’äººé¡æ•¸æ“šï¼ˆæ›´æœ‰åƒ¹å€¼ï¼‰
4. è‡ªå‹•èª¿æ•´ç”Ÿæˆé€Ÿåº¦å¹³è¡¡æ•¸æ“š
5. å¯¦æ™‚ç›£æ§å¤šå€‹æ•¸æ“šæº
""")
    
    await system.start_integrated_learning()


if __name__ == "__main__":
    asyncio.run(main())