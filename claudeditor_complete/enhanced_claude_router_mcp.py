"""
å¢å¼·ç‰ˆ Claude Router MCP
å°ˆç‚º K2 æ¨¡å¼ä¸‹çš„ Claude Code å‘½ä»¤å¢å¼·è€Œè¨­è¨ˆ
æä¾›æ™ºèƒ½è·¯ç”±ã€å‘½ä»¤å¢å¼·ã€ä¸Šä¸‹æ–‡ä¿æŒç­‰åŠŸèƒ½
"""

import asyncio
import json
import time
from typing import Dict, List, Any, Optional, Union
from dataclasses import dataclass, asdict
from enum import Enum
import logging

logger = logging.getLogger(__name__)

class ModelProvider(Enum):
    """æ¨¡å‹æä¾›è€…"""
    CLAUDE = "claude"
    K2_GROQ = "k2_groq"
    K2_MOONSHOT = "k2_moonshot"
    K2_QWEN = "k2_qwen"

class CommandComplexity(Enum):
    """å‘½ä»¤è¤‡é›œåº¦"""
    SIMPLE = "simple"        # ç°¡å–®æŸ¥è©¢ã€åŸºæœ¬æ“ä½œ
    MODERATE = "moderate"    # ä¸­ç­‰é‚è¼¯ã€éœ€è¦æ¨ç†
    COMPLEX = "complex"      # è¤‡é›œä»»å‹™ã€éœ€è¦æ·±åº¦æ€è€ƒ
    CRITICAL = "critical"    # é—œéµä»»å‹™ã€éœ€è¦æœ€é«˜æº–ç¢ºæ€§

class EnhancementType(Enum):
    """å¢å¼·é¡å‹"""
    CONTEXT_ENRICHMENT = "context_enrichment"      # ä¸Šä¸‹æ–‡è±å¯ŒåŒ–
    PROMPT_OPTIMIZATION = "prompt_optimization"    # æç¤ºè©å„ªåŒ–
    CHAIN_OF_THOUGHT = "chain_of_thought"         # æ€ç¶­éˆ
    MULTI_STEP_REASONING = "multi_step_reasoning" # å¤šæ­¥æ¨ç†
    ERROR_CORRECTION = "error_correction"         # éŒ¯èª¤ç³¾æ­£
    VERIFICATION = "verification"                 # çµæœé©—è­‰

@dataclass
class CommandContext:
    """å‘½ä»¤ä¸Šä¸‹æ–‡"""
    command_id: str
    original_command: str
    enhanced_command: str
    complexity: CommandComplexity
    required_enhancements: List[EnhancementType]
    execution_history: List[Dict[str, Any]]
    context_data: Dict[str, Any]
    target_provider: ModelProvider
    fallback_providers: List[ModelProvider]

@dataclass
class EnhancementResult:
    """å¢å¼·çµæœ"""
    original_input: str
    enhanced_input: str
    enhancement_methods: List[str]
    confidence_score: float
    expected_quality_improvement: float
    processing_time: float

class EnhancedClaudeRouterMCP:
    """å¢å¼·ç‰ˆ Claude Router MCP"""
    
    def __init__(self):
        self.command_analyzer = CommandAnalyzer()
        self.enhancement_engine = CommandEnhancementEngine()
        self.routing_optimizer = RoutingOptimizer()
        self.quality_evaluator = QualityEvaluator()
        self.context_manager = ContextManager()
        
        # æ¨¡å‹èƒ½åŠ›é…ç½®
        self.model_capabilities = {
            ModelProvider.CLAUDE: {
                "strength": ["complex_reasoning", "code_generation", "analysis"],
                "weakness": ["cost", "latency"],
                "quality_score": 0.95,
                "cost_per_token": 0.015
            },
            ModelProvider.K2_GROQ: {
                "strength": ["speed", "cost_efficiency", "simple_tasks"],
                "weakness": ["complex_reasoning", "context_handling"],
                "quality_score": 0.75,
                "cost_per_token": 0.0008
            },
            ModelProvider.K2_MOONSHOT: {
                "strength": ["chinese_tasks", "cost_efficiency", "moderate_complexity"],
                "weakness": ["complex_reasoning", "latest_knowledge"],
                "quality_score": 0.78,
                "cost_per_token": 0.001
            },
            ModelProvider.K2_QWEN: {
                "strength": ["chinese_language", "code_tasks", "cost_efficiency"],
                "weakness": ["complex_analysis", "creative_tasks"],
                "quality_score": 0.72,
                "cost_per_token": 0.0005
            }
        }
        
        logger.info("ğŸš€ Enhanced Claude Router MCP åˆå§‹åŒ–å®Œæˆ")
    
    async def route_claude_code_command(self, command: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """è·¯ç”± Claude Code å‘½ä»¤"""
        
        start_time = time.time()
        
        # 1. åˆ†æå‘½ä»¤è¤‡é›œåº¦å’Œéœ€æ±‚
        command_analysis = await self.command_analyzer.analyze_command(command, context)
        
        # 2. é¸æ“‡æœ€ä½³æ¨¡å‹æä¾›è€…
        optimal_provider = await self.routing_optimizer.select_optimal_provider(
            command_analysis, self.model_capabilities
        )
        
        # 3. æ ¹æ“šé¸æ“‡çš„æä¾›è€…æ±ºå®šæ˜¯å¦éœ€è¦å¢å¼·
        if optimal_provider != ModelProvider.CLAUDE:
            # K2 æ¨¡å¼éœ€è¦å¢å¼·
            enhancement_result = await self.enhancement_engine.enhance_command_for_k2(
                command, command_analysis, optimal_provider
            )
            enhanced_command = enhancement_result.enhanced_input
        else:
            # Claude æ¨¡å¼ï¼Œå¯èƒ½ä»éœ€è¦è¼•åº¦å„ªåŒ–
            enhancement_result = await self.enhancement_engine.optimize_for_claude(
                command, command_analysis
            )
            enhanced_command = enhancement_result.enhanced_input
        
        # 4. åŸ·è¡Œå‘½ä»¤
        execution_result = await self._execute_enhanced_command(
            enhanced_command, optimal_provider, command_analysis
        )
        
        # 5. è³ªé‡è©•ä¼°å’Œå¯èƒ½çš„å›é€€
        quality_assessment = await self.quality_evaluator.assess_result_quality(
            execution_result, command_analysis
        )
        
        # 6. å¦‚æœè³ªé‡ä¸é”æ¨™ä¸”æœ‰å›é€€é¸é …ï¼Œå˜—è©¦å›é€€
        if quality_assessment["quality_score"] < 0.8 and optimal_provider != ModelProvider.CLAUDE:
            logger.warning(f"K2 çµæœè³ªé‡ä¸é”æ¨™ ({quality_assessment['quality_score']:.2f})ï¼Œå˜—è©¦ Claude å›é€€")
            
            fallback_enhancement = await self.enhancement_engine.prepare_fallback_command(
                command, execution_result, command_analysis
            )
            
            fallback_result = await self._execute_enhanced_command(
                fallback_enhancement.enhanced_input, ModelProvider.CLAUDE, command_analysis
            )
            
            # æ›´æ–°åŸ·è¡Œçµæœ
            execution_result = fallback_result
            execution_result["fallback_used"] = True
            execution_result["original_provider"] = optimal_provider.value
            execution_result["fallback_provider"] = ModelProvider.CLAUDE.value
        
        # 7. æ›´æ–°ä¸Šä¸‹æ–‡
        await self.context_manager.update_context(command, execution_result, context)
        
        processing_time = time.time() - start_time
        
        return {
            "command_id": f"cmd_{int(time.time())}",
            "original_command": command,
            "enhanced_command": enhanced_command,
            "selected_provider": optimal_provider.value,
            "enhancement_applied": optimal_provider != ModelProvider.CLAUDE,
            "enhancement_details": asdict(enhancement_result),
            "execution_result": execution_result,
            "quality_assessment": quality_assessment,
            "processing_time": processing_time,
            "cost_optimization": {
                "estimated_claude_cost": self._calculate_cost(command, ModelProvider.CLAUDE),
                "actual_cost": self._calculate_cost(enhanced_command, optimal_provider),
                "savings_percentage": self._calculate_savings_percentage(command, optimal_provider)
            }
        }
    
    async def _execute_enhanced_command(self, command: str, provider: ModelProvider, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """åŸ·è¡Œå¢å¼·å‘½ä»¤"""
        
        # æ¨¡æ“¬ä¸åŒæä¾›è€…çš„åŸ·è¡Œ
        if provider == ModelProvider.CLAUDE:
            return await self._execute_with_claude(command, analysis)
        elif provider == ModelProvider.K2_GROQ:
            return await self._execute_with_k2_groq(command, analysis)
        elif provider == ModelProvider.K2_MOONSHOT:
            return await self._execute_with_k2_moonshot(command, analysis)
        elif provider == ModelProvider.K2_QWEN:
            return await self._execute_with_k2_qwen(command, analysis)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æä¾›è€…: {provider}")
    
    async def _execute_with_claude(self, command: str, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨ Claude åŸ·è¡Œ"""
        await asyncio.sleep(0.2)  # æ¨¡æ“¬ç¶²çµ¡å»¶é²
        
        return {
            "provider": "claude",
            "response": f"Claude åŸ·è¡Œçµæœ: {command}",
            "quality_indicators": {
                "reasoning_depth": 0.95,
                "accuracy": 0.92,
                "completeness": 0.90,
                "creativity": 0.88
            },
            "execution_time": 2.5,
            "tokens_used": len(command.split()) * 1.5,
            "status": "success"
        }
    
    async def _execute_with_k2_groq(self, command: str, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨ K2 Groq åŸ·è¡Œ"""
        await asyncio.sleep(0.05)  # K2 æ›´å¿«
        
        # æ ¹æ“šå¢å¼·ç¨‹åº¦èª¿æ•´è³ªé‡
        enhancement_boost = 0.15 if "enhanced" in command else 0
        
        return {
            "provider": "k2_groq",
            "response": f"K2 Groq åŸ·è¡Œçµæœ: {command}",
            "quality_indicators": {
                "reasoning_depth": 0.70 + enhancement_boost,
                "accuracy": 0.75 + enhancement_boost,
                "completeness": 0.72 + enhancement_boost,
                "creativity": 0.65 + enhancement_boost
            },
            "execution_time": 0.8,
            "tokens_used": len(command.split()) * 1.2,
            "status": "success"
        }
    
    async def _execute_with_k2_moonshot(self, command: str, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨ K2 Moonshot åŸ·è¡Œ"""
        await asyncio.sleep(0.1)
        
        enhancement_boost = 0.12 if "enhanced" in command else 0
        
        return {
            "provider": "k2_moonshot", 
            "response": f"K2 Moonshot åŸ·è¡Œçµæœ: {command}",
            "quality_indicators": {
                "reasoning_depth": 0.73 + enhancement_boost,
                "accuracy": 0.78 + enhancement_boost,
                "completeness": 0.75 + enhancement_boost,
                "creativity": 0.70 + enhancement_boost
            },
            "execution_time": 1.2,
            "tokens_used": len(command.split()) * 1.3,
            "status": "success"
        }
    
    async def _execute_with_k2_qwen(self, command: str, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨ K2 Qwen åŸ·è¡Œ"""
        await asyncio.sleep(0.08)
        
        enhancement_boost = 0.18 if "enhanced" in command else 0
        
        return {
            "provider": "k2_qwen",
            "response": f"K2 Qwen åŸ·è¡Œçµæœ: {command}",
            "quality_indicators": {
                "reasoning_depth": 0.68 + enhancement_boost,
                "accuracy": 0.72 + enhancement_boost,
                "completeness": 0.70 + enhancement_boost,
                "creativity": 0.65 + enhancement_boost
            },
            "execution_time": 1.0,
            "tokens_used": len(command.split()) * 1.1,
            "status": "success"
        }
    
    def _calculate_cost(self, command: str, provider: ModelProvider) -> float:
        """è¨ˆç®—åŸ·è¡Œæˆæœ¬"""
        token_count = len(command.split()) * 1.2
        cost_per_token = self.model_capabilities[provider]["cost_per_token"]
        return token_count * cost_per_token
    
    def _calculate_savings_percentage(self, command: str, provider: ModelProvider) -> float:
        """è¨ˆç®—æˆæœ¬ç¯€çœç™¾åˆ†æ¯”"""
        claude_cost = self._calculate_cost(command, ModelProvider.CLAUDE)
        actual_cost = self._calculate_cost(command, provider)
        if claude_cost > 0:
            return ((claude_cost - actual_cost) / claude_cost) * 100
        return 0

class CommandAnalyzer:
    """å‘½ä»¤åˆ†æå™¨"""
    
    async def analyze_command(self, command: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """åˆ†æå‘½ä»¤è¤‡é›œåº¦å’Œéœ€æ±‚"""
        
        # åˆ†æå‘½ä»¤è¤‡é›œåº¦
        complexity = self._assess_complexity(command)
        
        # åˆ†ææ‰€éœ€æŠ€èƒ½
        required_skills = self._identify_required_skills(command)
        
        # åˆ†æèªè¨€éœ€æ±‚
        language_requirements = self._analyze_language_requirements(command)
        
        # åˆ†ææ€§èƒ½éœ€æ±‚
        performance_requirements = self._analyze_performance_requirements(command)
        
        return {
            "complexity": complexity,
            "required_skills": required_skills,
            "language_requirements": language_requirements,
            "performance_requirements": performance_requirements,
            "estimated_tokens": len(command.split()) * 1.5,
            "priority": context.get("priority", "medium") if context else "medium"
        }
    
    def _assess_complexity(self, command: str) -> CommandComplexity:
        """è©•ä¼°å‘½ä»¤è¤‡é›œåº¦"""
        command_lower = command.lower()
        
        # é—œéµè©è¤‡é›œåº¦æ˜ å°„
        complex_indicators = [
            "analyze", "design", "architecture", "implement", "optimize",
            "debug", "refactor", "security", "performance", "algorithm"
        ]
        
        moderate_indicators = [
            "create", "modify", "update", "fix", "test", "review", "explain"
        ]
        
        simple_indicators = [
            "show", "list", "get", "find", "search", "display", "print"
        ]
        
        complex_count = sum(1 for indicator in complex_indicators if indicator in command_lower)
        moderate_count = sum(1 for indicator in moderate_indicators if indicator in command_lower)
        simple_count = sum(1 for indicator in simple_indicators if indicator in command_lower)
        
        if complex_count >= 2 or len(command.split()) > 50:
            return CommandComplexity.COMPLEX
        elif complex_count >= 1 or moderate_count >= 2:
            return CommandComplexity.MODERATE
        elif moderate_count >= 1:
            return CommandComplexity.MODERATE
        else:
            return CommandComplexity.SIMPLE
    
    def _identify_required_skills(self, command: str) -> List[str]:
        """è­˜åˆ¥æ‰€éœ€æŠ€èƒ½"""
        skills = []
        command_lower = command.lower()
        
        skill_keywords = {
            "code_generation": ["create", "generate", "write", "implement"],
            "debugging": ["debug", "fix", "error", "issue"],
            "analysis": ["analyze", "review", "examine", "evaluate"],
            "optimization": ["optimize", "improve", "enhance", "performance"],
            "testing": ["test", "verify", "validate", "check"],
            "documentation": ["document", "explain", "describe", "comment"]
        }
        
        for skill, keywords in skill_keywords.items():
            if any(keyword in command_lower for keyword in keywords):
                skills.append(skill)
        
        return skills
    
    def _analyze_language_requirements(self, command: str) -> Dict[str, Any]:
        """åˆ†æèªè¨€éœ€æ±‚"""
        # æª¢æ¸¬ä¸­æ–‡å…§å®¹
        chinese_chars = sum(1 for char in command if '\u4e00' <= char <= '\u9fff')
        total_chars = len(command)
        chinese_ratio = chinese_chars / total_chars if total_chars > 0 else 0
        
        return {
            "primary_language": "chinese" if chinese_ratio > 0.3 else "english",
            "chinese_ratio": chinese_ratio,
            "requires_chinese_expertise": chinese_ratio > 0.5
        }
    
    def _analyze_performance_requirements(self, command: str) -> Dict[str, Any]:
        """åˆ†ææ€§èƒ½éœ€æ±‚"""
        command_lower = command.lower()
        
        urgent_indicators = ["urgent", "quickly", "fast", "immediate"]
        is_urgent = any(indicator in command_lower for indicator in urgent_indicators)
        
        return {
            "urgency": "high" if is_urgent else "normal",
            "latency_sensitivity": "high" if is_urgent else "medium",
            "cost_sensitivity": "high" if not is_urgent else "medium"
        }

class CommandEnhancementEngine:
    """å‘½ä»¤å¢å¼·å¼•æ“"""
    
    async def enhance_command_for_k2(self, command: str, analysis: Dict[str, Any], provider: ModelProvider) -> EnhancementResult:
        """ç‚º K2 æ¨¡å‹å¢å¼·å‘½ä»¤"""
        
        start_time = time.time()
        
        # æ ¹æ“šè¤‡é›œåº¦é¸æ“‡å¢å¼·ç­–ç•¥
        complexity = analysis.get("complexity", CommandComplexity.SIMPLE)
        
        enhancement_methods = []
        enhanced_command = command
        
        # 1. ä¸Šä¸‹æ–‡è±å¯ŒåŒ–
        if complexity in [CommandComplexity.MODERATE, CommandComplexity.COMPLEX]:
            enhanced_command = await self._add_context_enrichment(enhanced_command, analysis)
            enhancement_methods.append("context_enrichment")
        
        # 2. æç¤ºè©å„ªåŒ–
        enhanced_command = await self._optimize_prompt_for_k2(enhanced_command, provider)
        enhancement_methods.append("prompt_optimization")
        
        # 3. æ€ç¶­éˆå¢å¼·
        if complexity == CommandComplexity.COMPLEX:
            enhanced_command = await self._add_chain_of_thought(enhanced_command)
            enhancement_methods.append("chain_of_thought")
        
        # 4. å¤šæ­¥æ¨ç†
        if "analysis" in analysis.get("required_skills", []):
            enhanced_command = await self._add_multi_step_reasoning(enhanced_command)
            enhancement_methods.append("multi_step_reasoning")
        
        # 5. éŒ¯èª¤é é˜²
        enhanced_command = await self._add_error_prevention(enhanced_command, analysis)
        enhancement_methods.append("error_prevention")
        
        processing_time = time.time() - start_time
        
        # è¨ˆç®—é æœŸè³ªé‡æå‡
        base_quality = 0.75  # K2 åŸºç¤è³ªé‡
        enhancement_boost = len(enhancement_methods) * 0.08  # æ¯å€‹å¢å¼·æ–¹æ³•æå‡ 8%
        expected_quality = min(base_quality + enhancement_boost, 0.95)
        
        return EnhancementResult(
            original_input=command,
            enhanced_input=enhanced_command,
            enhancement_methods=enhancement_methods,
            confidence_score=expected_quality,
            expected_quality_improvement=enhancement_boost,
            processing_time=processing_time
        )
    
    async def optimize_for_claude(self, command: str, analysis: Dict[str, Any]) -> EnhancementResult:
        """ç‚º Claude å„ªåŒ–å‘½ä»¤"""
        
        # Claude å·²ç¶“å¾ˆå¼·ï¼Œåªéœ€è¦è¼•åº¦å„ªåŒ–
        enhanced_command = await self._optimize_prompt_structure(command)
        
        return EnhancementResult(
            original_input=command,
            enhanced_input=enhanced_command,
            enhancement_methods=["prompt_structure_optimization"],
            confidence_score=0.95,
            expected_quality_improvement=0.05,
            processing_time=0.01
        )
    
    async def prepare_fallback_command(self, original_command: str, k2_result: Dict[str, Any], analysis: Dict[str, Any]) -> EnhancementResult:
        """æº–å‚™å›é€€å‘½ä»¤"""
        
        # åˆ†æ K2 çµæœçš„å•é¡Œ
        quality_issues = self._identify_quality_issues(k2_result)
        
        # é‡å°æ€§å¢å¼·
        enhanced_command = f"""
        åŸå§‹ä»»å‹™: {original_command}
        
        K2æ¨¡å‹å·²ç¶“å˜—è©¦è™•ç†ï¼Œä½†å­˜åœ¨ä»¥ä¸‹å•é¡Œ: {', '.join(quality_issues)}
        
        è«‹ä½œç‚ºå°ˆå®¶ç´šAIï¼Œæä¾›é«˜è³ªé‡çš„è§£æ±ºæ–¹æ¡ˆï¼Œç‰¹åˆ¥æ³¨æ„:
        1. æ·±åº¦åˆ†æå’Œæ¨ç†
        2. å®Œæ•´æ€§å’Œæº–ç¢ºæ€§ 
        3. å‰µæ–°æ€§æ€è€ƒ
        4. å¯¦ç”¨æ€§è€ƒæ…®
        
        è«‹è©³ç´°å›ç­”:
        """
        
        return EnhancementResult(
            original_input=original_command,
            enhanced_input=enhanced_command,
            enhancement_methods=["fallback_enhancement", "problem_targeted_prompt"],
            confidence_score=0.92,
            expected_quality_improvement=0.25,
            processing_time=0.02
        )
    
    async def _add_context_enrichment(self, command: str, analysis: Dict[str, Any]) -> str:
        """æ·»åŠ ä¸Šä¸‹æ–‡è±å¯ŒåŒ–"""
        context_prefix = """
        ä½œç‚ºä¸€å€‹å°ˆæ¥­çš„AIåŠ©æ‰‹ï¼Œè«‹ä»”ç´°åˆ†æä»¥ä¸‹ä»»å‹™ä¸¦æä¾›è©³ç´°çš„è§£æ±ºæ–¹æ¡ˆã€‚
        
        ä»»å‹™èƒŒæ™¯: é€™æ˜¯ä¸€å€‹éœ€è¦æ·±åº¦æ€è€ƒçš„å°ˆæ¥­ä»»å‹™
        æœŸæœ›è¼¸å‡º: å…¨é¢ã€æº–ç¢ºã€å¯¦ç”¨çš„è§£æ±ºæ–¹æ¡ˆ
        
        å…·é«”ä»»å‹™: 
        """
        
        return context_prefix + command
    
    async def _optimize_prompt_for_k2(self, command: str, provider: ModelProvider) -> str:
        """é‡å° K2 æ¨¡å‹å„ªåŒ–æç¤ºè©"""
        
        if provider == ModelProvider.K2_GROQ:
            # Groq åå¥½ç°¡æ½”æ˜ç¢ºçš„æŒ‡ä»¤
            prefix = "è«‹é€æ­¥åˆ†æä¸¦æä¾›è§£æ±ºæ–¹æ¡ˆ: "
        elif provider == ModelProvider.K2_MOONSHOT:
            # Moonshot å°ä¸­æ–‡ä»»å‹™è¡¨ç¾æ›´å¥½
            prefix = "è«‹è©³ç´°åˆ†æä»¥ä¸‹ä»»å‹™ï¼Œä¸¦çµ¦å‡ºå°ˆæ¥­å»ºè­°: "
        elif provider == ModelProvider.K2_QWEN:
            # Qwen å°ä»£ç¢¼ä»»å‹™è¡¨ç¾è¼ƒå¥½
            prefix = "è«‹ä½œç‚ºå°ˆæ¥­é–‹ç™¼è€…ï¼Œåˆ†æä¸¦è§£æ±ºä»¥ä¸‹å•é¡Œ: "
        else:
            prefix = "è«‹ä»”ç´°åˆ†æä¸¦å›ç­”: "
        
        return prefix + command
    
    async def _add_chain_of_thought(self, command: str) -> str:
        """æ·»åŠ æ€ç¶­éˆ"""
        cot_suffix = """
        
        è«‹æŒ‰ç…§ä»¥ä¸‹æ­¥é©Ÿæ€è€ƒ:
        1. ç†è§£å•é¡Œçš„æ ¸å¿ƒ
        2. åˆ†æå¯èƒ½çš„è§£æ±ºæ–¹æ¡ˆ
        3. è©•ä¼°æ¯å€‹æ–¹æ¡ˆçš„å„ªç¼ºé»
        4. é¸æ“‡æœ€ä½³æ–¹æ¡ˆä¸¦è©³ç´°èªªæ˜
        5. æä¾›å¯¦æ–½å»ºè­°
        """
        
        return command + cot_suffix
    
    async def _add_multi_step_reasoning(self, command: str) -> str:
        """æ·»åŠ å¤šæ­¥æ¨ç†"""
        reasoning_framework = """
        
        è«‹ä½¿ç”¨ç³»çµ±æ€§æ¨ç†æ–¹æ³•:
        - ç¬¬ä¸€æ­¥: å•é¡Œåˆ†è§£
        - ç¬¬äºŒæ­¥: ä¿¡æ¯æ”¶é›†
        - ç¬¬ä¸‰æ­¥: æ–¹æ¡ˆè¨­è¨ˆ
        - ç¬¬å››æ­¥: çµæœé©—è­‰
        
        æ¯ä¸€æ­¥éƒ½è¦è©³ç´°èªªæ˜æ¨ç†éç¨‹ã€‚
        """
        
        return command + reasoning_framework
    
    async def _add_error_prevention(self, command: str, analysis: Dict[str, Any]) -> str:
        """æ·»åŠ éŒ¯èª¤é é˜²"""
        error_prevention = """
        
        è«‹ç‰¹åˆ¥æ³¨æ„:
        - ç¢ºä¿å›ç­”çš„æº–ç¢ºæ€§
        - æª¢æŸ¥é‚è¼¯ä¸€è‡´æ€§
        - è€ƒæ…®é‚Šç•Œæƒ…æ³
        - æä¾›å…·é«”ç¤ºä¾‹
        """
        
        return command + error_prevention
    
    async def _optimize_prompt_structure(self, command: str) -> str:
        """å„ªåŒ–æç¤ºè©çµæ§‹"""
        return f"è«‹è©³ç´°åˆ†æä¸¦è§£ç­”: {command}"
    
    def _identify_quality_issues(self, k2_result: Dict[str, Any]) -> List[str]:
        """è­˜åˆ¥è³ªé‡å•é¡Œ"""
        issues = []
        quality_indicators = k2_result.get("quality_indicators", {})
        
        if quality_indicators.get("reasoning_depth", 0) < 0.8:
            issues.append("æ¨ç†æ·±åº¦ä¸è¶³")
        if quality_indicators.get("accuracy", 0) < 0.8:
            issues.append("æº–ç¢ºæ€§æœ‰å¾…æå‡")
        if quality_indicators.get("completeness", 0) < 0.8:
            issues.append("å›ç­”ä¸å¤ å®Œæ•´")
        if quality_indicators.get("creativity", 0) < 0.7:
            issues.append("å‰µæ–°æ€§ä¸è¶³")
        
        return issues if issues else ["æ•´é«”è³ªé‡éœ€è¦æå‡"]

class RoutingOptimizer:
    """è·¯ç”±å„ªåŒ–å™¨"""
    
    async def select_optimal_provider(self, analysis: Dict[str, Any], capabilities: Dict[ModelProvider, Dict[str, Any]]) -> ModelProvider:
        """é¸æ“‡æœ€ä½³æä¾›è€…"""
        
        complexity = analysis.get("complexity", CommandComplexity.SIMPLE)
        required_skills = analysis.get("required_skills", [])
        language_req = analysis.get("language_requirements", {})
        performance_req = analysis.get("performance_requirements", {})
        
        # è¨ˆç®—æ¯å€‹æä¾›è€…çš„é©é…åˆ†æ•¸
        scores = {}
        
        for provider, capability in capabilities.items():
            score = 0
            
            # åŸºç¤è³ªé‡åˆ†æ•¸
            score += capability["quality_score"] * 40
            
            # è¤‡é›œåº¦é©é…
            if complexity == CommandComplexity.SIMPLE:
                if provider != ModelProvider.CLAUDE:
                    score += 20  # K2 é©åˆç°¡å–®ä»»å‹™
            elif complexity == CommandComplexity.COMPLEX:
                if provider == ModelProvider.CLAUDE:
                    score += 30  # Claude é©åˆè¤‡é›œä»»å‹™
                else:
                    score -= 10  # K2 ä¸å¤ªé©åˆè¤‡é›œä»»å‹™
            
            # æŠ€èƒ½åŒ¹é…
            provider_strengths = capability["strength"]
            skill_match = sum(1 for skill in required_skills if any(s in skill for s in provider_strengths))
            score += skill_match * 5
            
            # èªè¨€éœ€æ±‚
            if language_req.get("requires_chinese_expertise", False):
                if provider in [ModelProvider.K2_MOONSHOT, ModelProvider.K2_QWEN]:
                    score += 15
            
            # æ€§èƒ½éœ€æ±‚
            if performance_req.get("urgency") == "high":
                if provider in [ModelProvider.K2_GROQ, ModelProvider.K2_QWEN]:
                    score += 10  # K2 æ›´å¿«
            
            # æˆæœ¬è€ƒæ…®
            if performance_req.get("cost_sensitivity") == "high":
                if provider != ModelProvider.CLAUDE:
                    score += 25  # K2 æ›´ä¾¿å®œ
            
            scores[provider] = score
        
        # é¸æ“‡åˆ†æ•¸æœ€é«˜çš„æä¾›è€…
        optimal_provider = max(scores, key=scores.get)
        
        logger.info(f"Provider selection scores: {scores}")
        logger.info(f"Selected optimal provider: {optimal_provider}")
        
        return optimal_provider

class QualityEvaluator:
    """è³ªé‡è©•ä¼°å™¨"""
    
    async def assess_result_quality(self, result: Dict[str, Any], analysis: Dict[str, Any]) -> Dict[str, Any]:
        """è©•ä¼°çµæœè³ªé‡"""
        
        quality_indicators = result.get("quality_indicators", {})
        
        # è¨ˆç®—ç¶œåˆè³ªé‡åˆ†æ•¸
        weights = {
            "reasoning_depth": 0.3,
            "accuracy": 0.35,
            "completeness": 0.25,
            "creativity": 0.1
        }
        
        quality_score = sum(
            quality_indicators.get(metric, 0) * weight
            for metric, weight in weights.items()
        )
        
        # æ ¹æ“šä»»å‹™è¤‡é›œåº¦èª¿æ•´æœŸæœ›
        complexity = analysis.get("complexity", CommandComplexity.SIMPLE)
        if complexity == CommandComplexity.COMPLEX:
            quality_threshold = 0.85
        elif complexity == CommandComplexity.MODERATE:
            quality_threshold = 0.75
        else:
            quality_threshold = 0.65
        
        meets_threshold = quality_score >= quality_threshold
        
        return {
            "quality_score": quality_score,
            "quality_threshold": quality_threshold,
            "meets_threshold": meets_threshold,
            "quality_breakdown": quality_indicators,
            "improvement_suggestions": self._generate_improvement_suggestions(quality_indicators, quality_threshold)
        }
    
    def _generate_improvement_suggestions(self, indicators: Dict[str, float], threshold: float) -> List[str]:
        """ç”Ÿæˆæ”¹é€²å»ºè­°"""
        suggestions = []
        
        for metric, score in indicators.items():
            if score < threshold:
                if metric == "reasoning_depth":
                    suggestions.append("éœ€è¦æ›´æ·±å…¥çš„æ¨ç†å’Œåˆ†æ")
                elif metric == "accuracy":
                    suggestions.append("éœ€è¦æé«˜å›ç­”çš„æº–ç¢ºæ€§")
                elif metric == "completeness":
                    suggestions.append("éœ€è¦æ›´å®Œæ•´çš„å›ç­”")
                elif metric == "creativity":
                    suggestions.append("éœ€è¦æ›´å¤šå‰µæ–°æ€§æ€è€ƒ")
        
        return suggestions

class ContextManager:
    """ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    
    def __init__(self):
        self.context_store = {}
    
    async def update_context(self, command: str, result: Dict[str, Any], context: Dict[str, Any] = None) -> None:
        """æ›´æ–°ä¸Šä¸‹æ–‡"""
        
        session_id = context.get("session_id", "default") if context else "default"
        
        if session_id not in self.context_store:
            self.context_store[session_id] = {
                "command_history": [],
                "quality_history": [],
                "preferences": {}
            }
        
        self.context_store[session_id]["command_history"].append({
            "command": command,
            "result": result,
            "timestamp": time.time()
        })
        
        # ä¿æŒæœ€è¿‘ 10 æ¢è¨˜éŒ„
        if len(self.context_store[session_id]["command_history"]) > 10:
            self.context_store[session_id]["command_history"] = \
                self.context_store[session_id]["command_history"][-10:]

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    """ä¸»å‡½æ•¸ç¤ºä¾‹"""
    router = EnhancedClaudeRouterMCP()
    
    # æ¸¬è©¦ä¸åŒé¡å‹çš„å‘½ä»¤
    test_commands = [
        "list all files in current directory",  # ç°¡å–®å‘½ä»¤
        "create a user management system with authentication",  # ä¸­ç­‰è¤‡é›œåº¦
        "è¨­è¨ˆä¸€å€‹é«˜æ€§èƒ½çš„åˆ†ä½ˆå¼å¾®æœå‹™æ¶æ§‹ï¼ŒåŒ…å«è² è¼‰å‡è¡¡ã€æœå‹™ç™¼ç¾ã€å®¹éŒ¯æ©Ÿåˆ¶",  # è¤‡é›œå‘½ä»¤
        "debug this performance issue and optimize the algorithm"  # éœ€è¦æ·±åº¦åˆ†æ
    ]
    
    for i, command in enumerate(test_commands):
        print(f"\n{'='*50}")
        print(f"æ¸¬è©¦å‘½ä»¤ {i+1}: {command}")
        print(f"{'='*50}")
        
        result = await router.route_claude_code_command(command)
        
        print(f"é¸æ“‡çš„æä¾›è€…: {result['selected_provider']}")
        print(f"æ˜¯å¦æ‡‰ç”¨å¢å¼·: {result['enhancement_applied']}")
        print(f"è³ªé‡è©•åˆ†: {result['quality_assessment']['quality_score']:.2f}")
        print(f"æˆæœ¬ç¯€çœ: {result['cost_optimization']['savings_percentage']:.1f}%")
        print(f"è™•ç†æ™‚é–“: {result['processing_time']:.2f}s")
        
        if result.get('fallback_used'):
            print(f"âš ï¸ ä½¿ç”¨äº†å›é€€æ©Ÿåˆ¶: {result['original_provider']} â†’ {result['fallback_provider']}")

if __name__ == "__main__":
    asyncio.run(main())