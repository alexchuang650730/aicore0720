#!/usr/bin/env python3
"""
PowerAutomation RAG + å·¥å…·èª¿ç”¨èƒ½åŠ›å„ªåŒ–ç³»çµ±
é‡é»æå‡K2æ¨¡å‹çš„RAGæª¢ç´¢å’Œå·¥å…·äº¤äº’èƒ½åŠ›ï¼Œé”åˆ°Claudeæ°´æº–
"""

import asyncio
import json
import logging
import time
import uuid
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass, asdict
import numpy as np
from sentence_transformers import SentenceTransformer
import faiss
import sqlite3
from datetime import datetime
import inspect

logger = logging.getLogger(__name__)

@dataclass
class ToolFunction:
    """å·¥å…·å‡½æ•¸å®šç¾©"""
    name: str
    description: str
    parameters: Dict[str, Any]
    function: Callable
    examples: List[str]
    category: str

@dataclass
class RAGDocument:
    """RAGæ–‡æª”çµæ§‹"""
    doc_id: str
    content: str
    metadata: Dict[str, Any]
    embedding: Optional[np.ndarray] = None
    relevance_score: float = 0.0

class EnhancedRAGSystem:
    """å¢å¼·çš„RAGç³»çµ± - é‡å°é–‹ç™¼è€…å ´æ™¯å„ªåŒ–"""
    
    def __init__(self, embedding_model_name: str = "all-MiniLM-L6-v2"):
        self.embedding_model = SentenceTransformer(embedding_model_name)
        self.vector_store = None
        self.document_store = {}
        self.query_cache = {}
        
        # å°ˆæ¥­çŸ¥è­˜åº«
        self.knowledge_bases = {
            "code_patterns": CodePatternKB(),
            "frameworks": FrameworkKB(), 
            "best_practices": BestPracticeKB(),
            "troubleshooting": TroubleshootingKB()
        }
        
        logger.info("ğŸ§  å¢å¼·RAGç³»çµ±åˆå§‹åŒ–å®Œæˆ")
    
    async def initialize_vector_store(self, documents: List[RAGDocument]):
        """åˆå§‹åŒ–å‘é‡å­˜å„²"""
        try:
            # ç”Ÿæˆæ–‡æª”åµŒå…¥
            texts = [doc.content for doc in documents]
            embeddings = self.embedding_model.encode(texts)
            
            # å‰µå»ºFAISSç´¢å¼•
            dimension = embeddings.shape[1]
            self.vector_store = faiss.IndexFlatIP(dimension)  # å…§ç©æœç´¢
            self.vector_store.add(embeddings.astype('float32'))
            
            # å­˜å„²æ–‡æª”æ˜ å°„
            for i, doc in enumerate(documents):
                doc.embedding = embeddings[i]
                self.document_store[i] = doc
            
            logger.info(f"âœ… å‘é‡å­˜å„²åˆå§‹åŒ–å®Œæˆ: {len(documents)}å€‹æ–‡æª”")
            
        except Exception as e:
            logger.error(f"âŒ å‘é‡å­˜å„²åˆå§‹åŒ–å¤±æ•—: {e}")
            raise
    
    async def smart_retrieval(self, query: str, context: Dict[str, Any], top_k: int = 10) -> List[RAGDocument]:
        """æ™ºèƒ½æª¢ç´¢ - çµåˆä¸Šä¸‹æ–‡çš„å¤šå±¤æ¬¡æª¢ç´¢"""
        try:
            # æŸ¥è©¢åˆ†æå’Œé‡å¯«
            enhanced_query = await self._enhance_query(query, context)
            
            # å¤šå±¤æ¬¡æª¢ç´¢ç­–ç•¥
            retrieval_results = []
            
            # 1. èªç¾©æª¢ç´¢
            semantic_docs = await self._semantic_search(enhanced_query, top_k // 2)
            retrieval_results.extend(semantic_docs)
            
            # 2. é—œéµè©æª¢ç´¢  
            keyword_docs = await self._keyword_search(query, top_k // 4)
            retrieval_results.extend(keyword_docs)
            
            # 3. ä¸Šä¸‹æ–‡ç›¸é—œæª¢ç´¢
            context_docs = await self._context_aware_search(query, context, top_k // 4)
            retrieval_results.extend(context_docs)
            
            # å»é‡å’Œé‡æ’åº
            unique_docs = self._deduplicate_and_rerank(retrieval_results, query, context)
            
            return unique_docs[:top_k]
            
        except Exception as e:
            logger.error(f"âŒ æ™ºèƒ½æª¢ç´¢å¤±æ•—: {e}")
            return []
    
    async def _enhance_query(self, query: str, context: Dict[str, Any]) -> str:
        """æŸ¥è©¢å¢å¼· - åŸºæ–¼ä¸Šä¸‹æ–‡è±å¯ŒæŸ¥è©¢"""
        enhanced_parts = [query]
        
        # æ·»åŠ æŠ€è¡“æ£§ä¸Šä¸‹æ–‡
        if "tech_stack" in context:
            tech_context = " ".join(context["tech_stack"])
            enhanced_parts.append(f"ä½¿ç”¨æŠ€è¡“æ£§: {tech_context}")
        
        # æ·»åŠ é …ç›®ä¸Šä¸‹æ–‡
        if "project_type" in context:
            enhanced_parts.append(f"é …ç›®é¡å‹: {context['project_type']}")
        
        # æ·»åŠ ç”¨æˆ¶è§’è‰²ä¸Šä¸‹æ–‡
        if "user_role" in context:
            enhanced_parts.append(f"ç”¨æˆ¶è§’è‰²: {context['user_role']}")
        
        return " ".join(enhanced_parts)
    
    async def _semantic_search(self, query: str, k: int) -> List[RAGDocument]:
        """èªç¾©æœç´¢"""
        if not self.vector_store:
            return []
        
        # æŸ¥è©¢å‘é‡åŒ–
        query_embedding = self.embedding_model.encode([query])
        
        # FAISSæœç´¢
        scores, indices = self.vector_store.search(query_embedding.astype('float32'), k)
        
        # æ§‹å»ºçµæœ
        results = []
        for i, (score, idx) in enumerate(zip(scores[0], indices[0])):
            if idx in self.document_store:
                doc = self.document_store[idx]
                doc.relevance_score = float(score)
                results.append(doc)
        
        return results
    
    async def _keyword_search(self, query: str, k: int) -> List[RAGDocument]:
        """é—œéµè©æœç´¢"""
        # ç°¡åŒ–çš„é—œéµè©åŒ¹é…
        query_terms = set(query.lower().split())
        scored_docs = []
        
        for doc in self.document_store.values():
            doc_terms = set(doc.content.lower().split())
            overlap = len(query_terms.intersection(doc_terms))
            
            if overlap > 0:
                score = overlap / len(query_terms)
                doc_copy = RAGDocument(
                    doc_id=doc.doc_id,
                    content=doc.content,
                    metadata=doc.metadata,
                    relevance_score=score
                )
                scored_docs.append(doc_copy)
        
        # æŒ‰åˆ†æ•¸æ’åº
        scored_docs.sort(key=lambda x: x.relevance_score, reverse=True)
        return scored_docs[:k]
    
    async def _context_aware_search(self, query: str, context: Dict[str, Any], k: int) -> List[RAGDocument]:
        """ä¸Šä¸‹æ–‡æ„ŸçŸ¥æœç´¢"""
        # åŸºæ–¼ä¸Šä¸‹æ–‡çš„å°ˆæ¥­çŸ¥è­˜åº«æœç´¢
        context_docs = []
        
        # æ ¹æ“šæŸ¥è©¢é¡å‹é¸æ“‡åˆé©çš„çŸ¥è­˜åº«
        if "code" in query.lower() or "function" in query.lower():
            kb_docs = await self.knowledge_bases["code_patterns"].search(query, k//2)
            context_docs.extend(kb_docs)
        
        if any(fw in query.lower() for fw in ["react", "vue", "angular", "fastapi", "django"]):
            kb_docs = await self.knowledge_bases["frameworks"].search(query, k//2)
            context_docs.extend(kb_docs)
        
        return context_docs
    
    def _deduplicate_and_rerank(self, docs: List[RAGDocument], query: str, context: Dict[str, Any]) -> List[RAGDocument]:
        """å»é‡å’Œé‡æ’åº"""
        # åŸºæ–¼doc_idå»é‡
        seen_ids = set()
        unique_docs = []
        
        for doc in docs:
            if doc.doc_id not in seen_ids:
                seen_ids.add(doc.doc_id)
                unique_docs.append(doc)
        
        # é‡æ’åº - ç¶œåˆç›¸é—œæ€§å’Œä¸Šä¸‹æ–‡åŒ¹é…åº¦
        for doc in unique_docs:
            context_bonus = self._calculate_context_bonus(doc, context)
            doc.relevance_score += context_bonus
        
        # æŒ‰æœ€çµ‚åˆ†æ•¸æ’åº
        unique_docs.sort(key=lambda x: x.relevance_score, reverse=True)
        return unique_docs
    
    def _calculate_context_bonus(self, doc: RAGDocument, context: Dict[str, Any]) -> float:
        """è¨ˆç®—ä¸Šä¸‹æ–‡çå‹µåˆ†æ•¸"""
        bonus = 0.0
        
        # æŠ€è¡“æ£§åŒ¹é…çå‹µ
        if "tech_stack" in context:
            for tech in context["tech_stack"]:
                if tech.lower() in doc.content.lower():
                    bonus += 0.1
        
        # é …ç›®é¡å‹åŒ¹é…çå‹µ
        if "project_type" in context and context["project_type"].lower() in doc.content.lower():
            bonus += 0.2
        
        # æ–‡æª”æ–°é®®åº¦çå‹µ
        if "last_updated" in doc.metadata:
            days_old = (datetime.now() - datetime.fromisoformat(doc.metadata["last_updated"])).days
            freshness_bonus = max(0, 0.1 - days_old * 0.001)  # è¶Šæ–°çå‹µè¶Šé«˜
            bonus += freshness_bonus
        
        return bonus

class AdvancedToolCallSystem:
    """é«˜ç´šå·¥å…·èª¿ç”¨ç³»çµ± - æ™ºèƒ½å·¥å…·é¸æ“‡å’Œçµ„åˆ"""
    
    def __init__(self):
        self.tools = {}
        self.tool_categories = {}
        self.execution_history = []
        self.tool_performance_stats = {}
        
        # è¨»å†ŠåŸºç¤å·¥å…·
        self._register_default_tools()
        
        logger.info("ğŸ”§ é«˜ç´šå·¥å…·èª¿ç”¨ç³»çµ±åˆå§‹åŒ–å®Œæˆ")
    
    def _register_default_tools(self):
        """è¨»å†Šé»˜èªå·¥å…·é›†"""
        
        # ä»£ç¢¼åŸ·è¡Œå·¥å…·
        self.register_tool(ToolFunction(
            name="execute_python",
            description="åŸ·è¡ŒPythonä»£ç¢¼ä¸¦è¿”å›çµæœ",
            parameters={
                "code": {"type": "string", "description": "è¦åŸ·è¡Œçš„Pythonä»£ç¢¼"},
                "timeout": {"type": "integer", "description": "åŸ·è¡Œè¶…æ™‚æ™‚é–“(ç§’)", "default": 30}
            },
            function=self._execute_python_code,
            examples=[
                "è¨ˆç®—æ–æ³¢é‚£å¥‘æ•¸åˆ—",
                "æ•¸æ“šåˆ†æå’Œå¯è¦–åŒ–",
                "APIæ¸¬è©¦è…³æœ¬"
            ],
            category="code_execution"
        ))
        
        # æ–‡ä»¶æ“ä½œå·¥å…·
        self.register_tool(ToolFunction(
            name="read_file",
            description="è®€å–æ–‡ä»¶å…§å®¹",
            parameters={
                "file_path": {"type": "string", "description": "æ–‡ä»¶è·¯å¾‘"},
                "encoding": {"type": "string", "description": "æ–‡ä»¶ç·¨ç¢¼", "default": "utf-8"}
            },
            function=self._read_file,
            examples=[
                "è®€å–é…ç½®æ–‡ä»¶",
                "åˆ†ææ—¥èªŒæ–‡ä»¶",
                "æª¢æŸ¥ä»£ç¢¼æ–‡ä»¶"
            ],
            category="file_operations"
        ))
        
        # Webè«‹æ±‚å·¥å…·
        self.register_tool(ToolFunction(
            name="web_request",
            description="ç™¼é€HTTPè«‹æ±‚",
            parameters={
                "url": {"type": "string", "description": "è«‹æ±‚URL"},
                "method": {"type": "string", "description": "HTTPæ–¹æ³•", "default": "GET"},
                "headers": {"type": "object", "description": "è«‹æ±‚é ­", "default": {}},
                "data": {"type": "object", "description": "è«‹æ±‚æ•¸æ“š", "default": {}}
            },
            function=self._web_request,
            examples=[
                "APIæ¥å£æ¸¬è©¦",
                "ç²å–ç¶²é å…§å®¹",
                "èª¿ç”¨ç¬¬ä¸‰æ–¹æœå‹™"
            ],
            category="web_requests"
        ))
        
        # æ•¸æ“šåº«æŸ¥è©¢å·¥å…·
        self.register_tool(ToolFunction(
            name="database_query",
            description="åŸ·è¡Œæ•¸æ“šåº«æŸ¥è©¢",
            parameters={
                "query": {"type": "string", "description": "SQLæŸ¥è©¢èªå¥"},
                "connection_string": {"type": "string", "description": "æ•¸æ“šåº«é€£æ¥å­—ç¬¦ä¸²"}
            },
            function=self._database_query,
            examples=[
                "æŸ¥è©¢ç”¨æˆ¶æ•¸æ“š",
                "åˆ†ææ¥­å‹™æŒ‡æ¨™",
                "æ•¸æ“šåº«æ€§èƒ½æª¢æŸ¥"
            ],
            category="database"
        ))
    
    def register_tool(self, tool: ToolFunction):
        """è¨»å†Šæ–°å·¥å…·"""
        self.tools[tool.name] = tool
        
        if tool.category not in self.tool_categories:
            self.tool_categories[tool.category] = []
        self.tool_categories[tool.category].append(tool.name)
        
        # åˆå§‹åŒ–æ€§èƒ½çµ±è¨ˆ
        self.tool_performance_stats[tool.name] = {
            "total_calls": 0,
            "success_rate": 1.0,
            "avg_execution_time": 0.0,
            "user_satisfaction": 0.0
        }
        
        logger.info(f"ğŸ”§ å·¥å…·å·²è¨»å†Š: {tool.name}")
    
    async def intelligent_tool_selection(self, query: str, context: Dict[str, Any]) -> List[str]:
        """æ™ºèƒ½å·¥å…·é¸æ“‡"""
        try:
            # åˆ†ææŸ¥è©¢æ„åœ–
            intent = await self._analyze_query_intent(query)
            
            # åŸºæ–¼æ„åœ–é¸æ“‡å·¥å…·é¡åˆ¥
            relevant_categories = self._map_intent_to_categories(intent)
            
            # å¾ç›¸é—œé¡åˆ¥ä¸­é¸æ“‡æœ€ä½³å·¥å…·
            selected_tools = []
            for category in relevant_categories:
                if category in self.tool_categories:
                    # æ ¹æ“šæ€§èƒ½çµ±è¨ˆé¸æ“‡æœ€ä½³å·¥å…·
                    best_tool = self._select_best_tool_in_category(category, context)
                    if best_tool:
                        selected_tools.append(best_tool)
            
            # å·¥å…·çµ„åˆå„ªåŒ–
            optimized_tools = self._optimize_tool_combination(selected_tools, query)
            
            return optimized_tools
            
        except Exception as e:
            logger.error(f"âŒ æ™ºèƒ½å·¥å…·é¸æ“‡å¤±æ•—: {e}")
            return []
    
    async def _analyze_query_intent(self, query: str) -> Dict[str, float]:
        """åˆ†ææŸ¥è©¢æ„åœ–"""
        intent_keywords = {
            "code_execution": ["åŸ·è¡Œ", "é‹è¡Œ", "æ¸¬è©¦", "è¨ˆç®—", "è™•ç†"],
            "file_operations": ["è®€å–", "å¯«å…¥", "æ–‡ä»¶", "ä¿å­˜", "åŠ è¼‰"],
            "web_requests": ["è«‹æ±‚", "API", "ä¸‹è¼‰", "çˆ¬å–", "èª¿ç”¨"],
            "database": ["æŸ¥è©¢", "æ•¸æ“šåº«", "SQL", "æ•¸æ“š", "è¡¨"],
            "analysis": ["åˆ†æ", "çµ±è¨ˆ", "å ±å‘Š", "åœ–è¡¨", "å¯è¦–åŒ–"]
        }
        
        intent_scores = {}
        query_lower = query.lower()
        
        for intent, keywords in intent_keywords.items():
            score = sum(1 for keyword in keywords if keyword in query_lower)
            intent_scores[intent] = score / len(keywords)
        
        return intent_scores
    
    def _map_intent_to_categories(self, intent_scores: Dict[str, float]) -> List[str]:
        """å°‡æ„åœ–æ˜ å°„åˆ°å·¥å…·é¡åˆ¥"""
        # é¸æ“‡åˆ†æ•¸æœ€é«˜çš„æ„åœ–
        sorted_intents = sorted(intent_scores.items(), key=lambda x: x[1], reverse=True)
        
        relevant_categories = []
        for intent, score in sorted_intents:
            if score > 0:
                relevant_categories.append(intent)
        
        return relevant_categories
    
    def _select_best_tool_in_category(self, category: str, context: Dict[str, Any]) -> Optional[str]:
        """åœ¨é¡åˆ¥ä¸­é¸æ“‡æœ€ä½³å·¥å…·"""
        if category not in self.tool_categories:
            return None
        
        category_tools = self.tool_categories[category]
        
        # åŸºæ–¼æ€§èƒ½çµ±è¨ˆé¸æ“‡
        best_tool = None
        best_score = 0
        
        for tool_name in category_tools:
            stats = self.tool_performance_stats[tool_name]
            # ç¶œåˆæˆåŠŸç‡ã€åŸ·è¡Œæ™‚é–“å’Œç”¨æˆ¶æ»¿æ„åº¦
            score = (stats["success_rate"] * 0.4 + 
                    (1 / max(stats["avg_execution_time"], 0.1)) * 0.3 + 
                    stats["user_satisfaction"] * 0.3)
            
            if score > best_score:
                best_score = score
                best_tool = tool_name
        
        return best_tool
    
    def _optimize_tool_combination(self, tools: List[str], query: str) -> List[str]:
        """å„ªåŒ–å·¥å…·çµ„åˆ"""
        # ç°¡åŒ–ç‰ˆæœ¬ï¼šå»é‡ä¸¦æŒ‰å„ªå…ˆç´šæ’åº
        unique_tools = list(dict.fromkeys(tools))  # ä¿æŒé †åºçš„å»é‡
        
        # æ ¹æ“šæŸ¥è©¢è¤‡é›œåº¦é™åˆ¶å·¥å…·æ•¸é‡
        max_tools = 3 if len(query) > 100 else 2
        
        return unique_tools[:max_tools]
    
    async def execute_tool_chain(self, tools: List[str], query: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """åŸ·è¡Œå·¥å…·éˆ"""
        results = {}
        execution_context = context.copy()
        
        for tool_name in tools:
            if tool_name not in self.tools:
                continue
            
            try:
                start_time = time.time()
                
                # æ™ºèƒ½åƒæ•¸æå–
                parameters = await self._extract_tool_parameters(tool_name, query, execution_context)
                
                # åŸ·è¡Œå·¥å…·
                tool = self.tools[tool_name]
                result = await tool.function(**parameters)
                
                # è¨˜éŒ„åŸ·è¡Œæ™‚é–“
                execution_time = time.time() - start_time
                
                # æ›´æ–°æ€§èƒ½çµ±è¨ˆ
                self._update_tool_performance(tool_name, True, execution_time)
                
                # å°‡çµæœæ·»åŠ åˆ°ä¸Šä¸‹æ–‡
                results[tool_name] = result
                execution_context[f"{tool_name}_result"] = result
                
                logger.info(f"âœ… å·¥å…·åŸ·è¡ŒæˆåŠŸ: {tool_name}")
                
            except Exception as e:
                logger.error(f"âŒ å·¥å…·åŸ·è¡Œå¤±æ•—: {tool_name} - {e}")
                self._update_tool_performance(tool_name, False, 0)
                results[tool_name] = {"error": str(e)}
        
        return results
    
    async def _extract_tool_parameters(self, tool_name: str, query: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ™ºèƒ½æå–å·¥å…·åƒæ•¸"""
        tool = self.tools[tool_name]
        parameters = {}
        
        # ç°¡åŒ–çš„åƒæ•¸æå–é‚è¼¯
        for param_name, param_info in tool.parameters.items():
            if param_name in context:
                parameters[param_name] = context[param_name]
            elif "default" in param_info:
                parameters[param_name] = param_info["default"]
            else:
                # å¾æŸ¥è©¢ä¸­æå–åƒæ•¸ï¼ˆç°¡åŒ–ç‰ˆï¼‰
                extracted_value = self._extract_from_query(param_name, query, param_info)
                if extracted_value is not None:
                    parameters[param_name] = extracted_value
        
        return parameters
    
    def _extract_from_query(self, param_name: str, query: str, param_info: Dict[str, Any]) -> Any:
        """å¾æŸ¥è©¢ä¸­æå–åƒæ•¸å€¼"""
        # é€™è£¡æ‡‰è©²æœ‰æ›´è¤‡é›œçš„NLPé‚è¼¯ï¼Œç¾åœ¨ç”¨ç°¡åŒ–ç‰ˆæœ¬
        if param_name == "code" and "```python" in query:
            # æå–ä»£ç¢¼å¡Š
            start = query.find("```python") + 9
            end = query.find("```", start)
            if end > start:
                return query[start:end].strip()
        
        return None
    
    def _update_tool_performance(self, tool_name: str, success: bool, execution_time: float):
        """æ›´æ–°å·¥å…·æ€§èƒ½çµ±è¨ˆ"""
        stats = self.tool_performance_stats[tool_name]
        
        stats["total_calls"] += 1
        
        # æ›´æ–°æˆåŠŸç‡
        old_success_rate = stats["success_rate"]
        new_success_rate = (old_success_rate * (stats["total_calls"] - 1) + (1 if success else 0)) / stats["total_calls"]
        stats["success_rate"] = new_success_rate
        
        # æ›´æ–°å¹³å‡åŸ·è¡Œæ™‚é–“
        if success and execution_time > 0:
            old_avg_time = stats["avg_execution_time"]
            successful_calls = stats["total_calls"] * old_success_rate
            new_avg_time = (old_avg_time * (successful_calls - 1) + execution_time) / successful_calls
            stats["avg_execution_time"] = new_avg_time
    
    # å·¥å…·å¯¦ç¾æ–¹æ³•
    async def _execute_python_code(self, code: str, timeout: int = 30) -> Dict[str, Any]:
        """åŸ·è¡ŒPythonä»£ç¢¼"""
        # å®‰å…¨çš„ä»£ç¢¼åŸ·è¡Œç’°å¢ƒ
        try:
            # é€™è£¡æ‡‰è©²ä½¿ç”¨æ²™ç›’ç’°å¢ƒ
            # ç¾åœ¨ç”¨ç°¡åŒ–çš„execå¯¦ç¾
            local_vars = {}
            exec(code, {"__builtins__": {}}, local_vars)
            return {"success": True, "result": local_vars}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def _read_file(self, file_path: str, encoding: str = "utf-8") -> Dict[str, Any]:
        """è®€å–æ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding=encoding) as f:
                content = f.read()
            return {"success": True, "content": content}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def _web_request(self, url: str, method: str = "GET", headers: Dict = None, data: Dict = None) -> Dict[str, Any]:
        """ç™¼é€Webè«‹æ±‚"""
        import aiohttp
        try:
            async with aiohttp.ClientSession() as session:
                async with session.request(method, url, headers=headers, json=data) as response:
                    result_data = await response.text()
                    return {
                        "success": True,
                        "status": response.status,
                        "data": result_data
                    }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def _database_query(self, query: str, connection_string: str) -> Dict[str, Any]:
        """åŸ·è¡Œæ•¸æ“šåº«æŸ¥è©¢"""
        try:
            # é€™è£¡æ‡‰è©²æ ¹æ“šconnection_stringé¡å‹é¸æ“‡ä¸åŒçš„æ•¸æ“šåº«é©…å‹•
            # ç¾åœ¨ç”¨SQLiteä½œç‚ºç¤ºä¾‹
            import sqlite3
            conn = sqlite3.connect(connection_string)
            cursor = conn.cursor()
            cursor.execute(query)
            results = cursor.fetchall()
            conn.close()
            return {"success": True, "results": results}
        except Exception as e:
            return {"success": False, "error": str(e)}

# çŸ¥è­˜åº«é¡å®šç¾©
class CodePatternKB:
    """ä»£ç¢¼æ¨¡å¼çŸ¥è­˜åº«"""
    async def search(self, query: str, k: int) -> List[RAGDocument]:
        # æ¨¡æ“¬ä»£ç¢¼æ¨¡å¼æœç´¢
        return []

class FrameworkKB:
    """æ¡†æ¶çŸ¥è­˜åº«"""
    async def search(self, query: str, k: int) -> List[RAGDocument]:
        # æ¨¡æ“¬æ¡†æ¶çŸ¥è­˜æœç´¢
        return []

class BestPracticeKB:
    """æœ€ä½³å¯¦è¸çŸ¥è­˜åº«"""
    async def search(self, query: str, k: int) -> List[RAGDocument]:
        # æ¨¡æ“¬æœ€ä½³å¯¦è¸æœç´¢
        return []

class TroubleshootingKB:
    """æ•…éšœæ’é™¤çŸ¥è­˜åº«"""
    async def search(self, query: str, k: int) -> List[RAGDocument]:
        # æ¨¡æ“¬æ•…éšœæ’é™¤æœç´¢
        return []

# ä¸»è¦é›†æˆé¡
class PowerAutomationRAGToolSystem:
    """PowerAutomation RAG + å·¥å…·èª¿ç”¨é›†æˆç³»çµ±"""
    
    def __init__(self):
        self.rag_system = EnhancedRAGSystem()
        self.tool_system = AdvancedToolCallSystem()
        self.integration_stats = {
            "total_queries": 0,
            "rag_enhanced_queries": 0,
            "tool_assisted_queries": 0,
            "avg_response_quality": 0.0
        }
        
        logger.info("ğŸš€ PowerAutomation RAG+å·¥å…·èª¿ç”¨ç³»çµ±åˆå§‹åŒ–å®Œæˆ")
    
    async def process_enhanced_query(self, query: str, context: Dict[str, Any], k2_model_client) -> Dict[str, Any]:
        """è™•ç†å¢å¼·æŸ¥è©¢ - RAG + å·¥å…·èª¿ç”¨ + K2æ¨¡å‹"""
        try:
            start_time = time.time()
            
            # 1. RAGæª¢ç´¢å¢å¼·
            rag_documents = await self.rag_system.smart_retrieval(query, context, top_k=10)
            rag_context = self._build_rag_context(rag_documents)
            
            # 2. æ™ºèƒ½å·¥å…·é¸æ“‡
            relevant_tools = await self.tool_system.intelligent_tool_selection(query, context)
            
            # 3. æ§‹å»ºå¢å¼·çš„æç¤º
            enhanced_prompt = self._build_enhanced_prompt(query, rag_context, relevant_tools, context)
            
            # 4. K2æ¨¡å‹èª¿ç”¨
            k2_response = await k2_model_client.chat_completion(enhanced_prompt)
            
            # 5. å·¥å…·åŸ·è¡Œï¼ˆå¦‚æœéœ€è¦ï¼‰
            tool_results = {}
            if relevant_tools and self._should_execute_tools(k2_response):
                tool_results = await self.tool_system.execute_tool_chain(relevant_tools, query, context)
            
            # 6. çµæœæ•´åˆ
            final_response = self._integrate_results(k2_response, tool_results, rag_documents)
            
            # 7. æ›´æ–°çµ±è¨ˆ
            processing_time = time.time() - start_time
            await self._update_system_stats(query, rag_documents, tool_results, processing_time)
            
            return {
                "success": True,
                "response": final_response,
                "rag_sources": len(rag_documents),
                "tools_used": list(tool_results.keys()),
                "processing_time": processing_time
            }
            
        except Exception as e:
            logger.error(f"âŒ å¢å¼·æŸ¥è©¢è™•ç†å¤±æ•—: {e}")
            return {
                "success": False,
                "error": str(e),
                "response": "æŠ±æ­‰ï¼Œè™•ç†æ‚¨çš„è«‹æ±‚æ™‚å‡ºç¾éŒ¯èª¤ã€‚"
            }
    
    def _build_rag_context(self, documents: List[RAGDocument]) -> str:
        """æ§‹å»ºRAGä¸Šä¸‹æ–‡"""
        if not documents:
            return ""
        
        context_parts = ["# ç›¸é—œçŸ¥è­˜å’Œåƒè€ƒè³‡æ–™\n"]
        
        for i, doc in enumerate(documents[:5]):  # åªä½¿ç”¨å‰5å€‹æœ€ç›¸é—œçš„æ–‡æª”
            context_parts.append(f"## åƒè€ƒè³‡æ–™ {i+1} (ç›¸é—œåº¦: {doc.relevance_score:.2f})")
            context_parts.append(doc.content[:500] + "..." if len(doc.content) > 500 else doc.content)
            context_parts.append("")
        
        return "\n".join(context_parts)
    
    def _build_enhanced_prompt(self, query: str, rag_context: str, tools: List[str], context: Dict[str, Any]) -> str:
        """æ§‹å»ºå¢å¼·æç¤º"""
        prompt_parts = []
        
        # ç³»çµ±æç¤º
        prompt_parts.append("""ä½ æ˜¯PowerAutomationçš„é«˜ç´šAIåŠ©æ‰‹ï¼Œå°ˆé–€å¹«åŠ©é–‹ç™¼è€…è§£æ±ºç·¨ç¨‹å’Œé–‹ç™¼å•é¡Œã€‚

ä½ çš„èƒ½åŠ›åŒ…æ‹¬ï¼š
1. åŸºæ–¼è±å¯Œçš„çŸ¥è­˜åº«æä¾›æº–ç¢ºçš„æŠ€è¡“å»ºè­°
2. èª¿ç”¨å„ç¨®å·¥å…·ä¾†åŸ·è¡Œå¯¦éš›æ“ä½œ
3. ç”Ÿæˆé«˜è³ªé‡çš„ä»£ç¢¼å’Œè§£æ±ºæ–¹æ¡ˆ
4. æä¾›è©³ç´°çš„è§£é‡‹å’Œæœ€ä½³å¯¦è¸

è«‹æ ¹æ“šæä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯å’Œå¯ç”¨å·¥å…·ï¼Œçµ¦å‡ºå®Œæ•´ã€æº–ç¢ºã€å¯¦ç”¨çš„å›ç­”ã€‚""")
        
        # RAGä¸Šä¸‹æ–‡
        if rag_context:
            prompt_parts.append(f"\n{rag_context}")
        
        # å¯ç”¨å·¥å…·ä¿¡æ¯
        if tools:
            tool_info = []
            for tool_name in tools:
                if tool_name in self.tool_system.tools:
                    tool = self.tool_system.tools[tool_name]
                    tool_info.append(f"- {tool_name}: {tool.description}")
            
            if tool_info:
                prompt_parts.append(f"\n# å¯ç”¨å·¥å…·\n" + "\n".join(tool_info))
        
        # ç”¨æˆ¶æŸ¥è©¢
        prompt_parts.append(f"\n# ç”¨æˆ¶å•é¡Œ\n{query}")
        
        # ä¸Šä¸‹æ–‡ä¿¡æ¯
        if context:
            context_info = []
            for key, value in context.items():
                if key not in ["tech_stack", "project_type", "user_role"]:
                    continue
                context_info.append(f"- {key}: {value}")
            
            if context_info:
                prompt_parts.append(f"\n# ä¸Šä¸‹æ–‡ä¿¡æ¯\n" + "\n".join(context_info))
        
        return "\n".join(prompt_parts)
    
    def _should_execute_tools(self, k2_response: str) -> bool:
        """åˆ¤æ–·æ˜¯å¦éœ€è¦åŸ·è¡Œå·¥å…·"""
        # ç°¡åŒ–çš„åˆ¤æ–·é‚è¼¯
        tool_indicators = ["åŸ·è¡Œ", "é‹è¡Œ", "æ¸¬è©¦", "æŸ¥è©¢", "æª¢æŸ¥", "èª¿ç”¨"]
        response_lower = k2_response.lower()
        
        return any(indicator in response_lower for indicator in tool_indicators)
    
    def _integrate_results(self, k2_response: str, tool_results: Dict[str, Any], rag_docs: List[RAGDocument]) -> str:
        """æ•´åˆçµæœ"""
        result_parts = [k2_response]
        
        # æ·»åŠ å·¥å…·åŸ·è¡Œçµæœ
        if tool_results:
            result_parts.append("\n## åŸ·è¡Œçµæœ")
            for tool_name, result in tool_results.items():
                if result.get("success"):
                    result_parts.append(f"### {tool_name}")
                    result_parts.append(f"```\n{json.dumps(result, indent=2, ensure_ascii=False)}\n```")
                else:
                    result_parts.append(f"### {tool_name} (åŸ·è¡Œå¤±æ•—)")
                    result_parts.append(f"éŒ¯èª¤: {result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
        
        # æ·»åŠ åƒè€ƒè³‡æ–™
        if rag_docs:
            result_parts.append(f"\n## åƒè€ƒè³‡æ–™ä¾†æº")
            for i, doc in enumerate(rag_docs[:3]):
                result_parts.append(f"{i+1}. {doc.metadata.get('title', 'ç›¸é—œæ–‡æª”')} (ç›¸é—œåº¦: {doc.relevance_score:.2f})")
        
        return "\n".join(result_parts)
    
    async def _update_system_stats(self, query: str, rag_docs: List[RAGDocument], tool_results: Dict[str, Any], processing_time: float):
        """æ›´æ–°ç³»çµ±çµ±è¨ˆ"""
        self.integration_stats["total_queries"] += 1
        
        if rag_docs:
            self.integration_stats["rag_enhanced_queries"] += 1
        
        if tool_results:
            self.integration_stats["tool_assisted_queries"] += 1
        
        # é€™è£¡å¯ä»¥æ·»åŠ æ›´è¤‡é›œçš„è³ªé‡è©•ä¼°é‚è¼¯
        estimated_quality = self._estimate_response_quality(query, rag_docs, tool_results, processing_time)
        
        total_queries = self.integration_stats["total_queries"]
        current_avg = self.integration_stats["avg_response_quality"]
        new_avg = (current_avg * (total_queries - 1) + estimated_quality) / total_queries
        self.integration_stats["avg_response_quality"] = new_avg
    
    def _estimate_response_quality(self, query: str, rag_docs: List[RAGDocument], tool_results: Dict[str, Any], processing_time: float) -> float:
        """ä¼°ç®—å›æ‡‰è³ªé‡"""
        quality_score = 5.0  # åŸºç¤åˆ†æ•¸
        
        # RAGå¢å¼·çå‹µ
        if rag_docs:
            quality_score += min(len(rag_docs) * 0.5, 2.0)
        
        # å·¥å…·ä½¿ç”¨çå‹µ
        if tool_results:
            successful_tools = sum(1 for result in tool_results.values() if result.get("success"))
            quality_score += successful_tools * 0.5
        
        # è™•ç†æ™‚é–“æ‡²ç½°
        if processing_time > 10:
            quality_score -= (processing_time - 10) * 0.1
        
        return min(max(quality_score, 0), 10)  # é™åˆ¶åœ¨0-10ç¯„åœå…§

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    """ä¸»å‡½æ•¸ç¤ºä¾‹"""
    # åˆå§‹åŒ–ç³»çµ±
    system = PowerAutomationRAGToolSystem()
    
    # æ¨¡æ“¬æ–‡æª”åˆå§‹åŒ–
    sample_docs = [
        RAGDocument(
            doc_id="doc_001",
            content="Reactçµ„ä»¶æœ€ä½³å¯¦è¸åŒ…æ‹¬ä½¿ç”¨å‡½æ•¸å¼çµ„ä»¶ã€é©ç•¶çš„ç‹€æ…‹ç®¡ç†ã€æ€§èƒ½å„ªåŒ–ç­‰...",
            metadata={"title": "Reactæœ€ä½³å¯¦è¸", "category": "frontend", "last_updated": "2024-01-15"}
        ),
        RAGDocument(
            doc_id="doc_002", 
            content="Pythonç•°æ­¥ç·¨ç¨‹ä½¿ç”¨async/awaitèªæ³•ï¼Œå¯ä»¥å¤§å¤§æé«˜I/Oå¯†é›†å‹ä»»å‹™çš„æ€§èƒ½...",
            metadata={"title": "Pythonç•°æ­¥ç·¨ç¨‹", "category": "backend", "last_updated": "2024-01-10"}
        )
    ]
    
    await system.rag_system.initialize_vector_store(sample_docs)
    
    # æ¨¡æ“¬æŸ¥è©¢
    query = "å¦‚ä½•å„ªåŒ–Reactçµ„ä»¶çš„æ€§èƒ½ï¼Ÿ"
    context = {
        "tech_stack": ["react", "javascript"],
        "project_type": "web_frontend",
        "user_role": "frontend_developer"
    }
    
    # æ¨¡æ“¬K2å®¢æˆ¶ç«¯
    class MockK2Client:
        async def chat_completion(self, prompt):
            return "æ ¹æ“šæ‚¨çš„æŸ¥è©¢ï¼Œé€™è£¡æ˜¯é—œæ–¼Reactæ€§èƒ½å„ªåŒ–çš„å»ºè­°..."
    
    k2_client = MockK2Client()
    
    # è™•ç†æŸ¥è©¢
    result = await system.process_enhanced_query(query, context, k2_client)
    
    print("æŸ¥è©¢çµæœ:")
    print(json.dumps(result, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    asyncio.run(main())