#!/usr/bin/env python3
"""
Manus å·¥å…·ä½¿ç”¨æ¨¡å¼æå–å™¨
å°ˆé–€å­¸ç¿’ Manus çš„å·¥å…·èª¿ç”¨æ¨¡å¼å’Œä»»å‹™åŸ·è¡Œç­–ç•¥
"""

import json
from pathlib import Path
from datetime import datetime
import re
from typing import Dict, List, Any
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ManusToolUsageExtractor:
    """å¾ Manus å°è©±ä¸­æå–å·¥å…·ä½¿ç”¨æ¨¡å¼"""
    
    def __init__(self):
        self.output_dir = Path("./data/manus_tool_patterns")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # å¸¸è¦‹çš„å·¥å…·èª¿ç”¨æ¨¡å¼
        self.tool_patterns = {
            'file_operations': [
                r'å‰µå»º.*æ–‡ä»¶', r'ç·¨è¼¯.*æ–‡ä»¶', r'åˆªé™¤.*æ–‡ä»¶', r'é‡å‘½å.*æ–‡ä»¶',
                r'create.*file', r'edit.*file', r'delete.*file', r'rename.*file'
            ],
            'code_execution': [
                r'åŸ·è¡Œ.*ä»£ç¢¼', r'é‹è¡Œ.*è…³æœ¬', r'æ¸¬è©¦.*åŠŸèƒ½', r'èª¿è©¦.*ç¨‹åº',
                r'run.*code', r'execute.*script', r'test.*function', r'debug.*program'
            ],
            'search_operations': [
                r'æœç´¢.*', r'æŸ¥æ‰¾.*', r'å®šä½.*', r'æª¢ç´¢.*',
                r'search.*', r'find.*', r'locate.*', r'retrieve.*'
            ],
            'analysis_operations': [
                r'åˆ†æ.*', r'è©•ä¼°.*', r'æª¢æŸ¥.*', r'è¨ºæ–·.*',
                r'analyze.*', r'evaluate.*', r'check.*', r'diagnose.*'
            ],
            'automation_tasks': [
                r'è‡ªå‹•åŒ–.*', r'æ‰¹é‡.*', r'ç”Ÿæˆ.*', r'æ§‹å»º.*',
                r'automate.*', r'batch.*', r'generate.*', r'build.*'
            ]
        }
        
    def extract_tool_patterns_from_conversations(self, conversations_file: str):
        """å¾å°è©±æ–‡ä»¶ä¸­æå–å·¥å…·ä½¿ç”¨æ¨¡å¼"""
        logger.info(f"é–‹å§‹æå–å·¥å…·ä½¿ç”¨æ¨¡å¼: {conversations_file}")
        
        # è®€å–å°è©±æ•¸æ“š
        with open(conversations_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
        conversations = data.get('conversations', [])
        logger.info(f"æ‰¾åˆ° {len(conversations)} å€‹å°è©±")
        
        # æå–å·¥å…·ä½¿ç”¨æ¨¡å¼
        tool_usage_patterns = []
        
        for conv in conversations:
            if not conv or 'messages' not in conv:
                continue
                
            # åˆ†ææ¯å€‹å°è©±
            pattern = self._analyze_conversation(conv)
            if pattern:
                tool_usage_patterns.append(pattern)
                
        # çµ±è¨ˆå’Œåˆ†æ
        analysis = self._analyze_patterns(tool_usage_patterns)
        
        # ä¿å­˜çµæœ
        self._save_analysis(tool_usage_patterns, analysis)
        
        return analysis
        
    def _analyze_conversation(self, conversation: Dict) -> Dict:
        """åˆ†æå–®å€‹å°è©±çš„å·¥å…·ä½¿ç”¨æ¨¡å¼"""
        messages = conversation.get('messages', [])
        task_info = conversation.get('task_info', {})
        
        pattern = {
            'task_id': task_info.get('id', 'unknown'),
            'task_title': task_info.get('title', ''),
            'tool_sequences': [],
            'user_intents': [],
            'execution_steps': [],
            'code_blocks': [],
            'file_operations': [],
            'success_indicators': []
        }
        
        # åˆ†ææ¶ˆæ¯åºåˆ—
        for i, msg in enumerate(messages):
            role = msg.get('role', '')
            content = msg.get('content', '')
            
            if role == 'user':
                # æå–ç”¨æˆ¶æ„åœ–
                intent = self._extract_user_intent(content)
                if intent:
                    pattern['user_intents'].append({
                        'index': i,
                        'intent': intent,
                        'original': content[:100]
                    })
                    
            elif role == 'assistant':
                # æå–åŠ©æ‰‹çš„å·¥å…·ä½¿ç”¨
                tools_used = self._extract_tool_usage(content)
                if tools_used:
                    pattern['tool_sequences'].extend(tools_used)
                    
                # æå–ä»£ç¢¼å¡Š
                code_blocks = self._extract_code_blocks(content)
                pattern['code_blocks'].extend(code_blocks)
                
                # æå–åŸ·è¡Œæ­¥é©Ÿ
                steps = self._extract_execution_steps(content)
                pattern['execution_steps'].extend(steps)
                
        return pattern if pattern['tool_sequences'] else None
        
    def _extract_user_intent(self, content: str) -> str:
        """æå–ç”¨æˆ¶æ„åœ–"""
        content_lower = content.lower()
        
        # å¸¸è¦‹æ„åœ–æ¨¡å¼
        intent_keywords = {
            'create': ['å‰µå»º', 'æ–°å»º', 'create', 'new', 'make'],
            'modify': ['ä¿®æ”¹', 'ç·¨è¼¯', 'æ›´æ–°', 'modify', 'edit', 'update'],
            'fix': ['ä¿®å¾©', 'è§£æ±º', 'è™•ç†', 'fix', 'solve', 'handle'],
            'analyze': ['åˆ†æ', 'æª¢æŸ¥', 'è¨ºæ–·', 'analyze', 'check', 'diagnose'],
            'automate': ['è‡ªå‹•åŒ–', 'æ‰¹é‡', 'automate', 'batch'],
            'search': ['æœç´¢', 'æŸ¥æ‰¾', 'æ‰¾åˆ°', 'search', 'find', 'locate'],
            'test': ['æ¸¬è©¦', 'é©—è­‰', 'test', 'verify', 'validate'],
            'optimize': ['å„ªåŒ–', 'æ”¹é€²', 'optimize', 'improve']
        }
        
        for intent, keywords in intent_keywords.items():
            for keyword in keywords:
                if keyword in content_lower:
                    return intent
                    
        return 'general'
        
    def _extract_tool_usage(self, content: str) -> List[Dict]:
        """æå–å·¥å…·ä½¿ç”¨ä¿¡æ¯"""
        tools = []
        
        # æª¢æŸ¥å„ç¨®å·¥å…·æ¨¡å¼
        for tool_type, patterns in self.tool_patterns.items():
            for pattern in patterns:
                matches = re.finditer(pattern, content, re.IGNORECASE)
                for match in matches:
                    tools.append({
                        'type': tool_type,
                        'action': match.group(),
                        'position': match.start()
                    })
                    
        # æª¢æŸ¥ç‰¹å®šå·¥å…·æ¨™è¨˜
        if '```' in content:
            tools.append({'type': 'code_execution', 'action': 'code_block'})
            
        if any(marker in content for marker in ['[åŸ·è¡Œ]', '[é‹è¡Œ]', '[Execute]', '[Run]']):
            tools.append({'type': 'command_execution', 'action': 'command'})
            
        return tools
        
    def _extract_code_blocks(self, content: str) -> List[Dict]:
        """æå–ä»£ç¢¼å¡Š"""
        code_blocks = []
        
        # åŒ¹é… ``` ä»£ç¢¼å¡Š
        pattern = r'```(\w*)\n(.*?)```'
        matches = re.finditer(pattern, content, re.DOTALL)
        
        for match in matches:
            language = match.group(1) or 'text'
            code = match.group(2).strip()
            
            code_blocks.append({
                'language': language,
                'code': code[:500],  # åªä¿å­˜å‰500å­—ç¬¦
                'purpose': self._infer_code_purpose(code)
            })
            
        return code_blocks
        
    def _extract_execution_steps(self, content: str) -> List[str]:
        """æå–åŸ·è¡Œæ­¥é©Ÿ"""
        steps = []
        
        # æŸ¥æ‰¾æ­¥é©Ÿæ¨™è¨˜
        step_patterns = [
            r'æ­¥é©Ÿ\s*(\d+)[ï¼š:](.+)',
            r'Step\s*(\d+)[ï¼š:](.+)',
            r'(\d+)\.\s*(.+)',
            r'ç¬¬(\d+)æ­¥[ï¼š:](.+)'
        ]
        
        for pattern in step_patterns:
            matches = re.finditer(pattern, content, re.MULTILINE)
            for match in matches:
                step_text = match.group(2).strip()
                if len(step_text) > 10:  # éæ¿¾å¤ªçŸ­çš„
                    steps.append(step_text[:200])
                    
        return steps
        
    def _infer_code_purpose(self, code: str) -> str:
        """æ¨æ–·ä»£ç¢¼ç”¨é€”"""
        code_lower = code.lower()
        
        if 'import' in code_lower or 'from' in code_lower:
            return 'import_setup'
        elif 'def ' in code_lower or 'function' in code_lower:
            return 'function_definition'
        elif 'class ' in code_lower:
            return 'class_definition'
        elif 'for ' in code_lower or 'while ' in code_lower:
            return 'loop_operation'
        elif 'if ' in code_lower:
            return 'conditional_logic'
        elif 'open(' in code_lower or 'read' in code_lower or 'write' in code_lower:
            return 'file_operation'
        elif 'request' in code_lower or 'api' in code_lower:
            return 'api_call'
        else:
            return 'general_code'
            
    def _analyze_patterns(self, patterns: List[Dict]) -> Dict:
        """åˆ†æå·¥å…·ä½¿ç”¨æ¨¡å¼"""
        analysis = {
            'total_conversations': len(patterns),
            'tool_usage_stats': {},
            'common_sequences': [],
            'intent_distribution': {},
            'code_language_distribution': {},
            'execution_patterns': []
        }
        
        # çµ±è¨ˆå·¥å…·ä½¿ç”¨
        tool_counts = {}
        intent_counts = {}
        language_counts = {}
        
        for pattern in patterns:
            # çµ±è¨ˆå·¥å…·é¡å‹
            for tool in pattern['tool_sequences']:
                tool_type = tool['type']
                tool_counts[tool_type] = tool_counts.get(tool_type, 0) + 1
                
            # çµ±è¨ˆç”¨æˆ¶æ„åœ–
            for intent_info in pattern['user_intents']:
                intent = intent_info['intent']
                intent_counts[intent] = intent_counts.get(intent, 0) + 1
                
            # çµ±è¨ˆä»£ç¢¼èªè¨€
            for code_block in pattern['code_blocks']:
                lang = code_block['language']
                language_counts[lang] = language_counts.get(lang, 0) + 1
                
        analysis['tool_usage_stats'] = tool_counts
        analysis['intent_distribution'] = intent_counts
        analysis['code_language_distribution'] = language_counts
        
        # æ‰¾å‡ºå¸¸è¦‹çš„å·¥å…·åºåˆ—
        analysis['common_sequences'] = self._find_common_sequences(patterns)
        
        return analysis
        
    def _find_common_sequences(self, patterns: List[Dict]) -> List[Dict]:
        """æ‰¾å‡ºå¸¸è¦‹çš„å·¥å…·ä½¿ç”¨åºåˆ—"""
        sequences = []
        
        # æå–æ‰€æœ‰å·¥å…·åºåˆ—
        for pattern in patterns:
            if len(pattern['tool_sequences']) >= 2:
                # å‰µå»ºå·¥å…·é¡å‹åºåˆ—
                seq = [tool['type'] for tool in pattern['tool_sequences']]
                sequences.append({
                    'sequence': seq,
                    'intent': pattern['user_intents'][0]['intent'] if pattern['user_intents'] else 'unknown'
                })
                
        # çµ±è¨ˆåºåˆ—é »ç‡ï¼ˆç°¡åŒ–ç‰ˆï¼‰
        seq_counts = {}
        for seq_info in sequences:
            seq_str = ' -> '.join(seq_info['sequence'][:3])  # åªçœ‹å‰3å€‹
            if seq_str not in seq_counts:
                seq_counts[seq_str] = {'count': 0, 'intents': []}
            seq_counts[seq_str]['count'] += 1
            seq_counts[seq_str]['intents'].append(seq_info['intent'])
            
        # è¿”å›æœ€å¸¸è¦‹çš„åºåˆ—
        common_sequences = []
        for seq, info in sorted(seq_counts.items(), key=lambda x: x[1]['count'], reverse=True)[:10]:
            common_sequences.append({
                'sequence': seq,
                'count': info['count'],
                'common_intent': max(set(info['intents']), key=info['intents'].count)
            })
            
        return common_sequences
        
    def _save_analysis(self, patterns: List[Dict], analysis: Dict):
        """ä¿å­˜åˆ†æçµæœ"""
        # ä¿å­˜è©³ç´°æ¨¡å¼
        patterns_file = self.output_dir / f"tool_patterns_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(patterns_file, 'w', encoding='utf-8') as f:
            json.dump({
                'patterns': patterns[:100],  # ä¿å­˜å‰100å€‹ä½œç‚ºç¤ºä¾‹
                'analysis': analysis,
                'extracted_at': datetime.now().isoformat()
            }, f, ensure_ascii=False, indent=2)
            
        # ç”Ÿæˆå·¥å…·ä½¿ç”¨å ±å‘Š
        report_file = self.output_dir / f"tool_usage_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# Manus å·¥å…·ä½¿ç”¨æ¨¡å¼åˆ†æå ±å‘Š\n\n")
            f.write(f"ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("## æ¦‚è¦½\n\n")
            f.write(f"- åˆ†æå°è©±æ•¸: {analysis['total_conversations']}\n")
            f.write(f"- è­˜åˆ¥çš„å·¥å…·é¡å‹: {len(analysis['tool_usage_stats'])}\n\n")
            
            f.write("## å·¥å…·ä½¿ç”¨çµ±è¨ˆ\n\n")
            for tool_type, count in sorted(analysis['tool_usage_stats'].items(), key=lambda x: x[1], reverse=True):
                f.write(f"- **{tool_type}**: {count} æ¬¡\n")
                
            f.write("\n## ç”¨æˆ¶æ„åœ–åˆ†å¸ƒ\n\n")
            for intent, count in sorted(analysis['intent_distribution'].items(), key=lambda x: x[1], reverse=True):
                f.write(f"- **{intent}**: {count} æ¬¡\n")
                
            f.write("\n## å¸¸è¦‹å·¥å…·ä½¿ç”¨åºåˆ—\n\n")
            for seq_info in analysis['common_sequences']:
                f.write(f"- `{seq_info['sequence']}` (å‡ºç¾ {seq_info['count']} æ¬¡ï¼Œå¸¸è¦‹æ„åœ–: {seq_info['common_intent']})\n")
                
            f.write("\n## ä»£ç¢¼èªè¨€åˆ†å¸ƒ\n\n")
            for lang, count in sorted(analysis['code_language_distribution'].items(), key=lambda x: x[1], reverse=True):
                f.write(f"- **{lang}**: {count} å€‹ä»£ç¢¼å¡Š\n")
                
        # ç”Ÿæˆè¨“ç·´æ•¸æ“šï¼ˆå°ˆæ³¨æ–¼å·¥å…·ä½¿ç”¨ï¼‰
        training_file = self.output_dir / f"tool_training_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jsonl"
        with open(training_file, 'w', encoding='utf-8') as f:
            for pattern in patterns[:500]:  # ä½¿ç”¨å‰500å€‹
                if pattern['user_intents'] and pattern['tool_sequences']:
                    # å‰µå»ºè¨“ç·´æ¨£æœ¬
                    training_sample = {
                        'input': pattern['user_intents'][0]['original'],
                        'intent': pattern['user_intents'][0]['intent'],
                        'tools_used': [tool['type'] for tool in pattern['tool_sequences']],
                        'has_code': len(pattern['code_blocks']) > 0,
                        'steps_count': len(pattern['execution_steps'])
                    }
                    f.write(json.dumps(training_sample, ensure_ascii=False) + '\n')
                    
        logger.info(f"\nâœ… åˆ†æå®Œæˆï¼")
        logger.info(f"  æ¨¡å¼æ–‡ä»¶: {patterns_file}")
        logger.info(f"  åˆ†æå ±å‘Š: {report_file}")
        logger.info(f"  è¨“ç·´æ•¸æ“š: {training_file}")
        
        # é¡¯ç¤ºé—œéµç™¼ç¾
        logger.info(f"\nğŸ” é—œéµç™¼ç¾:")
        logger.info(f"  æœ€å¸¸ç”¨å·¥å…·: {max(analysis['tool_usage_stats'].items(), key=lambda x: x[1])[0]}")
        logger.info(f"  æœ€å¸¸è¦‹æ„åœ–: {max(analysis['intent_distribution'].items(), key=lambda x: x[1])[0]}")
        if analysis['common_sequences']:
            logger.info(f"  æœ€å¸¸è¦‹åºåˆ—: {analysis['common_sequences'][0]['sequence']}")


def create_tool_learning_dataset(patterns_file: str, output_file: str):
    """å‰µå»ºå°ˆé–€çš„å·¥å…·å­¸ç¿’æ•¸æ“šé›†"""
    logger.info("å‰µå»ºå·¥å…·å­¸ç¿’æ•¸æ“šé›†...")
    
    with open(patterns_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
        
    patterns = data['patterns']
    training_data = []
    
    for pattern in patterns:
        if not pattern['tool_sequences']:
            continue
            
        # æ§‹å»ºä¸Šä¸‹æ–‡å’Œå·¥å…·èª¿ç”¨åºåˆ—
        context = {
            'user_request': pattern['user_intents'][0]['original'] if pattern['user_intents'] else '',
            'tool_sequence': [],
            'execution_steps': pattern['execution_steps']
        }
        
        # æ•´ç†å·¥å…·èª¿ç”¨åºåˆ—
        for tool in pattern['tool_sequences']:
            context['tool_sequence'].append({
                'tool': tool['type'],
                'action': tool['action']
            })
            
        # æ·»åŠ ä»£ç¢¼ç¤ºä¾‹
        if pattern['code_blocks']:
            context['code_examples'] = pattern['code_blocks'][:3]  # æœ€å¤š3å€‹
            
        training_data.append(context)
        
    # ä¿å­˜è¨“ç·´æ•¸æ“š
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            'dataset': 'manus_tool_usage',
            'version': '1.0',
            'samples': training_data,
            'total': len(training_data),
            'created_at': datetime.now().isoformat()
        }, f, ensure_ascii=False, indent=2)
        
    logger.info(f"âœ… å‰µå»ºäº† {len(training_data)} å€‹å·¥å…·å­¸ç¿’æ¨£æœ¬")
    

def main():
    """ä¸»å‡½æ•¸"""
    print("""
    ğŸ”§ Manus å·¥å…·ä½¿ç”¨æ¨¡å¼æå–å™¨
    
    é€™å€‹å·¥å…·æœƒï¼š
    1. åˆ†æ Manus å°è©±ä¸­çš„å·¥å…·ä½¿ç”¨æ¨¡å¼
    2. æå–å¸¸è¦‹çš„å·¥å…·èª¿ç”¨åºåˆ—
    3. çµ±è¨ˆç”¨æˆ¶æ„åœ–å’Œå·¥å…·é¡å‹çš„å°æ‡‰é—œä¿‚
    4. ç”Ÿæˆå°ˆé–€çš„å·¥å…·ä½¿ç”¨è¨“ç·´æ•¸æ“š
    
    ç‰¹åˆ¥é—œæ³¨ï¼š
    - å·¥å…·èª¿ç”¨çš„é †åºå’Œçµ„åˆ
    - ä¸åŒä»»å‹™é¡å‹çš„å·¥å…·é¸æ“‡ç­–ç•¥
    - åŸ·è¡Œæ­¥é©Ÿçš„çµ„ç¹”æ–¹å¼
    """)
    
    # ä½¿ç”¨ä¹‹å‰æ”¶é›†çš„å°è©±æ•¸æ“š
    conversations_file = input("\nè«‹è¼¸å…¥ Manus å°è©±æ•¸æ“šæ–‡ä»¶è·¯å¾‘: ").strip()
    
    if not conversations_file:
        # ä½¿ç”¨é»˜èªè·¯å¾‘
        conversations_file = "./data/manus_complete_collection/all_conversations.json"
        
    if not Path(conversations_file).exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {conversations_file}")
        print("è«‹å…ˆé‹è¡Œ manus_precise_sidebar_collector.py æ”¶é›†å°è©±æ•¸æ“š")
        return
        
    extractor = ManusToolUsageExtractor()
    analysis = extractor.extract_tool_patterns_from_conversations(conversations_file)
    
    # å‰µå»ºå°ˆé–€çš„è¨“ç·´æ•¸æ“šé›†
    if input("\næ˜¯å¦å‰µå»ºå·¥å…·å­¸ç¿’æ•¸æ“šé›†ï¼Ÿ(y/n): ").lower() == 'y':
        patterns_file = list(Path("./data/manus_tool_patterns").glob("tool_patterns_*.json"))[-1]
        output_file = "./data/manus_tool_patterns/tool_learning_dataset.json"
        create_tool_learning_dataset(str(patterns_file), output_file)
        print(f"\nâœ… å·¥å…·å­¸ç¿’æ•¸æ“šé›†å·²ä¿å­˜: {output_file}")


if __name__ == "__main__":
    main()