#!/usr/bin/env python3
"""
æŒçºŒå­¸ç¿’ç³»çµ±
å¯¦æ™‚å¾ç”¨æˆ¶äº¤äº’ä¸­å­¸ç¿’ä¸¦æ”¹é€²
"""

import json
import logging
import asyncio
from pathlib import Path
from typing import Dict, List, Optional
from datetime import datetime
import numpy as np
from collections import defaultdict

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ContinuousLearningSystem:
    """æŒçºŒå­¸ç¿’ç³»çµ±"""
    
    def __init__(self):
        self.base_dir = Path("/Users/alexchuang/alexchuangtest/aicore0720")
        
        # å­¸ç¿’é…ç½®
        self.config = {
            "learning_rate": 0.01,
            "batch_size": 10,
            "update_frequency": 5,  # æ¯5å€‹æ¨£æœ¬æ›´æ–°ä¸€æ¬¡
            "confidence_threshold": 0.7,
            "exploration_rate": 0.1  # 10%çš„æ¢ç´¢ç‡
        }
        
        # åœ¨ç·šå­¸ç¿’ç·©è¡å€
        self.learning_buffer = {
            "pending_samples": [],
            "validated_samples": [],
            "failed_samples": []
        }
        
        # æ€§èƒ½è¿½è¹¤
        self.performance_tracker = {
            "hourly_stats": defaultdict(lambda: {"success": 0, "total": 0}),
            "daily_improvement": [],
            "current_accuracy": 0.0
        }
        
        # è¼‰å…¥æˆ–åˆå§‹åŒ–æ¨¡å‹
        self.model = self._load_or_init_model()
        
        # å•Ÿå‹•èƒŒæ™¯å­¸ç¿’ä»»å‹™
        self.learning_task = None
    
    def _load_or_init_model(self) -> Dict:
        """è¼‰å…¥æˆ–åˆå§‹åŒ–æ¨¡å‹"""
        model_path = self.base_dir / "continuous_model.json"
        
        if model_path.exists():
            with open(model_path, 'r') as f:
                logger.info("âœ… è¼‰å…¥ç¾æœ‰æŒçºŒå­¸ç¿’æ¨¡å‹")
                return json.load(f)
        else:
            logger.info("ğŸ†• åˆå§‹åŒ–æ–°çš„æŒçºŒå­¸ç¿’æ¨¡å‹")
            return {
                "intent_weights": defaultdict(lambda: defaultdict(float)),
                "tool_mapping": defaultdict(list),
                "context_patterns": defaultdict(list),
                "version": 1,
                "last_update": datetime.now().isoformat()
            }
    
    async def start_continuous_learning(self):
        """å•Ÿå‹•æŒçºŒå­¸ç¿’å¾ªç’°"""
        logger.info("ğŸš€ å•Ÿå‹•æŒçºŒå­¸ç¿’ç³»çµ±...")
        
        while True:
            try:
                # è™•ç†å­¸ç¿’ç·©è¡å€
                if len(self.learning_buffer["pending_samples"]) >= self.config["update_frequency"]:
                    await self._process_learning_batch()
                
                # å®šæœŸè©•ä¼°å’Œèª¿æ•´
                await self._evaluate_and_adjust()
                
                # ä¿å­˜æ¨¡å‹
                if datetime.now().minute % 10 == 0:  # æ¯10åˆ†é˜ä¿å­˜ä¸€æ¬¡
                    self._save_model()
                
                await asyncio.sleep(60)  # æ¯åˆ†é˜æª¢æŸ¥ä¸€æ¬¡
                
            except Exception as e:
                logger.error(f"æŒçºŒå­¸ç¿’éŒ¯èª¤: {e}")
                await asyncio.sleep(60)
    
    async def learn_from_interaction(self, interaction: Dict):
        """å¾å–®æ¬¡äº¤äº’ä¸­å­¸ç¿’"""
        # æå–å­¸ç¿’ä¿¡è™Ÿ
        learning_signal = {
            "timestamp": datetime.now().isoformat(),
            "input": interaction.get("user_input", ""),
            "predicted_intent": interaction.get("predicted_intent"),
            "actual_intent": interaction.get("actual_intent"),
            "tools_used": interaction.get("tools_used", []),
            "success": interaction.get("success", False),
            "confidence": interaction.get("confidence", 0.0),
            "execution_time": interaction.get("execution_time", 0.0),
            "user_feedback": interaction.get("user_feedback")
        }
        
        # åŠ å…¥å­¸ç¿’ç·©è¡å€
        self.learning_buffer["pending_samples"].append(learning_signal)
        
        # ç«‹å³å­¸ç¿’ï¼ˆå¦‚æœæ˜¯é«˜åƒ¹å€¼æ¨£æœ¬ï¼‰
        if self._is_high_value_sample(learning_signal):
            await self._immediate_learn(learning_signal)
        
        # æ›´æ–°æ€§èƒ½çµ±è¨ˆ
        hour = datetime.now().hour
        self.performance_tracker["hourly_stats"][hour]["total"] += 1
        if learning_signal["success"]:
            self.performance_tracker["hourly_stats"][hour]["success"] += 1
    
    def _is_high_value_sample(self, signal: Dict) -> bool:
        """åˆ¤æ–·æ˜¯å¦ç‚ºé«˜åƒ¹å€¼å­¸ç¿’æ¨£æœ¬"""
        # å¤±æ•—çš„æ¡ˆä¾‹
        if not signal["success"]:
            return True
        
        # ä½ç½®ä¿¡åº¦çš„æˆåŠŸæ¡ˆä¾‹
        if signal["confidence"] < 0.5:
            return True
        
        # æ–°çš„æ„åœ–æˆ–å·¥å…·çµ„åˆ
        if signal["predicted_intent"] not in self.model["intent_weights"]:
            return True
        
        return False
    
    async def _immediate_learn(self, signal: Dict):
        """ç«‹å³å­¸ç¿’ï¼ˆç”¨æ–¼é«˜åƒ¹å€¼æ¨£æœ¬ï¼‰"""
        logger.info(f"ğŸ¯ ç«‹å³å­¸ç¿’é«˜åƒ¹å€¼æ¨£æœ¬: {signal['input'][:30]}...")
        
        # æ›´æ–°æ„åœ–æ¬Šé‡
        if signal["actual_intent"] and signal["predicted_intent"]:
            # æ­£ç¢ºé æ¸¬ï¼šå¼·åŒ–
            if signal["actual_intent"] == signal["predicted_intent"] and signal["success"]:
                self._reinforce_weights(signal)
            # éŒ¯èª¤é æ¸¬ï¼šèª¿æ•´
            else:
                self._adjust_weights(signal)
        
        # æ›´æ–°å·¥å…·æ˜ å°„
        if signal["success"] and signal["tools_used"]:
            self.model["tool_mapping"][signal["actual_intent"]] = signal["tools_used"]
    
    def _reinforce_weights(self, signal: Dict):
        """å¼·åŒ–æ­£ç¢ºçš„æ¬Šé‡"""
        intent = signal["actual_intent"]
        features = self._extract_features(signal["input"])
        
        for feature, value in features.items():
            current = self.model["intent_weights"][intent].get(feature, 0.0)
            self.model["intent_weights"][intent][feature] = current + self.config["learning_rate"] * value
    
    def _adjust_weights(self, signal: Dict):
        """èª¿æ•´éŒ¯èª¤çš„æ¬Šé‡"""
        correct_intent = signal["actual_intent"]
        wrong_intent = signal["predicted_intent"]
        features = self._extract_features(signal["input"])
        
        # å¢åŠ æ­£ç¢ºæ„åœ–çš„æ¬Šé‡
        for feature, value in features.items():
            current = self.model["intent_weights"][correct_intent].get(feature, 0.0)
            self.model["intent_weights"][correct_intent][feature] = current + self.config["learning_rate"] * value
        
        # æ¸›å°‘éŒ¯èª¤æ„åœ–çš„æ¬Šé‡
        if wrong_intent:
            for feature, value in features.items():
                current = self.model["intent_weights"][wrong_intent].get(feature, 0.0)
                self.model["intent_weights"][wrong_intent][feature] = current - self.config["learning_rate"] * value * 0.5
    
    def _extract_features(self, text: str) -> Dict[str, float]:
        """æå–æ–‡æœ¬ç‰¹å¾µ"""
        features = {}
        words = text.lower().split()
        
        # å–®è©ç‰¹å¾µ
        for word in words:
            if len(word) > 2:
                features[f"word_{word}"] = 1.0
        
        # é›™è©çµ„åˆ
        for i in range(len(words) - 1):
            features[f"bigram_{words[i]}_{words[i+1]}"] = 1.0
        
        # é•·åº¦ç‰¹å¾µ
        features["length"] = len(words) / 10.0
        
        return features
    
    async def _process_learning_batch(self):
        """è™•ç†å­¸ç¿’æ‰¹æ¬¡"""
        batch = self.learning_buffer["pending_samples"][:self.config["batch_size"]]
        self.learning_buffer["pending_samples"] = self.learning_buffer["pending_samples"][self.config["batch_size"]:]
        
        logger.info(f"ğŸ“š è™•ç†å­¸ç¿’æ‰¹æ¬¡: {len(batch)} å€‹æ¨£æœ¬")
        
        success_count = 0
        for sample in batch:
            if sample["success"]:
                success_count += 1
                self.learning_buffer["validated_samples"].append(sample)
            else:
                self.learning_buffer["failed_samples"].append(sample)
        
        # æ‰¹é‡æ›´æ–°æ¨¡å‹
        await self._batch_update_model(batch)
        
        # è¨ˆç®—æ‰¹æ¬¡æº–ç¢ºç‡
        batch_accuracy = success_count / len(batch) if batch else 0
        logger.info(f"ğŸ“Š æ‰¹æ¬¡æº–ç¢ºç‡: {batch_accuracy:.1%}")
    
    async def _batch_update_model(self, batch: List[Dict]):
        """æ‰¹é‡æ›´æ–°æ¨¡å‹"""
        # çµ±è¨ˆæ„åœ–åˆ†ä½ˆ
        intent_counts = defaultdict(int)
        for sample in batch:
            if sample["actual_intent"]:
                intent_counts[sample["actual_intent"]] += 1
        
        # æ›´æ–°æ¨¡å‹ç‰ˆæœ¬
        self.model["version"] += 1
        self.model["last_update"] = datetime.now().isoformat()
        
        logger.info(f"âœ… æ¨¡å‹æ›´æ–°åˆ°ç‰ˆæœ¬ {self.model['version']}")
    
    async def _evaluate_and_adjust(self):
        """è©•ä¼°ä¸¦èª¿æ•´å­¸ç¿’ç­–ç•¥"""
        # è¨ˆç®—ç•¶å‰æº–ç¢ºç‡
        total = sum(stat["total"] for stat in self.performance_tracker["hourly_stats"].values())
        success = sum(stat["success"] for stat in self.performance_tracker["hourly_stats"].values())
        
        if total > 0:
            current_accuracy = success / total
            self.performance_tracker["current_accuracy"] = current_accuracy
            
            # èª¿æ•´å­¸ç¿’ç‡
            if current_accuracy < 0.7:
                self.config["learning_rate"] = min(0.1, self.config["learning_rate"] * 1.1)
            elif current_accuracy > 0.9:
                self.config["learning_rate"] = max(0.001, self.config["learning_rate"] * 0.9)
    
    def _save_model(self):
        """ä¿å­˜æ¨¡å‹"""
        model_path = self.base_dir / "continuous_model.json"
        
        # è½‰æ›defaultdictç‚ºæ™®é€šdict
        save_data = {
            "intent_weights": {
                intent: dict(weights)
                for intent, weights in self.model["intent_weights"].items()
            },
            "tool_mapping": dict(self.model["tool_mapping"]),
            "context_patterns": dict(self.model["context_patterns"]),
            "version": self.model["version"],
            "last_update": self.model["last_update"],
            "performance": {
                "current_accuracy": self.performance_tracker["current_accuracy"],
                "total_samples": sum(
                    stat["total"] 
                    for stat in self.performance_tracker["hourly_stats"].values()
                )
            }
        }
        
        with open(model_path, 'w') as f:
            json.dump(save_data, f, indent=2)
        
        logger.info(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜ (ç‰ˆæœ¬ {self.model['version']})")
    
    def generate_learning_report(self) -> str:
        """ç”Ÿæˆå­¸ç¿’å ±å‘Š"""
        total = sum(stat["total"] for stat in self.performance_tracker["hourly_stats"].values())
        success = sum(stat["success"] for stat in self.performance_tracker["hourly_stats"].values())
        accuracy = success / total if total > 0 else 0
        
        report = f"""
# æŒçºŒå­¸ç¿’ç³»çµ±å ±å‘Š

ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“Š å­¸ç¿’çµ±è¨ˆ
- æ¨¡å‹ç‰ˆæœ¬: {self.model['version']}
- ç¸½æ¨£æœ¬æ•¸: {total}
- æˆåŠŸæ¨£æœ¬: {success}
- ç•¶å‰æº–ç¢ºç‡: {accuracy:.1%}
- å­¸ç¿’ç‡: {self.config['learning_rate']}

## ğŸ“ˆ æ¯å°æ™‚æ€§èƒ½
"""
        
        for hour in sorted(self.performance_tracker["hourly_stats"].keys()):
            stat = self.performance_tracker["hourly_stats"][hour]
            if stat["total"] > 0:
                hour_accuracy = stat["success"] / stat["total"]
                report += f"- {hour:02d}:00 - æº–ç¢ºç‡: {hour_accuracy:.1%} ({stat['total']} æ¨£æœ¬)\n"
        
        report += f"""
## ğŸ¯ å­¸ç¿’ç·©è¡å€
- å¾…è™•ç†æ¨£æœ¬: {len(self.learning_buffer['pending_samples'])}
- å·²é©—è­‰æ¨£æœ¬: {len(self.learning_buffer['validated_samples'])}
- å¤±æ•—æ¨£æœ¬: {len(self.learning_buffer['failed_samples'])}

## ğŸ’¡ é—œéµç™¼ç¾
1. ç³»çµ±æŒçºŒå¾æ¯æ¬¡äº¤äº’ä¸­å­¸ç¿’
2. é«˜åƒ¹å€¼æ¨£æœ¬ï¼ˆå¤±æ•—æ¡ˆä¾‹ï¼‰ç«‹å³å­¸ç¿’
3. å­¸ç¿’ç‡æ ¹æ“šæ€§èƒ½å‹•æ…‹èª¿æ•´
4. æ¨¡å‹å®šæœŸä¿å­˜ï¼Œæ”¯æŒæ–·é»æ¢å¾©
"""
        
        return report
    
    def generate_diverse_dialogues(self, count: int = 100) -> List[Dict]:
        """ç”Ÿæˆå¤šæ¨£åŒ–çš„å°è©±æ•¸æ“š"""
        dialogues = []
        
        # å°è©±æ¨¡æ¿åº«
        templates = {
        "read_code": [
            "å¹«æˆ‘çœ‹çœ‹{file}çš„å…§å®¹",
            "é¡¯ç¤º{file}æ–‡ä»¶",
            "è®€å–{file}",
            "æŸ¥çœ‹{file}çš„ä»£ç¢¼",
            "æ‰“é–‹{file}çœ‹çœ‹",
            "èƒ½ä¸èƒ½é¡¯ç¤ºä¸€ä¸‹{file}",
            "æˆ‘æƒ³çœ‹{file}è£¡é¢æ˜¯ä»€éº¼",
            "{file}æ–‡ä»¶çš„å…§å®¹æ˜¯ä»€éº¼",
            "æŠŠ{file}çš„ä»£ç¢¼é¡¯ç¤ºå‡ºä¾†",
            "è®“æˆ‘çœ‹çœ‹{file}"
        ],
        "write_code": [
            "å‰µå»ºä¸€å€‹{type}ä¾†{purpose}",
            "å¯«ä¸€å€‹{function}å‡½æ•¸",
            "å¹«æˆ‘å¯¦ç¾{feature}åŠŸèƒ½",
            "æ–°å»º{file}æ–‡ä»¶",
            "ç”Ÿæˆ{type}çš„ä»£ç¢¼",
            "ç·¨å¯«ä¸€å€‹{component}çµ„ä»¶",
            "å¯¦ç¾{algorithm}ç®—æ³•",
            "å‰µå»º{purpose}çš„è…³æœ¬",
            "å¯«å€‹{type}è™•ç†{task}",
            "å¹«æˆ‘ç”Ÿæˆ{template}æ¨¡æ¿"
        ],
        "edit_code": [
            "æŠŠ{old}æ”¹æˆ{new}",
            "ä¿®æ”¹{file}ä¸­çš„{part}",
            "æ›´æ–°{variable}çš„å€¼ç‚º{value}",
            "æ›¿æ›æ‰€æœ‰çš„{pattern}",
            "ç·¨è¼¯{function}å‡½æ•¸",
            "èª¿æ•´{parameter}åƒæ•¸",
            "é‡å‘½å{old}ç‚º{new}",
            "ä¿®æ­£{file}çš„æ ¼å¼",
            "æ”¹ä¸€ä¸‹{code}é€™éƒ¨åˆ†",
            "å„ªåŒ–{function}çš„å¯¦ç¾"
        ],
        "debug_error": [
            "ç‚ºä»€éº¼æœƒå‡ºç¾{error}éŒ¯èª¤",
            "{error}æ˜¯ä»€éº¼æ„æ€",
            "é€™å€‹{exception}æ€éº¼è§£æ±º",
            "ç¨‹åº{action}æ™‚å ±éŒ¯äº†",
            "èª¿è©¦ä¸€ä¸‹{problem}",
            "åˆ†æé€™å€‹{error}çš„åŸå› ",
            "{function}ç‚ºä»€éº¼æœƒå¤±æ•—",
            "å¹«æˆ‘çœ‹çœ‹é€™å€‹{traceback}",
            "è§£é‡‹ä¸€ä¸‹{error_type}éŒ¯èª¤",
            "è¨ºæ–·{symptom}çš„å•é¡Œ"
        ],
        "fix_bug": [
            "ä¿®å¾©{feature}çš„bug",
            "è§£æ±º{problem}å•é¡Œ",
            "ä¿®æ­£{error}éŒ¯èª¤",
            "è™•ç†{exception}ç•°å¸¸",
            "ç³¾æ­£{logic}é‚è¼¯",
            "ä¿®è£œ{vulnerability}æ¼æ´",
            "æ”¹æ­£{mistake}",
            "è§£æ±º{function}ä¸å·¥ä½œçš„å•é¡Œ",
            "ä¿®å¾©{component}çš„æ•…éšœ",
            "è™•ç†{edge_case}çš„æƒ…æ³"
        ],
        "search_code": [
            "æœç´¢æ‰€æœ‰{pattern}çš„åœ°æ–¹",
            "æ‰¾{keyword}é—œéµå­—",
            "æŸ¥æ‰¾{function}çš„å®šç¾©",
            "grep {pattern}",
            "å°‹æ‰¾{variable}çš„ä½¿ç”¨",
            "æ‰¾å‡ºæ‰€æœ‰{type}æ–‡ä»¶",
            "æœç´¢åŒ…å«{text}çš„ä»£ç¢¼",
            "å®šä½{function}å‡½æ•¸",
            "æŸ¥æ‰¾{import}çš„å¼•ç”¨",
            "æ‰¾æ‰¾{comment}è¨»é‡‹"
        ],
        "run_test": [
            "é‹è¡Œ{test}æ¸¬è©¦",
            "åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦ç”¨ä¾‹",
            "è·‘ä¸€ä¸‹{suite}æ¸¬è©¦å¥—ä»¶",
            "æ¸¬è©¦{function}åŠŸèƒ½",
            "é©—è­‰{feature}æ˜¯å¦æ­£å¸¸",
            "æª¢æŸ¥æ¸¬è©¦è¦†è“‹ç‡",
            "é‹è¡Œ{type}æ¸¬è©¦",
            "åŸ·è¡Œ{file}çš„æ¸¬è©¦",
            "æ¸¬è©¦ä¸€ä¸‹{component}",
            "é©—è­‰{scenario}å ´æ™¯"
        ],
        "run_command": [
            "åŸ·è¡Œ{command}å‘½ä»¤",
            "é‹è¡Œ{script}è…³æœ¬",
            "å•Ÿå‹•{service}æœå‹™",
            "åŸ·è¡Œ{tool} {args}",
            "é‹è¡Œ{build}æ§‹å»º",
            "å•Ÿå‹•{server}",
            "åŸ·è¡Œ{package}å®‰è£",
            "é‹è¡Œ{deployment}éƒ¨ç½²",
            "åŸ·è¡Œ{migration}é·ç§»",
            "å•Ÿå‹•{process}é€²ç¨‹"
        ]
        }
        
        # åƒæ•¸å€¼åº«
        params = {
        "file": ["config.json", "main.py", "server.js", "index.html", "utils.ts", 
                 "app.jsx", "test.py", "README.md", "package.json", "docker-compose.yml"],
        "type": ["å‡½æ•¸", "é¡", "æ¨¡å¡Š", "çµ„ä»¶", "æœå‹™", "æ¥å£", "å·¥å…·", "è…³æœ¬", "é…ç½®", "æ¸¬è©¦"],
        "purpose": ["è™•ç†æ•¸æ“š", "é©—è­‰è¼¸å…¥", "è¨ˆç®—çµæœ", "ç™¼é€è«‹æ±‚", "è§£æéŸ¿æ‡‰", 
                    "ç®¡ç†ç‹€æ…‹", "æ¸²æŸ“ç•Œé¢", "è™•ç†éŒ¯èª¤", "è¨˜éŒ„æ—¥èªŒ", "å„ªåŒ–æ€§èƒ½"],
        "function": ["getData", "processInput", "calculateResult", "validateForm", 
                     "handleError", "updateState", "renderView", "fetchAPI", "parseJSON", "formatDate"],
        "error": ["TypeError", "SyntaxError", "ReferenceError", "ImportError", 
                  "ValueError", "KeyError", "AttributeError", "IndexError", "NameError", "RuntimeError"],
        "pattern": ["TODO", "FIXME", "console.log", "print", "debug", 
                    "deprecated", "async", "await", "import", "export"],
        "command": ["npm install", "pip install", "git status", "docker build", 
                    "yarn test", "make build", "pytest", "eslint", "prettier", "webpack"]
        }
        
        # ç”Ÿæˆå°è©±
        for _ in range(count):
            intent = np.random.choice(list(templates.keys()))
            template = np.random.choice(templates[intent])
            
            # å¡«å……æ¨¡æ¿
            dialogue = template
            for match in set(word[1:-1] for word in template.split() if word.startswith('{') and word.endswith('}')):
                if match in params:
                    value = np.random.choice(params[match])
                    dialogue = dialogue.replace(f"{{{match}}}", value)
                else:
                    # ç‚ºæœªå®šç¾©çš„åƒæ•¸ç”Ÿæˆéš¨æ©Ÿå€¼
                    value = f"{match}_{np.random.randint(1, 100)}"
                    dialogue = dialogue.replace(f"{{{match}}}", value)
            
            dialogues.append({
                "user_input": dialogue,
                "actual_intent": intent,
                "timestamp": datetime.now().isoformat(),
                "generated": True
            })
        
        return dialogues

async def simulate_continuous_learning():
    """æ¨¡æ“¬æŒçºŒå­¸ç¿’éç¨‹"""
    system = ContinuousLearningSystem()
    
    # å•Ÿå‹•å­¸ç¿’ä»»å‹™
    learning_task = asyncio.create_task(system.start_continuous_learning())
    
    logger.info("ğŸ® é–‹å§‹ç”Ÿæˆå¤šæ¨£åŒ–å°è©±æ•¸æ“š...")
    
    # ç”Ÿæˆå¤§é‡å¤šæ¨£åŒ–å°è©±
    generated_dialogues = system.generate_diverse_dialogues(count=200)
    
    # æ··åˆçœŸå¯¦æ¨¡å¼çš„äº¤äº’æ•¸æ“š
    real_patterns = [
        # è¤‡é›œæŸ¥è©¢
        {"user_input": "å¹«æˆ‘æ‰¾å‡ºæ‰€æœ‰ä½¿ç”¨äº†deprecated APIçš„åœ°æ–¹ä¸¦æä¾›ä¿®å¾©å»ºè­°", "actual_intent": "search_code"},
        {"user_input": "åˆ†æä¸€ä¸‹ç‚ºä»€éº¼å–®å…ƒæ¸¬è©¦åœ¨CIç’°å¢ƒæœƒå¤±æ•—ä½†æœ¬åœ°èƒ½é€šé", "actual_intent": "debug_error"},
        {"user_input": "é‡æ§‹é€™å€‹å‡½æ•¸ï¼Œè®“å®ƒæ”¯æŒç•°æ­¥æ“ä½œä¸¦ä¿æŒå‘å¾Œå…¼å®¹", "actual_intent": "edit_code"},
        
        # å¤šæ­¥é©Ÿä»»å‹™
        {"user_input": "å‰µå»ºä¸€å€‹å®Œæ•´çš„ç”¨æˆ¶èªè­‰ç³»çµ±ï¼ŒåŒ…æ‹¬ç™»éŒ„ã€è¨»å†Šå’Œå¯†ç¢¼é‡ç½®", "actual_intent": "write_code"},
        {"user_input": "æŠŠæ‰€æœ‰çš„class componentæ”¹æˆfunctional componentä¸¦ä½¿ç”¨hooks", "actual_intent": "edit_code"},
        {"user_input": "è¨­ç½®GitHub Actionsä¾†è‡ªå‹•é‹è¡Œæ¸¬è©¦å’Œéƒ¨ç½²", "actual_intent": "write_code"},
        
        # æ€§èƒ½ç›¸é—œ
        {"user_input": "å„ªåŒ–é€™å€‹æŸ¥è©¢ï¼Œç¾åœ¨éœ€è¦30ç§’æ‰èƒ½åŸ·è¡Œå®Œ", "actual_intent": "fix_bug"},
        {"user_input": "æ‰¾å‡ºå…§å­˜æ´©æ¼çš„åŸå› ä¸¦ä¿®å¾©", "actual_intent": "debug_error"},
        {"user_input": "å¯¦ç¾ç·©å­˜æ©Ÿåˆ¶ä¾†æ¸›å°‘APIèª¿ç”¨æ¬¡æ•¸", "actual_intent": "write_code"},
        
        # å®‰å…¨ç›¸é—œ
        {"user_input": "æª¢æŸ¥ä»£ç¢¼ä¸­æ˜¯å¦æœ‰SQLæ³¨å…¥æ¼æ´", "actual_intent": "search_code"},
        {"user_input": "æ·»åŠ è¼¸å…¥é©—è­‰é˜²æ­¢XSSæ”»æ“Š", "actual_intent": "fix_bug"},
        {"user_input": "å¯¦ç¾JWT tokençš„åˆ·æ–°æ©Ÿåˆ¶", "actual_intent": "write_code"}
    ]
    
    # åˆä½µæ‰€æœ‰å°è©±
    all_dialogues = generated_dialogues + real_patterns
    np.random.shuffle(all_dialogues)
    
    logger.info(f"ğŸ“Š ç¸½å…±ç”Ÿæˆ {len(all_dialogues)} å€‹å°è©±æ¨£æœ¬")
    
    # æ‰¹é‡è™•ç†å°è©±
    batch_size = 20
    for i in range(0, len(all_dialogues), batch_size):
        batch = all_dialogues[i:i+batch_size]
        logger.info(f"\nğŸ“¤ è™•ç†ç¬¬ {i//batch_size + 1} æ‰¹ ({len(batch)} å€‹æ¨£æœ¬)...")
        
        for dialogue in batch:
            # æ¨¡æ“¬é æ¸¬å’ŒåŸ·è¡Œ
            dialogue["predicted_intent"] = dialogue["actual_intent"] if np.random.random() > 0.15 else np.random.choice(list(templates.keys()))
            dialogue["confidence"] = np.random.uniform(0.3, 0.95)
            dialogue["success"] = dialogue["predicted_intent"] == dialogue["actual_intent"] and np.random.random() > 0.1
            dialogue["execution_time"] = np.random.uniform(0.05, 3.0)
            
            # æ ¹æ“šæ„åœ–åˆ†é…å·¥å…·
            tool_mapping = {
                "read_code": ["Read", "Glob"],
                "write_code": ["Write", "MultiEdit"],
                "edit_code": ["Edit", "MultiEdit"],
                "debug_error": ["Read", "Grep", "Task"],
                "fix_bug": ["Edit", "MultiEdit", "SmartIntervention"],
                "search_code": ["Grep", "Search", "Glob"],
                "run_test": ["Bash", "Read"],
                "run_command": ["Bash"]
            }
            dialogue["tools_used"] = tool_mapping.get(dialogue["actual_intent"], ["Task"])
            
            await system.learn_from_interaction(dialogue)
            
        await asyncio.sleep(2)  # æ‰¹æ¬¡é–“éš”
    
    # ç­‰å¾…å­¸ç¿’å®Œæˆ
    await asyncio.sleep(5)
    
    # ç”Ÿæˆå ±å‘Š
    report = system.generate_learning_report()
    print(report)
    
    # ä¿å­˜è©³ç´°å ±å‘Š
    detailed_report = f"""
# æŒçºŒå­¸ç¿’ç³»çµ±è©³ç´°å ±å‘Š

## ç”Ÿæˆçš„å°è©±çµ±è¨ˆ
- ç¸½å°è©±æ•¸: {len(all_dialogues)}
- è‡ªå‹•ç”Ÿæˆ: {len(generated_dialogues)}
- çœŸå¯¦æ¨¡å¼: {len(real_patterns)}

## å°è©±ç¤ºä¾‹
### è‡ªå‹•ç”Ÿæˆçš„å°è©±:
"""
    
    for dialogue in generated_dialogues[:5]:
        detailed_report += f"- {dialogue['user_input']} ({dialogue['actual_intent']})\n"
    
    detailed_report += "\n### çœŸå¯¦æ¨¡å¼å°è©±:\n"
    for dialogue in real_patterns[:5]:
        detailed_report += f"- {dialogue['user_input']} ({dialogue['actual_intent']})\n"
    
    detailed_report += f"\n{report}"
    
    with open("continuous_learning_detailed_report.md", 'w') as f:
        f.write(detailed_report)
    
    logger.info("ğŸ“„ è©³ç´°å ±å‘Šå·²ä¿å­˜")
    
    # å–æ¶ˆå­¸ç¿’ä»»å‹™
    learning_task.cancel()
    
    return system


async def main():
    """ä¸»å‡½æ•¸"""
    system = await simulate_continuous_learning()
    logger.info("\nâœ… æŒçºŒå­¸ç¿’æ¼”ç¤ºå®Œæˆ")
    
    # é¡¯ç¤ºæœ€çµ‚çµ±è¨ˆ
    print("\nğŸ¯ æŒçºŒå­¸ç¿’ç³»çµ±ç‰¹é»:")
    print("1. å¯¦æ™‚å¾ç”¨æˆ¶äº¤äº’ä¸­å­¸ç¿’")
    print("2. è‡ªå‹•è­˜åˆ¥é«˜åƒ¹å€¼å­¸ç¿’æ¨£æœ¬")
    print("3. å‹•æ…‹èª¿æ•´å­¸ç¿’ç‡")
    print("4. å®šæœŸè©•ä¼°å’Œå„ªåŒ–")
    print("5. æ”¯æŒæ–·é»æ¢å¾©å’Œç‰ˆæœ¬ç®¡ç†")


if __name__ == "__main__":
    asyncio.run(main())