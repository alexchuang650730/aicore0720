#!/usr/bin/env python3
"""
æ„åœ–ç†è§£è©•ä¼°ç³»çµ±
å°ˆæ³¨æ–¼å·¥å…·èª¿ç”¨æº–ç¢ºç‡å’Œæ„åœ–ç†è§£è©•åˆ†
ç›®æ¨™ï¼šç¬¬ä¸€éšæ®µé”åˆ°100%å·¥å…·èª¿ç”¨æº–ç¢ºç‡
"""

import json
import logging
import time
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from enum import Enum
from groq import Groq
import numpy as np

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class IntentType(Enum):
    """ç”¨æˆ¶æ„åœ–é¡å‹"""
    CODE_GENERATION = "ä»£ç¢¼ç”Ÿæˆ"
    FILE_OPERATION = "æ–‡ä»¶æ“ä½œ"
    CODE_ANALYSIS = "ä»£ç¢¼åˆ†æ"
    CODE_REFACTOR = "ä»£ç¢¼é‡æ§‹"
    PROJECT_SETUP = "å°ˆæ¡ˆè¨­ç½®"
    DEBUG_HELP = "èª¿è©¦å¹«åŠ©"
    SEARCH_CODE = "æœç´¢ä»£ç¢¼"
    RUN_COMMAND = "åŸ·è¡Œå‘½ä»¤"
    DOCUMENTATION = "æ–‡æª”ç·¨å¯«"
    TESTING = "æ¸¬è©¦ç›¸é—œ"


@dataclass
class IntentEvaluation:
    """æ„åœ–è©•ä¼°çµæœ"""
    intent_type: IntentType
    confidence: float  # æ„åœ–è­˜åˆ¥ä¿¡å¿ƒåº¦ 0-1
    tool_accuracy: float  # å·¥å…·èª¿ç”¨æº–ç¢ºç‡ 0-1
    tool_sequence_correct: bool  # å·¥å…·èª¿ç”¨é †åºæ˜¯å¦æ­£ç¢º
    missing_tools: List[str]  # ç¼ºå¤±çš„å·¥å…·
    extra_tools: List[str]  # å¤šé¤˜çš„å·¥å…·
    intent_fulfillment: float  # æ„åœ–æ»¿è¶³åº¦ 0-1


class IntentUnderstandingEvaluator:
    """æ„åœ–ç†è§£è©•ä¼°å™¨"""
    
    def __init__(self, groq_api_key: str):
        self.groq_client = Groq(api_key=groq_api_key)
        self.k2_model = "moonshotai/kimi-k2-instruct"
        
        # æ„åœ–åˆ°å·¥å…·çš„æ˜ å°„è¦å‰‡
        self.intent_tool_mapping = {
            IntentType.CODE_GENERATION: {
                "required": [],
                "optional": ["Write"],
                "sequence": []
            },
            IntentType.FILE_OPERATION: {
                "required": ["Read"],
                "optional": ["Grep", "Glob", "LS"],
                "sequence": ["Read"]  # Read é€šå¸¸å…ˆåŸ·è¡Œ
            },
            IntentType.CODE_ANALYSIS: {
                "required": ["Read"],
                "optional": ["Grep", "Glob", "Task"],
                "sequence": ["Read", "Grep"]
            },
            IntentType.CODE_REFACTOR: {
                "required": ["Read", "Edit"],
                "optional": ["MultiEdit", "Write"],
                "sequence": ["Read", "Edit"]  # å…ˆè®€å¾Œæ”¹
            },
            IntentType.PROJECT_SETUP: {
                "required": ["Bash"],
                "optional": ["Write", "Edit"],
                "sequence": ["Bash", "Write"]  # å…ˆå‰µå»ºç›®éŒ„å¾Œå¯«æ–‡ä»¶
            },
            IntentType.DEBUG_HELP: {
                "required": [],
                "optional": ["Read", "Grep", "Bash"],
                "sequence": []
            },
            IntentType.SEARCH_CODE: {
                "required": ["Grep"],
                "optional": ["Glob", "Task", "Read"],
                "sequence": ["Grep"]  # Grep æ˜¯ä¸»è¦å·¥å…·
            },
            IntentType.RUN_COMMAND: {
                "required": ["Bash"],
                "optional": [],
                "sequence": ["Bash"]
            },
            IntentType.DOCUMENTATION: {
                "required": ["Write"],
                "optional": ["Read", "Edit"],
                "sequence": []
            },
            IntentType.TESTING: {
                "required": ["Bash"],
                "optional": ["Read", "Write", "Edit"],
                "sequence": ["Bash"]  # é‹è¡Œæ¸¬è©¦
            }
        }
        
        # æ¸¬è©¦æ¡ˆä¾‹ï¼ˆåŒ…å«æ›´å¤šæ„åœ–ç†è§£å ´æ™¯ï¼‰
        self.test_cases = self._create_comprehensive_test_cases()
    
    def _create_comprehensive_test_cases(self) -> List[Dict]:
        """å‰µå»ºå…¨é¢çš„æ¸¬è©¦æ¡ˆä¾‹"""
        return [
            # æ–‡ä»¶æ“ä½œæ„åœ–
            {
                "id": "file_read_analyze",
                "prompt": "è«‹å¹«æˆ‘è®€å– main.py æ–‡ä»¶ä¸¦æ‰¾å‡ºæ‰€æœ‰çš„å‡½æ•¸å®šç¾©",
                "intent": IntentType.FILE_OPERATION,
                "expected_tools": ["Read", "Grep"],
                "tool_sequence": ["Read", "Grep"]
            },
            {
                "id": "search_pattern",
                "prompt": "åœ¨æ‰€æœ‰ Python æ–‡ä»¶ä¸­æœç´¢åŒ…å« 'TODO' çš„è¨»é‡‹",
                "intent": IntentType.SEARCH_CODE,
                "expected_tools": ["Grep"],
                "tool_sequence": ["Grep"]
            },
            {
                "id": "refactor_code",
                "prompt": "å°‡ config.py ä¸­çš„æ‰€æœ‰ print èªå¥æ”¹ç‚º logger.info",
                "intent": IntentType.CODE_REFACTOR,
                "expected_tools": ["Read", "Edit"],
                "tool_sequence": ["Read", "Edit"]
            },
            {
                "id": "create_project",
                "prompt": "å‰µå»ºä¸€å€‹æ–°çš„ Flask å°ˆæ¡ˆï¼ŒåŒ…å«åŸºæœ¬çš„ç›®éŒ„çµæ§‹å’Œé…ç½®æ–‡ä»¶",
                "intent": IntentType.PROJECT_SETUP,
                "expected_tools": ["Bash", "Write"],
                "tool_sequence": ["Bash", "Write"]
            },
            {
                "id": "run_tests",
                "prompt": "é‹è¡Œæ‰€æœ‰çš„å–®å…ƒæ¸¬è©¦ä¸¦é¡¯ç¤ºè¦†è“‹ç‡å ±å‘Š",
                "intent": IntentType.TESTING,
                "expected_tools": ["Bash"],
                "tool_sequence": ["Bash"]
            },
            {
                "id": "analyze_error",
                "prompt": "åˆ†æé€™å€‹éŒ¯èª¤ä¸¦çµ¦å‡ºè§£æ±ºæ–¹æ¡ˆ: ImportError: No module named 'requests'",
                "intent": IntentType.DEBUG_HELP,
                "expected_tools": [],  # å¯èƒ½ä¸éœ€è¦å·¥å…·ï¼Œåªéœ€åˆ†æ
                "tool_sequence": []
            },
            {
                "id": "multi_file_refactor",
                "prompt": "å°‡æ‰€æœ‰æ–‡ä»¶ä¸­çš„é¡å UserManager æ”¹ç‚º UserService",
                "intent": IntentType.CODE_REFACTOR,
                "expected_tools": ["Grep", "Read", "Edit"],
                "tool_sequence": ["Grep", "Read", "Edit"]
            },
            {
                "id": "complex_search",
                "prompt": "æ‰¾å‡ºæ‰€æœ‰å®šç¾©äº† async å‡½æ•¸ä½†æ²’æœ‰ä½¿ç”¨ await çš„æ–‡ä»¶",
                "intent": IntentType.SEARCH_CODE,
                "expected_tools": ["Grep", "Read"],
                "tool_sequence": ["Grep", "Read"]
            },
            {
                "id": "create_documentation",
                "prompt": "ç‚ºé€™å€‹å°ˆæ¡ˆå‰µå»ºä¸€å€‹è©³ç´°çš„ README.md æ–‡ä»¶",
                "intent": IntentType.DOCUMENTATION,
                "expected_tools": ["Write"],
                "tool_sequence": ["Write"]
            },
            {
                "id": "install_dependencies",
                "prompt": "å®‰è£ requirements.txt ä¸­çš„æ‰€æœ‰ä¾è³´ä¸¦ç¢ºä¿æ²’æœ‰ç‰ˆæœ¬è¡çª",
                "intent": IntentType.RUN_COMMAND,
                "expected_tools": ["Bash"],
                "tool_sequence": ["Bash"]
            }
        ]
    
    def _detect_intent(self, prompt: str) -> Tuple[IntentType, float]:
        """æª¢æ¸¬ç”¨æˆ¶æ„åœ–"""
        # é—œéµè©æ˜ å°„
        intent_keywords = {
            IntentType.FILE_OPERATION: ["è®€å–", "æ‰“é–‹", "æŸ¥çœ‹", "æ–‡ä»¶", "å…§å®¹"],
            IntentType.SEARCH_CODE: ["æœç´¢", "æŸ¥æ‰¾", "å°‹æ‰¾", "grep", "åŒ…å«"],
            IntentType.CODE_REFACTOR: ["é‡æ§‹", "ä¿®æ”¹", "æ”¹ç‚º", "æ›¿æ›", "æ›´æ–°"],
            IntentType.PROJECT_SETUP: ["å‰µå»º", "å°ˆæ¡ˆ", "é …ç›®", "çµæ§‹", "åˆå§‹åŒ–"],
            IntentType.TESTING: ["æ¸¬è©¦", "é‹è¡Œ", "pytest", "è¦†è“‹ç‡", "å–®å…ƒæ¸¬è©¦"],
            IntentType.DEBUG_HELP: ["éŒ¯èª¤", "ç•°å¸¸", "èª¿è©¦", "è§£æ±º", "åˆ†æ"],
            IntentType.CODE_GENERATION: ["å¯«", "ç”Ÿæˆ", "å‰µå»ºå‡½æ•¸", "å¯¦ç¾"],
            IntentType.RUN_COMMAND: ["åŸ·è¡Œ", "é‹è¡Œ", "å®‰è£", "å‘½ä»¤"],
            IntentType.DOCUMENTATION: ["æ–‡æª”", "README", "èªªæ˜", "è¨»é‡‹"],
            IntentType.CODE_ANALYSIS: ["åˆ†æ", "ç†è§£", "è§£é‡‹", "æª¢æŸ¥"]
        }
        
        prompt_lower = prompt.lower()
        intent_scores = {}
        
        for intent, keywords in intent_keywords.items():
            score = sum(1 for keyword in keywords if keyword.lower() in prompt_lower)
            intent_scores[intent] = score
        
        # æ‰¾å‡ºæœ€é«˜åˆ†çš„æ„åœ–
        best_intent = max(intent_scores, key=intent_scores.get)
        max_score = intent_scores[best_intent]
        
        # è¨ˆç®—ä¿¡å¿ƒåº¦ï¼ˆåŸºæ–¼é—œéµè©åŒ¹é…æ•¸é‡ï¼‰
        confidence = min(max_score / 3.0, 1.0) if max_score > 0 else 0.3
        
        return best_intent, confidence
    
    def _extract_tools_from_response(self, response: str) -> List[str]:
        """å¾å›æ‡‰ä¸­æå–å·¥å…·èª¿ç”¨"""
        import re
        tools = []
        
        # æå– <invoke name="..."> æ ¼å¼
        invokes = re.findall(r'<invoke name="([^"]+)">', response)
        tools.extend(invokes)
        
        # æå– function_calls æ ¼å¼
        func_calls = re.findall(r'<function_calls>.*?name="([^"]+)".*?</function_calls>', 
                               response, re.DOTALL)
        tools.extend(func_calls)
        
        return tools
    
    def evaluate_intent_understanding(self, 
                                    prompt: str, 
                                    response: str,
                                    expected_intent: IntentType,
                                    expected_tools: List[str]) -> IntentEvaluation:
        """è©•ä¼°æ„åœ–ç†è§£å’Œå·¥å…·èª¿ç”¨"""
        
        # æª¢æ¸¬æ„åœ–
        detected_intent, confidence = self._detect_intent(prompt)
        
        # æå–å¯¦éš›ä½¿ç”¨çš„å·¥å…·
        actual_tools = self._extract_tools_from_response(response)
        
        # ç²å–æ„åœ–å°æ‡‰çš„å·¥å…·è¦å‰‡
        tool_rules = self.intent_tool_mapping.get(expected_intent, {})
        required_tools = set(tool_rules.get("required", []))
        optional_tools = set(tool_rules.get("optional", []))
        expected_sequence = tool_rules.get("sequence", [])
        
        # è¨ˆç®—å·¥å…·æº–ç¢ºç‡
        expected_set = set(expected_tools)
        actual_set = set(actual_tools)
        
        # æ‰¾å‡ºç¼ºå¤±å’Œå¤šé¤˜çš„å·¥å…·
        missing_tools = list(expected_set - actual_set)
        extra_tools = list(actual_set - expected_set - optional_tools)
        
        # è¨ˆç®—å·¥å…·æº–ç¢ºç‡
        if not expected_tools:
            tool_accuracy = 1.0 if not actual_tools else 0.5
        else:
            correct_tools = len(expected_set & actual_set)
            tool_accuracy = correct_tools / len(expected_set)
            
            # å¦‚æœæœ‰å¤šé¤˜çš„å·¥å…·ï¼Œæ‰£åˆ†
            if extra_tools:
                tool_accuracy *= 0.8
        
        # æª¢æŸ¥å·¥å…·èª¿ç”¨é †åº
        sequence_correct = True
        if expected_sequence and actual_tools:
            # æª¢æŸ¥é—œéµå·¥å…·çš„é †åº
            for i, tool in enumerate(expected_sequence):
                if tool in actual_tools:
                    actual_index = actual_tools.index(tool)
                    # æª¢æŸ¥æ˜¯å¦æŒ‰é †åºå‡ºç¾
                    for j in range(i):
                        if expected_sequence[j] in actual_tools:
                            prev_index = actual_tools.index(expected_sequence[j])
                            if prev_index > actual_index:
                                sequence_correct = False
                                break
        
        # è¨ˆç®—æ„åœ–æ»¿è¶³åº¦
        intent_fulfillment = 0.0
        
        # æ„åœ–åŒ¹é…æ¬Šé‡ 40%
        if detected_intent == expected_intent:
            intent_fulfillment += 0.4
        
        # å·¥å…·æº–ç¢ºç‡æ¬Šé‡ 40%
        intent_fulfillment += tool_accuracy * 0.4
        
        # å·¥å…·é †åºæ¬Šé‡ 20%
        if sequence_correct:
            intent_fulfillment += 0.2
        
        return IntentEvaluation(
            intent_type=detected_intent,
            confidence=confidence,
            tool_accuracy=tool_accuracy,
            tool_sequence_correct=sequence_correct,
            missing_tools=missing_tools,
            extra_tools=extra_tools,
            intent_fulfillment=intent_fulfillment
        )
    
    def generate_k2_response_with_intent(self, prompt: str, intent: IntentType) -> Dict:
        """ç”Ÿæˆå¸¶æœ‰æ„åœ–ç†è§£çš„K2å›æ‡‰"""
        
        # æ§‹å»ºæç¤ºï¼Œå¼·èª¿å·¥å…·ä½¿ç”¨
        tool_rules = self.intent_tool_mapping.get(intent, {})
        required_tools = tool_rules.get("required", [])
        
        enhanced_prompt = f"""
ä½ æ˜¯ä¸€å€‹ç²¾ç¢ºçš„ç·¨ç¨‹åŠ©æ‰‹ã€‚ç”¨æˆ¶çš„æ„åœ–æ˜¯ï¼š{intent.value}

å¿…é ˆä½¿ç”¨çš„å·¥å…·ï¼š{', '.join(required_tools) if required_tools else 'æ ¹æ“šéœ€è¦é¸æ“‡'}

å¯ç”¨å·¥å…·ï¼š
- Read: è®€å–æ–‡ä»¶å…§å®¹
- Write: å¯«å…¥æ–°æ–‡ä»¶
- Edit/MultiEdit: ç·¨è¼¯ç¾æœ‰æ–‡ä»¶
- Grep: æœç´¢æ–‡ä»¶å…§å®¹
- Glob: æŸ¥æ‰¾æ–‡ä»¶
- Bash: åŸ·è¡Œå‘½ä»¤
- Task: è¤‡é›œä»»å‹™ä»£ç†

ä½¿ç”¨å·¥å…·æ™‚è«‹ç”¨ä»¥ä¸‹æ ¼å¼ï¼š
<function_calls>
<invoke name="å·¥å…·å">
<parameter name="åƒæ•¸å">åƒæ•¸å€¼</parameter>
</invoke>
</function_calls>

ç”¨æˆ¶è«‹æ±‚: {prompt}
"""
        
        try:
            completion = self.groq_client.chat.completions.create(
                model=self.k2_model,
                messages=[{"role": "user", "content": enhanced_prompt}],
                temperature=0.3,  # é™ä½æº«åº¦ä»¥æé«˜ä¸€è‡´æ€§
                max_completion_tokens=1024
            )
            
            response = completion.choices[0].message.content
            tools = self._extract_tools_from_response(response)
            
            return {
                "response": response,
                "tools": tools,
                "success": True
            }
            
        except Exception as e:
            logger.error(f"K2 ç”Ÿæˆå¤±æ•—: {e}")
            return {
                "response": f"éŒ¯èª¤: {str(e)}",
                "tools": [],
                "success": False
            }
    
    def run_intent_evaluation_suite(self) -> Dict:
        """é‹è¡Œå®Œæ•´çš„æ„åœ–è©•ä¼°å¥—ä»¶"""
        results = {
            "test_time": time.strftime("%Y-%m-%d %H:%M:%S"),
            "test_results": [],
            "intent_metrics": {},
            "overall_metrics": {}
        }
        
        # æŒ‰æ„åœ–é¡å‹çµ±è¨ˆ
        intent_stats = {intent: {"total": 0, "accuracy": 0, "fulfillment": 0} 
                       for intent in IntentType}
        
        total_tool_accuracy = 0
        total_intent_fulfillment = 0
        successful_tests = 0
        
        for test_case in self.test_cases:
            logger.info(f"\nğŸ§ª æ¸¬è©¦: {test_case['id']} - {test_case['intent'].value}")
            logger.info(f"ğŸ“ æç¤º: {test_case['prompt']}")
            
            # ç”ŸæˆK2å›æ‡‰
            k2_result = self.generate_k2_response_with_intent(
                test_case['prompt'],
                test_case['intent']
            )
            
            if k2_result['success']:
                # è©•ä¼°æ„åœ–ç†è§£
                evaluation = self.evaluate_intent_understanding(
                    test_case['prompt'],
                    k2_result['response'],
                    test_case['intent'],
                    test_case['expected_tools']
                )
                
                logger.info(f"âœ… å·¥å…·æº–ç¢ºç‡: {evaluation.tool_accuracy:.1%}")
                logger.info(f"ğŸ¯ æ„åœ–æ»¿è¶³åº¦: {evaluation.intent_fulfillment:.1%}")
                
                # è¨˜éŒ„çµæœ
                test_result = {
                    "test_id": test_case['id'],
                    "prompt": test_case['prompt'],
                    "intent": test_case['intent'].value,
                    "detected_intent": evaluation.intent_type.value,
                    "confidence": evaluation.confidence,
                    "expected_tools": test_case['expected_tools'],
                    "actual_tools": k2_result['tools'],
                    "tool_accuracy": evaluation.tool_accuracy,
                    "sequence_correct": evaluation.tool_sequence_correct,
                    "missing_tools": evaluation.missing_tools,
                    "extra_tools": evaluation.extra_tools,
                    "intent_fulfillment": evaluation.intent_fulfillment,
                    "response_preview": k2_result['response'][:200] + "..."
                }
                
                results["test_results"].append(test_result)
                
                # æ›´æ–°çµ±è¨ˆ
                intent_stats[test_case['intent']]["total"] += 1
                intent_stats[test_case['intent']]["accuracy"] += evaluation.tool_accuracy
                intent_stats[test_case['intent']]["fulfillment"] += evaluation.intent_fulfillment
                
                total_tool_accuracy += evaluation.tool_accuracy
                total_intent_fulfillment += evaluation.intent_fulfillment
                successful_tests += 1
                
            else:
                results["test_results"].append({
                    "test_id": test_case['id'],
                    "error": k2_result['response'],
                    "success": False
                })
            
            time.sleep(1)  # é¿å…é€Ÿç‡é™åˆ¶
        
        # è¨ˆç®—ç¸½é«”æŒ‡æ¨™
        if successful_tests > 0:
            results["overall_metrics"] = {
                "average_tool_accuracy": total_tool_accuracy / successful_tests,
                "average_intent_fulfillment": total_intent_fulfillment / successful_tests,
                "success_rate": successful_tests / len(self.test_cases),
                "total_tests": len(self.test_cases),
                "successful_tests": successful_tests
            }
            
            # è¨ˆç®—æ¯å€‹æ„åœ–é¡å‹çš„å¹³å‡å€¼
            for intent, stats in intent_stats.items():
                if stats["total"] > 0:
                    results["intent_metrics"][intent.value] = {
                        "average_accuracy": stats["accuracy"] / stats["total"],
                        "average_fulfillment": stats["fulfillment"] / stats["total"],
                        "test_count": stats["total"]
                    }
        
        return results
    
    def generate_improvement_plan(self, results: Dict) -> str:
        """ç”Ÿæˆæ”¹é€²è¨ˆåŠƒ"""
        plan = """
# æ„åœ–ç†è§£æ”¹é€²è¨ˆåŠƒ

## ç•¶å‰ç‹€æ…‹
"""
        
        metrics = results["overall_metrics"]
        plan += f"""
- **å¹³å‡å·¥å…·æº–ç¢ºç‡**: {metrics['average_tool_accuracy']:.1%}
- **å¹³å‡æ„åœ–æ»¿è¶³åº¦**: {metrics['average_intent_fulfillment']:.1%}
- **æ¸¬è©¦æˆåŠŸç‡**: {metrics['success_rate']:.1%}

## åˆ†æ„åœ–é¡å‹åˆ†æ
"""
        
        # æ‰¾å‡ºéœ€è¦æ”¹é€²çš„æ„åœ–é¡å‹
        improvement_needed = []
        
        for intent_type, metrics in results["intent_metrics"].items():
            plan += f"\n### {intent_type}\n"
            plan += f"- å·¥å…·æº–ç¢ºç‡: {metrics['average_accuracy']:.1%}\n"
            plan += f"- æ„åœ–æ»¿è¶³åº¦: {metrics['average_fulfillment']:.1%}\n"
            
            if metrics['average_accuracy'] < 0.9:
                improvement_needed.append((intent_type, metrics['average_accuracy']))
        
        # ç”Ÿæˆå…·é«”æ”¹é€²å»ºè­°
        plan += "\n## æ”¹é€²ç­–ç•¥\n\n"
        
        if improvement_needed:
            plan += "### å„ªå…ˆæ”¹é€²é …ç›®\n"
            for intent_type, accuracy in sorted(improvement_needed, key=lambda x: x[1]):
                plan += f"\n**{intent_type}** (ç•¶å‰æº–ç¢ºç‡: {accuracy:.1%})\n"
                
                # åˆ†æå¸¸è¦‹éŒ¯èª¤
                intent_errors = [r for r in results["test_results"] 
                               if r.get("intent") == intent_type and r.get("tool_accuracy", 0) < 1.0]
                
                if intent_errors:
                    plan += "å¸¸è¦‹å•é¡Œ:\n"
                    for error in intent_errors[:3]:
                        if error.get("missing_tools"):
                            plan += f"- ç¼ºå¤±å·¥å…·: {', '.join(error['missing_tools'])}\n"
                        if error.get("extra_tools"):
                            plan += f"- å¤šé¤˜å·¥å…·: {', '.join(error['extra_tools'])}\n"
        
        # è¨“ç·´å»ºè­°
        plan += """
### è¨“ç·´å»ºè­°

1. **å¢å¼·å·¥å…·é¸æ“‡è¨“ç·´**
   - æ”¶é›†æ›´å¤šåŒ…å«æ­£ç¢ºå·¥å…·èª¿ç”¨çš„å°è©±
   - ç‚ºæ¯å€‹æ„åœ–é¡å‹å‰µå»ºå°ˆé–€çš„è¨“ç·´æ•¸æ“š
   - å¼·åŒ–å·¥å…·èª¿ç”¨é †åºçš„å­¸ç¿’

2. **æ„åœ–è­˜åˆ¥å„ªåŒ–**
   - æ“´å……æ„åœ–é—œéµè©åº«
   - ä½¿ç”¨æ›´è¤‡é›œçš„æ„åœ–åˆ†é¡æ¨¡å‹
   - å¢åŠ ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›

3. **æ¼¸é€²å¼æ”¹é€²è·¯å¾‘**
   - ç¬¬ä¸€éšæ®µï¼šé”åˆ°90%å·¥å…·æº–ç¢ºç‡
   - ç¬¬äºŒéšæ®µï¼šé”åˆ°95%å·¥å…·æº–ç¢ºç‡
   - ç¬¬ä¸‰éšæ®µï¼šé”åˆ°100%å·¥å…·æº–ç¢ºç‡
"""
        
        return plan


def main():
    """ä¸»å‡½æ•¸"""
    api_key = os.getenv("GROQ_API_KEY", "your-api-key-here")
    
    logger.info("ğŸš€ å•Ÿå‹•æ„åœ–ç†è§£è©•ä¼°ç³»çµ±")
    logger.info("ğŸ¯ ç›®æ¨™ï¼šç¬¬ä¸€éšæ®µé”åˆ°100%å·¥å…·èª¿ç”¨æº–ç¢ºç‡")
    
    # å‰µå»ºè©•ä¼°å™¨
    evaluator = IntentUnderstandingEvaluator(api_key)
    
    # é‹è¡Œè©•ä¼°
    results = evaluator.run_intent_evaluation_suite()
    
    # ç”Ÿæˆæ”¹é€²è¨ˆåŠƒ
    improvement_plan = evaluator.generate_improvement_plan(results)
    
    # ä¿å­˜çµæœ
    with open("intent_evaluation_results.json", "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    with open("intent_improvement_plan.md", "w", encoding="utf-8") as f:
        f.write(improvement_plan)
    
    # ç”Ÿæˆè©³ç´°å ±å‘Š
    report = f"""
# æ„åœ–ç†è§£è©•ä¼°å ±å‘Š

æ¸¬è©¦æ™‚é–“: {results['test_time']}

## ç¸½é«”æŒ‡æ¨™

- **å¹³å‡å·¥å…·æº–ç¢ºç‡**: {results['overall_metrics']['average_tool_accuracy']:.1%}
- **å¹³å‡æ„åœ–æ»¿è¶³åº¦**: {results['overall_metrics']['average_intent_fulfillment']:.1%}
- **è·é›¢ç›®æ¨™å·®è·**: {100 - results['overall_metrics']['average_tool_accuracy']*100:.1f}%

## è©³ç´°æ¸¬è©¦çµæœ
"""
    
    for test in results['test_results']:
        if test.get('success', True):
            report += f"""
### {test['test_id']}

- **æç¤º**: {test['prompt']}
- **æ„åœ–**: {test['intent']} â†’ {test['detected_intent']}
- **å·¥å…·æº–ç¢ºç‡**: {test['tool_accuracy']:.1%}
- **é æœŸå·¥å…·**: {', '.join(test['expected_tools']) if test['expected_tools'] else 'ç„¡'}
- **å¯¦éš›å·¥å…·**: {', '.join(test['actual_tools']) if test['actual_tools'] else 'ç„¡'}
- **ç¼ºå¤±å·¥å…·**: {', '.join(test['missing_tools']) if test['missing_tools'] else 'ç„¡'}
- **é †åºæ­£ç¢º**: {'âœ…' if test['sequence_correct'] else 'âŒ'}

---
"""
    
    with open("intent_evaluation_report.md", "w", encoding="utf-8") as f:
        f.write(report)
    
    # æ‰“å°æ‘˜è¦
    logger.info("\n" + "="*50)
    logger.info("ğŸ“Š è©•ä¼°å®Œæˆï¼")
    logger.info(f"ğŸ¯ å·¥å…·æº–ç¢ºç‡: {results['overall_metrics']['average_tool_accuracy']:.1%}")
    logger.info(f"ğŸ“ˆ æ„åœ–æ»¿è¶³åº¦: {results['overall_metrics']['average_intent_fulfillment']:.1%}")
    logger.info(f"ğŸš€ è·é›¢100%ç›®æ¨™: {100 - results['overall_metrics']['average_tool_accuracy']*100:.1f}%")
    logger.info("\nè©³ç´°å ±å‘Šå·²ä¿å­˜è‡³:")
    logger.info("- intent_evaluation_results.json")
    logger.info("- intent_evaluation_report.md")
    logger.info("- intent_improvement_plan.md")


if __name__ == "__main__":
    main()