#!/usr/bin/env python3
"""
æª¢æŸ¥è¨“ç·´ç³»çµ±ç‹€æ…‹
"""

import subprocess
import psutil
import json
from pathlib import Path
from datetime import datetime


def check_system_status():
    """æª¢æŸ¥æ‰€æœ‰è¨“ç·´ç³»çµ±çµ„ä»¶ç‹€æ…‹"""
    
    print("ğŸ” æª¢æŸ¥è¨“ç·´ç³»çµ±ç‹€æ…‹...")
    print("=" * 60)
    
    # 1. æª¢æŸ¥Pythoné€²ç¨‹
    python_processes = []
    for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
        try:
            if 'python' in proc.info['name'].lower():
                cmdline = ' '.join(proc.info['cmdline'] or [])
                if any(keyword in cmdline for keyword in ['unified', 'collector', 'replay', 'k2']):
                    python_processes.append({
                        'pid': proc.info['pid'],
                        'script': cmdline.split()[-1] if cmdline.split() else 'unknown'
                    })
        except:
            pass
    
    print("ğŸ“Š é‹è¡Œä¸­çš„è¨“ç·´é€²ç¨‹:")
    if python_processes:
        for proc in python_processes:
            print(f"  âœ… PID {proc['pid']}: {proc['script']}")
    else:
        print("  âŒ æ²’æœ‰ç™¼ç¾è¨“ç·´é€²ç¨‹")
    
    # 2. æª¢æŸ¥æœ€æ–°çš„æ—¥èªŒ
    print("\nğŸ“ æœ€æ–°æ—¥èªŒç‹€æ…‹:")
    log_file = Path("unified_k2_training.log")
    if log_file.exists():
        # ç²å–æœ€å¾Œå¹¾è¡Œ
        result = subprocess.run(['tail', '-n', '5', str(log_file)], 
                              capture_output=True, text=True)
        if result.stdout:
            for line in result.stdout.strip().split('\n'):
                if 'ç›®æ¨™é”æˆç‡' in line:
                    print(f"  {line}")
                elif 'Claude Codeç›¸ä¼¼åº¦' in line:
                    print(f"  {line}")
    
    # 3. æª¢æŸ¥è¨“ç·´æ•¸æ“š
    print("\nğŸ’¾ è¨“ç·´æ•¸æ“šçµ±è¨ˆ:")
    data_dir = Path("data")
    
    # çµ±è¨ˆreplayæ–‡ä»¶
    replay_files = list(data_dir.glob("**/replay_*.json"))
    print(f"  - Replayæ–‡ä»¶: {len(replay_files)} å€‹")
    
    # çµ±è¨ˆè¨“ç·´æ¨£æœ¬
    training_samples = 0
    for f in data_dir.glob("**/*training*.jsonl"):
        try:
            with open(f, 'r') as file:
                training_samples += sum(1 for _ in file)
        except:
            pass
    print(f"  - è¨“ç·´æ¨£æœ¬: {training_samples} æ¢")
    
    # 4. æª¢æŸ¥æº–ç¢ºç‡æŒ‡æ¨™
    print("\nğŸ“ˆ ç•¶å‰æ€§èƒ½æŒ‡æ¨™:")
    metrics_file = Path("accuracy_metrics.json")
    if metrics_file.exists():
        try:
            with open(metrics_file, 'r') as f:
                metrics = json.load(f)
                print(f"  - å·¥å…·èª¿ç”¨æº–ç¢ºç‡: {metrics.get('tool_call_accuracy', 'N/A')}%")
                print(f"  - èªç¾©ç›¸ä¼¼åº¦: {metrics.get('semantic_similarity', 'N/A')}%")
        except:
            print("  - æŒ‡æ¨™æ–‡ä»¶æš«ç„¡æ•¸æ“š")
    else:
        print("  - ç­‰å¾…ç”ŸæˆæŒ‡æ¨™...")
    
    # 5. ç³»çµ±å»ºè­°
    print("\nğŸ’¡ ç³»çµ±å»ºè­°:")
    if not python_processes:
        print("  âš ï¸  å»ºè­°é‹è¡Œ: python3 start_optimized_training.py")
    else:
        print("  âœ… ç³»çµ±é‹è¡Œæ­£å¸¸")
    
    if training_samples < 1000:
        print("  âš ï¸  è¨“ç·´æ¨£æœ¬è¼ƒå°‘ï¼Œå»ºè­°è™•ç†æ›´å¤šreplayæ•¸æ“š")
    
    print("\nğŸ¯ 3å¤©ç›®æ¨™é€²åº¦:")
    print("  Day 1 (ä»Šå¤©): 80% æº–ç¢ºç‡")
    print("  Day 2 (æ˜å¤©): 85% æº–ç¢ºç‡") 
    print("  Day 3 (å¾Œå¤©): 89% æº–ç¢ºç‡")
    
    print("=" * 60)
    print(f"æª¢æŸ¥æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


if __name__ == "__main__":
    check_system_status()