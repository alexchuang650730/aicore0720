#!/usr/bin/env python3
"""
å®Œæ•´æ¸¬è©¦K2 Providers
åŒ…å«APIå¯†é‘°
"""

import asyncio
import aiohttp
import time
import json

class K2ProvidersCompleteTest:
    """K2 Providerså®Œæ•´æ¸¬è©¦"""
    
    def __init__(self):
        # ç›´æ¥è¨­ç½®APIå¯†é‘°
        self.api_keys = {
            "groq": "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",
            "moonshot": "sk-ocQ1YiAJtB2yfaXVXFzkW0973MXXKLR0OCEi0BbVqqmc31UK"
        }
        
        self.results = []
    
    async def test_groq(self):
        """æ¸¬è©¦Groq APIæ€§èƒ½"""
        print("\nğŸš€ æ¸¬è©¦Groq Provider")
        print("-"*40)
        
        url = "https://api.groq.com/openai/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {self.api_keys['groq']}",
            "Content-Type": "application/json"
        }
        
        test_messages = [
            {"role": "user", "content": "Hello, respond in one word"},
            {"role": "user", "content": "What is 2+2?"},
            {"role": "user", "content": "Write hello world in Python"}
        ]
        
        latencies = []
        
        async with aiohttp.ClientSession() as session:
            for msg in test_messages:
                start = time.time()
                
                try:
                    async with session.post(
                        url,
                        headers=headers,
                        json={
                            "model": "llama-3.1-8b-instant",
                            "messages": [msg],
                            "max_tokens": 50,
                            "temperature": 0.7
                        }
                    ) as response:
                        if response.status == 200:
                            data = await response.json()
                            latency = (time.time() - start) * 1000
                            latencies.append(latency)
                            
                            content = data['choices'][0]['message']['content']
                            print(f"âœ… æŸ¥è©¢: {msg['content'][:30]}...")
                            print(f"   å»¶é²: {latency:.0f}ms")
                            print(f"   éŸ¿æ‡‰: {content[:50]}...")
                        else:
                            print(f"âŒ éŒ¯èª¤: {response.status}")
                            
                except Exception as e:
                    print(f"âŒ ç•°å¸¸: {e}")
        
        if latencies:
            avg = sum(latencies) / len(latencies)
            self.results.append({
                "provider": "Groq",
                "model": "llama-3.1-8b-instant",
                "avg_latency": avg,
                "min_latency": min(latencies),
                "max_latency": max(latencies),
                "success_rate": f"{len(latencies)}/3"
            })
            print(f"\nğŸ“Š Groqçµ±è¨ˆ:")
            print(f"   å¹³å‡å»¶é²: {avg:.0f}ms")
            print(f"   æœ€ä½/æœ€é«˜: {min(latencies):.0f}ms / {max(latencies):.0f}ms")
    
    async def test_moonshot(self):
        """æ¸¬è©¦Moonshot APIæ€§èƒ½"""
        print("\nğŸŒ™ æ¸¬è©¦Moonshot Provider")
        print("-"*40)
        
        url = "https://api.moonshot.cn/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {self.api_keys['moonshot']}",
            "Content-Type": "application/json"
        }
        
        test_messages = [
            {"role": "user", "content": "ä½ å¥½ï¼Œç”¨ä¸€å€‹è©å›ç­”"},
            {"role": "user", "content": "2åŠ 2ç­‰æ–¼å¹¾ï¼Ÿ"},
            {"role": "user", "content": "ç”¨Pythonå¯«hello world"}
        ]
        
        latencies = []
        
        async with aiohttp.ClientSession() as session:
            for msg in test_messages:
                start = time.time()
                
                try:
                    async with session.post(
                        url,
                        headers=headers,
                        json={
                            "model": "moonshot-v1-8k",
                            "messages": [msg],
                            "max_tokens": 50,
                            "temperature": 0.7
                        }
                    ) as response:
                        if response.status == 200:
                            data = await response.json()
                            latency = (time.time() - start) * 1000
                            latencies.append(latency)
                            
                            content = data['choices'][0]['message']['content']
                            print(f"âœ… æŸ¥è©¢: {msg['content'][:30]}...")
                            print(f"   å»¶é²: {latency:.0f}ms")
                            print(f"   éŸ¿æ‡‰: {content[:50]}...")
                        else:
                            error = await response.text()
                            print(f"âŒ éŒ¯èª¤ {response.status}: {error[:100]}")
                            
                except Exception as e:
                    print(f"âŒ ç•°å¸¸: {e}")
        
        if latencies:
            avg = sum(latencies) / len(latencies)
            self.results.append({
                "provider": "Moonshot",
                "model": "moonshot-v1-8k",
                "avg_latency": avg,
                "min_latency": min(latencies),
                "max_latency": max(latencies),
                "success_rate": f"{len(latencies)}/3"
            })
            print(f"\nğŸ“Š Moonshotçµ±è¨ˆ:")
            print(f"   å¹³å‡å»¶é²: {avg:.0f}ms")
            print(f"   æœ€ä½/æœ€é«˜: {min(latencies):.0f}ms / {max(latencies):.0f}ms")
    
    async def test_rag_simulation(self):
        """æ¨¡æ“¬RAGå¢å¼·å»¶é²"""
        print("\nğŸ§  æ¨¡æ“¬RAGå¢å¼·")
        print("-"*40)
        
        rag_operations = [
            ("å‘é‡æœç´¢", 50),
            ("ä¸Šä¸‹æ–‡æª¢ç´¢", 80),
            ("éŸ¿æ‡‰å¢å¼·", 70)
        ]
        
        total_rag_time = 0
        for op, latency in rag_operations:
            print(f"   {op}: {latency}ms")
            total_rag_time += latency
            await asyncio.sleep(latency / 1000)
        
        print(f"\n   RAGç¸½å»¶é²: {total_rag_time}ms")
        return total_rag_time
    
    def generate_final_report(self, rag_latency):
        """ç”Ÿæˆæœ€çµ‚å ±å‘Š"""
        print("\nğŸ“‹ PowerAutomation K2é›†æˆå ±å‘Š")
        print("="*60)
        
        if not self.results:
            print("âŒ æ²’æœ‰æ¸¬è©¦çµæœ")
            return
        
        print("\nğŸ“Š Provideræ€§èƒ½å°æ¯”:")
        for result in self.results:
            print(f"\n{result['provider']} ({result['model']}):")
            print(f"   å¹³å‡å»¶é²: {result['avg_latency']:.0f}ms")
            print(f"   å»¶é²ç¯„åœ: {result['min_latency']:.0f}-{result['max_latency']:.0f}ms")
            print(f"   æˆåŠŸç‡: {result['success_rate']}")
        
        # æ‰¾å‡ºæœ€ä½³provider
        best = min(self.results, key=lambda x: x['avg_latency'])
        
        print(f"\nğŸ† æœ€ä½³Provider: {best['provider']}")
        print(f"   å¹³å‡å»¶é²: {best['avg_latency']:.0f}ms")
        
        # è¨ˆç®—ç¸½å»¶é²
        total_latency = best['avg_latency'] + rag_latency + 100  # +100msç¶²çµ¡é–‹éŠ·
        
        print(f"\nâ±ï¸ ç«¯åˆ°ç«¯å»¶é²é ä¼°:")
        print(f"   K2éŸ¿æ‡‰: {best['avg_latency']:.0f}ms")
        print(f"   RAGå¢å¼·: {rag_latency}ms")
        print(f"   ç¶²çµ¡é–‹éŠ·: 100ms")
        print(f"   ç¸½å»¶é²: {total_latency:.0f}ms")
        
        if total_latency < 1000:
            print(f"\nâœ… æ€§èƒ½è©•ä¼°: å„ªç§€")
            print("   - ç¸½å»¶é²<1ç§’ï¼Œç”¨æˆ¶é«”é©—è‰¯å¥½")
            print("   - å®Œå…¨æ»¿è¶³PowerAutomationéœ€æ±‚")
            print("   - 7/30ä¸Šç·šç›®æ¨™å¯é”æˆ")
        else:
            print(f"\nâš ï¸ æ€§èƒ½è©•ä¼°: éœ€å„ªåŒ–")
            print("   - ç¸½å»¶é²>1ç§’ï¼Œéœ€è¦é€²ä¸€æ­¥å„ªåŒ–")
        
        # æˆæœ¬åˆ†æ
        print(f"\nğŸ’° æˆæœ¬ç¯€çœåˆ†æ:")
        print("   Claude: Â¥15/Mè¼¸å…¥, Â¥75/Mè¼¸å‡º")
        print(f"   {best['provider']}: ~Â¥0.4/Mè¼¸å…¥, ~Â¥0.6/Mè¼¸å‡º")
        print("   ç¯€çœç‡: >95%")
        
        # å¯¦æ–½å»ºè­°
        print(f"\nğŸš€ å¯¦æ–½å»ºè­°:")
        print(f"1. ä¸»åŠ›ä½¿ç”¨{best['provider']}ï¼Œå»¶é²{best['avg_latency']:.0f}ms")
        print("2. RAGå„ªåŒ–åˆ°200mså…§")
        print("3. å¯¦ç¾æ™ºèƒ½ç·©å­˜æ¸›å°‘å»¶é²")
        print("4. 7/30å‰å®Œæˆå£“åŠ›æ¸¬è©¦")

async def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸš€ PowerAutomation K2 Providerså®Œæ•´æ¸¬è©¦")
    print("æ¸¬è©¦Groqå’ŒMoonshotå¯¦éš›æ€§èƒ½")
    print("="*60)
    
    tester = K2ProvidersCompleteTest()
    
    # ä¸¦è¡Œæ¸¬è©¦å…©å€‹provider
    await asyncio.gather(
        tester.test_groq(),
        tester.test_moonshot()
    )
    
    # æ¸¬è©¦RAGå»¶é²
    rag_latency = await tester.test_rag_simulation()
    
    # ç”Ÿæˆæœ€çµ‚å ±å‘Š
    tester.generate_final_report(rag_latency)
    
    print("\nâœ… æ¸¬è©¦å®Œæˆï¼PowerAutomationå·²æº–å‚™å¥½ä½¿ç”¨K2 Providers")

if __name__ == "__main__":
    asyncio.run(main())