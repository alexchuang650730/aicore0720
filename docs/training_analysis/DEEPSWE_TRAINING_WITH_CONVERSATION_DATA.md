# åŸºæ–¼å°è©±æ•¸æ“šçš„ DeepSWE è¨“ç·´æ–¹æ¡ˆ

## ğŸ¯ æ•¸æ“šè³‡ç”¢è©•ä¼°

### ç¾æœ‰æ•¸æ“š
1. **Manus ç¨‹åºå°è©±**: 1,000 å°æ™‚
2. **Claude ç¨‹åºå°è©±**: æ¯å¤© 15 å°æ™‚ï¼ˆæŒçºŒå¢é•·ï¼‰
   - æœˆç´¯ç©: ~450 å°æ™‚
   - é è¨ˆ 3 å€‹æœˆ: ~1,350 å°æ™‚

**ç¸½è¨ˆ**: ~2,350 å°æ™‚é«˜è³ªé‡ç¨‹åºå°è©±æ•¸æ“š

## ğŸ’ æ•¸æ“šåƒ¹å€¼åˆ†æ

### ç‚ºä»€éº¼é€™äº›æ•¸æ“šæ¥µå…¶å¯¶è²´ï¼Ÿ

1. **çœŸå¯¦å ´æ™¯**
   - å¯¦éš›é–‹ç™¼ä¸­çš„å•é¡Œå’Œè§£æ±ºæ–¹æ¡ˆ
   - åŒ…å«å®Œæ•´çš„æ€è€ƒéç¨‹å’Œè¿­ä»£
   - æ¶µè“‹ bug ä¿®å¾©ã€å„ªåŒ–ã€é‡æ§‹ç­‰å ´æ™¯

2. **é«˜è³ªé‡æ¨™è¨»**
   - Claude/Manus çš„å›æ‡‰å¯ä½œç‚ºé«˜è³ªé‡æ¨™ç±¤
   - åŒ…å«è§£é‡‹å’Œæ¨ç†éç¨‹
   - å¤šè¼ªå°è©±å±•ç¤ºå®Œæ•´è§£æ±ºè·¯å¾‘

3. **é ˜åŸŸç‰¹å®š**
   - PowerAutomation é …ç›®ç‰¹å®šçŸ¥è­˜
   - MCP æ¶æ§‹å’Œé›†æˆæ¨¡å¼
   - K2 å„ªåŒ–ç¶“é©—

## ğŸ”§ æ•¸æ“šè™•ç†æµç¨‹

### 1. æ•¸æ“šæå–å’Œæ¸…æ´—

```python
# core/training/conversation_data_processor.py
import json
import re
from typing import List, Dict, Any
from pathlib import Path

class ConversationDataProcessor:
    """è™•ç† Claude å’Œ Manus å°è©±æ•¸æ“š"""
    
    def __init__(self):
        self.claude_conversations = []
        self.manus_conversations = []
        self.training_examples = []
        
    def extract_claude_conversations(self, export_path: str):
        """æå– Claude å°è©±æ•¸æ“š"""
        # Claude é€šå¸¸å¯ä»¥å°å‡ºç‚º JSON æ ¼å¼
        with open(export_path, 'r', encoding='utf-8') as f:
            conversations = json.load(f)
            
        for conv in conversations:
            processed = self._process_claude_conversation(conv)
            if processed:
                self.claude_conversations.append(processed)
                
    def _process_claude_conversation(self, conv: Dict) -> Dict:
        """è™•ç†å–®å€‹ Claude å°è©±"""
        examples = []
        
        for i, msg in enumerate(conv['messages']):
            if msg['role'] == 'user' and i + 1 < len(conv['messages']):
                user_msg = msg['content']
                assistant_msg = conv['messages'][i + 1]['content']
                
                # è­˜åˆ¥ä»£ç¢¼ç›¸é—œå°è©±
                if self._is_code_related(user_msg, assistant_msg):
                    example = {
                        'input': user_msg,
                        'output': assistant_msg,
                        'type': self._classify_conversation_type(user_msg),
                        'quality_score': self._assess_quality(assistant_msg)
                    }
                    examples.append(example)
                    
        return examples
    
    def _is_code_related(self, user_msg: str, assistant_msg: str) -> bool:
        """åˆ¤æ–·æ˜¯å¦ç‚ºä»£ç¢¼ç›¸é—œå°è©±"""
        code_indicators = [
            '```', 'def ', 'class ', 'import ', 'function',
            'éŒ¯èª¤', 'bug', 'å„ªåŒ–', 'å¯¦ç¾', 'ä»£ç¢¼'
        ]
        
        combined_text = user_msg + assistant_msg
        return any(indicator in combined_text for indicator in code_indicators)
    
    def _classify_conversation_type(self, user_msg: str) -> str:
        """åˆ†é¡å°è©±é¡å‹"""
        if any(word in user_msg for word in ['éŒ¯èª¤', 'error', 'bug', 'ä¿®å¾©']):
            return 'bug_fixing'
        elif any(word in user_msg for word in ['å„ªåŒ–', 'optimize', 'æ”¹é€²']):
            return 'optimization'
        elif any(word in user_msg for word in ['å¯¦ç¾', 'implement', 'å‰µå»º', 'ç”Ÿæˆ']):
            return 'code_generation'
        elif any(word in user_msg for word in ['è§£é‡‹', 'explain', 'åˆ†æ']):
            return 'code_explanation'
        else:
            return 'general'
```

### 2. å‰µå»º DeepSWE é¢¨æ ¼çš„è¨“ç·´æ•¸æ“š

```python
class DeepSWEDatasetCreator:
    """å‰µå»º DeepSWE é¢¨æ ¼çš„æ•¸æ“šé›†"""
    
    def create_training_examples(self, conversations: List[Dict]) -> List[Dict]:
        """å°‡å°è©±è½‰æ›ç‚º DeepSWE è¨“ç·´æ ¼å¼"""
        
        training_data = []
        
        for conv in conversations:
            # æå–æ€è€ƒéç¨‹
            thinking_process = self._extract_thinking_process(conv)
            
            # å‰µå»º DeepSWE æ ¼å¼
            deepswe_example = {
                "instruction": self._create_deepswe_prompt(conv),
                "input": conv['input'],
                "output": conv['output'],
                "thinking": thinking_process,
                "metadata": {
                    "type": conv['type'],
                    "quality": conv['quality_score'],
                    "source": "claude" if 'claude' in conv else "manus"
                }
            }
            
            training_data.append(deepswe_example)
            
        return training_data
    
    def _extract_thinking_process(self, conv: Dict) -> str:
        """å¾å°è©±ä¸­æå–æ€è€ƒéç¨‹"""
        output = conv['output']
        
        # å°‹æ‰¾æ€è€ƒæ¨¡å¼
        thinking_patterns = [
            r'è®“æˆ‘.*åˆ†æ',
            r'é¦–å…ˆ.*ç„¶å¾Œ',
            r'é€™å€‹å•é¡Œ.*éœ€è¦',
            r'æˆ‘å°‡.*æ­¥é©Ÿ'
        ]
        
        thinking_parts = []
        for pattern in thinking_patterns:
            matches = re.findall(pattern, output)
            thinking_parts.extend(matches)
            
        return '\n'.join(thinking_parts)
    
    def _create_deepswe_prompt(self, conv: Dict) -> str:
        """å‰µå»º DeepSWE é¢¨æ ¼çš„æç¤º"""
        task_type = conv['type']
        
        prompts = {
            'bug_fixing': "è«‹åˆ†æä¸¦ä¿®å¾©ä»¥ä¸‹ä»£ç¢¼å•é¡Œ",
            'optimization': "è«‹å„ªåŒ–ä»¥ä¸‹ä»£ç¢¼çš„æ€§èƒ½å’Œè³ªé‡",
            'code_generation': "è«‹æ ¹æ“šéœ€æ±‚ç”Ÿæˆç›¸æ‡‰çš„ä»£ç¢¼",
            'code_explanation': "è«‹è§£é‡‹ä»¥ä¸‹ä»£ç¢¼çš„åŠŸèƒ½å’Œå¯¦ç¾"
        }
        
        return prompts.get(task_type, "è«‹è™•ç†ä»¥ä¸‹ç·¨ç¨‹ä»»å‹™")
```

### 3. K2 å„ªåŒ–æ¨¡å¼æå–

```python
class K2OptimizationExtractor:
    """å¾å°è©±ä¸­æå– K2 å„ªåŒ–æ¨¡å¼"""
    
    def extract_optimization_patterns(self, conversations: List[Dict]) -> Dict:
        """æå–æˆåŠŸçš„ K2 äº¤äº’æ¨¡å¼"""
        
        patterns = {
            'prompt_templates': [],
            'successful_patterns': [],
            'failure_patterns': []
        }
        
        for conv in conversations:
            # åˆ†ææˆåŠŸçš„äº¤äº’
            if conv.get('quality_score', 0) > 0.8:
                pattern = {
                    'input_structure': self._analyze_input_structure(conv['input']),
                    'output_quality': conv['quality_score'],
                    'key_elements': self._extract_key_elements(conv)
                }
                patterns['successful_patterns'].append(pattern)
                
        # ç¸½çµæœ€ä½³å¯¦è¸
        patterns['best_practices'] = self._summarize_best_practices(patterns['successful_patterns'])
        
        return patterns
    
    def _analyze_input_structure(self, input_text: str) -> Dict:
        """åˆ†æè¼¸å…¥çµæ§‹"""
        return {
            'has_context': '```' in input_text,
            'has_requirements': 'éœ€è¦' in input_text or 'need' in input_text,
            'has_constraints': 'é™åˆ¶' in input_text or 'constraint' in input_text,
            'length': len(input_text),
            'complexity': self._assess_complexity(input_text)
        }
```

## ğŸ“Š è¨“ç·´ç­–ç•¥

### 1. ç¬¬ä¸€éšæ®µï¼šæ•¸æ“šæº–å‚™ï¼ˆ1é€±ï¼‰

```bash
# æ•¸æ“šè™•ç†è…³æœ¬
python process_conversation_data.py \
  --claude-export ./claude_conversations.json \
  --manus-export ./manus_conversations.json \
  --output ./training_data/

# é æœŸè¼¸å‡º
# - 50,000+ é«˜è³ªé‡å°è©±å°
# - 10,000+ bug ä¿®å¾©æ¡ˆä¾‹
# - 15,000+ ä»£ç¢¼ç”Ÿæˆæ¡ˆä¾‹
# - 5,000+ å„ªåŒ–æ¡ˆä¾‹
```

### 2. ç¬¬äºŒéšæ®µï¼šæ¨¡å¼å­¸ç¿’ï¼ˆ1é€±ï¼‰

```python
# ä½¿ç”¨å°æ¨¡å‹å­¸ç¿’å„ªåŒ–æ¨¡å¼
from transformers import AutoModelForCausalLM, Trainer, TrainingArguments

model = AutoModelForCausalLM.from_pretrained("deepseek-ai/deepseek-coder-1.3b-base")

training_args = TrainingArguments(
    output_dir="./k2-optimizer",
    num_train_epochs=3,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=8,
    warmup_steps=500,
    weight_decay=0.01,
    logging_dir="./logs",
    save_strategy="epoch",
    evaluation_strategy="epoch",
    load_best_model_at_end=True,
)

# å°ˆæ³¨æ–¼å­¸ç¿’æç¤ºå„ªåŒ–æ¨¡å¼
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=optimization_patterns_dataset,
    eval_dataset=eval_dataset,
)
```

### 3. ç¬¬ä¸‰éšæ®µï¼šK2 å„ªåŒ–å™¨éƒ¨ç½²ï¼ˆ1é€±ï¼‰

```python
# core/k2_optimizer/conversation_based_optimizer.py
class ConversationBasedK2Optimizer:
    """åŸºæ–¼å°è©±æ•¸æ“šè¨“ç·´çš„ K2 å„ªåŒ–å™¨"""
    
    def __init__(self, model_path: str):
        self.optimizer_model = self.load_optimizer(model_path)
        self.pattern_database = self.load_patterns()
        
    def optimize_k2_prompt(self, user_input: str) -> str:
        """ä½¿ç”¨å­¸ç¿’åˆ°çš„æ¨¡å¼å„ªåŒ– K2 æç¤º"""
        
        # 1. åˆ†æè¼¸å…¥é¡å‹
        input_type = self.classify_input(user_input)
        
        # 2. é¸æ“‡æœ€ä½³æ¨¡å¼
        best_pattern = self.pattern_database.get_best_pattern(input_type)
        
        # 3. æ‡‰ç”¨å„ªåŒ–
        optimized = self.apply_pattern(user_input, best_pattern)
        
        return optimized
```

## ğŸ’° æˆæœ¬æ•ˆç›Šåˆ†æ

### æ•¸æ“šåƒ¹å€¼
- **å¸‚å ´åƒ¹å€¼**: 2,350 å°æ™‚å°è©± â‰ˆ Â¥500,000+ï¼ˆå¦‚æœè³¼è²·é¡ä¼¼æ•¸æ“šï¼‰
- **ç¨ç‰¹æ€§**: 100%ï¼ˆç„¡æ³•è³¼è²·åˆ°æ‚¨çš„ç‰¹å®šé ˜åŸŸæ•¸æ“šï¼‰
- **è³ªé‡**: æ¥µé«˜ï¼ˆClaude/Manus ç”Ÿæˆï¼‰

### è¨“ç·´æˆæœ¬
- **æ•¸æ“šè™•ç†**: MacBook æœ¬åœ°ï¼Œç´„ Â¥100 é›»è²»
- **æ¨¡å¼å­¸ç¿’**: MacBook M4ï¼Œç´„ Â¥200 é›»è²»
- **é©—è­‰æ¸¬è©¦**: ç´„ Â¥300 é›²ç«¯è²»ç”¨
- **ç¸½è¨ˆ**: ~Â¥600

### ROI é æœŸ
- **K2 æˆæœ¬é™ä½**: 30-40%ï¼ˆé€šéå„ªåŒ–æ¸›å°‘ token ä½¿ç”¨ï¼‰
- **éŸ¿æ‡‰è³ªé‡æå‡**: 40-50%ï¼ˆåŸºæ–¼å¯¦éš›æˆåŠŸæ¡ˆä¾‹ï¼‰
- **æœˆç¯€çœ**: ~Â¥10,000ï¼ˆåŸºæ–¼ç•¶å‰ä½¿ç”¨é‡ï¼‰
- **å›æœ¬æ™‚é–“**: ç«‹å³

## ğŸš€ å¯¦æ–½è¨ˆåŠƒ

### Week 1: æ•¸æ“šæå–
```bash
# 1. å°å‡º Claude å°è©±
# Claude è¨­ç½® -> å°å‡ºæ•¸æ“š

# 2. å°å‡º Manus å°è©±
# Manus ç®¡ç†å¾Œå° -> å°å‡ºæ­·å²

# 3. é‹è¡Œæ•¸æ“šè™•ç†
python process_all_conversations.py
```

### Week 2: æ¨¡å¼å­¸ç¿’
```bash
# ä½¿ç”¨ MacBook æœ¬åœ°è¨“ç·´
python train_k2_optimizer.py \
  --data ./processed_conversations/ \
  --model deepseek-coder-1.3b \
  --epochs 5
```

### Week 3: éƒ¨ç½²å„ªåŒ–
```python
# é›†æˆåˆ°ç¾æœ‰ç³»çµ±
k2_optimizer = ConversationBasedK2Optimizer("./k2-optimizer")

# åœ¨ Claude Router ä¸­ä½¿ç”¨
async def route_to_k2_optimized(request):
    optimized_prompt = k2_optimizer.optimize_k2_prompt(request.prompt)
    return await call_k2_api(optimized_prompt)
```

## ğŸ¯ ç¨ç‰¹å„ªå‹¢

1. **é›¶é¡å¤–æ•¸æ“šæˆæœ¬** - ä½¿ç”¨å·²æœ‰å°è©±
2. **é ˜åŸŸé«˜åº¦ç›¸é—œ** - 100% PowerAutomation ç›¸é—œ
3. **æŒçºŒæ”¹é€²** - æ¯å¤©æ–°å¢ 15 å°æ™‚æ•¸æ“š
4. **ç«‹å³è¦‹æ•ˆ** - åŸºæ–¼å¯¦éš›æˆåŠŸæ¡ˆä¾‹

é€™å€‹æ–¹æ¡ˆå……åˆ†åˆ©ç”¨äº†æ‚¨çš„æ•¸æ“šè³‡ç”¢ï¼Œä»¥æ¥µä½æˆæœ¬å¯¦ç¾é¡¯è‘—çš„å„ªåŒ–æ•ˆæœï¼