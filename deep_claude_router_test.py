#!/usr/bin/env python3
"""
æ·±å…¥æ¸¬è©¦Claude Routeré€æ˜åˆ‡æ›èƒ½åŠ›
é©—è­‰çœŸå¯¦çš„ç„¡æ„Ÿåˆ‡æ›æ•ˆæœ
"""

import asyncio
import time
import os
import json
from typing import Dict, List, Any

class ClaudeRouterDeepTest:
    """Claude Routeré€æ˜åˆ‡æ›æ·±åº¦æ¸¬è©¦"""
    
    def __init__(self):
        self.test_results = []
        
    async def test_transparent_switching(self):
        """æ¸¬è©¦é€æ˜åˆ‡æ›çš„å¯¦éš›æ•ˆæœ"""
        print("ğŸ”„ æ¸¬è©¦é€æ˜åˆ‡æ›æ•ˆæœ")
        print("="*60)
        
        # æ¸¬è©¦å ´æ™¯ï¼šç”¨æˆ¶ä»¥ç‚ºåœ¨ç”¨Claudeï¼Œå¯¦éš›ä½¿ç”¨K2
        test_cases = [
            {
                "scenario": "ç°¡å–®å•ç­”",
                "user_input": "ä»€éº¼æ˜¯Pythonè£é£¾å™¨ï¼Ÿ",
                "user_expectation": "Claudeç´šåˆ¥çš„è©³ç´°è§£é‡‹",
                "switching_requirement": "K2éœ€è¦æä¾›åŒç­‰è³ªé‡å›ç­”"
            },
            {
                "scenario": "ä»£ç¢¼ç”Ÿæˆ",
                "user_input": "å¯«ä¸€å€‹PythonäºŒåˆ†æœç´¢å‡½æ•¸",
                "user_expectation": "å®Œæ•´ã€æ­£ç¢ºçš„ä»£ç¢¼å¯¦ç¾",
                "switching_requirement": "K2ç”Ÿæˆçš„ä»£ç¢¼è³ªé‡è¦æ¥è¿‘Claude"
            },
            {
                "scenario": "ä»£ç¢¼å¯©æŸ¥",
                "user_input": "å¯©æŸ¥é€™æ®µä»£ç¢¼ï¼šdef add(a,b): return a+b",
                "user_expectation": "å°ˆæ¥­çš„ä»£ç¢¼å¯©æŸ¥å»ºè­°",
                "switching_requirement": "K2æä¾›æœ‰åƒ¹å€¼çš„å¯©æŸ¥æ„è¦‹"
            },
            {
                "scenario": "éŒ¯èª¤è¨ºæ–·",
                "user_input": "ç‚ºä»€éº¼æœƒå ±éŒ¯ï¼šlist.append(1, 2)",
                "user_expectation": "æº–ç¢ºçš„éŒ¯èª¤è§£é‡‹å’Œä¿®å¾©å»ºè­°",
                "switching_requirement": "K2èƒ½æº–ç¢ºè­˜åˆ¥ä¸¦è§£é‡‹éŒ¯èª¤"
            }
        ]
        
        from huggingface_hub import InferenceClient
        os.environ['HF_TOKEN'] = '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'
        client = InferenceClient(provider='groq', api_key=os.environ['HF_TOKEN'])
        
        results = []
        
        for test in test_cases:
            print(f"\nğŸ“‹ å ´æ™¯: {test['scenario']}")
            print(f"   ç”¨æˆ¶æœŸæœ›: {test['user_expectation']}")
            
            try:
                # æ¸¬è©¦K2éŸ¿æ‡‰
                start_time = time.time()
                
                completion = client.chat.completions.create(
                    model='moonshotai/Kimi-K2-Instruct',
                    messages=[
                        {
                            "role": "system",
                            "content": "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ç·¨ç¨‹åŠ©æ‰‹ï¼Œè«‹æä¾›è©³ç´°ã€æº–ç¢ºçš„å›ç­”ã€‚"
                        },
                        {
                            "role": "user",
                            "content": test['user_input']
                        }
                    ],
                    max_tokens=800
                )
                
                k2_response = completion.choices[0].message.content
                response_time = time.time() - start_time
                
                # è©•ä¼°éŸ¿æ‡‰è³ªé‡
                quality_score = self._evaluate_response_quality(k2_response, test['user_expectation'])
                
                print(f"   K2éŸ¿æ‡‰æ™‚é–“: {response_time:.2f}s")
                print(f"   éŸ¿æ‡‰è³ªé‡è©•åˆ†: {quality_score:.2f}/10")
                print(f"   éŸ¿æ‡‰é è¦½: {k2_response[:150]}...")
                
                # åˆ¤æ–·æ˜¯å¦èƒ½é€æ˜åˆ‡æ›
                can_switch = quality_score >= 7.0 and response_time < 5.0
                print(f"   å¯å¦é€æ˜åˆ‡æ›: {'âœ… æ˜¯' if can_switch else 'âŒ å¦'}")
                
                results.append({
                    "scenario": test['scenario'],
                    "quality_score": quality_score,
                    "response_time": response_time,
                    "can_switch": can_switch,
                    "k2_response_length": len(k2_response)
                })
                
            except Exception as e:
                print(f"   âŒ æ¸¬è©¦å¤±æ•—: {e}")
                results.append({
                    "scenario": test['scenario'],
                    "error": str(e)
                })
        
        return results
    
    def _evaluate_response_quality(self, response: str, expectation: str) -> float:
        """è©•ä¼°éŸ¿æ‡‰è³ªé‡ï¼ˆ0-10åˆ†ï¼‰"""
        score = 5.0  # åŸºç¤åˆ†
        
        # é•·åº¦è©•åˆ†
        if len(response) > 200:
            score += 1.0
        if len(response) > 400:
            score += 0.5
            
        # çµæ§‹è©•åˆ†
        if any(marker in response for marker in ['1.', '2.', '-', '```']):
            score += 1.0
            
        # å°ˆæ¥­æ€§è©•åˆ†
        professional_terms = ['å‡½æ•¸', 'åƒæ•¸', 'è¿”å›', 'è®Šé‡', 'é¡å‹', 'æ–¹æ³•', 'function', 'parameter', 'return', 'variable']
        term_count = sum(1 for term in professional_terms if term in response.lower())
        score += min(term_count * 0.3, 1.5)
        
        # å®Œæ•´æ€§è©•åˆ†
        if 'ä¾‹å¦‚' in response or 'example' in response.lower() or '```' in response:
            score += 1.0
            
        return min(score, 10.0)
    
    async def test_error_recovery(self):
        """æ¸¬è©¦éŒ¯èª¤æ¢å¾©å’Œå›é€€æ©Ÿåˆ¶"""
        print("\nğŸ”§ æ¸¬è©¦éŒ¯èª¤æ¢å¾©æ©Ÿåˆ¶")
        print("="*50)
        
        error_scenarios = [
            {
                "name": "APIè¶…æ™‚",
                "simulate": "timeout",
                "expected_behavior": "è‡ªå‹•å›é€€åˆ°Claudeæˆ–é‡è©¦"
            },
            {
                "name": "K2è¿”å›ç©ºéŸ¿æ‡‰",
                "simulate": "empty_response",
                "expected_behavior": "æª¢æ¸¬ä¸¦å›é€€"
            },
            {
                "name": "K2éŸ¿æ‡‰è³ªé‡å¤ªä½",
                "simulate": "low_quality",
                "expected_behavior": "è³ªé‡æª¢æŸ¥å¾Œå›é€€"
            }
        ]
        
        for scenario in error_scenarios:
            print(f"\nâŒ æ¨¡æ“¬: {scenario['name']}")
            print(f"   æœŸæœ›è¡Œç‚º: {scenario['expected_behavior']}")
            
            # é€™è£¡æ‡‰è©²æ¸¬è©¦å¯¦éš›çš„RouteréŒ¯èª¤è™•ç†
            # ä½†ç”±æ–¼æ²’æœ‰éƒ¨ç½²å¯¦éš›çš„Routerï¼Œåªèƒ½æ¨¡æ“¬
            
            if scenario['simulate'] == 'timeout':
                print("   æ¨¡æ“¬çµæœ: Routeræ‡‰è©²åœ¨3ç§’å¾Œè¶…æ™‚ä¸¦å›é€€")
            elif scenario['simulate'] == 'empty_response':
                print("   æ¨¡æ“¬çµæœ: Routeræ‡‰è©²æª¢æ¸¬ç©ºéŸ¿æ‡‰ä¸¦é‡è©¦æˆ–å›é€€")
            elif scenario['simulate'] == 'low_quality':
                print("   æ¨¡æ“¬çµæœ: Routeræ‡‰è©²æœ‰è³ªé‡é–¾å€¼æª¢æŸ¥")
    
    async def test_user_experience_consistency(self):
        """æ¸¬è©¦ç”¨æˆ¶é«”é©—ä¸€è‡´æ€§"""
        print("\nğŸ‘¤ æ¸¬è©¦ç”¨æˆ¶é«”é©—ä¸€è‡´æ€§")
        print("="*50)
        
        # é—œéµé«”é©—æŒ‡æ¨™
        experience_metrics = {
            "éŸ¿æ‡‰é€Ÿåº¦": {
                "claude_baseline": "2-3ç§’",
                "k2_actual": None,
                "acceptable_range": "1-5ç§’"
            },
            "éŸ¿æ‡‰æ ¼å¼": {
                "claude_baseline": "çµæ§‹åŒ–ã€å°ˆæ¥­",
                "k2_actual": None,
                "acceptable_range": "è‡³å°‘æœ‰åŸºæœ¬çµæ§‹"
            },
            "éŒ¯èª¤è™•ç†": {
                "claude_baseline": "å‹å¥½ã€å»ºè¨­æ€§",
                "k2_actual": None,
                "acceptable_range": "èƒ½è­˜åˆ¥ä¸¦è§£é‡‹éŒ¯èª¤"
            },
            "ä»£ç¢¼è³ªé‡": {
                "claude_baseline": "å¯é‹è¡Œã€è¦ç¯„",
                "k2_actual": None,
                "acceptable_range": "åŸºæœ¬æ­£ç¢º"
            }
        }
        
        # å¯¦éš›æ¸¬è©¦ä¸€å€‹å®Œæ•´äº¤äº’
        from huggingface_hub import InferenceClient
        client = InferenceClient(provider='groq', api_key=os.environ['HF_TOKEN'])
        
        print("\nğŸ” å¯¦éš›é«”é©—æ¸¬è©¦:")
        
        test_interaction = "å¹«æˆ‘å„ªåŒ–é€™æ®µä»£ç¢¼ï¼š\nfor i in range(len(arr)):\n    for j in range(len(arr)):\n        if arr[i] > arr[j]:\n            arr[i], arr[j] = arr[j], arr[i]"
        
        try:
            start_time = time.time()
            
            completion = client.chat.completions.create(
                model='moonshotai/Kimi-K2-Instruct',
                messages=[{"role": "user", "content": test_interaction}],
                max_tokens=800
            )
            
            response = completion.choices[0].message.content
            response_time = time.time() - start_time
            
            # æ›´æ–°å¯¦éš›æŒ‡æ¨™
            experience_metrics["éŸ¿æ‡‰é€Ÿåº¦"]["k2_actual"] = f"{response_time:.2f}ç§’"
            
            # æª¢æŸ¥éŸ¿æ‡‰æ ¼å¼
            has_structure = any(marker in response for marker in ['1.', '2.', '```', '-'])
            experience_metrics["éŸ¿æ‡‰æ ¼å¼"]["k2_actual"] = "æœ‰çµæ§‹" if has_structure else "ç„¡çµæ§‹"
            
            # æª¢æŸ¥æ˜¯å¦åŒ…å«å„ªåŒ–å»ºè­°
            has_optimization = any(word in response.lower() for word in ['å„ªåŒ–', 'æ”¹é€²', 'å»ºè­°', 'better', 'improve'])
            experience_metrics["ä»£ç¢¼è³ªé‡"]["k2_actual"] = "æœ‰å„ªåŒ–å»ºè­°" if has_optimization else "ç„¡å„ªåŒ–å»ºè­°"
            
            print(f"K2éŸ¿æ‡‰æ™‚é–“: {response_time:.2f}ç§’")
            print(f"éŸ¿æ‡‰çµæ§‹åŒ–: {'âœ…' if has_structure else 'âŒ'}")
            print(f"åŒ…å«å„ªåŒ–å»ºè­°: {'âœ…' if has_optimization else 'âŒ'}")
            
        except Exception as e:
            print(f"æ¸¬è©¦å¤±æ•—: {e}")
        
        # é¡¯ç¤ºå°æ¯”çµæœ
        print("\nğŸ“Š é«”é©—ä¸€è‡´æ€§å°æ¯”:")
        for metric, data in experience_metrics.items():
            print(f"\n{metric}:")
            print(f"  ClaudeåŸºæº–: {data['claude_baseline']}")
            print(f"  K2å¯¦éš›: {data['k2_actual'] or 'æœªæ¸¬è©¦'}")
            print(f"  å¯æ¥å—ç¯„åœ: {data['acceptable_range']}")
            
            # åˆ¤æ–·æ˜¯å¦é”æ¨™
            if data['k2_actual']:
                if metric == "éŸ¿æ‡‰é€Ÿåº¦":
                    acceptable = response_time < 5.0
                elif metric == "éŸ¿æ‡‰æ ¼å¼":
                    acceptable = "æœ‰çµæ§‹" in str(data['k2_actual'])
                else:
                    acceptable = data['k2_actual'] != "ç„¡å„ªåŒ–å»ºè­°"
                
                print(f"  é”æ¨™: {'âœ…' if acceptable else 'âŒ'}")
    
    async def test_cost_benefit_reality(self):
        """æ¸¬è©¦å¯¦éš›çš„æˆæœ¬æ•ˆç›Š"""
        print("\nğŸ’° æ¸¬è©¦å¯¦éš›æˆæœ¬æ•ˆç›Š")
        print("="*50)
        
        # åŸºæ–¼å¯¦éš›å®šåƒ¹è¨ˆç®—
        pricing = {
            "k2": {
                "input": 2.0,   # 2å…ƒ/M tokens
                "output": 8.0   # 8å…ƒ/M tokens
            },
            "claude": {
                "input": 15.0,  # 15å…ƒ/M tokens
                "output": 75.0  # 75å…ƒ/M tokens
            }
        }
        
        # æ¨¡æ“¬ä¸åŒè¦æ¨¡ä½¿ç”¨
        usage_scenarios = [
            {"name": "å€‹äººé–‹ç™¼è€…", "daily_requests": 50, "avg_tokens": 1000},
            {"name": "å°åœ˜éšŠ", "daily_requests": 200, "avg_tokens": 1500},
            {"name": "ä¸­å‹å…¬å¸", "daily_requests": 1000, "avg_tokens": 2000}
        ]
        
        print("ğŸ“Š 30å¤©æˆæœ¬å°æ¯”ï¼ˆäººæ°‘å¹£ï¼‰:")
        
        for scenario in usage_scenarios:
            total_tokens = scenario['daily_requests'] * scenario['avg_tokens'] * 30
            
            # å‡è¨­è¼¸å…¥è¼¸å‡ºå„å 50%
            input_tokens = total_tokens * 0.4
            output_tokens = total_tokens * 0.6
            
            k2_cost = (input_tokens * pricing['k2']['input'] + 
                      output_tokens * pricing['k2']['output']) / 1000000
            
            claude_cost = (input_tokens * pricing['claude']['input'] + 
                          output_tokens * pricing['claude']['output']) / 1000000
            
            savings = claude_cost - k2_cost
            savings_rate = (savings / claude_cost) * 100
            
            print(f"\n{scenario['name']}:")
            print(f"  K2æˆæœ¬: Â¥{k2_cost:.2f}")
            print(f"  Claudeæˆæœ¬: Â¥{claude_cost:.2f}")
            print(f"  ç¯€çœ: Â¥{savings:.2f} ({savings_rate:.1f}%)")
            
            # ä½†è¦è€ƒæ…®é€æ˜åˆ‡æ›çš„å¯¦éš›æƒ…æ³
            if savings_rate > 50:
                print(f"  ğŸ’¡ å¯¦éš›ç¯€çœéœ€è€ƒæ…®ï¼š")
                print(f"     - éƒ¨åˆ†è¤‡é›œä»»å‹™ä»éœ€Claude")
                print(f"     - K2å¯èƒ½éœ€è¦æ›´å¤štokensé”åˆ°åŒç­‰æ•ˆæœ")
                print(f"     - å¯¦éš›ç¯€çœå¯èƒ½ç‚º: {savings_rate * 0.7:.1f}%")
    
    async def generate_deep_router_report(self, switching_results):
        """ç”ŸæˆClaude Routeræ·±åº¦åˆ†æå ±å‘Š"""
        print("\nğŸ“‹ Claude Routeré€æ˜åˆ‡æ›æ·±åº¦åˆ†æå ±å‘Š")
        print("="*70)
        
        # åˆ†æåˆ‡æ›æˆåŠŸç‡
        switchable = [r for r in switching_results if r.get('can_switch', False)]
        switch_rate = len(switchable) / len(switching_results) if switching_results else 0
        
        print(f"\n1ï¸âƒ£ é€æ˜åˆ‡æ›å¯è¡Œæ€§:")
        print(f"   å¯åˆ‡æ›å ´æ™¯: {len(switchable)}/{len(switching_results)} ({switch_rate:.1%})")
        
        # åˆ†æè³ªé‡åˆ†æ•¸
        avg_quality = sum(r.get('quality_score', 0) for r in switching_results) / len(switching_results) if switching_results else 0
        print(f"   å¹³å‡è³ªé‡åˆ†æ•¸: {avg_quality:.1f}/10")
        
        # åˆ†æéŸ¿æ‡‰æ™‚é–“
        avg_time = sum(r.get('response_time', 0) for r in switching_results if 'response_time' in r) / len([r for r in switching_results if 'response_time' in r]) if switching_results else 0
        print(f"   å¹³å‡éŸ¿æ‡‰æ™‚é–“: {avg_time:.2f}ç§’")
        
        print(f"\n2ï¸âƒ£ å ´æ™¯åˆ†æ:")
        for result in switching_results:
            if 'error' not in result:
                print(f"   {result['scenario']}: {'âœ… å¯åˆ‡æ›' if result['can_switch'] else 'âŒ ä¸å¯åˆ‡æ›'} (è³ªé‡: {result['quality_score']:.1f}/10)")
        
        print(f"\n3ï¸âƒ£ é—œéµç™¼ç¾:")
        if switch_rate >= 0.7:
            print("   âœ… å¤§éƒ¨åˆ†å ´æ™¯å¯ä»¥é€æ˜åˆ‡æ›")
        elif switch_rate >= 0.5:
            print("   âš ï¸ éƒ¨åˆ†å ´æ™¯å¯ä»¥åˆ‡æ›ï¼Œéœ€è¦æ™ºèƒ½è·¯ç”±")
        else:
            print("   âŒ é€æ˜åˆ‡æ›æ•ˆæœä¸ç†æƒ³")
        
        if avg_quality >= 7.0:
            print("   âœ… K2éŸ¿æ‡‰è³ªé‡æ¥è¿‘Claudeæ°´å¹³")
        elif avg_quality >= 5.0:
            print("   âš ï¸ K2éŸ¿æ‡‰è³ªé‡å°šå¯ï¼Œä½†æœ‰å·®è·")
        else:
            print("   âŒ K2éŸ¿æ‡‰è³ªé‡æ˜é¡¯ä¸è¶³")
        
        return {
            "switch_rate": switch_rate,
            "avg_quality": avg_quality,
            "avg_response_time": avg_time
        }

async def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸš€ Claude Routeré€æ˜åˆ‡æ›æ·±åº¦æ¸¬è©¦")
    print("é©—è­‰çœŸå¯¦çš„ç„¡æ„Ÿåˆ‡æ›æ•ˆæœ")
    print("="*70)
    
    tester = ClaudeRouterDeepTest()
    
    # 1. æ¸¬è©¦é€æ˜åˆ‡æ›
    switching_results = await tester.test_transparent_switching()
    
    # 2. æ¸¬è©¦éŒ¯èª¤æ¢å¾©
    await tester.test_error_recovery()
    
    # 3. æ¸¬è©¦ç”¨æˆ¶é«”é©—ä¸€è‡´æ€§
    await tester.test_user_experience_consistency()
    
    # 4. æ¸¬è©¦æˆæœ¬æ•ˆç›Š
    await tester.test_cost_benefit_reality()
    
    # 5. ç”Ÿæˆæ·±åº¦å ±å‘Š
    report = await tester.generate_deep_router_report(switching_results)
    
    print("\nğŸ¯ æœ€çµ‚çµè«–:")
    if report['switch_rate'] >= 0.6 and report['avg_quality'] >= 6.0:
        print("âœ… Claude Routerå¯ä»¥å¯¦ç¾æœ‰æ•ˆçš„é€æ˜åˆ‡æ›")
        print("âœ… ç°¡å–®åˆ°ä¸­ç­‰è¤‡é›œåº¦ä»»å‹™å¯ä»¥ç„¡æ„Ÿåˆ‡æ›åˆ°K2")
        print("âœ… ç”¨æˆ¶å¯ä»¥äº«å—é¡¯è‘—çš„æˆæœ¬ç¯€çœ")
        print("âš ï¸ è¤‡é›œä»»å‹™å»ºè­°ä¿ç•™Claudeè™•ç†")
    else:
        print("âŒ é€æ˜åˆ‡æ›æ•ˆæœæœªé”é æœŸ")
        print("âš ï¸ éœ€è¦æ›´æ™ºèƒ½çš„è·¯ç”±ç­–ç•¥")
        print("ğŸ”§ å»ºè­°å„ªåŒ–K2éŸ¿æ‡‰è³ªé‡å¾Œå†éƒ¨ç½²")

if __name__ == "__main__":
    asyncio.run(main())