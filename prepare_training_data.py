#!/usr/bin/env python3
"""
æº–å‚™K2+DeepSWE+MemoryRAGè¨“ç·´æ•¸æ“š
å°‡Manuså°è©±å’Œå·¥å…·èª¿ç”¨è½‰æ›ç‚ºçµ±ä¸€è¨“ç·´æ ¼å¼
"""

import json
import numpy as np
import logging
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from datetime import datetime
import random
from collections import defaultdict
import re

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class TrainingDataPreparer:
    """è¨“ç·´æ•¸æ“šæº–å‚™å™¨"""
    
    def __init__(self):
        self.data_dir = Path("data")
        self.output_dir = Path("data/training_ready")
        self.output_dir.mkdir(exist_ok=True)
        
        # MCPå·¥å…·æ˜ å°„
        self.tool_mapping = {
            "Read": 0, "Write": 1, "Edit": 2, "MultiEdit": 3,
            "Grep": 4, "Glob": 5, "LS": 6, "Task": 7,
            "Bash": 8, "TodoWrite": 9, "NotebookRead": 10,
            "NotebookEdit": 11, "WebFetch": 12, "WebSearch": 13,
            "exit_plan_mode": 14, "create_file": 15, "delete_file": 16,
            "rename_file": 17, "move_file": 18, "copy_file": 19
        }
        
        # çµ±è¨ˆä¿¡æ¯
        self.stats = defaultdict(int)
        
    def prepare_all_data(self):
        """æº–å‚™æ‰€æœ‰è¨“ç·´æ•¸æ“š"""
        logger.info("ğŸš€ é–‹å§‹æº–å‚™è¨“ç·´æ•¸æ“š...")
        
        all_samples = []
        
        # 1. è™•ç†Manuså°è©±æ•¸æ“š
        manus_samples = self._process_manus_conversations()
        all_samples.extend(manus_samples)
        logger.info(f"âœ… è™•ç†äº† {len(manus_samples)} å€‹Manuså°è©±æ¨£æœ¬")
        
        # 2. å‰µå»ºåˆæˆçš„å·¥å…·èª¿ç”¨æ•¸æ“š
        tool_samples = self._create_synthetic_tool_data()
        all_samples.extend(tool_samples)
        logger.info(f"âœ… å‰µå»ºäº† {len(tool_samples)} å€‹å·¥å…·èª¿ç”¨æ¨£æœ¬")
        
        # 3. å‰µå»ºç¨‹å¼ç†è§£æ•¸æ“š
        code_samples = self._create_code_understanding_data()
        all_samples.extend(code_samples)
        logger.info(f"âœ… å‰µå»ºäº† {len(code_samples)} å€‹ç¨‹å¼ç†è§£æ¨£æœ¬")
        
        # 4. å‰µå»ºè¨˜æ†¶å¢å¼·æ•¸æ“š
        memory_samples = self._create_memory_augmented_data()
        all_samples.extend(memory_samples)
        logger.info(f"âœ… å‰µå»ºäº† {len(memory_samples)} å€‹è¨˜æ†¶å¢å¼·æ¨£æœ¬")
        
        # æ‰“äº‚æ•¸æ“š
        random.shuffle(all_samples)
        
        # åˆ†å‰²è¨“ç·´é›†å’Œé©—è­‰é›†
        split_point = int(len(all_samples) * 0.9)
        train_samples = all_samples[:split_point]
        val_samples = all_samples[split_point:]
        
        # ä¿å­˜æ•¸æ“š
        self._save_dataset(train_samples, "train.json")
        self._save_dataset(val_samples, "val.json")
        
        # æ‰“å°çµ±è¨ˆä¿¡æ¯
        self._print_statistics()
        
        return train_samples, val_samples
    
    def _process_manus_conversations(self):
        """è™•ç†Manuså°è©±æ•¸æ“š"""
        samples = []
        chat_dir = self.data_dir / "enhanced_extracted_chats"
        
        if not chat_dir.exists():
            logger.warning(f"æ‰¾ä¸åˆ°å°è©±ç›®éŒ„: {chat_dir}")
            return samples
        
        for json_file in chat_dir.glob("*.json"):
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                conversation = data.get("conversation", [])
                
                # æ§‹å»ºä¸Šä¸‹æ–‡å°è©±
                for i in range(0, len(conversation) - 1, 2):
                    if i + 1 < len(conversation):
                        user_msg = conversation[i]
                        assistant_msg = conversation[i + 1]
                        
                        if user_msg.get("role") == "user" and assistant_msg.get("role") == "assistant":
                            # æª¢æŸ¥æ˜¯å¦åŒ…å«å·¥å…·èª¿ç”¨
                            tool_calls = self._extract_tool_calls(assistant_msg["content"])
                            
                            sample = {
                                "input": user_msg["content"],
                                "output": assistant_msg["content"],
                                "type": "conversation",
                                "has_tool_calls": len(tool_calls) > 0,
                                "tool_calls": tool_calls,
                                "context": self._get_conversation_context(conversation, i),
                                "metadata": {
                                    "source": "manus",
                                    "url": data.get("url", ""),
                                    "timestamp": data.get("timestamp", ""),
                                    "message_count": len(conversation)
                                }
                            }
                            
                            samples.append(sample)
                            self.stats["manus_conversations"] += 1
                            
                            if tool_calls:
                                self.stats["conversations_with_tools"] += 1
            
            except Exception as e:
                logger.warning(f"è™•ç†æ–‡ä»¶å¤±æ•— {json_file}: {e}")
        
        return samples
    
    def _extract_tool_calls(self, content):
        """å¾å›è¦†ä¸­æå–å·¥å…·èª¿ç”¨"""
        tool_calls = []
        
        # æŸ¥æ‰¾ <function_calls> æ¨™ç±¤
        function_call_pattern = r'<function_calls>(.*?)</function_calls>'
        matches = re.findall(function_call_pattern, content, re.DOTALL)
        
        for match in matches:
            # æå–æ¯å€‹ invoke
            invoke_pattern = r'<invoke name="([^"]+)">(.*?)</invoke>'
            invokes = re.findall(invoke_pattern, match, re.DOTALL)
            
            for tool_name, params_content in invokes:
                if tool_name in self.tool_mapping:
                    # æå–åƒæ•¸
                    param_pattern = r'<parameter name="([^"]+)">([^<]*)</parameter>'
                    params = dict(re.findall(param_pattern, params_content))
                    
                    tool_calls.append({
                        "tool": tool_name,
                        "tool_id": self.tool_mapping[tool_name],
                        "parameters": params
                    })
                    
                    self.stats[f"tool_{tool_name}"] += 1
        
        return tool_calls
    
    def _get_conversation_context(self, conversation, current_idx, context_window=2):
        """ç²å–å°è©±ä¸Šä¸‹æ–‡"""
        context = []
        start_idx = max(0, current_idx - context_window * 2)
        
        for i in range(start_idx, current_idx):
            if i < len(conversation):
                msg = conversation[i]
                context.append({
                    "role": msg.get("role", ""),
                    "content": msg.get("content", "")[:200]  # æˆªæ–·ä»¥ç¯€çœç©ºé–“
                })
        
        return context
    
    def _create_synthetic_tool_data(self):
        """å‰µå»ºåˆæˆçš„å·¥å…·èª¿ç”¨è¨“ç·´æ•¸æ“š"""
        samples = []
        
        # å·¥å…·ä½¿ç”¨å ´æ™¯æ¨¡æ¿
        tool_scenarios = [
            # Readå·¥å…·å ´æ™¯
            {
                "tool": "Read",
                "scenarios": [
                    {
                        "input": "è«‹å¹«æˆ‘æŸ¥çœ‹ {file} æ–‡ä»¶çš„å…§å®¹",
                        "params": {"file_path": "{file}"},
                        "response": "æˆ‘å°‡ç‚ºæ‚¨è®€å– {file} æ–‡ä»¶çš„å…§å®¹ã€‚"
                    },
                    {
                        "input": "é¡¯ç¤º {file} çš„å‰ {n} è¡Œ",
                        "params": {"file_path": "{file}", "limit": "{n}"},
                        "response": "æˆ‘å°‡é¡¯ç¤º {file} æ–‡ä»¶çš„å‰ {n} è¡Œã€‚"
                    }
                ]
            },
            # Writeå·¥å…·å ´æ™¯
            {
                "tool": "Write",
                "scenarios": [
                    {
                        "input": "å‰µå»ºä¸€å€‹æ–°çš„ {type} æ–‡ä»¶å« {file}",
                        "params": {"file_path": "{file}", "content": ""},
                        "response": "æˆ‘å°‡ç‚ºæ‚¨å‰µå»ºæ–°çš„ {type} æ–‡ä»¶ {file}ã€‚"
                    }
                ]
            },
            # Editå·¥å…·å ´æ™¯
            {
                "tool": "Edit",
                "scenarios": [
                    {
                        "input": "å°‡ {file} ä¸­çš„ {old} æ›¿æ›ç‚º {new}",
                        "params": {"file_path": "{file}", "old_string": "{old}", "new_string": "{new}"},
                        "response": "æˆ‘å°‡åœ¨ {file} ä¸­å°‡ {old} æ›¿æ›ç‚º {new}ã€‚"
                    }
                ]
            },
            # Grepå·¥å…·å ´æ™¯
            {
                "tool": "Grep",
                "scenarios": [
                    {
                        "input": "æœç´¢æ‰€æœ‰åŒ…å« {pattern} çš„ {ext} æ–‡ä»¶",
                        "params": {"pattern": "{pattern}", "glob": "*.{ext}"},
                        "response": "æˆ‘å°‡æœç´¢æ‰€æœ‰åŒ…å« {pattern} çš„ {ext} æ–‡ä»¶ã€‚"
                    }
                ]
            },
            # Bashå·¥å…·å ´æ™¯
            {
                "tool": "Bash",
                "scenarios": [
                    {
                        "input": "åŸ·è¡Œ {command} å‘½ä»¤",
                        "params": {"command": "{command}", "description": "åŸ·è¡Œå‘½ä»¤"},
                        "response": "æˆ‘å°‡åŸ·è¡Œ {command} å‘½ä»¤ã€‚"
                    }
                ]
            }
        ]
        
        # ç”Ÿæˆæ¨£æœ¬
        file_types = ["Python", "JavaScript", "é…ç½®", "æ–‡æª”", "æ¸¬è©¦"]
        file_names = ["main.py", "config.json", "utils.js", "README.md", "test.py"]
        patterns = ["TODO", "FIXME", "import", "function", "class"]
        commands = ["pytest", "npm test", "git status", "ls -la", "python script.py"]
        
        for tool_info in tool_scenarios:
            tool_name = tool_info["tool"]
            
            for scenario in tool_info["scenarios"]:
                # ç”Ÿæˆå¤šå€‹è®Šé«”
                for _ in range(20):  # æ¯å€‹å ´æ™¯ç”Ÿæˆ20å€‹æ¨£æœ¬
                    # éš¨æ©Ÿå¡«å……æ¨¡æ¿
                    replacements = {
                        "{file}": random.choice(file_names),
                        "{type}": random.choice(file_types),
                        "{n}": str(random.randint(10, 100)),
                        "{old}": f"old_{random.randint(1, 100)}",
                        "{new}": f"new_{random.randint(1, 100)}",
                        "{pattern}": random.choice(patterns),
                        "{ext}": random.choice(["py", "js", "json", "md"]),
                        "{command}": random.choice(commands)
                    }
                    
                    # æ§‹å»ºè¼¸å…¥è¼¸å‡º
                    input_text = scenario["input"]
                    params = {}
                    response = scenario["response"]
                    
                    for key, value in replacements.items():
                        input_text = input_text.replace(key, value)
                        response = response.replace(key, value)
                        
                        # è™•ç†åƒæ•¸
                        for param_key, param_value in scenario["params"].items():
                            if key in param_value:
                                params[param_key] = param_value.replace(key, value)
                    
                    # æ§‹å»ºå·¥å…·èª¿ç”¨XML
                    params_xml = ""
                    for param_name, param_value in params.items():
                        params_xml += f'\n<parameter name="{param_name}">{param_value}</parameter>'
                    
                    output_text = f"{response}\n\n<function_calls>\n<invoke name=\"{tool_name}\">{params_xml}\n</invoke>\n</function_calls>"
                    
                    sample = {
                        "input": input_text,
                        "output": output_text,
                        "type": "tool_call",
                        "has_tool_calls": True,
                        "tool_calls": [{
                            "tool": tool_name,
                            "tool_id": self.tool_mapping[tool_name],
                            "parameters": params
                        }],
                        "context": [],
                        "metadata": {
                            "source": "synthetic",
                            "tool": tool_name
                        }
                    }
                    
                    samples.append(sample)
                    self.stats["synthetic_tool_calls"] += 1
        
        return samples
    
    def _create_code_understanding_data(self):
        """å‰µå»ºç¨‹å¼ç†è§£è¨“ç·´æ•¸æ“š"""
        samples = []
        
        # ç¨‹å¼ç†è§£å ´æ™¯
        code_scenarios = [
            {
                "input": "é€™æ®µä»£ç¢¼çš„åŠŸèƒ½æ˜¯ä»€éº¼ï¼Ÿ\n```python\ndef fibonacci(n):\n    if n <= 1:\n        return n\n    return fibonacci(n-1) + fibonacci(n-2)\n```",
                "output": "é€™æ®µä»£ç¢¼å¯¦ç¾äº†æ–æ³¢é‚£å¥‘æ•¸åˆ—çš„éæ­¸è¨ˆç®—ã€‚å‡½æ•¸æ¥å—ä¸€å€‹æ•´æ•¸ n ä½œç‚ºåƒæ•¸ï¼Œè¿”å›ç¬¬ n å€‹æ–æ³¢é‚£å¥‘æ•¸ã€‚ç•¶ n å°æ–¼ç­‰æ–¼ 1 æ™‚ç›´æ¥è¿”å› nï¼Œå¦å‰‡è¿”å›å‰å…©å€‹æ–æ³¢é‚£å¥‘æ•¸çš„å’Œã€‚",
                "type": "code_explanation"
            },
            {
                "input": "è«‹å¹«æˆ‘å„ªåŒ–é€™æ®µä»£ç¢¼çš„æ€§èƒ½",
                "output": "æˆ‘æœƒåˆ†æä»£ç¢¼ä¸¦æä¾›æ€§èƒ½å„ªåŒ–å»ºè­°ã€‚è®“æˆ‘å…ˆæŸ¥çœ‹æ‚¨çš„ä»£ç¢¼ã€‚\n\n<function_calls>\n<invoke name=\"Read\">\n<parameter name=\"file_path\">main.py</parameter>\n</invoke>\n</function_calls>",
                "type": "code_optimization"
            },
            {
                "input": "é€™å€‹éŒ¯èª¤æ˜¯ä»€éº¼æ„æ€ï¼ŸTypeError: 'NoneType' object is not iterable",
                "output": "é€™å€‹éŒ¯èª¤è¡¨ç¤ºæ‚¨å˜—è©¦è¿­ä»£ä¸€å€‹ None å°è±¡ã€‚é€šå¸¸ç™¼ç”Ÿåœ¨å‡½æ•¸æ²’æœ‰è¿”å›å€¼ï¼ˆé»˜èªè¿”å› Noneï¼‰æˆ–è®Šé‡è¢«è¨­ç½®ç‚º None æ™‚ï¼Œå»è¢«ç•¶ä½œå¯è¿­ä»£å°è±¡ä½¿ç”¨ã€‚è«‹æª¢æŸ¥ç›¸é—œè®Šé‡æ˜¯å¦æ­£ç¢ºåˆå§‹åŒ–ã€‚",
                "type": "error_explanation"
            }
        ]
        
        # ç”Ÿæˆæ›´å¤šè®Šé«”
        for scenario in code_scenarios:
            for i in range(30):  # æ¯å€‹å ´æ™¯30å€‹è®Šé«”
                sample = {
                    "input": scenario["input"],
                    "output": scenario["output"],
                    "type": "code_understanding",
                    "has_tool_calls": "function_calls" in scenario["output"],
                    "tool_calls": self._extract_tool_calls(scenario["output"]),
                    "context": [],
                    "metadata": {
                        "source": "synthetic",
                        "understanding_type": scenario["type"]
                    }
                }
                samples.append(sample)
                self.stats["code_understanding_samples"] += 1
        
        return samples
    
    def _create_memory_augmented_data(self):
        """å‰µå»ºè¨˜æ†¶å¢å¼·è¨“ç·´æ•¸æ“š"""
        samples = []
        
        # éœ€è¦è¨˜æ†¶çš„å ´æ™¯
        memory_scenarios = [
            {
                "context": [
                    {"role": "user", "content": "æˆ‘çš„é …ç›®ä½¿ç”¨ Python 3.9"},
                    {"role": "assistant", "content": "äº†è§£ï¼Œæ‚¨çš„é …ç›®ä½¿ç”¨ Python 3.9ã€‚"}
                ],
                "input": "å¹«æˆ‘å‰µå»ºä¸€å€‹å…¼å®¹çš„ requirements.txt",
                "output": "åŸºæ–¼æ‚¨ä¹‹å‰æåˆ°çš„ Python 3.9 ç’°å¢ƒï¼Œæˆ‘å°‡å‰µå»ºä¸€å€‹å…¼å®¹çš„ requirements.txt æ–‡ä»¶ã€‚",
                "requires_memory": True
            },
            {
                "context": [
                    {"role": "user", "content": "æˆ‘å€‘çš„ç·¨ç¢¼è¦ç¯„è¦æ±‚ä½¿ç”¨ 4 å€‹ç©ºæ ¼ç¸®é€²"},
                    {"role": "assistant", "content": "å¥½çš„ï¼Œæˆ‘æœƒéµå¾ª 4 å€‹ç©ºæ ¼çš„ç¸®é€²è¦ç¯„ã€‚"}
                ],
                "input": "å¹«æˆ‘æ ¼å¼åŒ–é€™å€‹æ–‡ä»¶",
                "output": "æˆ‘å°‡æŒ‰ç…§æ‚¨ä¹‹å‰æåˆ°çš„ç·¨ç¢¼è¦ç¯„ï¼ˆ4 å€‹ç©ºæ ¼ç¸®é€²ï¼‰ä¾†æ ¼å¼åŒ–æ–‡ä»¶ã€‚",
                "requires_memory": True
            }
        ]
        
        for scenario in memory_scenarios:
            for i in range(25):
                sample = {
                    "input": scenario["input"],
                    "output": scenario["output"],
                    "type": "memory_augmented",
                    "has_tool_calls": False,
                    "tool_calls": [],
                    "context": scenario["context"],
                    "metadata": {
                        "source": "synthetic",
                        "requires_memory": scenario["requires_memory"]
                    }
                }
                samples.append(sample)
                self.stats["memory_augmented_samples"] += 1
        
        return samples
    
    def _save_dataset(self, samples, filename):
        """ä¿å­˜æ•¸æ“šé›†"""
        output_path = self.output_dir / filename
        
        # è½‰æ›ç‚ºè¨“ç·´æ ¼å¼
        processed_samples = []
        for sample in samples:
            processed = {
                "id": f"{sample['type']}_{len(processed_samples)}",
                "input": sample["input"],
                "output": sample["output"],
                "type": sample["type"],
                "has_tool_calls": sample["has_tool_calls"],
                "tool_labels": [tc["tool_id"] for tc in sample["tool_calls"]] if sample["tool_calls"] else [],
                "context": sample["context"],
                "metadata": sample["metadata"]
            }
            processed_samples.append(processed)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(processed_samples, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ’¾ ä¿å­˜äº† {len(processed_samples)} å€‹æ¨£æœ¬åˆ° {output_path}")
    
    def _print_statistics(self):
        """æ‰“å°çµ±è¨ˆä¿¡æ¯"""
        logger.info("\nğŸ“Š æ•¸æ“šçµ±è¨ˆ:")
        logger.info("="*50)
        
        total_samples = sum(v for k, v in self.stats.items() if k.endswith("_samples") or k == "manus_conversations")
        logger.info(f"ç¸½æ¨£æœ¬æ•¸: {total_samples}")
        
        logger.info("\næŒ‰é¡å‹åˆ†ä½ˆ:")
        logger.info(f"  - Manuså°è©±: {self.stats['manus_conversations']}")
        logger.info(f"  - åˆæˆå·¥å…·èª¿ç”¨: {self.stats['synthetic_tool_calls']}")
        logger.info(f"  - ç¨‹å¼ç†è§£: {self.stats['code_understanding_samples']}")
        logger.info(f"  - è¨˜æ†¶å¢å¼·: {self.stats['memory_augmented_samples']}")
        
        logger.info("\nå·¥å…·ä½¿ç”¨çµ±è¨ˆ:")
        for tool_name in self.tool_mapping.keys():
            count = self.stats.get(f"tool_{tool_name}", 0)
            if count > 0:
                logger.info(f"  - {tool_name}: {count}")
        
        logger.info("\nå…¶ä»–çµ±è¨ˆ:")
        logger.info(f"  - åŒ…å«å·¥å…·èª¿ç”¨çš„å°è©±: {self.stats['conversations_with_tools']}")

def main():
    """ä¸»å‡½æ•¸"""
    preparer = TrainingDataPreparer()
    train_data, val_data = preparer.prepare_all_data()
    
    logger.info(f"\nâœ… æ•¸æ“šæº–å‚™å®Œæˆ!")
    logger.info(f"è¨“ç·´é›†: {len(train_data)} æ¨£æœ¬")
    logger.info(f"é©—è­‰é›†: {len(val_data)} æ¨£æœ¬")

if __name__ == "__main__":
    main()