#!/usr/bin/env python3
"""
æ·±å…¥æ¸¬è©¦K2å·¥å…·èª¿ç”¨èƒ½åŠ›èˆ‡Claudeçš„å¯¦éš›å·®è·
çœŸå¯¦çš„ã€è©³ç´°çš„å°æ¯”æ¸¬è©¦
"""

import asyncio
import json
import time
import os
from typing import Dict, List, Any

class K2ToolCallingDeepTest:
    """K2å·¥å…·èª¿ç”¨æ·±åº¦æ¸¬è©¦"""
    
    def __init__(self):
        self.test_results = []
        
    async def test_k2_tool_format(self):
        """æ¸¬è©¦K2çš„å·¥å…·èª¿ç”¨æ ¼å¼"""
        print("ğŸ”¬ æ¸¬è©¦K2å·¥å…·èª¿ç”¨æ ¼å¼")
        print("="*60)
        
        from huggingface_hub import InferenceClient
        os.environ['HF_TOKEN'] = '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'
        client = InferenceClient(provider='groq', api_key=os.environ['HF_TOKEN'])
        
        # æ¸¬è©¦ä¸åŒçš„å·¥å…·å®šç¾©æ ¼å¼
        test_formats = [
            {
                "name": "æ¨™æº–å‡½æ•¸æ ¼å¼",
                "system_prompt": """ä½ æœ‰ä»¥ä¸‹å·¥å…·å¯ç”¨ï¼š
1. read_file(path: str) - è®€å–æ–‡ä»¶
2. write_file(path: str, content: str) - å¯«å…¥æ–‡ä»¶
3. run_command(cmd: str) - åŸ·è¡Œå‘½ä»¤

è«‹ä½¿ç”¨æ­£ç¢ºçš„å·¥å…·èª¿ç”¨æ ¼å¼ã€‚""",
                "user_prompt": "è«‹è®€å–config.jsonæ–‡ä»¶"
            },
            {
                "name": "JSONå·¥å…·æ ¼å¼",
                "system_prompt": """å¯ç”¨å·¥å…·ï¼š
```json
[
  {"name": "read_file", "parameters": {"path": "string"}},
  {"name": "write_file", "parameters": {"path": "string", "content": "string"}}
]
```
ä½¿ç”¨<|tool_calls_section_begin|>æ ¼å¼èª¿ç”¨å·¥å…·ã€‚""",
                "user_prompt": "è«‹è®€å–config.jsonæ–‡ä»¶"
            },
            {
                "name": "è‡ªç„¶èªè¨€æç¤º",
                "system_prompt": "ä½ å¯ä»¥èª¿ç”¨read_fileã€write_fileç­‰å·¥å…·ã€‚",
                "user_prompt": "è«‹è®€å–config.jsonæ–‡ä»¶çš„å…§å®¹"
            }
        ]
        
        for test in test_formats:
            print(f"\nğŸ“‹ æ¸¬è©¦: {test['name']}")
            
            try:
                completion = client.chat.completions.create(
                    model='moonshotai/Kimi-K2-Instruct',
                    messages=[
                        {"role": "system", "content": test['system_prompt']},
                        {"role": "user", "content": test['user_prompt']}
                    ],
                    max_tokens=300
                )
                
                response = completion.choices[0].message.content
                
                # åˆ†æå·¥å…·èª¿ç”¨
                has_tool_call = '<|tool_call' in response
                tool_format_correct = '<|tool_call_begin|>' in response and '<|tool_call_end|>' in response
                has_parameters = 'tool_call_argument' in response or 'path' in response.lower()
                
                print(f"   åŒ…å«å·¥å…·èª¿ç”¨: {'âœ…' if has_tool_call else 'âŒ'}")
                print(f"   æ ¼å¼æ­£ç¢º: {'âœ…' if tool_format_correct else 'âŒ'}")
                print(f"   åŒ…å«åƒæ•¸: {'âœ…' if has_parameters else 'âŒ'}")
                print(f"   éŸ¿æ‡‰é è¦½: {response[:150]}...")
                
                self.test_results.append({
                    "format": test['name'],
                    "success": has_tool_call and tool_format_correct,
                    "response": response
                })
                
            except Exception as e:
                print(f"   âŒ æ¸¬è©¦å¤±æ•—: {e}")
                
        return self.test_results
    
    async def test_tool_calling_scenarios(self):
        """æ¸¬è©¦ä¸åŒå ´æ™¯çš„å·¥å…·èª¿ç”¨"""
        print("\nğŸ¯ æ¸¬è©¦å¯¦éš›å·¥å…·èª¿ç”¨å ´æ™¯")
        print("="*60)
        
        from huggingface_hub import InferenceClient
        client = InferenceClient(provider='groq', api_key=os.environ['HF_TOKEN'])
        
        # å¯¦éš›é–‹ç™¼å ´æ™¯
        scenarios = [
            {
                "name": "å–®ä¸€å·¥å…·èª¿ç”¨",
                "prompt": "è®€å–main.pyæ–‡ä»¶",
                "expected_tools": ["read_file"],
                "complexity": "simple"
            },
            {
                "name": "é †åºå·¥å…·èª¿ç”¨",
                "prompt": "å…ˆè®€å–config.jsonï¼Œç„¶å¾ŒæŠŠdebugæ”¹ç‚ºtrueï¼Œå†å¯«å›å»",
                "expected_tools": ["read_file", "write_file"],
                "complexity": "medium"
            },
            {
                "name": "æ¢ä»¶å·¥å…·èª¿ç”¨",
                "prompt": "å¦‚æœerror.logæ–‡ä»¶å­˜åœ¨ï¼Œè®€å–å®ƒä¸¦åˆ†æéŒ¯èª¤é¡å‹",
                "expected_tools": ["check_file", "read_file", "analyze"],
                "complexity": "complex"
            },
            {
                "name": "ä¸¦è¡Œå·¥å…·èª¿ç”¨",
                "prompt": "åŒæ™‚è®€å–package.jsonå’ŒREADME.mdï¼Œå°æ¯”ç‰ˆæœ¬ä¿¡æ¯",
                "expected_tools": ["read_file", "read_file", "compare"],
                "complexity": "complex"
            }
        ]
        
        results = []
        
        for scenario in scenarios:
            print(f"\nğŸ“ å ´æ™¯: {scenario['name']}")
            print(f"   è¤‡é›œåº¦: {scenario['complexity']}")
            print(f"   æœŸæœ›å·¥å…·: {scenario['expected_tools']}")
            
            try:
                start_time = time.time()
                
                completion = client.chat.completions.create(
                    model='moonshotai/Kimi-K2-Instruct',
                    messages=[
                        {
                            "role": "system", 
                            "content": "ä½ æ˜¯é–‹ç™¼åŠ©æ‰‹ã€‚å¯ç”¨å·¥å…·ï¼šread_file(path), write_file(path, content), check_file(path), analyze(content), compare(file1, file2)ã€‚ä½¿ç”¨<|tool_calls_section_begin|>æ ¼å¼èª¿ç”¨å·¥å…·ã€‚"
                        },
                        {
                            "role": "user",
                            "content": scenario['prompt']
                        }
                    ],
                    max_tokens=500
                )
                
                response = completion.choices[0].message.content
                response_time = time.time() - start_time
                
                # åˆ†æå·¥å…·èª¿ç”¨
                tool_calls = response.count('<|tool_call_begin|>')
                tools_found = []
                
                # æå–å¯¦éš›èª¿ç”¨çš„å·¥å…·
                import re
                tool_pattern = r'functions\.(\w+):'
                matches = re.findall(tool_pattern, response)
                tools_found = matches
                
                # è©•ä¼°çµæœ
                expected_count = len(scenario['expected_tools'])
                actual_count = len(tools_found)
                coverage = actual_count / expected_count if expected_count > 0 else 0
                
                print(f"   å¯¦éš›èª¿ç”¨: {tools_found}")
                print(f"   å·¥å…·æ•¸é‡: {actual_count}/{expected_count}")
                print(f"   è¦†è“‹ç‡: {coverage:.1%}")
                print(f"   éŸ¿æ‡‰æ™‚é–“: {response_time:.2f}s")
                
                results.append({
                    "scenario": scenario['name'],
                    "complexity": scenario['complexity'],
                    "expected": expected_count,
                    "actual": actual_count,
                    "coverage": coverage,
                    "time": response_time,
                    "tools_called": tools_found
                })
                
            except Exception as e:
                print(f"   âŒ æ¸¬è©¦å¤±æ•—: {e}")
                results.append({
                    "scenario": scenario['name'],
                    "error": str(e)
                })
        
        return results
    
    async def test_error_handling(self):
        """æ¸¬è©¦å·¥å…·èª¿ç”¨çš„éŒ¯èª¤è™•ç†"""
        print("\nâš ï¸ æ¸¬è©¦éŒ¯èª¤è™•ç†èƒ½åŠ›")
        print("="*50)
        
        from huggingface_hub import InferenceClient
        client = InferenceClient(provider='groq', api_key=os.environ['HF_TOKEN'])
        
        error_scenarios = [
            {
                "name": "ç„¡æ•ˆå·¥å…·åç¨±",
                "prompt": "ä½¿ç”¨invalid_tool()ä¾†è™•ç†æ–‡ä»¶"
            },
            {
                "name": "ç¼ºå°‘å¿…éœ€åƒæ•¸",
                "prompt": "èª¿ç”¨read_fileä½†ä¸æä¾›æ–‡ä»¶è·¯å¾‘"
            },
            {
                "name": "åƒæ•¸é¡å‹éŒ¯èª¤",
                "prompt": "èª¿ç”¨write_fileï¼Œç”¨æ•¸å­—123ä½œç‚ºæ–‡ä»¶è·¯å¾‘"
            }
        ]
        
        for scenario in error_scenarios:
            print(f"\nğŸ”§ {scenario['name']}")
            
            try:
                completion = client.chat.completions.create(
                    model='moonshotai/Kimi-K2-Instruct',
                    messages=[
                        {
                            "role": "system",
                            "content": "ä½ æ˜¯é–‹ç™¼åŠ©æ‰‹ï¼Œå¯ä»¥èª¿ç”¨read_file(path: str)å’Œwrite_file(path: str, content: str)å·¥å…·ã€‚"
                        },
                        {
                            "role": "user",
                            "content": scenario['prompt']
                        }
                    ],
                    max_tokens=300
                )
                
                response = completion.choices[0].message.content
                
                # æª¢æŸ¥éŒ¯èª¤è™•ç†
                handles_error = any(word in response.lower() for word in ['éŒ¯èª¤', 'ç„¡æ•ˆ', 'å¤±æ•—', 'error', 'invalid', 'fail'])
                suggests_correction = any(word in response.lower() for word in ['æ‡‰è©²', 'éœ€è¦', 'è«‹æä¾›', 'should', 'need', 'please'])
                
                print(f"   è­˜åˆ¥éŒ¯èª¤: {'âœ…' if handles_error else 'âŒ'}")
                print(f"   æä¾›å»ºè­°: {'âœ…' if suggests_correction else 'âŒ'}")
                
            except Exception as e:
                print(f"   æ¸¬è©¦ç•°å¸¸: {e}")
    
    async def compare_with_claude_format(self):
        """å°æ¯”K2å’ŒClaudeçš„å·¥å…·èª¿ç”¨æ ¼å¼å·®ç•°"""
        print("\nğŸ“Š K2 vs Claude å·¥å…·èª¿ç”¨æ ¼å¼å°æ¯”")
        print("="*60)
        
        print("\nğŸ“Œ K2å·¥å…·èª¿ç”¨æ ¼å¼:")
        print("""
<|tool_calls_section_begin|>
<|tool_call_begin|>functions.read_file:0
<|tool_call_argument_begin|>{"path": "config.json"}
<|tool_call_end|>
<|tool_calls_section_end|>
        """)
        
        print("\nğŸ“Œ Claudeå·¥å…·èª¿ç”¨æ ¼å¼ï¼ˆç†è«–ï¼‰:")
        print("""
I'll help you read the file. Let me do that for you.

<function_calls>
<invoke name="read_file">
<parameter name="path">config.json</parameter>
</invoke>
</function_calls>
        """)
        
        print("\nğŸ” é—œéµå·®ç•°:")
        print("1. æ ¼å¼æ¨™è¨˜: K2ä½¿ç”¨<|tool_*|>ï¼ŒClaudeä½¿ç”¨XMLé¢¨æ ¼")
        print("2. å‡½æ•¸å‘½å: K2ä½¿ç”¨functions.å‰ç¶´ï¼ŒClaudeç›´æ¥ä½¿ç”¨å‡½æ•¸å")
        print("3. åƒæ•¸æ ¼å¼: K2ä½¿ç”¨JSONï¼ŒClaudeä½¿ç”¨XMLåƒæ•¸")
        print("4. èª¿ç”¨é¢¨æ ¼: K2æ›´ç¨‹åºåŒ–ï¼ŒClaudeæ›´è‡ªç„¶èªè¨€åŒ–")
        
        return {
            "k2_format": "pipeline_style",
            "claude_format": "xml_style",
            "compatibility": "éœ€è¦æ ¼å¼è½‰æ›"
        }
    
    async def generate_deep_analysis_report(self, format_results, scenario_results):
        """ç”Ÿæˆæ·±åº¦åˆ†æå ±å‘Š"""
        print("\nğŸ“‹ K2å·¥å…·èª¿ç”¨èƒ½åŠ›æ·±åº¦åˆ†æå ±å‘Š")
        print("="*70)
        
        # æ ¼å¼æ¸¬è©¦åˆ†æ
        format_success = sum(1 for r in format_results if r.get('success', False))
        print(f"\n1ï¸âƒ£ å·¥å…·æ ¼å¼æ”¯æŒ:")
        print(f"   æˆåŠŸç‡: {format_success}/{len(format_results)} ({format_success/len(format_results)*100:.1f}%)")
        
        # å ´æ™¯æ¸¬è©¦åˆ†æ
        simple_scenarios = [r for r in scenario_results if r.get('complexity') == 'simple']
        medium_scenarios = [r for r in scenario_results if r.get('complexity') == 'medium']
        complex_scenarios = [r for r in scenario_results if r.get('complexity') == 'complex']
        
        print(f"\n2ï¸âƒ£ å ´æ™¯è¤‡é›œåº¦åˆ†æ:")
        if simple_scenarios:
            simple_coverage = sum(r.get('coverage', 0) for r in simple_scenarios) / len(simple_scenarios)
            print(f"   ç°¡å–®å ´æ™¯: {simple_coverage:.1%} è¦†è“‹ç‡")
        if medium_scenarios:
            medium_coverage = sum(r.get('coverage', 0) for r in medium_scenarios) / len(medium_scenarios)
            print(f"   ä¸­ç­‰å ´æ™¯: {medium_coverage:.1%} è¦†è“‹ç‡")
        if complex_scenarios:
            complex_coverage = sum(r.get('coverage', 0) for r in complex_scenarios) / len(complex_scenarios)
            print(f"   è¤‡é›œå ´æ™¯: {complex_coverage:.1%} è¦†è“‹ç‡")
        
        # æ€§èƒ½åˆ†æ
        valid_results = [r for r in scenario_results if 'time' in r]
        if valid_results:
            avg_time = sum(r['time'] for r in valid_results) / len(valid_results)
            print(f"\n3ï¸âƒ£ æ€§èƒ½æŒ‡æ¨™:")
            print(f"   å¹³å‡éŸ¿æ‡‰æ™‚é–“: {avg_time:.2f}s")
            print(f"   æœ€å¿«éŸ¿æ‡‰: {min(r['time'] for r in valid_results):.2f}s")
            print(f"   æœ€æ…¢éŸ¿æ‡‰: {max(r['time'] for r in valid_results):.2f}s")
        
        # ç¸½é«”è©•ä¼°
        print(f"\n4ï¸âƒ£ ç¸½é«”è©•ä¼°:")
        overall_coverage = sum(r.get('coverage', 0) for r in scenario_results) / len(scenario_results) if scenario_results else 0
        
        if overall_coverage >= 0.8:
            print("   âœ… K2å·¥å…·èª¿ç”¨èƒ½åŠ›ï¼šå„ªç§€")
            print("   å¯ä»¥æ”¯æŒå¤§éƒ¨åˆ†é–‹ç™¼å ´æ™¯")
        elif overall_coverage >= 0.6:
            print("   âš ï¸ K2å·¥å…·èª¿ç”¨èƒ½åŠ›ï¼šè‰¯å¥½")
            print("   åŸºæœ¬å ´æ™¯å¯ç”¨ï¼Œè¤‡é›œå ´æ™¯éœ€å„ªåŒ–")
        else:
            print("   âŒ K2å·¥å…·èª¿ç”¨èƒ½åŠ›ï¼šä¸è¶³")
            print("   éœ€è¦é¡¯è‘—æ”¹é€²æ‰èƒ½æŠ•å…¥ä½¿ç”¨")
        
        return {
            "overall_coverage": overall_coverage,
            "format_compatibility": format_success / len(format_results) if format_results else 0,
            "performance_acceptable": avg_time < 3.0 if valid_results else False
        }

async def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸš€ K2å·¥å…·èª¿ç”¨èƒ½åŠ›æ·±åº¦æ¸¬è©¦")
    print("çœŸå¯¦ã€è©³ç´°çš„å°æ¯”åˆ†æ")
    print("="*70)
    
    tester = K2ToolCallingDeepTest()
    
    # 1. æ¸¬è©¦å·¥å…·æ ¼å¼
    format_results = await tester.test_k2_tool_format()
    
    # 2. æ¸¬è©¦å¯¦éš›å ´æ™¯
    scenario_results = await tester.test_tool_calling_scenarios()
    
    # 3. æ¸¬è©¦éŒ¯èª¤è™•ç†
    await tester.test_error_handling()
    
    # 4. å°æ¯”Claudeæ ¼å¼
    format_comparison = await tester.compare_with_claude_format()
    
    # 5. ç”Ÿæˆæ·±åº¦å ±å‘Š
    analysis = await tester.generate_deep_analysis_report(format_results, scenario_results)
    
    print("\nğŸ¯ æœ€çµ‚çµè«–:")
    if analysis['overall_coverage'] >= 0.7 and analysis['format_compatibility'] >= 0.7:
        print("âœ… K2å·¥å…·èª¿ç”¨èƒ½åŠ›å¯ä»¥æ”¯æŒPowerAutomation")
        print("âœ… èˆ‡Claudeçš„å·®è·åœ¨å¯æ¥å—ç¯„åœå…§")
        print("âœ… é€éæ ¼å¼è½‰æ›å¯ä»¥å¯¦ç¾é€æ˜åˆ‡æ›")
    else:
        print("âŒ K2å·¥å…·èª¿ç”¨èƒ½åŠ›å­˜åœ¨é¡¯è‘—å·®è·")
        print("âš ï¸ éœ€è¦é¡å¤–çš„å„ªåŒ–å’Œé©é…å·¥ä½œ")
        print("ğŸ”§ å»ºè­°å…ˆåœ¨ç°¡å–®å ´æ™¯ä¸­ä½¿ç”¨")

if __name__ == "__main__":
    asyncio.run(main())