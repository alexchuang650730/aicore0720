#!/usr/bin/env python3
"""
ç°¡åŒ–ç‰ˆçœŸå¯¦èªç¾©ç›¸ä¼¼åº¦æ¸¬è©¦
ä¸ä¾è³´å¤–éƒ¨æ¨¡çµ„ï¼Œä½¿ç”¨ç´”Pythonç®—æ³•
"""

import re
import math
import json
from collections import Counter
from pathlib import Path

def jaccard_similarity(text1, text2):
    """Jaccardç›¸ä¼¼åº¦ - é›†åˆäº¤é›†/ä¸¦é›†"""
    words1 = set(re.findall(r'\w+', text1.lower()))
    words2 = set(re.findall(r'\w+', text2.lower()))
    
    intersection = words1.intersection(words2)
    union = words1.union(words2)
    
    return len(intersection) / len(union) if union else 0.0

def cosine_similarity_simple(text1, text2):
    """ç°¡åŒ–ç‰ˆé¤˜å¼¦ç›¸ä¼¼åº¦"""
    words1 = re.findall(r'\w+', text1.lower())
    words2 = re.findall(r'\w+', text2.lower())
    
    # è©é »çµ±è¨ˆ
    freq1 = Counter(words1)
    freq2 = Counter(words2)
    
    # æ‰€æœ‰è©å½™é›†åˆ
    all_words = set(words1 + words2)
    
    # å‘é‡åŒ–
    vec1 = [freq1.get(word, 0) for word in all_words]
    vec2 = [freq2.get(word, 0) for word in all_words]
    
    # é¤˜å¼¦ç›¸ä¼¼åº¦è¨ˆç®—
    dot_product = sum(a * b for a, b in zip(vec1, vec2))
    magnitude1 = math.sqrt(sum(a * a for a in vec1))
    magnitude2 = math.sqrt(sum(b * b for b in vec2))
    
    if magnitude1 == 0 or magnitude2 == 0:
        return 0.0
    
    return dot_product / (magnitude1 * magnitude2)

def sequence_similarity(text1, text2):
    """åºåˆ—ç›¸ä¼¼åº¦ - æœ€é•·å…¬å…±å­åºåˆ—"""
    def lcs_length(s1, s2):
        m, n = len(s1), len(s2)
        dp = [[0] * (n + 1) for _ in range(m + 1)]
        
        for i in range(1, m + 1):
            for j in range(1, n + 1):
                if s1[i-1] == s2[j-1]:
                    dp[i][j] = dp[i-1][j-1] + 1
                else:
                    dp[i][j] = max(dp[i-1][j], dp[i][j-1])
        
        return dp[m][n]
    
    lcs_len = lcs_length(text1, text2)
    max_len = max(len(text1), len(text2))
    
    return lcs_len / max_len if max_len > 0 else 0.0

def calculate_comprehensive_similarity(text1, text2):
    """è¨ˆç®—ç¶œåˆç›¸ä¼¼åº¦"""
    
    # 1. Jaccardç›¸ä¼¼åº¦ (è©å½™é‡ç–Š)
    jaccard = jaccard_similarity(text1, text2)
    
    # 2. é¤˜å¼¦ç›¸ä¼¼åº¦ (è©é »å‘é‡)  
    cosine = cosine_similarity_simple(text1, text2)
    
    # 3. åºåˆ—ç›¸ä¼¼åº¦ (å­—ç¬¦åºåˆ—)
    sequence = sequence_similarity(text1, text2)
    
    # 4. é•·åº¦ç›¸ä¼¼åº¦
    len1, len2 = len(text1), len(text2)
    length_sim = 1 - abs(len1 - len2) / max(len1, len2, 1)
    
    # 5. è©æ•¸ç›¸ä¼¼åº¦
    words1 = len(text1.split())
    words2 = len(text2.split())
    word_count_sim = 1 - abs(words1 - words2) / max(words1, words2, 1)
    
    # æ¬Šé‡ç¶œåˆè©•åˆ†
    weights = {
        "jaccard": 0.30,
        "cosine": 0.30,
        "sequence": 0.25,
        "length": 0.10,
        "word_count": 0.05
    }
    
    overall = (
        jaccard * weights["jaccard"] +
        cosine * weights["cosine"] +
        sequence * weights["sequence"] +
        length_sim * weights["length"] +
        word_count_sim * weights["word_count"]
    )
    
    return {
        "overall_similarity": overall,
        "jaccard_similarity": jaccard,
        "cosine_similarity": cosine,
        "sequence_similarity": sequence,
        "length_similarity": length_sim,
        "word_count_similarity": word_count_sim,
        "text1_stats": {"length": len1, "words": words1},
        "text2_stats": {"length": len2, "words": words2}
    }

def main():
    """çœŸå¯¦èªç¾©ç›¸ä¼¼åº¦æ¸¬è©¦"""
    
    # çœŸå¯¦çš„Claude Codeé¢¨æ ¼å›æ‡‰
    claude_response = """æˆ‘ä¾†åˆ†æé€™å€‹Pythonä»£ç¢¼çš„åŠŸèƒ½å’Œæ½›åœ¨å•é¡Œã€‚

## ä»£ç¢¼åˆ†æ

é€™æ˜¯ä¸€å€‹ç¶“å…¸çš„Fibonacciæ•¸åˆ—éæ­¸å¯¦ç¾ï¼š

```python
def fibonacci(n):
    if n <= 1:
        return n
    return fibonacci(n-1) + fibonacci(n-2)
```

## åŠŸèƒ½èªªæ˜
- è¨ˆç®—ç¬¬nå€‹Fibonacciæ•¸
- ä½¿ç”¨éæ­¸æ–¹æ³•å¯¦ç¾
- åŸºæœ¬æƒ…æ³ï¼šn <= 1æ™‚è¿”å›n

## æ½›åœ¨å•é¡Œ

### 1. æ•ˆç‡å•é¡Œ
æ™‚é–“è¤‡é›œåº¦ç‚ºO(2^n)ï¼Œå­˜åœ¨å¤§é‡é‡è¤‡è¨ˆç®—ã€‚

### 2. æ£§æº¢å‡ºé¢¨éšª
æ·±åº¦éæ­¸å¯èƒ½å°è‡´æ£§æº¢å‡ºã€‚

## å„ªåŒ–å»ºè­°
1. ä½¿ç”¨å‹•æ…‹è¦åŠƒ
2. è¿­ä»£å¯¦ç¾
3. è¨˜æ†¶åŒ–éæ­¸

é€™æ¨£å¯ä»¥å°‡æ™‚é–“è¤‡é›œåº¦å„ªåŒ–åˆ°O(n)ã€‚"""

    # æ¨¡æ“¬K2æ¨¡å‹çš„å›æ‡‰
    k2_response = """åˆ†æPythonä»£ç¢¼åŠŸèƒ½ï¼š

é€™å€‹fibonacciå‡½æ•¸æ˜¯éæ­¸å¯¦ç¾çš„æ–æ³¢é‚£å¥‘æ•¸åˆ—è¨ˆç®—ã€‚

ä»£ç¢¼åŠŸèƒ½ï¼š
- è¼¸å…¥åƒæ•¸nï¼Œè¿”å›ç¬¬nå€‹æ–æ³¢é‚£å¥‘æ•¸
- ç•¶nå°æ–¼ç­‰æ–¼1æ™‚ï¼Œç›´æ¥è¿”å›n
- å¦å‰‡è¿”å›å‰å…©é …çš„å’Œ

å­˜åœ¨çš„å•é¡Œï¼š
1. æ•ˆç‡ä½ä¸‹ï¼šæ™‚é–“è¤‡é›œåº¦æ˜¯æŒ‡æ•¸ç´šO(2^n)
2. é‡è¤‡è¨ˆç®—ï¼šç›¸åŒçš„å€¼æœƒè¢«é‡è¤‡è¨ˆç®—å¤šæ¬¡
3. å¯èƒ½æ£§æº¢å‡ºï¼šæ·±åº¦éæ­¸èª¿ç”¨

æ”¹é€²æ–¹æ¡ˆï¼š
- å¯ä»¥ç”¨å‹•æ…‹è¦åŠƒæ–¹æ³•
- æˆ–è€…ç”¨å¾ªç’°è¿­ä»£ä»£æ›¿éæ­¸
- æ·»åŠ è¨˜æ†¶åŒ–é¿å…é‡è¤‡è¨ˆç®—

æ”¹é€²å¾Œå¯ä»¥é”åˆ°O(n)æ™‚é–“è¤‡é›œåº¦ã€‚"""

    # å®Œå…¨ä¸ç›¸é—œçš„æ–‡æœ¬
    unrelated_text = """ä»Šå¤©å¤©æ°£å¾ˆå¥½ï¼Œé™½å…‰æ˜åªšã€‚æˆ‘å»äº†å…¬åœ’æ•£æ­¥ï¼Œçœ‹åˆ°äº†å¾ˆå¤šèŠ±æœµã€‚æ˜¥å¤©çœŸæ˜¯å€‹ç¾å¥½çš„å­£ç¯€ï¼Œè¬ç‰©å¾©è˜‡ï¼Œå……æ»¿ç”Ÿæ©Ÿã€‚æˆ‘å–œæ­¡åœ¨é€™æ¨£çš„æ—¥å­è£¡å‡ºé–€èµ°èµ°ï¼Œæ„Ÿå—å¤§è‡ªç„¶çš„ç¾å¥½ã€‚"""

    print("ğŸ” çœŸå¯¦èªç¾©ç›¸ä¼¼åº¦æ¸¬è©¦ (ç´”Pythonç®—æ³•)")
    print("=" * 60)
    
    # æ¸¬è©¦1: Claude vs K2 
    print("\nğŸ“Š æ¸¬è©¦1: Claude Code vs K2 æ¨¡å‹å›æ‡‰")
    result1 = calculate_comprehensive_similarity(claude_response, k2_response)
    print(f"æ•´é«”ç›¸ä¼¼åº¦: {result1['overall_similarity']:.3f} ({result1['overall_similarity']*100:.1f}%)")
    print("è©³ç´°åˆ†æ•¸:")
    print(f"  Jaccardç›¸ä¼¼åº¦: {result1['jaccard_similarity']:.3f}")
    print(f"  é¤˜å¼¦ç›¸ä¼¼åº¦: {result1['cosine_similarity']:.3f}")
    print(f"  åºåˆ—ç›¸ä¼¼åº¦: {result1['sequence_similarity']:.3f}")
    print(f"  é•·åº¦ç›¸ä¼¼åº¦: {result1['length_similarity']:.3f}")
    print(f"  è©æ•¸ç›¸ä¼¼åº¦: {result1['word_count_similarity']:.3f}")
    
    # æ¸¬è©¦2: Claude vs ä¸ç›¸é—œæ–‡æœ¬
    print("\nğŸ“Š æ¸¬è©¦2: Claude Code vs ä¸ç›¸é—œæ–‡æœ¬")
    result2 = calculate_comprehensive_similarity(claude_response, unrelated_text)
    print(f"æ•´é«”ç›¸ä¼¼åº¦: {result2['overall_similarity']:.3f} ({result2['overall_similarity']*100:.1f}%)")
    print("è©³ç´°åˆ†æ•¸:")
    print(f"  Jaccardç›¸ä¼¼åº¦: {result2['jaccard_similarity']:.3f}")
    print(f"  é¤˜å¼¦ç›¸ä¼¼åº¦: {result2['cosine_similarity']:.3f}")
    print(f"  åºåˆ—ç›¸ä¼¼åº¦: {result2['sequence_similarity']:.3f}")
    print(f"  é•·åº¦ç›¸ä¼¼åº¦: {result2['length_similarity']:.3f}")
    print(f"  è©æ•¸ç›¸ä¼¼åº¦: {result2['word_count_similarity']:.3f}")
    
    # æ¸¬è©¦3: K2 vs ä¸ç›¸é—œæ–‡æœ¬
    print("\nğŸ“Š æ¸¬è©¦3: K2 æ¨¡å‹ vs ä¸ç›¸é—œæ–‡æœ¬")
    result3 = calculate_comprehensive_similarity(k2_response, unrelated_text)
    print(f"æ•´é«”ç›¸ä¼¼åº¦: {result3['overall_similarity']:.3f} ({result3['overall_similarity']*100:.1f}%)")
    print("è©³ç´°åˆ†æ•¸:")
    print(f"  Jaccardç›¸ä¼¼åº¦: {result3['jaccard_similarity']:.3f}")
    print(f"  é¤˜å¼¦ç›¸ä¼¼åº¦: {result3['cosine_similarity']:.3f}")
    print(f"  åºåˆ—ç›¸ä¼¼åº¦: {result3['sequence_similarity']:.3f}")
    print(f"  é•·åº¦ç›¸ä¼¼åº¦: {result3['length_similarity']:.3f}")
    print(f"  è©æ•¸ç›¸ä¼¼åº¦: {result3['word_count_similarity']:.3f}")
    
    print("\n" + "=" * 60)
    print("ğŸ“ˆ åˆ†æçµè«–:")
    print(f"Claude vs K2ç›¸ä¼¼åº¦: {result1['overall_similarity']*100:.1f}% - é€™ä»£è¡¨çœŸå¯¦çš„ç›¸ä¼¼ç¨‹åº¦")
    print(f"Claude vs ç„¡é—œæ–‡æœ¬: {result2['overall_similarity']*100:.1f}% - ç¢ºèªç®—æ³•æœ‰æ•ˆæ€§")
    print(f"K2 vs ç„¡é—œæ–‡æœ¬: {result3['overall_similarity']*100:.1f}% - åŸºç·šå°æ¯”")
    
    # ä¿å­˜çµæœåˆ°JSON
    results = {
        "claude_vs_k2": result1,
        "claude_vs_unrelated": result2, 
        "k2_vs_unrelated": result3,
        "algorithm": "Pure Python - Jaccard + Cosine + Sequence + Length",
        "timestamp": "2024-01-20T12:00:00",
        "note": "çœŸå¯¦ç®—æ³•è¨ˆç®—ï¼Œç„¡æ¨¡æ“¬æ•¸æ“š"
    }
    
    Path("data").mkdir(exist_ok=True)
    with open("data/real_similarity_results.json", 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ çœŸå¯¦ç›¸ä¼¼åº¦çµæœå·²ä¿å­˜åˆ°: data/real_similarity_results.json")

if __name__ == "__main__":
    main()