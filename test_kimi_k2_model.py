#!/usr/bin/env python3
"""
æ¸¬è©¦çœŸæ­£çš„Kimi K2æ¨¡å‹
ä½¿ç”¨Moonshot APIçš„K2æ¨¡å‹
"""

import asyncio
import aiohttp
import time
import json

class KimiK2ModelTest:
    """Kimi K2æ¨¡å‹æ¸¬è©¦"""
    
    def __init__(self):
        self.moonshot_api_key = "sk-ocQ1YiAJtB2yfaXVXFzkW0973MXXKLR0OCEi0BbVqqmc31UK"
        self.api_url = "https://api.moonshot.cn/v1/chat/completions"
        
        # Kimi K2å¯ç”¨æ¨¡å‹
        self.k2_models = [
            "kimi-k2-instruct",      # K2 Instructæ¨¡å‹
            "moonshot-v1-8k",        # æ¨™æº–8Kæ¨¡å‹
            "moonshot-v1-32k",       # 32Kä¸Šä¸‹æ–‡
            "moonshot-v1-128k"       # 128Kä¸Šä¸‹æ–‡
        ]
    
    async def test_k2_models(self):
        """æ¸¬è©¦æ‰€æœ‰K2æ¨¡å‹"""
        print("ğŸš€ æ¸¬è©¦Kimi K2æ¨¡å‹æ€§èƒ½")
        print("="*60)
        
        results = []
        
        async with aiohttp.ClientSession() as session:
            for model in self.k2_models:
                print(f"\nğŸ“‹ æ¸¬è©¦æ¨¡å‹: {model}")
                
                # æ¸¬è©¦ä¸åŒé¡å‹çš„æŸ¥è©¢
                test_queries = [
                    {
                        "type": "ç°¡å–®å•ç­”",
                        "content": "ä»€éº¼æ˜¯Pythonï¼Ÿä¸€å¥è©±å›ç­”ã€‚"
                    },
                    {
                        "type": "ä»£ç¢¼ç”Ÿæˆ",
                        "content": "å¯«ä¸€å€‹Pythonå‡½æ•¸è¨ˆç®—æ–æ³¢é‚£å¥‘æ•¸åˆ—"
                    },
                    {
                        "type": "éŒ¯èª¤è¨ºæ–·",
                        "content": "è§£é‡‹list.append(1,2)ç‚ºä»€éº¼å ±éŒ¯"
                    }
                ]
                
                model_latencies = []
                model_success = True
                
                for query in test_queries:
                    start_time = time.time()
                    
                    try:
                        async with session.post(
                            self.api_url,
                            headers={
                                "Content-Type": "application/json",
                                "Authorization": f"Bearer {self.moonshot_api_key}"
                            },
                            json={
                                "model": model,
                                "messages": [
                                    {"role": "user", "content": query["content"]}
                                ],
                                "max_tokens": 200,
                                "temperature": 0.7
                            },
                            timeout=aiohttp.ClientTimeout(total=30)
                        ) as response:
                            if response.status == 200:
                                data = await response.json()
                                latency = (time.time() - start_time) * 1000
                                model_latencies.append(latency)
                                
                                content = data['choices'][0]['message']['content']
                                tokens = data.get('usage', {})
                                
                                print(f"   âœ… {query['type']}")
                                print(f"      å»¶é²: {latency:.0f}ms")
                                print(f"      Tokens: è¼¸å…¥{tokens.get('prompt_tokens', 0)}, è¼¸å‡º{tokens.get('completion_tokens', 0)}")
                                print(f"      éŸ¿æ‡‰: {content[:80]}...")
                            else:
                                model_success = False
                                error = await response.text()
                                print(f"   âŒ {query['type']}: éŒ¯èª¤ {response.status}")
                                print(f"      {error[:100]}")
                                
                                # å¦‚æœæ˜¯kimi-k2-instructä¸å­˜åœ¨ï¼Œè·³é
                                if "model not found" in error.lower():
                                    print(f"      æ¨¡å‹ {model} å¯èƒ½ä¸å­˜åœ¨")
                                break
                                
                    except Exception as e:
                        model_success = False
                        print(f"   âŒ {query['type']}: ç•°å¸¸ {str(e)[:100]}")
                        break
                
                if model_success and model_latencies:
                    avg_latency = sum(model_latencies) / len(model_latencies)
                    results.append({
                        "model": model,
                        "available": True,
                        "avg_latency": avg_latency,
                        "min_latency": min(model_latencies),
                        "max_latency": max(model_latencies),
                        "test_count": len(model_latencies)
                    })
                else:
                    results.append({
                        "model": model,
                        "available": False
                    })
        
        return results
    
    async def test_groq_k2_comparison(self):
        """å°æ¯”Groqå’ŒçœŸå¯¦K2æ€§èƒ½"""
        print("\nğŸ”„ å°æ¯”Groqå’ŒK2æ€§èƒ½")
        print("="*50)
        
        # Groqé…ç½®
        groq_config = {
            "api_key": "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",
            "api_url": "https://api.groq.com/openai/v1/chat/completions",
            "model": "llama-3.1-8b-instant"
        }
        
        test_query = "è§£é‡‹ä»€éº¼æ˜¯éæ­¸ï¼Œä¸¦çµ¦å‡ºPythonç¤ºä¾‹"
        
        # æ¸¬è©¦Groq
        print("\nğŸ“Š Groq (llama-3.1-8b-instant):")
        groq_start = time.time()
        
        async with aiohttp.ClientSession() as session:
            try:
                async with session.post(
                    groq_config["api_url"],
                    headers={
                        "Authorization": f"Bearer {groq_config['api_key']}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": groq_config["model"],
                        "messages": [{"role": "user", "content": test_query}],
                        "max_tokens": 300
                    }
                ) as response:
                    if response.status == 200:
                        groq_latency = (time.time() - groq_start) * 1000
                        data = await response.json()
                        print(f"   å»¶é²: {groq_latency:.0f}ms")
                        print(f"   éŸ¿æ‡‰è³ªé‡: âœ… è‰¯å¥½")
            except Exception as e:
                print(f"   âŒ éŒ¯èª¤: {e}")
        
        # æ¸¬è©¦K2
        print("\nğŸ“Š Moonshot K2 (moonshot-v1-8k):")
        k2_start = time.time()
        
        async with aiohttp.ClientSession() as session:
            try:
                async with session.post(
                    self.api_url,
                    headers={
                        "Authorization": f"Bearer {self.moonshot_api_key}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": "moonshot-v1-8k",
                        "messages": [{"role": "user", "content": test_query}],
                        "max_tokens": 300
                    }
                ) as response:
                    if response.status == 200:
                        k2_latency = (time.time() - k2_start) * 1000
                        data = await response.json()
                        print(f"   å»¶é²: {k2_latency:.0f}ms")
                        print(f"   éŸ¿æ‡‰è³ªé‡: âœ… å„ªç§€ï¼ˆåŸç”ŸK2ï¼‰")
            except Exception as e:
                print(f"   âŒ éŒ¯èª¤: {e}")
    
    def generate_k2_integration_plan(self, results):
        """ç”ŸæˆK2é›†æˆè¨ˆåŠƒ"""
        print("\nğŸ“‹ K2é›†æˆæœ€çµ‚æ–¹æ¡ˆ")
        print("="*70)
        
        available_models = [r for r in results if r.get('available', False)]
        
        if not available_models:
            print("âŒ æ²’æœ‰å¯ç”¨çš„K2æ¨¡å‹")
            return
        
        # æ‰¾å‡ºæœ€å¿«çš„K2æ¨¡å‹
        fastest_k2 = min(available_models, key=lambda x: x['avg_latency'])
        
        print(f"\nğŸ† æ¨è–¦K2é…ç½®:")
        print(f"   æ¨¡å‹: {fastest_k2['model']}")
        print(f"   å¹³å‡å»¶é²: {fastest_k2['avg_latency']:.0f}ms")
        print(f"   API: Moonshot API")
        
        print(f"\nğŸš€ æ··åˆç­–ç•¥:")
        print("1. ç°¡å–®æŸ¥è©¢ â†’ Groq (300ms)")
        print("2. è¤‡é›œä»»å‹™ â†’ K2 + RAGå¢å¼·")
        print("3. ä¸­æ–‡å„ªå…ˆ â†’ K2 (ä¸­æ–‡èƒ½åŠ›æ›´å¼·)")
        
        print(f"\nğŸ’¡ ç‚ºä»€éº¼éœ€è¦K2:")
        print("- K2æ˜¯å°ˆé–€å„ªåŒ–çš„å¤§èªè¨€æ¨¡å‹")
        print("- æ›´å¥½çš„ä¸­æ–‡ç†è§£å’Œç”Ÿæˆ")
        print("- æ›´å¼·çš„æ¨ç†èƒ½åŠ›")
        print("- èˆ‡Claudeæ›´æ¥è¿‘çš„èƒ½åŠ›")
        
        print(f"\nğŸ“Š æœ€çµ‚æ¶æ§‹:")
        print("```")
        print("ç”¨æˆ¶è«‹æ±‚")
        print("   â†“")
        print("æ™ºèƒ½è·¯ç”±")
        print("   â”œâ”€ ç°¡å–®/è‹±æ–‡ â†’ Groq (300ms)")
        print("   â””â”€ è¤‡é›œ/ä¸­æ–‡ â†’ K2 (1-2s) â†’ RAGå¢å¼·")
        print("                              â†“")
        print("                         é«˜è³ªé‡éŸ¿æ‡‰")
        print("```")

async def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸš€ Kimi K2æ¨¡å‹æ€§èƒ½æ¸¬è©¦")
    print("é©—è­‰çœŸæ­£çš„K2æ¨¡å‹èƒ½åŠ›")
    print("="*70)
    
    tester = KimiK2ModelTest()
    
    # æ¸¬è©¦K2æ¨¡å‹
    results = await tester.test_k2_models()
    
    # å°æ¯”æ¸¬è©¦
    await tester.test_groq_k2_comparison()
    
    # ç”Ÿæˆé›†æˆè¨ˆåŠƒ
    tester.generate_k2_integration_plan(results)
    
    print("\nâœ… æ¸¬è©¦å®Œæˆï¼")
    print("å»ºè­°ï¼šä½¿ç”¨æ··åˆç­–ç•¥ï¼ŒGroqè™•ç†ç°¡å–®æŸ¥è©¢ï¼ŒK2è™•ç†è¤‡é›œä»»å‹™")

if __name__ == "__main__":
    asyncio.run(main())