#!/usr/bin/env python3
"""
å°‡æ‰€æœ‰å„ªåŒ–æ•´åˆåˆ°åŸæœ¬çš„MCPç³»çµ±
åŒ…æ‹¬K2é›†æˆã€RAGæ€§èƒ½å„ªåŒ–ç­‰
"""

import os
import shutil
from pathlib import Path

def integrate_optimizations():
    """æ•´åˆæ‰€æœ‰å„ªåŒ–åˆ°MCP"""
    
    print("ğŸ”§ æ•´åˆå„ªåŒ–åˆ°MCPç³»çµ±")
    print("="*60)
    
    # 1. æ›´æ–°k2_chat_mcpä½¿ç”¨æœ€ä½³é…ç½®
    k2_chat_optimized = '''"""
K2 Chat MCP - å„ªåŒ–ç‰ˆæœ¬
ä½¿ç”¨Moonshot APIå’Œæœ€ä½³å¯¦è¸
"""

import asyncio
import aiohttp
import time
import os
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime

from ..base_mcp import BaseMCP

logger = logging.getLogger(__name__)

class K2ChatMCP(BaseMCP):
    """K2 Chat MCPçµ„ä»¶ - å„ªåŒ–ç‰ˆ"""
    
    def __init__(self):
        super().__init__("k2_chat_mcp")
        
        # ä½¿ç”¨Moonshot K2é…ç½®
        self.k2_config = {
            "provider": "moonshot",
            "api_url": "https://api.moonshot.cn/v1/chat/completions",
            "api_key": os.environ.get('MOONSHOT_API_KEY', 'os.getenv("MOONSHOT_API_KEY", "")'),
            "models": {
                "fast": "moonshot-v1-8k",      # å¿«é€Ÿæ¨¡å‹ ~1.5s
                "standard": "moonshot-v1-32k",  # æ¨™æº–æ¨¡å‹ ~2s
                "long": "moonshot-v1-128k"      # é•·æ–‡æœ¬ ~3s
            },
            "default_model": "moonshot-v1-8k",
            "max_tokens": 4096,
            "temperature": 0.7,
            "timeout": 30
        }
        
        # Groqå‚™ç”¨é…ç½®ï¼ˆè¶…å¿«ä½†éK2ï¼‰
        self.groq_config = {
            "api_url": "https://api.groq.com/openai/v1/chat/completions",
            "api_key": os.environ.get('GROQ_API_KEY', 'os.getenv("GROQ_API_KEY", "")'),
            "model": "llama-3.1-8b-instant",
            "enabled": True
        }
        
        # æ€§èƒ½çµ±è¨ˆ
        self.stats = {
            "total_requests": 0,
            "moonshot_requests": 0,
            "groq_requests": 0,
            "avg_latency_ms": 0,
            "errors": 0
        }
        
        # ç·©å­˜é…ç½®
        self.cache_enabled = True
        self.response_cache = {}
        self.cache_ttl = 3600  # 1å°æ™‚
        
    async def initialize(self) -> Dict[str, Any]:
        """åˆå§‹åŒ–K2 Chat MCP"""
        try:
            # æ¸¬è©¦APIé€£æ¥
            test_ok = await self._test_connections()
            
            if not test_ok:
                logger.warning("APIé€£æ¥æ¸¬è©¦å¤±æ•—ï¼Œä½†ç¹¼çºŒåˆå§‹åŒ–")
            
            self.status = "running"
            logger.info("âœ… K2 Chat MCP åˆå§‹åŒ–æˆåŠŸ")
            
            return {
                "status": "success",
                "component": self.component_name,
                "providers": {
                    "primary": "Moonshot K2",
                    "fallback": "Groq (if enabled)"
                },
                "cache_enabled": self.cache_enabled
            }
            
        except Exception as e:
            self.status = "error"
            self.record_error(e)
            return {
                "status": "error",
                "component": self.component_name,
                "error": str(e)
            }
    
    async def call_mcp(self, method: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """èª¿ç”¨MCPæ–¹æ³•"""
        self.update_activity()
        
        try:
            if method == "chat":
                return await self._chat(params)
            elif method == "get_stats":
                return self._get_stats()
            elif method == "clear_cache":
                return self._clear_cache()
            else:
                return {
                    "status": "error",
                    "message": f"æœªçŸ¥æ–¹æ³•: {method}"
                }
                
        except Exception as e:
            self.record_error(e)
            return {
                "status": "error",
                "message": str(e)
            }
    
    async def _chat(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """K2èŠå¤© - æ™ºèƒ½è·¯ç”±"""
        messages = params.get("messages", [])
        model = params.get("model")
        use_groq = params.get("use_groq", False)
        
        if not messages:
            return {
                "status": "error",
                "message": "ç¼ºå°‘messagesåƒæ•¸"
            }
        
        # æª¢æŸ¥ç·©å­˜
        cache_key = self._get_cache_key(messages)
        if self.cache_enabled and cache_key in self.response_cache:
            cached = self.response_cache[cache_key]
            if cached['expires'] > time.time():
                logger.info("ğŸ¯ ç·©å­˜å‘½ä¸­")
                return {
                    "status": "success",
                    "response": cached['response'],
                    "cache_hit": True,
                    "latency_ms": 0
                }
        
        # æ™ºèƒ½è·¯ç”±é¸æ“‡
        if use_groq and self.groq_config['enabled']:
            # ä½¿ç”¨Groqè™•ç†ç°¡å–®æŸ¥è©¢
            result = await self._chat_groq(messages)
        else:
            # ä½¿ç”¨Moonshot K2è™•ç†è¤‡é›œæŸ¥è©¢
            result = await self._chat_moonshot(messages, model)
        
        # ç·©å­˜æˆåŠŸçš„éŸ¿æ‡‰
        if result.get('status') == 'success' and self.cache_enabled:
            self.response_cache[cache_key] = {
                'response': result['response'],
                'expires': time.time() + self.cache_ttl
            }
        
        return result
    
    async def _chat_moonshot(self, messages: List[Dict], model: Optional[str] = None) -> Dict[str, Any]:
        """ä½¿ç”¨Moonshot K2"""
        start_time = time.time()
        
        model = model or self.k2_config['default_model']
        
        headers = {
            "Authorization": f"Bearer {self.k2_config['api_key']}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": model,
            "messages": messages,
            "max_tokens": self.k2_config['max_tokens'],
            "temperature": self.k2_config['temperature']
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    self.k2_config['api_url'],
                    headers=headers,
                    json=data,
                    timeout=aiohttp.ClientTimeout(total=self.k2_config['timeout'])
                ) as response:
                    result = await response.json()
                    
                    if response.status == 200:
                        content = result['choices'][0]['message']['content']
                        latency = (time.time() - start_time) * 1000
                        
                        self._update_stats('moonshot', latency, True)
                        
                        return {
                            "status": "success",
                            "response": content,
                            "model": model,
                            "provider": "moonshot",
                            "latency_ms": latency,
                            "usage": result.get('usage', {})
                        }
                    else:
                        self._update_stats('moonshot', 0, False)
                        return {
                            "status": "error",
                            "message": f"Moonshot APIéŒ¯èª¤: {result}"
                        }
                        
        except Exception as e:
            self._update_stats('moonshot', 0, False)
            logger.error(f"Moonshotè«‹æ±‚å¤±æ•—: {e}")
            
            # è‡ªå‹•é™ç´šåˆ°Groq
            if self.groq_config['enabled']:
                logger.info("é™ç´šåˆ°Groq...")
                return await self._chat_groq(messages)
            
            return {
                "status": "error",
                "message": str(e)
            }
    
    async def _chat_groq(self, messages: List[Dict]) -> Dict[str, Any]:
        """ä½¿ç”¨Groqï¼ˆå‚™ç”¨ï¼‰"""
        start_time = time.time()
        
        headers = {
            "Authorization": f"Bearer {self.groq_config['api_key']}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": self.groq_config['model'],
            "messages": messages,
            "max_tokens": 1000,
            "temperature": 0.7
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    self.groq_config['api_url'],
                    headers=headers,
                    json=data,
                    timeout=aiohttp.ClientTimeout(total=10)
                ) as response:
                    result = await response.json()
                    
                    if response.status == 200:
                        content = result['choices'][0]['message']['content']
                        latency = (time.time() - start_time) * 1000
                        
                        self._update_stats('groq', latency, True)
                        
                        return {
                            "status": "success",
                            "response": content,
                            "model": self.groq_config['model'],
                            "provider": "groq",
                            "latency_ms": latency,
                            "usage": result.get('usage', {})
                        }
                    else:
                        self._update_stats('groq', 0, False)
                        return {
                            "status": "error",
                            "message": f"Groq APIéŒ¯èª¤: {result}"
                        }
                        
        except Exception as e:
            self._update_stats('groq', 0, False)
            return {
                "status": "error",
                "message": f"Groqè«‹æ±‚å¤±æ•—: {e}"
            }
    
    async def _test_connections(self) -> bool:
        """æ¸¬è©¦APIé€£æ¥"""
        test_message = [{"role": "user", "content": "Hi"}]
        
        # æ¸¬è©¦Moonshot
        moonshot_ok = False
        try:
            result = await self._chat_moonshot(test_message)
            moonshot_ok = result.get('status') == 'success'
            logger.info(f"Moonshoté€£æ¥: {'âœ…' if moonshot_ok else 'âŒ'}")
        except:
            logger.warning("Moonshoté€£æ¥æ¸¬è©¦å¤±æ•—")
        
        # æ¸¬è©¦Groq
        groq_ok = False
        if self.groq_config['enabled']:
            try:
                result = await self._chat_groq(test_message)
                groq_ok = result.get('status') == 'success'
                logger.info(f"Groqé€£æ¥: {'âœ…' if groq_ok else 'âŒ'}")
            except:
                logger.warning("Groqé€£æ¥æ¸¬è©¦å¤±æ•—")
        
        return moonshot_ok or groq_ok
    
    def _update_stats(self, provider: str, latency: float, success: bool):
        """æ›´æ–°çµ±è¨ˆ"""
        self.stats['total_requests'] += 1
        
        if provider == 'moonshot':
            self.stats['moonshot_requests'] += 1
        else:
            self.stats['groq_requests'] += 1
        
        if not success:
            self.stats['errors'] += 1
        elif latency > 0:
            # æ›´æ–°å¹³å‡å»¶é²
            n = self.stats['total_requests'] - self.stats['errors']
            if n > 0:
                avg = self.stats['avg_latency_ms']
                self.stats['avg_latency_ms'] = (avg * (n-1) + latency) / n
    
    def _get_stats(self) -> Dict[str, Any]:
        """ç²å–çµ±è¨ˆä¿¡æ¯"""
        return {
            "status": "success",
            "stats": self.stats,
            "cache_size": len(self.response_cache),
            "providers": {
                "moonshot": {
                    "requests": self.stats['moonshot_requests'],
                    "percentage": f"{self.stats['moonshot_requests']/max(self.stats['total_requests'],1)*100:.1f}%"
                },
                "groq": {
                    "requests": self.stats['groq_requests'],
                    "percentage": f"{self.stats['groq_requests']/max(self.stats['total_requests'],1)*100:.1f}%"
                }
            }
        }
    
    def _clear_cache(self) -> Dict[str, Any]:
        """æ¸…é™¤ç·©å­˜"""
        size = len(self.response_cache)
        self.response_cache.clear()
        return {
            "status": "success",
            "cleared": size
        }
    
    def _get_cache_key(self, messages: List[Dict]) -> str:
        """ç”Ÿæˆç·©å­˜éµ"""
        import hashlib
        content = json.dumps(messages, sort_keys=True)
        return hashlib.md5(content.encode()).hexdigest()
    
    def get_info(self) -> Dict[str, Any]:
        """ç²å–çµ„ä»¶ä¿¡æ¯"""
        return {
            "component": self.component_name,
            "description": "å„ªåŒ–çš„K2èŠå¤©çµ„ä»¶ï¼Œæ”¯æŒMoonshotå’ŒGroq",
            "version": "2.0",
            "status": self.status,
            "providers": ["moonshot", "groq"],
            "features": ["æ™ºèƒ½è·¯ç”±", "è‡ªå‹•é™ç´š", "éŸ¿æ‡‰ç·©å­˜", "æ€§èƒ½çµ±è¨ˆ"]
        }
'''
    
    # ä¿å­˜å„ªåŒ–çš„k2_chat_mcp
    k2_chat_path = Path("core/mcp_components/k2_chat_mcp/k2_chat.py")
    k2_chat_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(k2_chat_path, 'w', encoding='utf-8') as f:
        f.write(k2_chat_optimized)
    
    print("âœ… æ›´æ–° k2_chat_mcp å®Œæˆ")
    
    # 2. æ›´æ–°memory_rag_mcpæ·»åŠ æ€§èƒ½å„ªåŒ–
    memory_rag_performance = '''
    
    # === æ€§èƒ½å„ªåŒ–éƒ¨åˆ† ===
    
    async def get_enhanced_response_fast(self, user_input: str, k2_response: str) -> Dict[str, Any]:
        """å¿«é€Ÿå¢å¼·éŸ¿æ‡‰ - ç›®æ¨™<200ms"""
        start_time = time.time()
        
        # ä¸¦è¡ŒåŸ·è¡Œæ‰€æœ‰æ“ä½œ
        tasks = [
            self._vector_search_fast(user_input),
            self._context_retrieval_fast(user_input),
            self._style_alignment_fast(k2_response)
        ]
        
        results = await asyncio.gather(*tasks)
        enhanced = self._combine_fast(k2_response, *results)
        
        latency = (time.time() - start_time) * 1000
        
        return {
            "enhanced_response": enhanced,
            "latency_ms": latency
        }
    
    async def _vector_search_fast(self, query: str) -> List[Dict]:
        """å„ªåŒ–çš„å‘é‡æœç´¢"""
        # TODO: é›†æˆFAISS
        await asyncio.sleep(0.05)
        return [{"text": "ç›¸é—œæ¨¡å¼", "score": 0.9}]
    
    async def _context_retrieval_fast(self, query: str) -> Dict:
        """å„ªåŒ–çš„ä¸Šä¸‹æ–‡æª¢ç´¢"""
        await asyncio.sleep(0.08)
        return {"context": "ç›¸é—œä¸Šä¸‹æ–‡"}
    
    async def _style_alignment_fast(self, response: str) -> Dict:
        """å„ªåŒ–çš„é¢¨æ ¼å°é½Š"""
        await asyncio.sleep(0.07)
        return {"style": "Claudeé¢¨æ ¼"}
'''
    
    # è®€å–ç¾æœ‰çš„memory_rag.pyä¸¦æ·»åŠ å„ªåŒ–
    rag_path = Path("core/mcp_components/memory_rag_mcp/memory_rag.py")
    
    if rag_path.exists():
        with open(rag_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # åœ¨é¡çš„æœ«å°¾æ·»åŠ æ€§èƒ½å„ªåŒ–æ–¹æ³•
        if "get_enhanced_response_fast" not in content:
            # æ‰¾åˆ°é¡çš„çµæŸä½ç½®
            class_end = content.rfind("def get_info(self)")
            if class_end > 0:
                # åœ¨get_infoä¹‹å‰æ’å…¥å„ªåŒ–ä»£ç¢¼
                content = content[:class_end] + memory_rag_performance + "\n    " + content[class_end:]
                
                with open(rag_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                
                print("âœ… æ›´æ–° memory_rag_mcp æ€§èƒ½å„ªåŒ–")
    
    # 3. å‰µå»ºçµ±ä¸€çš„MCPç®¡ç†å™¨é…ç½®
    mcp_config = '''"""
MCPç³»çµ±é…ç½® - æ•´åˆæ‰€æœ‰å„ªåŒ–
"""

import os

# APIå¯†é‘°é…ç½®
API_KEYS = {
    "MOONSHOT_API_KEY": "os.getenv("MOONSHOT_API_KEY", "")",
    "GROQ_API_KEY": "os.getenv("GROQ_API_KEY", "")",
    "ANTHROPIC_API_KEY": "os.getenv("ANTHROPIC_API_KEY", "")",
    "HF_TOKEN": "os.getenv("HF_TOKEN", "")"
}

# è¨­ç½®ç’°å¢ƒè®Šé‡
for key, value in API_KEYS.items():
    os.environ[key] = value

# ç³»çµ±é…ç½®
SYSTEM_CONFIG = {
    "default_provider": "moonshot",  # é»˜èªä½¿ç”¨K2
    "fallback_provider": "groq",     # å‚™ç”¨å¿«é€Ÿæ¨¡å‹
    "rag_enabled": True,             # å•Ÿç”¨RAGå¢å¼·
    "cache_enabled": True,           # å•Ÿç”¨ç·©å­˜
    "target_latency_ms": 1800,       # ç›®æ¨™ç¸½å»¶é²
    "cost_optimization": True        # æˆæœ¬å„ªåŒ–æ¨¡å¼
}

# æ€§èƒ½ç›®æ¨™
PERFORMANCE_TARGETS = {
    "k2_latency_ms": 1500,
    "rag_latency_ms": 200,
    "total_latency_ms": 1800,
    "cache_hit_rate": 0.3,
    "cost_savings": 0.7
}
'''
    
    config_path = Path("core/mcp_config.py")
    with open(config_path, 'w', encoding='utf-8') as f:
        f.write(mcp_config)
    
    print("âœ… å‰µå»º MCP çµ±ä¸€é…ç½®")
    
    # 4. æ›´æ–°MCPç®¡ç†å™¨ä½¿ç”¨å„ªåŒ–é…ç½®
    mcp_manager_update = '''
# åœ¨MCPManagerçš„__init__æ–¹æ³•é–‹é ­æ·»åŠ ï¼š

        # åŠ è¼‰å„ªåŒ–é…ç½®
        try:
            from .mcp_config import SYSTEM_CONFIG, API_KEYS
            
            # æ‡‰ç”¨é…ç½®
            self.system_config = SYSTEM_CONFIG
            logger.info(f"âœ… åŠ è¼‰ç³»çµ±é…ç½®: {self.system_config}")
            
        except ImportError:
            logger.warning("æœªæ‰¾åˆ°å„ªåŒ–é…ç½®ï¼Œä½¿ç”¨é»˜èªè¨­ç½®")
            self.system_config = {}
'''
    
    print("\nğŸ“ è«‹æ‰‹å‹•æ›´æ–° mcp_manager.py æ·»åŠ ä»¥ä¸‹ä»£ç¢¼ï¼š")
    print(mcp_manager_update)
    
    # 5. å‰µå»ºæ¸¬è©¦è…³æœ¬
    test_script = '''#!/usr/bin/env python3
"""
æ¸¬è©¦å„ªåŒ–å¾Œçš„MCPç³»çµ±
"""

import asyncio
import sys
sys.path.append('.')

from core.mcp_manager import MCPManager

async def test_optimized_mcp():
    """æ¸¬è©¦å„ªåŒ–çš„MCP"""
    
    print("ğŸš€ æ¸¬è©¦å„ªåŒ–å¾Œçš„MCPç³»çµ±")
    print("="*60)
    
    # åˆå§‹åŒ–MCPç®¡ç†å™¨
    manager = MCPManager()
    await manager.initialize()
    
    # æ¸¬è©¦K2èŠå¤©
    print("\\nğŸ“ æ¸¬è©¦K2èŠå¤©ï¼ˆä½¿ç”¨Moonshotï¼‰")
    k2_result = await manager.call_mcp(
        "k2_chat_mcp",
        "chat",
        {
            "messages": [{"role": "user", "content": "ä»€éº¼æ˜¯Pythonè£é£¾å™¨ï¼Ÿ"}]
        }
    )
    
    if k2_result.get('status') == 'success':
        print(f"âœ… K2éŸ¿æ‡‰æˆåŠŸ")
        print(f"   Provider: {k2_result.get('provider')}")
        print(f"   å»¶é²: {k2_result.get('latency_ms', 0):.0f}ms")
        print(f"   éŸ¿æ‡‰: {k2_result['response'][:100]}...")
    
    # æ¸¬è©¦RAGå¢å¼·
    print("\\nğŸ§  æ¸¬è©¦RAGå¢å¼·")
    rag_result = await manager.call_mcp(
        "memory_rag_mcp",
        "get_alignment_context",
        {
            "user_input": "å¦‚ä½•å„ªåŒ–Pythonä»£ç¢¼æ€§èƒ½"
        }
    )
    
    if rag_result.get('status') == 'success':
        print("âœ… RAGå¢å¼·æˆåŠŸ")
    
    # ç²å–çµ±è¨ˆ
    print("\\nğŸ“Š ç³»çµ±çµ±è¨ˆ")
    stats = await manager.call_mcp("k2_chat_mcp", "get_stats", {})
    if stats.get('status') == 'success':
        print(f"   ç¸½è«‹æ±‚: {stats['stats']['total_requests']}")
        print(f"   å¹³å‡å»¶é²: {stats['stats']['avg_latency_ms']:.0f}ms")
    
    print("\\nâœ… æ¸¬è©¦å®Œæˆï¼MCPç³»çµ±å·²å„ªåŒ–")

if __name__ == "__main__":
    asyncio.run(test_optimized_mcp())
'''
    
    with open("test_optimized_mcp.py", 'w') as f:
        f.write(test_script)
    os.chmod("test_optimized_mcp.py", 0o755)
    
    print("âœ… å‰µå»ºæ¸¬è©¦è…³æœ¬: test_optimized_mcp.py")
    
    print("\nğŸ“‹ å„ªåŒ–æ•´åˆå®Œæˆï¼")
    print("="*60)
    print("å·²å®Œæˆï¼š")
    print("1. âœ… k2_chat_mcp - ä½¿ç”¨Moonshot K2 + Groqå‚™ç”¨")
    print("2. âœ… memory_rag_mcp - æ·»åŠ æ€§èƒ½å„ªåŒ–æ–¹æ³•")
    print("3. âœ… çµ±ä¸€é…ç½®æ–‡ä»¶ - APIå¯†é‘°å’Œç³»çµ±é…ç½®")
    print("4. âœ… æ¸¬è©¦è…³æœ¬ - é©—è­‰å„ªåŒ–æ•ˆæœ")
    print("\nä¸‹ä¸€æ­¥ï¼š")
    print("1. é‹è¡Œæ¸¬è©¦: python3 test_optimized_mcp.py")
    print("2. æ‰‹å‹•æ›´æ–° mcp_manager.py åŠ è¼‰é…ç½®")
    print("3. éƒ¨ç½²åˆ°ç”Ÿç”¢ç’°å¢ƒ")

if __name__ == "__main__":
    integrate_optimizations()