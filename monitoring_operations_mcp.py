#!/usr/bin/env python3
"""
ç›£æ§é‹ç¶­MCP - å…¨é¢ç›£æ§AICoreç³»çµ±å’ŒEC2å‚™ä»½
"""

import json
import logging
import asyncio
import psutil
import subprocess
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import smtplib
from email.mime.text import MIMEText
import boto3

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class MonitoringOperationsMCP:
    """ç›£æ§é‹ç¶­MCP - å…¨æ–¹ä½ç³»çµ±ç›£æ§"""
    
    def __init__(self):
        self.base_dir = Path("/Users/alexchuang/alexchuangtest/aicore0720")
        self.monitoring_config = {
            "check_interval": 300,  # 5åˆ†é˜æª¢æŸ¥ä¸€æ¬¡
            "alert_threshold": {
                "accuracy_drop": 2.0,  # æº–ç¢ºç‡ä¸‹é™2%è§¸ç™¼è­¦å ±
                "disk_usage": 90,      # ç£ç›¤ä½¿ç”¨ç‡90%è§¸ç™¼è­¦å ±
                "memory_usage": 85,    # å…§å­˜ä½¿ç”¨ç‡85%è§¸ç™¼è­¦å ±
                "backup_age": 24,      # å‚™ä»½è¶…é24å°æ™‚è§¸ç™¼è­¦å ±
                "training_stuck": 30   # è¨“ç·´å¡ä½30åˆ†é˜è§¸ç™¼è­¦å ±
            }
        }
        
        # ç›£æ§æŒ‡æ¨™
        self.metrics = {
            "system_health": {},
            "training_status": {},
            "accuracy_metrics": {},
            "backup_status": {},
            "ec2_status": {},
            "alerts": []
        }
        
        # EC2ç›£æ§é…ç½®
        self.ec2_config = {
            "instance_id": "i-0123456789abcdef0",
            "region": "us-west-2",
            "backup_path": "/home/ubuntu/aicore_backups/"
        }
        
        # è­¦å ±é…ç½®
        self.alert_config = {
            "email": {
                "enabled": True,
                "smtp_server": "smtp.gmail.com",
                "smtp_port": 587,
                "sender": "aicore.monitor@gmail.com",
                "recipients": ["alex@example.com"],
                "password": "your_app_password"
            },
            "slack": {
                "enabled": True,
                "webhook_url": "https://hooks.slack.com/services/xxx/yyy/zzz"
            },
            "log_file": self.base_dir / "monitoring_alerts.log"
        }
    
    async def start_monitoring(self):
        """å•Ÿå‹•ç›£æ§ç³»çµ±"""
        logger.info("ğŸš€ å•Ÿå‹•ç›£æ§é‹ç¶­MCP...")
        
        # å‰µå»ºç›£æ§ä»»å‹™
        tasks = [
            self.monitor_system_health(),
            self.monitor_training_progress(),
            self.monitor_accuracy_metrics(),
            self.monitor_backup_status(),
            self.monitor_ec2_health(),
            self.process_alerts()
        ]
        
        # ä¸¦è¡ŒåŸ·è¡Œæ‰€æœ‰ç›£æ§ä»»å‹™
        await asyncio.gather(*tasks)
    
    async def monitor_system_health(self):
        """ç›£æ§ç³»çµ±å¥åº·ç‹€æ…‹"""
        while True:
            try:
                # CPUä½¿ç”¨ç‡
                cpu_percent = psutil.cpu_percent(interval=1)
                
                # å…§å­˜ä½¿ç”¨
                memory = psutil.virtual_memory()
                
                # ç£ç›¤ä½¿ç”¨
                disk = psutil.disk_usage(str(self.base_dir))
                
                # GPUä½¿ç”¨ï¼ˆå¦‚æœæœ‰ï¼‰
                gpu_usage = await self.get_gpu_usage()
                
                # é€²ç¨‹ç‹€æ…‹
                claude_processes = len([p for p in psutil.process_iter(['name']) 
                                      if 'claude' in p.info['name'].lower()])
                
                self.metrics["system_health"] = {
                    "timestamp": datetime.now().isoformat(),
                    "cpu_percent": cpu_percent,
                    "memory_percent": memory.percent,
                    "memory_available_gb": memory.available / (1024**3),
                    "disk_percent": disk.percent,
                    "disk_free_gb": disk.free / (1024**3),
                    "gpu_usage": gpu_usage,
                    "claude_processes": claude_processes
                }
                
                # æª¢æŸ¥è­¦å ±æ¢ä»¶
                if memory.percent > self.monitoring_config["alert_threshold"]["memory_usage"]:
                    await self.create_alert(
                        "HIGH_MEMORY_USAGE",
                        f"å…§å­˜ä½¿ç”¨ç‡éé«˜: {memory.percent:.1f}%",
                        "warning"
                    )
                
                if disk.percent > self.monitoring_config["alert_threshold"]["disk_usage"]:
                    await self.create_alert(
                        "HIGH_DISK_USAGE",
                        f"ç£ç›¤ä½¿ç”¨ç‡éé«˜: {disk.percent:.1f}%",
                        "critical"
                    )
                
                logger.info(f"ğŸ’» ç³»çµ±å¥åº·: CPU {cpu_percent:.1f}% | "
                          f"å…§å­˜ {memory.percent:.1f}% | "
                          f"ç£ç›¤ {disk.percent:.1f}%")
                
            except Exception as e:
                logger.error(f"ç³»çµ±å¥åº·ç›£æ§éŒ¯èª¤: {str(e)}")
            
            await asyncio.sleep(self.monitoring_config["check_interval"])
    
    async def monitor_training_progress(self):
        """ç›£æ§è¨“ç·´é€²åº¦"""
        while True:
            try:
                # æª¢æŸ¥è¨“ç·´æ—¥èªŒ
                log_path = self.base_dir / "unified_k2_training.log"
                if log_path.exists():
                    # ç²å–æœ€å¾Œä¿®æ”¹æ™‚é–“
                    last_modified = datetime.fromtimestamp(log_path.stat().st_mtime)
                    time_since_update = datetime.now() - last_modified
                    
                    # æª¢æŸ¥æ˜¯å¦å¡ä½
                    if time_since_update > timedelta(minutes=self.monitoring_config["alert_threshold"]["training_stuck"]):
                        await self.create_alert(
                            "TRAINING_STUCK",
                            f"è¨“ç·´å¯èƒ½å¡ä½äº†ï¼Œ{time_since_update.seconds//60}åˆ†é˜æ²’æœ‰æ›´æ–°",
                            "warning"
                        )
                    
                    # è®€å–æœ€æ–°ç‹€æ…‹
                    with open(log_path, 'r') as f:
                        lines = f.readlines()
                        last_lines = lines[-10:] if len(lines) > 10 else lines
                        
                        # æå–é—œéµä¿¡æ¯
                        for line in last_lines:
                            if "ç›®æ¨™é”æˆç‡" in line:
                                achievement_rate = float(line.split(": ")[1].rstrip("%\n"))
                                self.metrics["training_status"]["achievement_rate"] = achievement_rate
                            elif "è¨“ç·´å‘¨æœŸ" in line:
                                training_cycle = int(line.split(": ")[1])
                                self.metrics["training_status"]["training_cycle"] = training_cycle
                
                self.metrics["training_status"]["last_update"] = datetime.now().isoformat()
                self.metrics["training_status"]["is_running"] = time_since_update < timedelta(minutes=5)
                
            except Exception as e:
                logger.error(f"è¨“ç·´é€²åº¦ç›£æ§éŒ¯èª¤: {str(e)}")
            
            await asyncio.sleep(self.monitoring_config["check_interval"])
    
    async def monitor_accuracy_metrics(self):
        """ç›£æ§æº–ç¢ºç‡æŒ‡æ¨™"""
        while True:
            try:
                metrics_file = self.base_dir / "accuracy_metrics.json"
                if metrics_file.exists():
                    with open(metrics_file, 'r') as f:
                        current_metrics = json.load(f)
                    
                    current_accuracy = current_metrics.get("tool_call_accuracy", 0)
                    
                    # æª¢æŸ¥æº–ç¢ºç‡æ˜¯å¦ä¸‹é™
                    if hasattr(self, 'last_accuracy'):
                        accuracy_drop = self.last_accuracy - current_accuracy
                        if accuracy_drop > self.monitoring_config["alert_threshold"]["accuracy_drop"]:
                            await self.create_alert(
                                "ACCURACY_DROP",
                                f"æº–ç¢ºç‡ä¸‹é™: {self.last_accuracy:.1f}% -> {current_accuracy:.1f}%",
                                "critical"
                            )
                    
                    self.last_accuracy = current_accuracy
                    
                    self.metrics["accuracy_metrics"] = {
                        "timestamp": datetime.now().isoformat(),
                        "current_accuracy": current_accuracy,
                        "memoryrag_impact": current_metrics.get("memoryrag_impact", 0),
                        "day1_achieved": current_metrics.get("day1_achieved", False),
                        "components_status": current_metrics.get("components", {})
                    }
                    
                    logger.info(f"ğŸ“Š æº–ç¢ºç‡ç›£æ§: {current_accuracy:.1f}%")
                
            except Exception as e:
                logger.error(f"æº–ç¢ºç‡ç›£æ§éŒ¯èª¤: {str(e)}")
            
            await asyncio.sleep(self.monitoring_config["check_interval"])
    
    async def monitor_backup_status(self):
        """ç›£æ§å‚™ä»½ç‹€æ…‹"""
        while True:
            try:
                # æª¢æŸ¥æœ¬åœ°å‚™ä»½
                backup_files = list(self.base_dir.glob("aicore_backup_*.tar.gz"))
                
                if backup_files:
                    latest_backup = max(backup_files, key=lambda p: p.stat().st_mtime)
                    backup_age = datetime.now() - datetime.fromtimestamp(latest_backup.stat().st_mtime)
                    
                    self.metrics["backup_status"]["local"] = {
                        "latest_backup": latest_backup.name,
                        "backup_time": datetime.fromtimestamp(latest_backup.stat().st_mtime).isoformat(),
                        "backup_age_hours": backup_age.total_seconds() / 3600,
                        "backup_size_mb": latest_backup.stat().st_size / (1024**2)
                    }
                    
                    # æª¢æŸ¥å‚™ä»½å¹´é½¡
                    if backup_age.total_seconds() / 3600 > self.monitoring_config["alert_threshold"]["backup_age"]:
                        await self.create_alert(
                            "OLD_BACKUP",
                            f"å‚™ä»½å·²è¶…é{self.monitoring_config['alert_threshold']['backup_age']}å°æ™‚",
                            "warning"
                        )
                else:
                    self.metrics["backup_status"]["local"] = {
                        "status": "no_backup_found",
                        "message": "æœªæ‰¾åˆ°æœ¬åœ°å‚™ä»½"
                    }
                    
                    await self.create_alert(
                        "NO_BACKUP",
                        "æœªæ‰¾åˆ°ä»»ä½•å‚™ä»½æ–‡ä»¶",
                        "critical"
                    )
                
                # æª¢æŸ¥å‚™ä»½æ¸…å–®
                manifest_files = list(self.base_dir.glob("backup_manifest_*.json"))
                if manifest_files:
                    latest_manifest = max(manifest_files, key=lambda p: p.stat().st_mtime)
                    with open(latest_manifest, 'r') as f:
                        manifest = json.load(f)
                    
                    self.metrics["backup_status"]["manifest"] = {
                        "total_samples": manifest["statistics"]["total_training_samples"],
                        "replay_urls": manifest["statistics"]["total_replay_urls"],
                        "file_size_mb": manifest["file_size_mb"]
                    }
                
                logger.info(f"ğŸ’¾ å‚™ä»½ç›£æ§: {len(backup_files)}å€‹å‚™ä»½æ–‡ä»¶")
                
            except Exception as e:
                logger.error(f"å‚™ä»½ç›£æ§éŒ¯èª¤: {str(e)}")
            
            await asyncio.sleep(self.monitoring_config["check_interval"])
    
    async def monitor_ec2_health(self):
        """ç›£æ§EC2å¥åº·ç‹€æ…‹"""
        while True:
            try:
                ec2_client = boto3.client('ec2', region_name=self.ec2_config["region"])
                
                # æª¢æŸ¥EC2å¯¦ä¾‹ç‹€æ…‹
                response = ec2_client.describe_instance_status(
                    InstanceIds=[self.ec2_config["instance_id"]]
                )
                
                if response['InstanceStatuses']:
                    status = response['InstanceStatuses'][0]
                    instance_state = status['InstanceState']['Name']
                    system_status = status['SystemStatus']['Status']
                    instance_status = status['InstanceStatus']['Status']
                    
                    self.metrics["ec2_status"] = {
                        "timestamp": datetime.now().isoformat(),
                        "instance_state": instance_state,
                        "system_status": system_status,
                        "instance_status": instance_status
                    }
                    
                    # æª¢æŸ¥ç•°å¸¸ç‹€æ…‹
                    if instance_state != "running":
                        await self.create_alert(
                            "EC2_NOT_RUNNING",
                            f"EC2å¯¦ä¾‹ç‹€æ…‹ç•°å¸¸: {instance_state}",
                            "critical"
                        )
                    
                    if system_status != "ok" or instance_status != "ok":
                        await self.create_alert(
                            "EC2_HEALTH_CHECK_FAILED",
                            f"EC2å¥åº·æª¢æŸ¥å¤±æ•—: ç³»çµ±{system_status}, å¯¦ä¾‹{instance_status}",
                            "warning"
                        )
                    
                    # æª¢æŸ¥EC2ä¸Šçš„å‚™ä»½
                    await self.check_ec2_backups()
                    
                else:
                    self.metrics["ec2_status"] = {
                        "status": "instance_not_found",
                        "message": "EC2å¯¦ä¾‹æœªæ‰¾åˆ°"
                    }
                
                logger.info(f"â˜ï¸ EC2ç›£æ§: å¯¦ä¾‹{instance_state}")
                
            except Exception as e:
                logger.error(f"EC2ç›£æ§éŒ¯èª¤: {str(e)}")
                self.metrics["ec2_status"] = {
                    "status": "error",
                    "error": str(e)
                }
            
            await asyncio.sleep(self.monitoring_config["check_interval"] * 2)  # EC2æª¢æŸ¥é »ç‡é™ä½
    
    async def check_ec2_backups(self):
        """æª¢æŸ¥EC2ä¸Šçš„å‚™ä»½"""
        try:
            # SSHé€£æ¥æª¢æŸ¥å‚™ä»½
            ssh_cmd = [
                "ssh",
                "-i", "/Users/alexchuang/alexchuang.pem",
                f"ubuntu@{self.ec2_config['instance_id']}.compute.amazonaws.com",
                f"ls -la {self.ec2_config['backup_path']} | grep aicore_backup"
            ]
            
            result = subprocess.run(ssh_cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                backup_lines = result.stdout.strip().split('\n')
                self.metrics["ec2_status"]["backup_count"] = len(backup_lines)
                logger.info(f"EC2å‚™ä»½æ•¸é‡: {len(backup_lines)}")
            
        except Exception as e:
            logger.error(f"EC2å‚™ä»½æª¢æŸ¥éŒ¯èª¤: {str(e)}")
    
    async def get_gpu_usage(self) -> Optional[float]:
        """ç²å–GPUä½¿ç”¨ç‡"""
        try:
            # macOS Metal Performance Shaders
            result = subprocess.run(
                ["ioreg", "-l", "-w0", "|", "grep", "PerformanceStatistics"],
                capture_output=True,
                text=True,
                shell=True
            )
            
            if result.returncode == 0 and result.stdout:
                # ç°¡å–®è§£æï¼Œå¯¦éš›éœ€è¦æ›´è¤‡é›œçš„é‚è¼¯
                return 0.0  # ä½”ä½ç¬¦
            
        except Exception:
            pass
        
        return None
    
    async def create_alert(self, alert_type: str, message: str, severity: str = "info"):
        """å‰µå»ºè­¦å ±"""
        alert = {
            "timestamp": datetime.now().isoformat(),
            "type": alert_type,
            "message": message,
            "severity": severity,
            "handled": False
        }
        
        self.metrics["alerts"].append(alert)
        
        # è¨˜éŒ„åˆ°æ—¥èªŒ
        logger.warning(f"ğŸš¨ è­¦å ±: [{severity.upper()}] {alert_type} - {message}")
        
        # å¯«å…¥è­¦å ±æ—¥èªŒ
        with open(self.alert_config["log_file"], 'a') as f:
            f.write(f"{json.dumps(alert)}\n")
    
    async def process_alerts(self):
        """è™•ç†è­¦å ±"""
        while True:
            try:
                unhandled_alerts = [a for a in self.metrics["alerts"] if not a["handled"]]
                
                if unhandled_alerts:
                    # æ‰¹é‡ç™¼é€è­¦å ±
                    critical_alerts = [a for a in unhandled_alerts if a["severity"] == "critical"]
                    warning_alerts = [a for a in unhandled_alerts if a["severity"] == "warning"]
                    
                    if critical_alerts:
                        await self.send_alert_notification(critical_alerts, "critical")
                    
                    if warning_alerts and len(warning_alerts) >= 3:  # ç´¯ç©3å€‹è­¦å‘Šæ‰ç™¼é€
                        await self.send_alert_notification(warning_alerts, "warning")
                    
                    # æ¨™è¨˜ç‚ºå·²è™•ç†
                    for alert in unhandled_alerts:
                        alert["handled"] = True
                
                # æ¸…ç†èˆŠè­¦å ±ï¼ˆä¿ç•™æœ€è¿‘100æ¢ï¼‰
                if len(self.metrics["alerts"]) > 100:
                    self.metrics["alerts"] = self.metrics["alerts"][-100:]
                
            except Exception as e:
                logger.error(f"è­¦å ±è™•ç†éŒ¯èª¤: {str(e)}")
            
            await asyncio.sleep(60)  # æ¯åˆ†é˜è™•ç†ä¸€æ¬¡è­¦å ±
    
    async def send_alert_notification(self, alerts: List[Dict], level: str):
        """ç™¼é€è­¦å ±é€šçŸ¥"""
        # ç™¼é€Email
        if self.alert_config["email"]["enabled"]:
            await self.send_email_alert(alerts, level)
        
        # ç™¼é€Slack
        if self.alert_config["slack"]["enabled"]:
            await self.send_slack_alert(alerts, level)
    
    async def send_email_alert(self, alerts: List[Dict], level: str):
        """ç™¼é€éƒµä»¶è­¦å ±"""
        try:
            subject = f"[AICoreç›£æ§] {level.upper()} è­¦å ± - {len(alerts)}æ¢"
            
            body = f"AICoreç›£æ§ç³»çµ±æª¢æ¸¬åˆ°ä»¥ä¸‹{level}ç´šè­¦å ±ï¼š\n\n"
            for alert in alerts:
                body += f"æ™‚é–“: {alert['timestamp']}\n"
                body += f"é¡å‹: {alert['type']}\n"
                body += f"æ¶ˆæ¯: {alert['message']}\n"
                body += "-" * 50 + "\n"
            
            body += f"\nç•¶å‰ç³»çµ±ç‹€æ…‹:\n"
            body += f"æº–ç¢ºç‡: {self.metrics.get('accuracy_metrics', {}).get('current_accuracy', 'N/A')}%\n"
            body += f"CPU: {self.metrics.get('system_health', {}).get('cpu_percent', 'N/A')}%\n"
            body += f"å…§å­˜: {self.metrics.get('system_health', {}).get('memory_percent', 'N/A')}%\n"
            
            msg = MIMEText(body)
            msg['Subject'] = subject
            msg['From'] = self.alert_config["email"]["sender"]
            msg['To'] = ", ".join(self.alert_config["email"]["recipients"])
            
            # ç™¼é€éƒµä»¶ï¼ˆéœ€è¦é…ç½®SMTPï¼‰
            logger.info(f"ğŸ“§ ç™¼é€éƒµä»¶è­¦å ±: {subject}")
            
        except Exception as e:
            logger.error(f"éƒµä»¶ç™¼é€éŒ¯èª¤: {str(e)}")
    
    async def send_slack_alert(self, alerts: List[Dict], level: str):
        """ç™¼é€Slackè­¦å ±"""
        try:
            # æ§‹å»ºSlackæ¶ˆæ¯
            color = "#ff0000" if level == "critical" else "#ffaa00"
            
            slack_message = {
                "attachments": [{
                    "color": color,
                    "title": f"AICore {level.upper()} è­¦å ±",
                    "fields": [
                        {
                            "title": alert["type"],
                            "value": alert["message"],
                            "short": False
                        } for alert in alerts
                    ],
                    "footer": "AICoreç›£æ§ç³»çµ±",
                    "ts": int(datetime.now().timestamp())
                }]
            }
            
            # ç™¼é€åˆ°Slackï¼ˆéœ€è¦webhook URLï¼‰
            logger.info(f"ğŸ’¬ ç™¼é€Slackè­¦å ±: {len(alerts)}æ¢{level}è­¦å ±")
            
        except Exception as e:
            logger.error(f"Slackç™¼é€éŒ¯èª¤: {str(e)}")
    
    def generate_monitoring_dashboard(self) -> str:
        """ç”Ÿæˆç›£æ§å„€è¡¨æ¿"""
        dashboard = f"""
# AICoreç›£æ§é‹ç¶­å„€è¡¨æ¿

æ›´æ–°æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ–¥ï¸ ç³»çµ±å¥åº·
- CPUä½¿ç”¨ç‡: {self.metrics.get('system_health', {}).get('cpu_percent', 'N/A')}%
- å…§å­˜ä½¿ç”¨ç‡: {self.metrics.get('system_health', {}).get('memory_percent', 'N/A')}%
- ç£ç›¤ä½¿ç”¨ç‡: {self.metrics.get('system_health', {}).get('disk_percent', 'N/A')}%
- Claudeé€²ç¨‹æ•¸: {self.metrics.get('system_health', {}).get('claude_processes', 'N/A')}

## ğŸ“Š æº–ç¢ºç‡æŒ‡æ¨™
- ç•¶å‰æº–ç¢ºç‡: {self.metrics.get('accuracy_metrics', {}).get('current_accuracy', 'N/A')}%
- MemoryRAGæå‡: {self.metrics.get('accuracy_metrics', {}).get('memoryrag_impact', 'N/A')}%
- Day 1ç›®æ¨™é”æˆ: {self.metrics.get('accuracy_metrics', {}).get('day1_achieved', 'N/A')}

## ğŸƒ è¨“ç·´ç‹€æ…‹
- é‹è¡Œç‹€æ…‹: {'é‹è¡Œä¸­' if self.metrics.get('training_status', {}).get('is_running', False) else 'å·²åœæ­¢'}
- ç›®æ¨™é”æˆç‡: {self.metrics.get('training_status', {}).get('achievement_rate', 'N/A')}%
- è¨“ç·´å‘¨æœŸ: {self.metrics.get('training_status', {}).get('training_cycle', 'N/A')}

## ğŸ’¾ å‚™ä»½ç‹€æ…‹
- æœ€æ–°å‚™ä»½: {self.metrics.get('backup_status', {}).get('local', {}).get('latest_backup', 'N/A')}
- å‚™ä»½å¹´é½¡: {self.metrics.get('backup_status', {}).get('local', {}).get('backup_age_hours', 'N/A'):.1f}å°æ™‚
- è¨“ç·´æ¨£æœ¬æ•¸: {self.metrics.get('backup_status', {}).get('manifest', {}).get('total_samples', 'N/A')}

## â˜ï¸ EC2ç‹€æ…‹
- å¯¦ä¾‹ç‹€æ…‹: {self.metrics.get('ec2_status', {}).get('instance_state', 'N/A')}
- ç³»çµ±æª¢æŸ¥: {self.metrics.get('ec2_status', {}).get('system_status', 'N/A')}
- EC2å‚™ä»½æ•¸: {self.metrics.get('ec2_status', {}).get('backup_count', 'N/A')}

## ğŸš¨ æœ€è¿‘è­¦å ±
"""
        
        recent_alerts = self.metrics.get("alerts", [])[-5:]
        if recent_alerts:
            for alert in recent_alerts:
                dashboard += f"- [{alert['severity'].upper()}] {alert['type']}: {alert['message']}\n"
        else:
            dashboard += "- ç„¡è­¦å ±\n"
        
        return dashboard
    
    async def save_monitoring_report(self):
        """ä¿å­˜ç›£æ§å ±å‘Š"""
        while True:
            try:
                # ç”Ÿæˆå„€è¡¨æ¿
                dashboard = self.generate_monitoring_dashboard()
                
                # ä¿å­˜åˆ°æ–‡ä»¶
                report_path = self.base_dir / "monitoring_dashboard.md"
                with open(report_path, 'w') as f:
                    f.write(dashboard)
                
                # ä¿å­˜æŒ‡æ¨™JSON
                metrics_path = self.base_dir / "monitoring_metrics.json"
                with open(metrics_path, 'w') as f:
                    json.dump(self.metrics, f, indent=2)
                
                logger.info("ğŸ“Š ç›£æ§å ±å‘Šå·²æ›´æ–°")
                
            except Exception as e:
                logger.error(f"ä¿å­˜ç›£æ§å ±å‘ŠéŒ¯èª¤: {str(e)}")
            
            await asyncio.sleep(300)  # æ¯5åˆ†é˜ä¿å­˜ä¸€æ¬¡


async def main():
    """ä¸»å‡½æ•¸"""
    monitor = MonitoringOperationsMCP()
    
    logger.info("ğŸ¯ AICoreç›£æ§é‹ç¶­MCPå•Ÿå‹•")
    logger.info("ç›£æ§å…§å®¹:")
    logger.info("  - ç³»çµ±å¥åº·ç‹€æ…‹")
    logger.info("  - è¨“ç·´é€²åº¦")
    logger.info("  - æº–ç¢ºç‡æŒ‡æ¨™")
    logger.info("  - å‚™ä»½ç‹€æ…‹")
    logger.info("  - EC2å¥åº·")
    logger.info("  - è­¦å ±è™•ç†")
    
    # æ·»åŠ å ±å‘Šä¿å­˜ä»»å‹™
    tasks = [
        monitor.start_monitoring(),
        monitor.save_monitoring_report()
    ]
    
    await asyncio.gather(*tasks)


if __name__ == "__main__":
    asyncio.run(main())