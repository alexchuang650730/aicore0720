#!/usr/bin/env python3
"""
Claudeå¯¦æ™‚æ”¶é›†å™¨MCPæ¸¬è©¦å’Œé©—è­‰è…³æœ¬
é©—è­‰ç¬¬21å€‹MCPçµ„ä»¶çš„åŠŸèƒ½å®Œæ•´æ€§
"""

import asyncio
import json
import logging
import sys
from pathlib import Path
from datetime import datetime

# æ·»åŠ é …ç›®è·¯å¾‘
sys.path.append(str(Path(__file__).parent))

from core.components.claude_realtime_mcp.claude_realtime_manager import ClaudeRealtimeMCPManager
from core.mcp_zero.mcp_registry import mcp_registry

class ClaudeRealtimeMCPTester:
    """Claudeå¯¦æ™‚æ”¶é›†å™¨MCPæ¸¬è©¦å™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(self.__class__.__name__)
        self.test_results = []
        self.mcp_manager = None
        
    async def run_all_tests(self):
        """é‹è¡Œæ‰€æœ‰æ¸¬è©¦"""
        print("ğŸ§ª Claudeå¯¦æ™‚æ”¶é›†å™¨MCP - åŠŸèƒ½æ¸¬è©¦å¥—ä»¶")
        print("=" * 50)
        
        # é…ç½®æ—¥èªŒ
        logging.basicConfig(level=logging.INFO)
        
        tests = [
            self.test_mcp_initialization,
            self.test_mcp_registry_integration,
            self.test_training_data_generation,
            self.test_k2_data_format,
            self.test_deepswe_data_format,
            self.test_quality_assessment,
            self.test_session_management,
            self.test_data_export,
            self.test_performance_metrics
        ]
        
        for test in tests:
            try:
                print(f"\nğŸ” åŸ·è¡Œæ¸¬è©¦: {test.__name__}")
                await test()
                self.test_results.append({"test": test.__name__, "status": "PASS", "error": None})
                print("âœ… æ¸¬è©¦é€šé")
            except Exception as e:
                self.test_results.append({"test": test.__name__, "status": "FAIL", "error": str(e)})
                print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        
        await self._generate_test_report()
    
    async def test_mcp_initialization(self):
        """æ¸¬è©¦MCPåˆå§‹åŒ–"""
        self.mcp_manager = ClaudeRealtimeMCPManager()
        success = await self.mcp_manager.initialize()
        
        assert success, "MCPåˆå§‹åŒ–å¤±æ•—"
        assert self.mcp_manager.collection_running, "æ”¶é›†æœå‹™æœªå•Ÿå‹•"
        assert self.mcp_manager.data_dir.exists(), "æ•¸æ“šç›®éŒ„æœªå‰µå»º"
    
    async def test_mcp_registry_integration(self):
        """æ¸¬è©¦MCPè¨»å†Šä¸­å¿ƒé›†æˆ"""
        # æª¢æŸ¥æ˜¯å¦å·²è¨»å†Š
        metadata = await mcp_registry.get_mcp_metadata("claude_realtime_mcp")
        assert metadata is not None, "MCPæœªåœ¨è¨»å†Šä¸­å¿ƒè¨»å†Š"
        
        # æª¢æŸ¥å…ƒæ•¸æ“šæ­£ç¢ºæ€§
        assert metadata.name == "claude_realtime_mcp"
        assert metadata.priority == "P0"
        assert "realtime_collection" in metadata.capabilities
        assert "k2_training" in metadata.capabilities
        assert "deepswe_training" in metadata.capabilities
        
        # æ¸¬è©¦æœç´¢åŠŸèƒ½
        search_results = await mcp_registry.search_mcps("K2 training data collection")
        assert "claude_realtime_mcp" in search_results, "æœç´¢åŠŸèƒ½æœªæ­£ç¢ºè­˜åˆ¥MCP"
    
    async def test_training_data_generation(self):
        """æ¸¬è©¦è¨“ç·´æ•¸æ“šç”Ÿæˆ"""
        # æ¨¡æ“¬ä¸€å€‹è¨“ç·´æœƒè©±
        from core.components.claude_realtime_mcp.claude_realtime_manager import TrainingSession, TrainingDataPoint
        import uuid
        import time
        
        session = TrainingSession(
            session_id=str(uuid.uuid4()),
            start_time=time.time(),
            project_context="/test/project"
        )
        
        # æ·»åŠ æ¸¬è©¦æ•¸æ“šé»
        data_point = TrainingDataPoint(
            id=str(uuid.uuid4()),
            timestamp=time.time(),
            user_input="K2å„ªåŒ–ï¼šåˆ†æé€™å€‹Pythonå‡½æ•¸çš„æ€§èƒ½",
            assistant_response="åŸºæ–¼åˆ†æï¼Œé€™å€‹å‡½æ•¸å­˜åœ¨O(nÂ²)è¤‡é›œåº¦å•é¡Œï¼Œå»ºè­°ä½¿ç”¨å­—å…¸å„ªåŒ–...",
            tool_calls=[{"name": "code_analyzer", "result": "performance_issue_detected"}],
            context={"language": "python", "function": "test_func"},
            session_id=session.session_id,
            category="k2",
            confidence=0.85,
            source="test"
        )
        
        session.data_points.append(data_point)
        session.k2_examples += 1
        session.total_interactions += 1
        
        # æ¸¬è©¦è³ªé‡è¨ˆç®—
        quality = self.mcp_manager._calculate_data_quality({
            "user": data_point.user_input,
            "assistant": data_point.assistant_response,
            "tools": data_point.tool_calls,
            "context": data_point.context
        })
        
        assert quality > 0.5, f"æ•¸æ“šè³ªé‡åˆ†æ•¸éä½: {quality}"
        assert session.k2_examples == 1, "K2æ¨£æœ¬è¨ˆæ•¸éŒ¯èª¤"
    
    async def test_k2_data_format(self):
        """æ¸¬è©¦K2æ•¸æ“šæ ¼å¼"""
        # å‰µå»ºæ¸¬è©¦æœƒè©±
        from core.components.claude_realtime_mcp.claude_realtime_manager import TrainingSession, TrainingDataPoint
        import uuid
        import time
        
        session = TrainingSession(
            session_id=str(uuid.uuid4()),
            start_time=time.time()
        )
        
        k2_data_point = TrainingDataPoint(
            id=str(uuid.uuid4()),
            timestamp=time.time(),
            user_input="åˆ†æä¸¦åŸ·è¡Œä»»å‹™ï¼šå„ªåŒ–æ•¸æ“šåº«æŸ¥è©¢",
            assistant_response="åŸºæ–¼åˆ†æï¼Œæˆ‘ç†è§£é€™å€‹ä»»å‹™éœ€è¦ï¼šæŸ¥è©¢å„ªåŒ–",
            tool_calls=[],
            context={},
            session_id=session.session_id,
            category="k2",
            confidence=0.8,
            source="test"
        )
        
        session.data_points.append(k2_data_point)
        session.k2_examples += 1
        
        # æ¸¬è©¦K2æ–‡ä»¶ç”Ÿæˆ
        await self.mcp_manager._generate_k2_training_files(session)
        
        # æª¢æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
        k2_files = list(self.mcp_manager.data_dir.glob("k2_training_*.jsonl"))
        assert len(k2_files) > 0, "K2è¨“ç·´æ–‡ä»¶æœªç”Ÿæˆ"
        
        # é©—è­‰æ–‡ä»¶æ ¼å¼
        with open(k2_files[0], 'r', encoding='utf-8') as f:
            line = f.readline().strip()
            k2_data = json.loads(line)
            
            assert "messages" in k2_data, "K2æ ¼å¼ç¼ºå°‘messageså­—æ®µ"
            assert len(k2_data["messages"]) == 3, "K2æ ¼å¼æ¶ˆæ¯æ•¸é‡éŒ¯èª¤"
            assert k2_data["messages"][0]["role"] == "system", "K2æ ¼å¼ç³»çµ±æ¶ˆæ¯éŒ¯èª¤"
            assert "K2 å„ªåŒ–å™¨" in k2_data["messages"][0]["content"], "K2ç³»çµ±æç¤ºè©éŒ¯èª¤"
    
    async def test_deepswe_data_format(self):
        """æ¸¬è©¦DeepSWEæ•¸æ“šæ ¼å¼"""
        from core.components.claude_realtime_mcp.claude_realtime_manager import TrainingSession, TrainingDataPoint
        import uuid
        import time
        
        session = TrainingSession(
            session_id=str(uuid.uuid4()),
            start_time=time.time()
        )
        
        deepswe_data_point = TrainingDataPoint(
            id=str(uuid.uuid4()),
            timestamp=time.time(),
            user_input="å¹«æˆ‘é‡æ§‹é€™å€‹Pythonå‡½æ•¸ï¼Œæé«˜ä»£ç¢¼å¯è®€æ€§",
            assistant_response="æˆ‘å°‡é‡æ§‹é€™å€‹å‡½æ•¸ï¼Œæ¡ç”¨å–®ä¸€è·è²¬åŸå‰‡...",
            tool_calls=[{"name": "code_refactor", "result": "refactored_code"}],
            context={"language": "python", "task": "refactoring"},
            session_id=session.session_id,
            category="deepswe",
            confidence=0.9,
            source="test"
        )
        
        session.data_points.append(deepswe_data_point)
        session.deepswe_examples += 1
        
        # æ¸¬è©¦DeepSWEæ–‡ä»¶ç”Ÿæˆ
        await self.mcp_manager._generate_deepswe_training_files(session)
        
        # æª¢æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
        deepswe_files = list(self.mcp_manager.data_dir.glob("deepswe_training_*.jsonl"))
        assert len(deepswe_files) > 0, "DeepSWEè¨“ç·´æ–‡ä»¶æœªç”Ÿæˆ"
        
        # é©—è­‰æ–‡ä»¶æ ¼å¼
        with open(deepswe_files[0], 'r', encoding='utf-8') as f:
            line = f.readline().strip()
            deepswe_data = json.loads(line)
            
            assert "instruction" in deepswe_data, "DeepSWEæ ¼å¼ç¼ºå°‘instructionå­—æ®µ"
            assert "output" in deepswe_data, "DeepSWEæ ¼å¼ç¼ºå°‘outputå­—æ®µ"
            assert "tools_used" in deepswe_data, "DeepSWEæ ¼å¼ç¼ºå°‘tools_usedå­—æ®µ"
            assert deepswe_data["metadata"]["category"] == "software_engineering", "DeepSWEé¡åˆ¥éŒ¯èª¤"
    
    async def test_quality_assessment(self):
        """æ¸¬è©¦æ•¸æ“šè³ªé‡è©•ä¼°"""
        # æ¸¬è©¦é«˜è³ªé‡æ•¸æ“š
        high_quality_interaction = {
            "user": "K2å„ªåŒ–ï¼šåˆ†æé€™å€‹è¤‡é›œçš„ç®—æ³•ä¸¦æä¾›å„ªåŒ–å»ºè­°ï¼Œéœ€è¦è€ƒæ…®æ™‚é–“è¤‡é›œåº¦å’Œç©ºé–“è¤‡é›œåº¦",
            "assistant": "åŸºæ–¼åˆ†æï¼Œæˆ‘ç™¼ç¾é€™å€‹ç®—æ³•å­˜åœ¨ä»¥ä¸‹å•é¡Œï¼š1. æ™‚é–“è¤‡é›œåº¦ç‚ºO(nÂ²)ï¼Œå¯ä»¥å„ªåŒ–åˆ°O(n log n)ï¼›2. ç©ºé–“è¤‡é›œåº¦å¯ä»¥å¾O(n)å„ªåŒ–åˆ°O(1)ã€‚å…·é«”å„ªåŒ–æ–¹æ¡ˆå¦‚ä¸‹...",
            "tools": [{"name": "algorithm_analyzer", "result": "complexity_analysis"}],
            "context": {"language": "python", "complexity": "high"}
        }
        
        high_quality_score = self.mcp_manager._calculate_data_quality(high_quality_interaction)
        assert high_quality_score > 0.7, f"é«˜è³ªé‡æ•¸æ“šè©•åˆ†éä½: {high_quality_score}"
        
        # æ¸¬è©¦ä½è³ªé‡æ•¸æ“š
        low_quality_interaction = {
            "user": "å¹«æˆ‘",
            "assistant": "å¥½çš„",
            "tools": [],
            "context": {}
        }
        
        low_quality_score = self.mcp_manager._calculate_data_quality(low_quality_interaction)
        assert low_quality_score < 0.6, f"ä½è³ªé‡æ•¸æ“šè©•åˆ†éé«˜: {low_quality_score}"
        
        assert high_quality_score > low_quality_score, "è³ªé‡è©•ä¼°é‚è¼¯éŒ¯èª¤"
    
    async def test_session_management(self):
        """æ¸¬è©¦æœƒè©±ç®¡ç†"""
        # æ¸¬è©¦æ´»èºæœƒè©±ç®¡ç†
        initial_active = len(self.mcp_manager.active_sessions)
        
        # æ¨¡æ“¬æ–°æœƒè©±é–‹å§‹
        proc_info = {
            "pid": 12345,
            "name": "claude-code",
            "cmdline": "claude-code /test/project",
            "create_time": 1234567890,
            "detected_at": 1234567890
        }
        
        await self.mcp_manager._on_claude_session_started(proc_info)
        
        assert len(self.mcp_manager.active_sessions) == initial_active + 1, "æ´»èºæœƒè©±è¨ˆæ•¸éŒ¯èª¤"
        assert self.mcp_manager.training_stats["total_sessions"] > 0, "æœƒè©±çµ±è¨ˆæœªæ›´æ–°"
        
        # æ¸¬è©¦æœƒè©±çµæŸ
        await self.mcp_manager._on_claude_session_ended(proc_info)
        
        # ç­‰å¾…æœƒè©±è™•ç†å®Œæˆ
        await asyncio.sleep(0.1)
    
    async def test_data_export(self):
        """æ¸¬è©¦æ•¸æ“šåŒ¯å‡º"""
        # ç¢ºä¿æœ‰ä¸€äº›æ¸¬è©¦æ•¸æ“š
        await self.test_training_data_generation()
        
        # æ¸¬è©¦ç¶œåˆæ ¼å¼åŒ¯å‡º
        export_file = await self.mcp_manager.export_training_data("combined")
        export_path = Path(export_file)
        
        assert export_path.exists(), "åŒ¯å‡ºæ–‡ä»¶æœªå‰µå»º"
        assert export_path.stat().st_size > 0, "åŒ¯å‡ºæ–‡ä»¶ç‚ºç©º"
        
        # é©—è­‰åŒ¯å‡ºå…§å®¹
        with open(export_path, 'r', encoding='utf-8') as f:
            export_data = json.load(f)
            
            assert "export_timestamp" in export_data, "åŒ¯å‡ºæ–‡ä»¶ç¼ºå°‘æ™‚é–“æˆ³"
            assert "training_stats" in export_data, "åŒ¯å‡ºæ–‡ä»¶ç¼ºå°‘çµ±è¨ˆæ•¸æ“š"
            assert "sessions" in export_data, "åŒ¯å‡ºæ–‡ä»¶ç¼ºå°‘æœƒè©±æ•¸æ“š"
            assert "summary" in export_data, "åŒ¯å‡ºæ–‡ä»¶ç¼ºå°‘æ‘˜è¦"
    
    async def test_performance_metrics(self):
        """æ¸¬è©¦æ€§èƒ½æŒ‡æ¨™"""
        # ç²å–è¨“ç·´æ‘˜è¦
        summary = await self.mcp_manager.get_training_summary()
        
        # é©—è­‰æ‘˜è¦çµæ§‹
        required_keys = [
            "active_sessions", "completed_sessions", "training_stats",
            "data_directory", "collection_running", "monitored_processes"
        ]
        
        for key in required_keys:
            assert key in summary, f"è¨“ç·´æ‘˜è¦ç¼ºå°‘{key}å­—æ®µ"
        
        # é©—è­‰çµ±è¨ˆæ•¸æ“šçµæ§‹
        stats = summary["training_stats"]
        stats_keys = [
            "total_k2_examples", "total_deepswe_examples", "total_general_examples",
            "sessions_completed", "data_quality_score"
        ]
        
        for key in stats_keys:
            assert key in stats, f"çµ±è¨ˆæ•¸æ“šç¼ºå°‘{key}å­—æ®µ"
            assert isinstance(stats[key], (int, float)), f"{key}å­—æ®µé¡å‹éŒ¯èª¤"
    
    async def _generate_test_report(self):
        """ç”Ÿæˆæ¸¬è©¦å ±å‘Š"""
        print("\n" + "=" * 50)
        print("ğŸ“Š Claudeå¯¦æ™‚æ”¶é›†å™¨MCPæ¸¬è©¦å ±å‘Š")
        print("=" * 50)
        
        total_tests = len(self.test_results)
        passed_tests = len([r for r in self.test_results if r["status"] == "PASS"])
        failed_tests = total_tests - passed_tests
        
        print(f"ç¸½æ¸¬è©¦æ•¸: {total_tests}")
        print(f"âœ… é€šé: {passed_tests}")
        print(f"âŒ å¤±æ•—: {failed_tests}")
        print(f"é€šéç‡: {(passed_tests/total_tests)*100:.1f}%")
        
        if failed_tests > 0:
            print("\nâŒ å¤±æ•—çš„æ¸¬è©¦:")
            for result in self.test_results:
                if result["status"] == "FAIL":
                    print(f"  - {result['test']}: {result['error']}")
        
        # ä¿å­˜æ¸¬è©¦å ±å‘Š
        report_file = Path("claude_realtime_mcp_test_report.json")
        report_data = {
            "timestamp": datetime.now().isoformat(),
            "total_tests": total_tests,
            "passed_tests": passed_tests,
            "failed_tests": failed_tests,
            "pass_rate": (passed_tests/total_tests)*100,
            "test_results": self.test_results
        }
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“ è©³ç´°å ±å‘Šå·²ä¿å­˜: {report_file}")
        
        # æ¸…ç†
        if self.mcp_manager:
            await self.mcp_manager.shutdown()
        
        return passed_tests == total_tests

async def main():
    """ä¸»å‡½æ•¸"""
    tester = ClaudeRealtimeMCPTester()
    success = await tester.run_all_tests()
    
    if success:
        print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼Claudeå¯¦æ™‚æ”¶é›†å™¨MCPæº–å‚™å°±ç·’ï¼")
        return 0
    else:
        print("\nğŸ’¥ éƒ¨åˆ†æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥éŒ¯èª¤ä¸¦ä¿®å¾©")
        return 1

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)