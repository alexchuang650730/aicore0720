#!/usr/bin/env python3
"""
å›ºå®šå ´æ™¯åŸºæº–æ¸¬è©¦ - åŸºæ–¼ä½ çš„æ ¸å¿ƒå›ºå®šéœ€æ±‚
å°ˆæ³¨æ–¼æœ€å¸¸ç”¨çš„é–‹ç™¼å ´æ™¯ï¼Œé¿å…è¤‡é›œçš„ç€è¦½å™¨è‡ªå‹•åŒ–
"""

import json
import time
from typing import Dict, List, Any
from real_time_comparison_tracker import quick_claude_log, add_k2_test, show_stats

class FixedScenarioBenchmark:
    """å›ºå®šå ´æ™¯åŸºæº–æ¸¬è©¦"""
    
    def __init__(self):
        self.core_scenarios = self._define_core_scenarios()
        
    def _define_core_scenarios(self) -> List[Dict]:
        """å®šç¾©ä½ çš„æ ¸å¿ƒå›ºå®šéœ€æ±‚å ´æ™¯"""
        return [
            {
                "id": "react_hook_form",
                "name": "React Hookè¡¨å–®ç®¡ç†",
                "prompt": "å‰µå»ºReactè‡ªå®šç¾©Hookç®¡ç†è¡¨å–®ç‹€æ…‹ï¼ŒåŒ…å«é©—è­‰ã€æäº¤ã€éŒ¯èª¤è™•ç†",
                "manus_satisfaction": 8,
                "category": "frontend",
                "complexity": "medium",
                "frequency": "æ¯æ—¥",
                "importance": "æ ¸å¿ƒ",
                "typical_use": "Webæ‡‰ç”¨è¡¨å–®é–‹ç™¼"
            },
            {
                "id": "python_api_design", 
                "name": "Python APIè¨­è¨ˆ",
                "prompt": "ä½¿ç”¨FastAPIå‰µå»ºRESTful APIï¼ŒåŒ…å«èªè­‰ã€CRUDæ“ä½œã€éŒ¯èª¤è™•ç†",
                "manus_satisfaction": 9,
                "category": "backend",
                "complexity": "medium",
                "frequency": "æ¯æ—¥",
                "importance": "æ ¸å¿ƒ",
                "typical_use": "å¾Œç«¯APIé–‹ç™¼"
            },
            {
                "id": "algorithm_optimization",
                "name": "ç®—æ³•æ€§èƒ½å„ªåŒ–",
                "prompt": "å„ªåŒ–Pythonç®—æ³•æ€§èƒ½ï¼Œè™•ç†å¤§æ•¸æ“šé›†ï¼ŒåŒ…å«æ™‚é–“è¤‡é›œåº¦åˆ†æ",
                "manus_satisfaction": 9,
                "category": "algorithm",
                "complexity": "medium",
                "frequency": "æ¯é€±", 
                "importance": "é‡è¦",
                "typical_use": "æ€§èƒ½å„ªåŒ–ä»»å‹™"
            },
            {
                "id": "database_query_opt",
                "name": "æ•¸æ“šåº«æŸ¥è©¢å„ªåŒ–",
                "prompt": "å„ªåŒ–è¤‡é›œSQLæŸ¥è©¢ï¼Œæ·»åŠ ç´¢å¼•å»ºè­°ï¼Œè™•ç†å¤§é‡æ•¸æ“šçš„åˆ†é ",
                "manus_satisfaction": 8,
                "category": "database", 
                "complexity": "medium",
                "frequency": "æ¯é€±",
                "importance": "é‡è¦",
                "typical_use": "æ•¸æ“šåº«æ€§èƒ½èª¿å„ª"
            },
            {
                "id": "component_architecture",
                "name": "çµ„ä»¶æ¶æ§‹è¨­è¨ˆ",
                "prompt": "è¨­è¨ˆå¯å¾©ç”¨çš„React/Vueçµ„ä»¶ï¼ŒåŒ…å«propsæ¥å£ã€äº‹ä»¶è™•ç†ã€æ¨£å¼ç³»çµ±",
                "manus_satisfaction": 8,
                "category": "frontend",
                "complexity": "medium",
                "frequency": "æ¯é€±",
                "importance": "é‡è¦", 
                "typical_use": "çµ„ä»¶åº«é–‹ç™¼"
            },
            {
                "id": "error_debugging",
                "name": "éŒ¯èª¤èª¿è©¦ä¿®å¾©",
                "prompt": "åˆ†æå’Œä¿®å¾©JavaScript/Pythoné‹è¡Œæ™‚éŒ¯èª¤ï¼ŒåŒ…å«å †æ£§è¿½è¹¤åˆ†æ",
                "manus_satisfaction": 9,
                "category": "debugging",
                "complexity": "simple",
                "frequency": "æ¯æ—¥",
                "importance": "æ ¸å¿ƒ",
                "typical_use": "æ—¥å¸¸èª¿è©¦å·¥ä½œ"
            },
            {
                "id": "docker_deployment",
                "name": "Dockeréƒ¨ç½²é…ç½®",
                "prompt": "ç‚ºæ‡‰ç”¨å‰µå»ºDockeré…ç½®ï¼ŒåŒ…å«å¤šéšæ®µæ§‹å»ºã€ç’°å¢ƒè®Šé‡ã€å¥åº·æª¢æŸ¥",
                "manus_satisfaction": 7,
                "category": "devops",
                "complexity": "medium",
                "frequency": "æ¯æœˆ",
                "importance": "é‡è¦",
                "typical_use": "æ‡‰ç”¨éƒ¨ç½²"
            },
            {
                "id": "code_refactoring",
                "name": "ä»£ç¢¼é‡æ§‹å„ªåŒ–",
                "prompt": "é‡æ§‹éºç•™ä»£ç¢¼ï¼Œæé«˜å¯è®€æ€§å’Œå¯ç¶­è­·æ€§ï¼Œéµå¾ªæœ€ä½³å¯¦è¸",
                "manus_satisfaction": 8,
                "category": "refactoring",
                "complexity": "medium",
                "frequency": "æ¯é€±",
                "importance": "é‡è¦",
                "typical_use": "ä»£ç¢¼è³ªé‡æ”¹é€²"
            }
        ]
    
    def setup_baseline_tests(self) -> List[str]:
        """è¨­ç½®åŸºæº–æ¸¬è©¦ - è¨˜éŒ„Manus 1000å°æ™‚ç¶“é©—ä½œç‚ºåŸºæº–"""
        print("ğŸ¯ å›ºå®šå ´æ™¯åŸºæº–æ¸¬è©¦è¨­ç½®")
        print("åŸºæ–¼ä½ çš„æ ¸å¿ƒå›ºå®šé–‹ç™¼éœ€æ±‚")
        print("=" * 50)
        
        comparison_ids = []
        
        for scenario in self.core_scenarios:
            print(f"\nğŸ“‹ è¨­ç½®: {scenario['name']}")
            print(f"   ä½¿ç”¨é »ç‡: {scenario['frequency']}")
            print(f"   é‡è¦ç¨‹åº¦: {scenario['importance']}")
            print(f"   Manusæ»¿æ„åº¦: {scenario['manus_satisfaction']}/10")
            
            # ä¼°ç®—éŸ¿æ‡‰æ™‚é–“
            time_estimate = {
                "simple": 20.0,
                "medium": 35.0,
                "complex": 60.0
            }.get(scenario['complexity'], 35.0)
            
            comparison_id = quick_claude_log(
                prompt=scenario['prompt'],
                response=f"[Manus 1000å°æ™‚åŸºæº–] {scenario['typical_use']}",
                satisfaction=scenario['manus_satisfaction'],
                time_seconds=time_estimate,
                category=scenario['category'],
                complexity=scenario['complexity'],
                notes=f"æ ¸å¿ƒå ´æ™¯ | é »ç‡: {scenario['frequency']} | é‡è¦æ€§: {scenario['importance']}"
            )
            
            scenario['comparison_id'] = comparison_id
            comparison_ids.append(comparison_id)
        
        print(f"\nâœ… å·²è¨­ç½® {len(comparison_ids)} å€‹æ ¸å¿ƒå ´æ™¯åŸºæº–æ¸¬è©¦")
        return comparison_ids
    
    def manual_k2_test_session(self) -> None:
        """æ‰‹å‹•K2æ¸¬è©¦æœƒè©± - é€ä¸€æ¸¬è©¦æ ¸å¿ƒå ´æ™¯"""
        print("\nğŸ§ª æ‰‹å‹•K2æ¸¬è©¦æœƒè©±")
        print("é‡å°ä½ çš„æ ¸å¿ƒå›ºå®šéœ€æ±‚é€²è¡ŒK2æ¸¬è©¦")
        print("-" * 40)
        
        # ç¢ºä¿åŸºæº–æ¸¬è©¦å·²è¨­ç½®
        if not any('comparison_id' in s for s in self.core_scenarios):
            print("âš ï¸ åŸºæº–æ¸¬è©¦æœªè¨­ç½®ï¼Œå…ˆè¨­ç½®åŸºæº–...")
            self.setup_baseline_tests()
        
        # æŒ‰é‡è¦ç¨‹åº¦æ’åº
        sorted_scenarios = sorted(
            self.core_scenarios,
            key=lambda x: (x['importance'] == 'æ ¸å¿ƒ', x['frequency'] == 'æ¯æ—¥'),
            reverse=True
        )
        
        print(f"\nğŸ“‹ æ ¸å¿ƒå ´æ™¯åˆ—è¡¨ (æŒ‰é‡è¦æ€§æ’åº):")
        for i, scenario in enumerate(sorted_scenarios):
            status = "ğŸ”´" if scenario['importance'] == 'æ ¸å¿ƒ' else "ğŸŸ¡"
            print(f"{i+1:2d}. {status} {scenario['name']} ({scenario['frequency']})")
        
        try:
            choice = int(input(f"\né¸æ“‡è¦æ¸¬è©¦çš„å ´æ™¯ (1-{len(sorted_scenarios)}): ")) - 1
            
            if 0 <= choice < len(sorted_scenarios):
                selected = sorted_scenarios[choice]
                self._conduct_k2_test(selected)
            else:
                print("âŒ ç„¡æ•ˆé¸æ“‡")
                
        except (ValueError, KeyboardInterrupt):
            print("\nğŸ‘‹ æ¸¬è©¦æœƒè©±çµæŸ")
    
    def _conduct_k2_test(self, scenario: Dict) -> None:
        """åŸ·è¡Œå–®å€‹K2æ¸¬è©¦"""
        print(f"\nğŸ§ª æ¸¬è©¦å ´æ™¯: {scenario['name']}")
        print(f"ğŸ“ Prompt: {scenario['prompt']}")
        print(f"ğŸ“Š ManusåŸºæº–: {scenario['manus_satisfaction']}/10")
        print(f"ğŸ¯ å…¸å‹ç”¨é€”: {scenario['typical_use']}")
        
        print(f"\nè«‹ä½¿ç”¨æ­¤promptæ¸¬è©¦K2ï¼Œç„¶å¾Œè¼¸å…¥çµæœ:")
        print("-" * 40)
        
        try:
            k2_satisfaction = int(input("K2æ»¿æ„åº¦ (1-10): "))
            k2_time = float(input("K2éŸ¿æ‡‰æ™‚é–“ (ç§’): "))
            k2_notes = input("K2æ¸¬è©¦å‚™è¨» (ç°¡çŸ­): ")
            
            # è¨˜éŒ„K2æ¸¬è©¦çµæœ
            add_k2_test(
                comparison_id=scenario['comparison_id'],
                k2_response=f"[K2æ¸¬è©¦] æ»¿æ„åº¦: {k2_satisfaction}/10",
                k2_satisfaction=k2_satisfaction,
                k2_time=k2_time,
                notes=k2_notes
            )
            
            # å³æ™‚åˆ†æ
            gap = scenario['manus_satisfaction'] - k2_satisfaction
            gap_percent = (gap / scenario['manus_satisfaction']) * 100
            
            print(f"\nğŸ“Š å³æ™‚åˆ†æ:")
            print(f"   è³ªé‡å·®è·: {gap:.1f} åˆ† ({gap_percent:.1f}%)")
            
            if gap <= 1:
                print("   ğŸŸ¢ K2è³ªé‡æ¥è¿‘Manusï¼Œå¯ä»¥ä½¿ç”¨")
            elif gap <= 2:
                print("   ğŸŸ¡ K2è³ªé‡å¯æ¥å—ï¼Œæˆæœ¬å„ªå‹¢æ˜é¡¯")
            else:
                print("   ğŸ”´ K2è³ªé‡ä¸è¶³ï¼Œå»ºè­°ä½¿ç”¨Manus/Claude")
            
        except ValueError:
            print("âŒ è¼¸å…¥æ ¼å¼éŒ¯èª¤")
    
    def batch_k2_simulation(self) -> None:
        """æ‰¹é‡K2æ¸¬è©¦æ¨¡æ“¬ - åŸºæ–¼é ä¼°çš„K2è¡¨ç¾"""
        print("\nğŸ”„ æ‰¹é‡K2æ¸¬è©¦æ¨¡æ“¬")
        print("åŸºæ–¼benchmarkåˆ†æçš„é ä¼°K2è¡¨ç¾")
        
        # ç¢ºä¿åŸºæº–æ¸¬è©¦å·²è¨­ç½®
        if not any('comparison_id' in s for s in self.core_scenarios):
            self.setup_baseline_tests()
        
        # åŸºæ–¼scenarioè¤‡é›œåº¦å’Œé¡åˆ¥çš„K2é ä¼°è¡¨ç¾
        k2_estimates = {
            "react_hook_form": {"satisfaction": 6, "time": 25.0, "notes": "åŸºæœ¬åŠŸèƒ½æ­£ç¢ºä½†ç¼ºå°‘é«˜ç´šé©—è­‰"},
            "python_api_design": {"satisfaction": 7, "time": 30.0, "notes": "APIçµæ§‹æ­£ç¢ºä½†ç¼ºå°‘å®‰å…¨è€ƒé‡"},
            "algorithm_optimization": {"satisfaction": 7, "time": 20.0, "notes": "ç®—æ³•æ­£ç¢ºä½†å„ªåŒ–ä¸è¶³"},
            "database_query_opt": {"satisfaction": 6, "time": 25.0, "notes": "æŸ¥è©¢æ­£ç¢ºä½†ç¼ºå°‘é«˜ç´šå„ªåŒ–ç­–ç•¥"},
            "component_architecture": {"satisfaction": 6, "time": 28.0, "notes": "åŸºæœ¬çµ„ä»¶è¨­è¨ˆä½†ç¼ºå°‘è¤‡ç”¨æ€§è€ƒé‡"},
            "error_debugging": {"satisfaction": 8, "time": 15.0, "notes": "èª¿è©¦èƒ½åŠ›å¼·ï¼Œç°¡å–®å•é¡Œè™•ç†å¥½"},
            "docker_deployment": {"satisfaction": 6, "time": 22.0, "notes": "åŸºæœ¬Dockeré…ç½®ä½†ç¼ºå°‘ç”Ÿç”¢å„ªåŒ–"},
            "code_refactoring": {"satisfaction": 5, "time": 35.0, "notes": "é‡æ§‹å»ºè­°åŸºç¤ï¼Œç¼ºå°‘æ·±åº¦åˆ†æ"}
        }
        
        print(f"\næ­£åœ¨æ¨¡æ“¬ {len(self.core_scenarios)} å€‹å ´æ™¯çš„K2æ¸¬è©¦...")
        
        for scenario in self.core_scenarios:
            estimate = k2_estimates.get(scenario['id'], {
                "satisfaction": 6,
                "time": 30.0, 
                "notes": "K2åŸºæœ¬è¡¨ç¾"
            })
            
            add_k2_test(
                comparison_id=scenario['comparison_id'],
                k2_response=f"[K2æ¨¡æ“¬] æ»¿æ„åº¦: {estimate['satisfaction']}/10",
                k2_satisfaction=estimate['satisfaction'],
                k2_time=estimate['time'],
                notes=f"æ¨¡æ“¬æ¸¬è©¦: {estimate['notes']}"
            )
            
            print(f"âœ… {scenario['name']}: K2={estimate['satisfaction']}/10 vs Manus={scenario['manus_satisfaction']}/10")
        
        print(f"\nğŸ“Š æ‰¹é‡æ¨¡æ“¬å®Œæˆ!")
    
    def generate_strategy_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆç­–ç•¥å ±å‘Š"""
        print("\nğŸ“‹ ç”ŸæˆPowerAutomationç­–ç•¥å ±å‘Š")
        
        # ç²å–çµ±è¨ˆæ•¸æ“š
        from real_time_comparison_tracker import RealTimeComparisonTracker
        tracker = RealTimeComparisonTracker()
        stats = tracker.get_statistics()
        
        if stats['summary']['comparison_records'] == 0:
            return {"error": "éœ€è¦å…ˆåŸ·è¡ŒK2æ¸¬è©¦"}
        
        # åˆ†æçµæœ
        claude_avg = stats['summary']['claude_avg_satisfaction']
        k2_avg = stats['summary']['k2_avg_satisfaction']
        quality_gap = stats['summary']['quality_gap']
        
        # ç­–ç•¥å»ºè­°
        strategy = {
            "overall_assessment": "",
            "routing_strategy": {},
            "cost_optimization": {},
            "product_positioning": {}
        }
        
        # æ•´é«”è©•ä¼°
        gap_percentage = (quality_gap / claude_avg) * 100 if claude_avg > 0 else 0
        
        if gap_percentage <= 15:
            strategy["overall_assessment"] = "K2è³ªé‡å„ªç§€ï¼Œå¯ä»¥å¤§è†½æ¨å»£K2å„ªå…ˆç­–ç•¥"
        elif gap_percentage <= 25:
            strategy["overall_assessment"] = "K2è³ªé‡è‰¯å¥½ï¼Œé©åˆæ··åˆç­–ç•¥"
        elif gap_percentage <= 35:
            strategy["overall_assessment"] = "K2è³ªé‡å¯æ¥å—ï¼Œéœ€è¦æ™ºèƒ½è·¯ç”±å„ªåŒ–"
        else:
            strategy["overall_assessment"] = "K2è³ªé‡ä¸è¶³ï¼Œå»ºè­°ä¿å®ˆç­–ç•¥"
        
        # è·¯ç”±ç­–ç•¥
        by_category = stats.get('by_category', {})
        for category, claude_score in by_category.get('claude', {}).items():
            k2_score = by_category.get('k2', {}).get(category, 0)
            if k2_score > 0:
                gap = claude_score - k2_score
                if gap <= 1:
                    strategy["routing_strategy"][category] = "K2å„ªå…ˆ"
                elif gap <= 2:
                    strategy["routing_strategy"][category] = "K2é»˜èªï¼ŒClaudeå‚™ç”¨"
                else:
                    strategy["routing_strategy"][category] = "Claudeå„ªå…ˆ"
        
        # æˆæœ¬å„ªåŒ–
        estimated_k2_usage = sum(1 for cat, rec in strategy["routing_strategy"].items() if "K2" in rec)
        total_categories = len(strategy["routing_strategy"])
        k2_percentage = (estimated_k2_usage / total_categories * 100) if total_categories > 0 else 0
        
        strategy["cost_optimization"] = {
            "estimated_k2_usage": f"{k2_percentage:.0f}%",
            "estimated_cost_saving": f"{k2_percentage * 0.9:.0f}%",
            "quality_retention": f"{100 - gap_percentage:.0f}%"
        }
        
        # ç”¢å“å®šä½
        if gap_percentage <= 20:
            strategy["product_positioning"] = {
                "primary": "æ™ºèƒ½æˆæœ¬å„ªåŒ–çš„Claude Code Toolç•Œé¢",
                "secondary": f"K2æä¾›{100-gap_percentage:.0f}% Claudeè³ªé‡ï¼Œ{k2_percentage*0.9:.0f}%æˆæœ¬ç¯€çœ",
                "target": "æˆæœ¬æ•æ„Ÿçš„é–‹ç™¼åœ˜éšŠ"
            }
        else:
            strategy["product_positioning"] = {
                "primary": "å¢å¼·Claude Code Toolé«”é©—çš„æ™ºèƒ½ç•Œé¢",
                "secondary": "æä¾›å¯é¸çš„æˆæœ¬å„ªåŒ–æ–¹æ¡ˆ", 
                "target": "æ³¨é‡é–‹ç™¼æ•ˆç‡çš„åœ˜éšŠ"
            }
        
        print(f"\nğŸ“Š ç­–ç•¥åˆ†æå®Œæˆ:")
        print(f"   è³ªé‡å·®è·: {gap_percentage:.1f}%")
        print(f"   K2ä½¿ç”¨æ¯”ä¾‹: {k2_percentage:.0f}%")
        print(f"   é ä¼°æˆæœ¬ç¯€çœ: {k2_percentage*0.9:.0f}%")
        print(f"   æ•´é«”è©•ä¼°: {strategy['overall_assessment']}")
        
        return strategy

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ¯ å›ºå®šå ´æ™¯åŸºæº–æ¸¬è©¦")
    print("åŸºæ–¼ä½ çš„æ ¸å¿ƒå›ºå®šé–‹ç™¼éœ€æ±‚")
    print("=" * 50)
    
    benchmark = FixedScenarioBenchmark()
    
    print("\né¸æ“‡æ“ä½œ:")
    print("1. è¨­ç½®åŸºæº–æ¸¬è©¦ (Manus 1000å°æ™‚ç¶“é©—)")
    print("2. æ‰‹å‹•K2æ¸¬è©¦æœƒè©±")
    print("3. æ‰¹é‡K2æ¸¬è©¦æ¨¡æ“¬")
    print("4. æŸ¥çœ‹çµ±è¨ˆå ±å‘Š")
    print("5. ç”Ÿæˆç­–ç•¥å ±å‘Š")
    
    try:
        choice = input("\nè¼¸å…¥é¸æ“‡ (1-5): ")
        
        if choice == "1":
            benchmark.setup_baseline_tests()
            
        elif choice == "2":
            benchmark.manual_k2_test_session()
            
        elif choice == "3":
            benchmark.batch_k2_simulation()
            
        elif choice == "4":
            show_stats()
            
        elif choice == "5":
            strategy = benchmark.generate_strategy_report()
            print(f"\nğŸ“‹ ç­–ç•¥å ±å‘Šå·²ç”Ÿæˆ")
            
        else:
            print("âŒ ç„¡æ•ˆé¸æ“‡")
            
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç¨‹åºçµæŸ")

if __name__ == "__main__":
    main()