#!/usr/bin/env python3
"""
PowerAutomation v4.75 - æŠ€è¡“æŒ‡æ¨™å’Œé«”é©—æŒ‡æ¨™ç³»çµ±
å»ºç«‹ P0-P2 MCP æŠ€è¡“æŒ‡æ¨™å’Œ ClaudeEditor é«”é©—æŒ‡æ¨™
"""

import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from enum import Enum
import asyncio
import time

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MCPPriority(Enum):
    """MCP å„ªå…ˆç´š"""
    P0 = "P0"  # æ ¸å¿ƒä¸­çš„æ ¸å¿ƒ
    P1 = "P1"  # æ ¸å¿ƒ
    P2 = "P2"  # é‡è¦

@dataclass
class TechnicalMetric:
    """æŠ€è¡“æŒ‡æ¨™"""
    name: str
    description: str
    unit: str
    target_value: float
    current_value: float = 0.0
    threshold_warning: float = 0.8  # è­¦å‘Šé–¾å€¼
    threshold_critical: float = 0.6  # å±éšªé–¾å€¼

@dataclass
class ExperienceMetric:
    """é«”é©—æŒ‡æ¨™"""
    name: str
    description: str
    area: str  # UI å€åŸŸ
    measurement: str  # æ¸¬é‡æ–¹å¼
    target_score: float
    current_score: float = 0.0

class MetricsSystem:
    """æŒ‡æ¨™ç³»çµ±"""
    
    def __init__(self):
        self.mcp_metrics = self._define_mcp_metrics()
        self.experience_metrics = self._define_experience_metrics()
        self.metrics_data = {
            "technical": {},
            "experience": {},
            "timestamp": datetime.now().isoformat()
        }
        
    def _define_mcp_metrics(self) -> Dict[str, Dict[str, List[TechnicalMetric]]]:
        """å®šç¾© MCP æŠ€è¡“æŒ‡æ¨™"""
        return {
            # P0 ç´š MCP
            "P0": {
                "smart_intervention": [
                    TechnicalMetric(
                        name="detection_accuracy",
                        description="ä»»å‹™é¡å‹æª¢æ¸¬æº–ç¢ºç‡",
                        unit="%",
                        target_value=95.0
                    ),
                    TechnicalMetric(
                        name="switch_latency",
                        description="åˆ‡æ›å»¶é²",
                        unit="ms",
                        target_value=100.0
                    ),
                    TechnicalMetric(
                        name="keyword_coverage",
                        description="é—œéµè©è¦†è“‹ç‡",
                        unit="%",
                        target_value=90.0
                    )
                ],
                "codeflow_mcp": [
                    TechnicalMetric(
                        name="generation_speed",
                        description="ä»£ç¢¼ç”Ÿæˆé€Ÿåº¦",
                        unit="tokens/s",
                        target_value=1000.0
                    ),
                    TechnicalMetric(
                        name="syntax_accuracy",
                        description="èªæ³•æ­£ç¢ºç‡",
                        unit="%",
                        target_value=98.0
                    ),
                    TechnicalMetric(
                        name="test_coverage",
                        description="æ¸¬è©¦è¦†è“‹ç‡ç”Ÿæˆ",
                        unit="%",
                        target_value=85.0
                    )
                ],
                "smartui_mcp": [
                    TechnicalMetric(
                        name="component_generation_time",
                        description="çµ„ä»¶ç”Ÿæˆæ™‚é–“",
                        unit="s",
                        target_value=2.0
                    ),
                    TechnicalMetric(
                        name="responsive_accuracy",
                        description="éŸ¿æ‡‰å¼è¨­è¨ˆæº–ç¢ºåº¦",
                        unit="%",
                        target_value=95.0
                    ),
                    TechnicalMetric(
                        name="theme_consistency",
                        description="ä¸»é¡Œä¸€è‡´æ€§",
                        unit="%",
                        target_value=100.0
                    )
                ],
                "memoryrag_mcp": [
                    TechnicalMetric(
                        name="retrieval_accuracy",
                        description="æª¢ç´¢æº–ç¢ºç‡",
                        unit="%",
                        target_value=92.0
                    ),
                    TechnicalMetric(
                        name="memory_efficiency",
                        description="è¨˜æ†¶é«”ä½¿ç”¨æ•ˆç‡",
                        unit="%",
                        target_value=85.0
                    ),
                    TechnicalMetric(
                        name="k2_optimization_rate",
                        description="K2 å„ªåŒ–ç‡",
                        unit="%",
                        target_value=30.0
                    )
                ]
            },
            
            # P1 ç´š MCP
            "P1": {
                "smarttool_mcp": [
                    TechnicalMetric(
                        name="tool_integration_count",
                        description="é›†æˆå·¥å…·æ•¸é‡",
                        unit="å€‹",
                        target_value=50.0
                    ),
                    TechnicalMetric(
                        name="api_response_time",
                        description="API éŸ¿æ‡‰æ™‚é–“",
                        unit="ms",
                        target_value=200.0
                    ),
                    TechnicalMetric(
                        name="success_rate",
                        description="èª¿ç”¨æˆåŠŸç‡",
                        unit="%",
                        target_value=99.0
                    )
                ],
                "test_mcp": [
                    TechnicalMetric(
                        name="test_generation_accuracy",
                        description="æ¸¬è©¦ç”Ÿæˆæº–ç¢ºç‡",
                        unit="%",
                        target_value=90.0
                    ),
                    TechnicalMetric(
                        name="execution_speed",
                        description="åŸ·è¡Œé€Ÿåº¦",
                        unit="tests/s",
                        target_value=100.0
                    ),
                    TechnicalMetric(
                        name="coverage_analysis",
                        description="è¦†è“‹ç‡åˆ†ææº–ç¢ºåº¦",
                        unit="%",
                        target_value=95.0
                    )
                ],
                "claude_router_mcp": [
                    TechnicalMetric(
                        name="routing_accuracy",
                        description="è·¯ç”±æº–ç¢ºç‡",
                        unit="%",
                        target_value=98.0
                    ),
                    TechnicalMetric(
                        name="k2_switch_time",
                        description="K2 åˆ‡æ›æ™‚é–“",
                        unit="ms",
                        target_value=50.0
                    ),
                    TechnicalMetric(
                        name="conversation_sync_rate",
                        description="å°è©±åŒæ­¥ç‡",
                        unit="%",
                        target_value=100.0
                    )
                ]
            },
            
            # P2 ç´š MCP
            "P2": {
                "command_mcp": [
                    TechnicalMetric(
                        name="command_recognition",
                        description="å‘½ä»¤è­˜åˆ¥ç‡",
                        unit="%",
                        target_value=99.0
                    ),
                    TechnicalMetric(
                        name="execution_time",
                        description="åŸ·è¡Œæ™‚é–“",
                        unit="ms",
                        target_value=100.0
                    )
                ],
                "local_adapter_mcp": [
                    TechnicalMetric(
                        name="file_operation_speed",
                        description="æ–‡ä»¶æ“ä½œé€Ÿåº¦",
                        unit="ops/s",
                        target_value=1000.0
                    ),
                    TechnicalMetric(
                        name="sync_accuracy",
                        description="åŒæ­¥æº–ç¢ºç‡",
                        unit="%",
                        target_value=100.0
                    )
                ],
                "mcp_coordinator_mcp": [
                    TechnicalMetric(
                        name="coordination_latency",
                        description="å”èª¿å»¶é²",
                        unit="ms",
                        target_value=20.0
                    ),
                    TechnicalMetric(
                        name="conflict_resolution",
                        description="è¡çªè§£æ±ºç‡",
                        unit="%",
                        target_value=95.0
                    )
                ],
                "docs_mcp": [
                    TechnicalMetric(
                        name="scan_speed",
                        description="æƒæé€Ÿåº¦",
                        unit="files/s",
                        target_value=100.0
                    ),
                    TechnicalMetric(
                        name="categorization_accuracy",
                        description="åˆ†é¡æº–ç¢ºç‡",
                        unit="%",
                        target_value=90.0
                    )
                ]
            }
        }
    
    def _define_experience_metrics(self) -> Dict[str, List[ExperienceMetric]]:
        """å®šç¾© ClaudeEditor é«”é©—æŒ‡æ¨™"""
        return {
            "ai_model_control": [
                ExperienceMetric(
                    name="model_switch_time",
                    description="æ¨¡å‹åˆ‡æ›æ™‚é–“",
                    area="AIæ¨¡å‹æ§åˆ¶å€",
                    measurement="å¾é»æ“Šåˆ°å®Œæˆåˆ‡æ›çš„æ™‚é–“",
                    target_score=1.0  # ç§’
                ),
                ExperienceMetric(
                    name="model_status_visibility",
                    description="æ¨¡å‹ç‹€æ…‹å¯è¦‹æ€§",
                    area="AIæ¨¡å‹æ§åˆ¶å€",
                    measurement="ç‹€æ…‹ä¿¡æ¯çš„æ¸…æ™°åº¦è©•åˆ†",
                    target_score=9.0  # 1-10åˆ†
                ),
                ExperienceMetric(
                    name="k2_indicator_clarity",
                    description="K2 æ¨¡å¼æŒ‡ç¤ºæ¸…æ™°åº¦",
                    area="AIæ¨¡å‹æ§åˆ¶å€",
                    measurement="ç”¨æˆ¶è­˜åˆ¥ç•¶å‰æ¨¡å¼çš„æº–ç¢ºç‡",
                    target_score=95.0  # %
                )
            ],
            
            "workflow_area": [
                ExperienceMetric(
                    name="workflow_discovery",
                    description="å·¥ä½œæµç™¼ç¾ä¾¿åˆ©æ€§",
                    area="å…­å¤§å·¥ä½œæµå€",
                    measurement="æ‰¾åˆ°æ‰€éœ€å·¥ä½œæµçš„å¹³å‡æ™‚é–“",
                    target_score=3.0  # ç§’
                ),
                ExperienceMetric(
                    name="workflow_execution",
                    description="å·¥ä½œæµåŸ·è¡Œæµæš¢åº¦",
                    area="å…­å¤§å·¥ä½œæµå€",
                    measurement="åŸ·è¡Œéç¨‹ä¸­çš„ä¸­æ–·æ¬¡æ•¸",
                    target_score=0.0  # æ¬¡
                ),
                ExperienceMetric(
                    name="workflow_monitoring",
                    description="ç›£æ§é‹ç¶­é«”é©—",
                    area="å…­å¤§å·¥ä½œæµå€-ç›£æ§é‹ç¶­",
                    measurement="é—œéµæŒ‡æ¨™çš„å¯¦æ™‚æ›´æ–°å»¶é²",
                    target_score=1.0  # ç§’
                )
            ],
            
            "code_editor": [
                ExperienceMetric(
                    name="auto_completion_speed",
                    description="è‡ªå‹•å®Œæˆé€Ÿåº¦",
                    area="ä»£ç¢¼ç·¨è¼¯å™¨",
                    measurement="å¾è¼¸å…¥åˆ°å»ºè­°å‡ºç¾çš„æ™‚é–“",
                    target_score=50.0  # ms
                ),
                ExperienceMetric(
                    name="syntax_highlight_accuracy",
                    description="èªæ³•é«˜äº®æº–ç¢ºæ€§",
                    area="ä»£ç¢¼ç·¨è¼¯å™¨",
                    measurement="æ­£ç¢ºé«˜äº®çš„ä»£ç¢¼æ¯”ä¾‹",
                    target_score=99.0  # %
                ),
                ExperienceMetric(
                    name="error_detection_rate",
                    description="éŒ¯èª¤æª¢æ¸¬ç‡",
                    area="ä»£ç¢¼ç·¨è¼¯å™¨",
                    measurement="å¯¦æ™‚æª¢æ¸¬åˆ°çš„éŒ¯èª¤æ¯”ä¾‹",
                    target_score=95.0  # %
                )
            ],
            
            "ui_designer": [
                ExperienceMetric(
                    name="drag_drop_responsiveness",
                    description="æ‹–æ”¾éŸ¿æ‡‰æ€§",
                    area="UIè¨­è¨ˆå™¨",
                    measurement="æ‹–æ”¾æ“ä½œçš„å»¶é²",
                    target_score=16.0  # ms (60fps)
                ),
                ExperienceMetric(
                    name="preview_accuracy",
                    description="é è¦½æº–ç¢ºæ€§",
                    area="UIè¨­è¨ˆå™¨",
                    measurement="é è¦½èˆ‡å¯¦éš›æ•ˆæœçš„ä¸€è‡´æ€§",
                    target_score=98.0  # %
                ),
                ExperienceMetric(
                    name="component_library_access",
                    description="çµ„ä»¶åº«è¨ªå•é€Ÿåº¦",
                    area="UIè¨­è¨ˆå™¨",
                    measurement="æ‰“é–‹çµ„ä»¶åº«çš„æ™‚é–“",
                    target_score=0.5  # ç§’
                )
            ],
            
            "command_center": [
                ExperienceMetric(
                    name="command_discovery",
                    description="å‘½ä»¤ç™¼ç¾æ•ˆç‡",
                    area="å‘½ä»¤ä¸­å¿ƒ",
                    measurement="æ‰¾åˆ°ç›®æ¨™å‘½ä»¤çš„å¹³å‡æ“Šéµæ•¸",
                    target_score=3.0  # æ¬¡
                ),
                ExperienceMetric(
                    name="command_execution_feedback",
                    description="å‘½ä»¤åŸ·è¡Œåé¥‹",
                    area="å‘½ä»¤ä¸­å¿ƒ",
                    measurement="åŸ·è¡Œå¾Œåé¥‹å‡ºç¾çš„æ™‚é–“",
                    target_score=100.0  # ms
                ),
                ExperienceMetric(
                    name="shortcut_effectiveness",
                    description="å¿«æ·éµæœ‰æ•ˆæ€§",
                    area="å‘½ä»¤ä¸­å¿ƒ",
                    measurement="å¿«æ·éµä½¿ç”¨æˆåŠŸç‡",
                    target_score=100.0  # %
                )
            ],
            
            "collaboration": [
                ExperienceMetric(
                    name="real_time_sync",
                    description="å¯¦æ™‚åŒæ­¥å»¶é²",
                    area="å”ä½œå€",
                    measurement="æ“ä½œåŒæ­¥åˆ°å…¶ä»–ç”¨æˆ¶çš„æ™‚é–“",
                    target_score=200.0  # ms
                ),
                ExperienceMetric(
                    name="conflict_resolution_ui",
                    description="è¡çªè§£æ±ºç•Œé¢å‹å¥½åº¦",
                    area="å”ä½œå€",
                    measurement="ç”¨æˆ¶è§£æ±ºè¡çªçš„å¹³å‡æ™‚é–“",
                    target_score=30.0  # ç§’
                ),
                ExperienceMetric(
                    name="presence_awareness",
                    description="å”ä½œè€…å­˜åœ¨æ„ŸçŸ¥",
                    area="å”ä½œå€",
                    measurement="é¡¯ç¤ºå…¶ä»–ç”¨æˆ¶ç‹€æ…‹çš„æº–ç¢ºæ€§",
                    target_score=100.0  # %
                )
            ],
            
            "performance_monitor": [
                ExperienceMetric(
                    name="metrics_refresh_rate",
                    description="æŒ‡æ¨™åˆ·æ–°ç‡",
                    area="æ€§èƒ½ç›£æ§",
                    measurement="é—œéµæŒ‡æ¨™çš„æ›´æ–°é »ç‡",
                    target_score=1.0  # Hz
                ),
                ExperienceMetric(
                    name="alert_response_time",
                    description="å‘Šè­¦éŸ¿æ‡‰æ™‚é–“",
                    area="æ€§èƒ½ç›£æ§",
                    measurement="å¾å•é¡Œç™¼ç”Ÿåˆ°å‘Šè­¦é¡¯ç¤ºçš„æ™‚é–“",
                    target_score=1000.0  # ms
                ),
                ExperienceMetric(
                    name="visualization_clarity",
                    description="å¯è¦–åŒ–æ¸…æ™°åº¦",
                    area="æ€§èƒ½ç›£æ§",
                    measurement="åœ–è¡¨ä¿¡æ¯çš„å¯ç†è§£æ€§è©•åˆ†",
                    target_score=8.5  # 1-10åˆ†
                )
            ],
            
            "smart_intervention": [
                ExperienceMetric(
                    name="intervention_accuracy",
                    description="å¹²é æº–ç¢ºæ€§",
                    area="æ™ºèƒ½å¹²é ",
                    measurement="æ­£ç¢ºè­˜åˆ¥éœ€è¦åˆ‡æ›å ´æ™¯çš„æ¯”ä¾‹",
                    target_score=90.0  # %
                ),
                ExperienceMetric(
                    name="suggestion_relevance",
                    description="å»ºè­°ç›¸é—œæ€§",
                    area="æ™ºèƒ½å¹²é ",
                    measurement="ç”¨æˆ¶æ¥å—å»ºè­°çš„æ¯”ä¾‹",
                    target_score=80.0  # %
                ),
                ExperienceMetric(
                    name="non_intrusive_score",
                    description="éä¾µå…¥æ€§è©•åˆ†",
                    area="æ™ºèƒ½å¹²é ",
                    measurement="ç”¨æˆ¶å°å¹²é æ™‚æ©Ÿçš„æ»¿æ„åº¦",
                    target_score=8.0  # 1-10åˆ†
                )
            ]
        }
    
    async def collect_technical_metrics(self) -> Dict[str, Any]:
        """æ”¶é›†æŠ€è¡“æŒ‡æ¨™"""
        logger.info("ğŸ“Š æ”¶é›†æŠ€è¡“æŒ‡æ¨™...")
        
        results = {}
        
        for priority in ["P0", "P1", "P2"]:
            results[priority] = {}
            
            for mcp_name, metrics in self.mcp_metrics[priority].items():
                mcp_results = []
                
                for metric in metrics:
                    # æ¨¡æ“¬æ”¶é›†æŒ‡æ¨™æ•¸æ“š
                    current_value = await self._measure_technical_metric(mcp_name, metric)
                    metric.current_value = current_value
                    
                    # è¨ˆç®—å¥åº·åº¦
                    health_score = current_value / metric.target_value
                    if metric.unit == "ms" or metric.unit == "s":  # æ™‚é–“é¡æŒ‡æ¨™ï¼Œè¶Šå°è¶Šå¥½
                        health_score = metric.target_value / current_value if current_value > 0 else 1.0
                    
                    status = "healthy"
                    if health_score < metric.threshold_critical:
                        status = "critical"
                    elif health_score < metric.threshold_warning:
                        status = "warning"
                    
                    mcp_results.append({
                        "metric": asdict(metric),
                        "health_score": round(health_score, 2),
                        "status": status
                    })
                
                results[priority][mcp_name] = {
                    "metrics": mcp_results,
                    "overall_health": self._calculate_overall_health(mcp_results)
                }
        
        return results
    
    async def collect_experience_metrics(self) -> Dict[str, Any]:
        """æ”¶é›†é«”é©—æŒ‡æ¨™"""
        logger.info("ğŸ¯ æ”¶é›†é«”é©—æŒ‡æ¨™...")
        
        results = {}
        
        for area, metrics in self.experience_metrics.items():
            area_results = []
            
            for metric in metrics:
                # æ¨¡æ“¬æ”¶é›†é«”é©—æ•¸æ“š
                current_score = await self._measure_experience_metric(area, metric)
                metric.current_score = current_score
                
                # è¨ˆç®—é«”é©—åˆ†æ•¸
                if metric.measurement.endswith("æ™‚é–“") or "å»¶é²" in metric.name:
                    # æ™‚é–“é¡æŒ‡æ¨™ï¼Œè¶Šå°è¶Šå¥½
                    experience_score = (metric.target_score / current_score * 100) if current_score > 0 else 100
                else:
                    # å…¶ä»–æŒ‡æ¨™ï¼Œè¶Šå¤§è¶Šå¥½
                    experience_score = (current_score / metric.target_score * 100)
                
                experience_score = min(100, experience_score)  # é™åˆ¶åœ¨100%ä»¥å…§
                
                area_results.append({
                    "metric": asdict(metric),
                    "experience_score": round(experience_score, 1),
                    "grade": self._get_experience_grade(experience_score)
                })
            
            results[area] = {
                "metrics": area_results,
                "area_score": round(sum(m["experience_score"] for m in area_results) / len(area_results), 1)
            }
        
        return results
    
    async def _measure_technical_metric(self, mcp_name: str, metric: TechnicalMetric) -> float:
        """æ¸¬é‡æŠ€è¡“æŒ‡æ¨™ï¼ˆæ¨¡æ“¬ï¼‰"""
        # å¯¦éš›å¯¦ç¾ä¸­æ‡‰è©²èª¿ç”¨ç›¸æ‡‰çš„ MCP ç²å–çœŸå¯¦æ•¸æ“š
        import random
        
        # æ¨¡æ“¬ä¸åŒçš„æ¸¬é‡å€¼
        if metric.unit == "%":
            return random.uniform(metric.target_value * 0.8, min(100, metric.target_value * 1.1))
        elif metric.unit == "ms" or metric.unit == "s":
            return random.uniform(metric.target_value * 0.7, metric.target_value * 1.3)
        else:
            return random.uniform(metric.target_value * 0.9, metric.target_value * 1.1)
    
    async def _measure_experience_metric(self, area: str, metric: ExperienceMetric) -> float:
        """æ¸¬é‡é«”é©—æŒ‡æ¨™ï¼ˆæ¨¡æ“¬ï¼‰"""
        # å¯¦éš›å¯¦ç¾ä¸­æ‡‰è©²é€šéç”¨æˆ¶è¡Œç‚ºåˆ†æç²å–
        import random
        
        # æ¨¡æ“¬æ¸¬é‡å€¼ï¼Œç•¥æœ‰æ³¢å‹•
        return random.uniform(metric.target_score * 0.85, metric.target_score * 1.05)
    
    def _calculate_overall_health(self, mcp_results: List[Dict]) -> Dict[str, Any]:
        """è¨ˆç®—æ•´é«”å¥åº·åº¦"""
        health_scores = [r["health_score"] for r in mcp_results]
        
        return {
            "average_health": round(sum(health_scores) / len(health_scores), 2),
            "min_health": round(min(health_scores), 2),
            "critical_count": sum(1 for r in mcp_results if r["status"] == "critical"),
            "warning_count": sum(1 for r in mcp_results if r["status"] == "warning"),
            "healthy_count": sum(1 for r in mcp_results if r["status"] == "healthy")
        }
    
    def _get_experience_grade(self, score: float) -> str:
        """ç²å–é«”é©—ç­‰ç´š"""
        if score >= 95:
            return "A+"
        elif score >= 90:
            return "A"
        elif score >= 85:
            return "B+"
        elif score >= 80:
            return "B"
        elif score >= 70:
            return "C"
        else:
            return "D"
    
    async def generate_dashboard_data(self) -> Dict[str, Any]:
        """ç”Ÿæˆå„€è¡¨æ¿æ•¸æ“š"""
        technical_metrics = await self.collect_technical_metrics()
        experience_metrics = await self.collect_experience_metrics()
        
        # è¨ˆç®—ç¸½é«”åˆ†æ•¸
        tech_scores = []
        for priority, mcps in technical_metrics.items():
            for mcp_name, data in mcps.items():
                tech_scores.append(data["overall_health"]["average_health"])
        
        exp_scores = [data["area_score"] for data in experience_metrics.values()]
        
        dashboard = {
            "timestamp": datetime.now().isoformat(),
            "overall_scores": {
                "technical_health": round(sum(tech_scores) / len(tech_scores) * 100, 1),
                "experience_score": round(sum(exp_scores) / len(exp_scores), 1)
            },
            "technical_metrics": technical_metrics,
            "experience_metrics": experience_metrics,
            "recommendations": self._generate_recommendations(technical_metrics, experience_metrics),
            "alerts": self._generate_alerts(technical_metrics, experience_metrics)
        }
        
        return dashboard
    
    def _generate_recommendations(self, tech_metrics: Dict, exp_metrics: Dict) -> List[str]:
        """ç”Ÿæˆæ”¹é€²å»ºè­°"""
        recommendations = []
        
        # æŠ€è¡“å»ºè­°
        for priority, mcps in tech_metrics.items():
            for mcp_name, data in mcps.items():
                if data["overall_health"]["critical_count"] > 0:
                    recommendations.append(f"ğŸš¨ {mcp_name} æœ‰ {data['overall_health']['critical_count']} å€‹é—œéµæŒ‡æ¨™éœ€è¦ç«‹å³å„ªåŒ–")
                elif data["overall_health"]["warning_count"] > 1:
                    recommendations.append(f"âš ï¸ {mcp_name} æœ‰å¤šå€‹æŒ‡æ¨™æ¥è¿‘è­¦å‘Šé–¾å€¼ï¼Œå»ºè­°æª¢æŸ¥")
        
        # é«”é©—å»ºè­°
        for area, data in exp_metrics.items():
            if data["area_score"] < 80:
                area_name = {
                    "ai_model_control": "AIæ¨¡å‹æ§åˆ¶",
                    "workflow_area": "å·¥ä½œæµå€åŸŸ",
                    "code_editor": "ä»£ç¢¼ç·¨è¼¯å™¨",
                    "ui_designer": "UIè¨­è¨ˆå™¨",
                    "command_center": "å‘½ä»¤ä¸­å¿ƒ",
                    "collaboration": "å”ä½œåŠŸèƒ½",
                    "performance_monitor": "æ€§èƒ½ç›£æ§",
                    "smart_intervention": "æ™ºèƒ½å¹²é "
                }.get(area, area)
                
                recommendations.append(f"ğŸ’¡ {area_name} é«”é©—è©•åˆ†è¼ƒä½ ({data['area_score']}%)ï¼Œå»ºè­°å„ªåŒ–ç”¨æˆ¶äº¤äº’")
        
        return recommendations[:5]  # è¿”å›å‰5å€‹æœ€é‡è¦çš„å»ºè­°
    
    def _generate_alerts(self, tech_metrics: Dict, exp_metrics: Dict) -> List[Dict[str, Any]]:
        """ç”Ÿæˆå‘Šè­¦"""
        alerts = []
        
        # æŠ€è¡“å‘Šè­¦
        for priority, mcps in tech_metrics.items():
            for mcp_name, data in mcps.items():
                for metric_data in data["metrics"]:
                    if metric_data["status"] == "critical":
                        alerts.append({
                            "type": "technical",
                            "severity": "critical",
                            "mcp": mcp_name,
                            "metric": metric_data["metric"]["name"],
                            "message": f"{mcp_name} çš„ {metric_data['metric']['description']} åš´é‡ä½æ–¼ç›®æ¨™å€¼",
                            "current": metric_data["metric"]["current_value"],
                            "target": metric_data["metric"]["target_value"]
                        })
        
        # é«”é©—å‘Šè­¦
        for area, data in exp_metrics.items():
            if data["area_score"] < 70:
                alerts.append({
                    "type": "experience",
                    "severity": "warning",
                    "area": area,
                    "message": f"{area} å€åŸŸé«”é©—è©•åˆ†éä½",
                    "score": data["area_score"]
                })
        
        return alerts
    
    def export_metrics_report(self, dashboard_data: Dict[str, Any]) -> str:
        """å°å‡ºæŒ‡æ¨™å ±å‘Š"""
        report = f"""# PowerAutomation v4.75 æŒ‡æ¨™å ±å‘Š

ç”Ÿæˆæ™‚é–“ï¼š{dashboard_data['timestamp']}

## ç¸½é«”è©•åˆ†
- æŠ€è¡“å¥åº·åº¦ï¼š{dashboard_data['overall_scores']['technical_health']}%
- ç”¨æˆ¶é«”é©—åˆ†ï¼š{dashboard_data['overall_scores']['experience_score']}%

## æŠ€è¡“æŒ‡æ¨™è©³æƒ…

"""
        
        # æŠ€è¡“æŒ‡æ¨™
        for priority in ["P0", "P1", "P2"]:
            if priority in dashboard_data["technical_metrics"]:
                report += f"### {priority} ç´š MCP\n\n"
                
                for mcp_name, data in dashboard_data["technical_metrics"][priority].items():
                    health = data["overall_health"]
                    report += f"#### {mcp_name}\n"
                    report += f"- å¹³å‡å¥åº·åº¦ï¼š{health['average_health'] * 100:.1f}%\n"
                    report += f"- å¥åº·/è­¦å‘Š/å±éšªï¼š{health['healthy_count']}/{health['warning_count']}/{health['critical_count']}\n\n"
                    
                    # è©³ç´°æŒ‡æ¨™
                    for metric_data in data["metrics"]:
                        metric = metric_data["metric"]
                        status_icon = {
                            "healthy": "âœ…",
                            "warning": "âš ï¸",
                            "critical": "ğŸš¨"
                        }[metric_data["status"]]
                        
                        report += f"  - {metric['name']} {status_icon}: {metric['current_value']:.2f} / {metric['target_value']} {metric['unit']}\n"
                    
                    report += "\n"
        
        # é«”é©—æŒ‡æ¨™
        report += "## ç”¨æˆ¶é«”é©—æŒ‡æ¨™\n\n"
        
        for area, data in dashboard_data["experience_metrics"].items():
            area_name = area.replace("_", " ").title()
            report += f"### {area_name} (è©•åˆ†: {data['area_score']}%)\n\n"
            
            for metric_data in data["metrics"]:
                metric = metric_data["metric"]
                grade = metric_data["grade"]
                score = metric_data["experience_score"]
                
                report += f"- **{metric['name']}** [{grade}]: {score:.1f}%\n"
                report += f"  - {metric['description']}\n"
                report += f"  - ç•¶å‰: {metric['current_score']:.2f} / ç›®æ¨™: {metric['target_score']}\n\n"
        
        # å»ºè­°å’Œå‘Šè­¦
        if dashboard_data["recommendations"]:
            report += "## æ”¹é€²å»ºè­°\n\n"
            for rec in dashboard_data["recommendations"]:
                report += f"- {rec}\n"
        
        if dashboard_data["alerts"]:
            report += "\n## å‘Šè­¦\n\n"
            for alert in dashboard_data["alerts"]:
                icon = "ğŸš¨" if alert["severity"] == "critical" else "âš ï¸"
                report += f"- {icon} {alert['message']}\n"
        
        return report


# å‰µå»ºå¯¦æ™‚ç›£æ§å„€è¡¨æ¿
def create_metrics_dashboard_ui() -> str:
    """å‰µå»ºæŒ‡æ¨™å„€è¡¨æ¿ UI"""
    return """
import React, { useState, useEffect } from 'react';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Progress } from '@/components/ui/progress';
import { Badge } from '@/components/ui/badge';
import { Tabs, TabsContent, TabsList, TabsTrigger } from '@/components/ui/tabs';
import { LineChart, Line, BarChart, Bar, PieChart, Pie, Cell, XAxis, YAxis, CartesianGrid, Tooltip, Legend, ResponsiveContainer } from 'recharts';

export function MetricsDashboard({ metricsData }) {
    const [selectedPriority, setSelectedPriority] = useState('P0');
    const [selectedArea, setSelectedArea] = useState('ai_model_control');
    
    // é¡è‰²é…ç½®
    const statusColors = {
        healthy: '#10b981',
        warning: '#f59e0b',
        critical: '#ef4444'
    };
    
    const gradeColors = {
        'A+': '#065f46',
        'A': '#10b981',
        'B+': '#34d399',
        'B': '#fbbf24',
        'C': '#f97316',
        'D': '#ef4444'
    };
    
    // æŠ€è¡“æŒ‡æ¨™å¡ç‰‡
    const TechnicalMetricCard = ({ mcp, data }) => {
        const health = data.overall_health;
        const healthPercent = health.average_health * 100;
        
        return (
            <Card className="mb-4">
                <CardHeader>
                    <CardTitle className="flex justify-between items-center">
                        <span>{mcp}</span>
                        <Badge variant={healthPercent > 80 ? 'success' : healthPercent > 60 ? 'warning' : 'destructive'}>
                            {healthPercent.toFixed(1)}%
                        </Badge>
                    </CardTitle>
                </CardHeader>
                <CardContent>
                    <div className="space-y-3">
                        {data.metrics.map((metric, idx) => (
                            <div key={idx}>
                                <div className="flex justify-between text-sm mb-1">
                                    <span>{metric.metric.description}</span>
                                    <span className={`font-medium text-${statusColors[metric.status]}`}>
                                        {metric.metric.current_value.toFixed(2)} {metric.metric.unit}
                                    </span>
                                </div>
                                <Progress 
                                    value={metric.health_score * 100} 
                                    className={`h-2 bg-${statusColors[metric.status]}/20`}
                                />
                            </div>
                        ))}
                    </div>
                    
                    <div className="mt-4 flex justify-around text-center">
                        <div>
                            <div className="text-2xl font-bold text-green-600">{health.healthy_count}</div>
                            <div className="text-xs text-muted-foreground">å¥åº·</div>
                        </div>
                        <div>
                            <div className="text-2xl font-bold text-yellow-600">{health.warning_count}</div>
                            <div className="text-xs text-muted-foreground">è­¦å‘Š</div>
                        </div>
                        <div>
                            <div className="text-2xl font-bold text-red-600">{health.critical_count}</div>
                            <div className="text-xs text-muted-foreground">å±éšª</div>
                        </div>
                    </div>
                </CardContent>
            </Card>
        );
    };
    
    // é«”é©—æŒ‡æ¨™å¡ç‰‡
    const ExperienceMetricCard = ({ area, data }) => {
        const areaScore = data.area_score;
        const scoreColor = areaScore >= 90 ? 'text-green-600' : areaScore >= 80 ? 'text-yellow-600' : 'text-red-600';
        
        return (
            <Card className="mb-4">
                <CardHeader>
                    <CardTitle className="flex justify-between items-center">
                        <span>{area.replace(/_/g, ' ').toUpperCase()}</span>
                        <span className={`text-2xl font-bold ${scoreColor}`}>
                            {areaScore.toFixed(1)}%
                        </span>
                    </CardTitle>
                </CardHeader>
                <CardContent>
                    <div className="space-y-4">
                        {data.metrics.map((metric, idx) => (
                            <div key={idx} className="border-l-4 pl-3" 
                                 style={{borderColor: gradeColors[metric.grade]}}>
                                <div className="flex justify-between items-start">
                                    <div>
                                        <div className="font-medium">{metric.metric.name}</div>
                                        <div className="text-sm text-muted-foreground">
                                            {metric.metric.description}
                                        </div>
                                    </div>
                                    <Badge className="ml-2" style={{backgroundColor: gradeColors[metric.grade]}}>
                                        {metric.grade}
                                    </Badge>
                                </div>
                                <div className="mt-2 text-sm">
                                    <span className="text-muted-foreground">æ¸¬é‡æ–¹å¼ï¼š</span>
                                    {metric.metric.measurement}
                                </div>
                                <Progress 
                                    value={metric.experience_score} 
                                    className="mt-2 h-2"
                                />
                            </div>
                        ))}
                    </div>
                </CardContent>
            </Card>
        );
    };
    
    // ç¸½è¦½åœ–è¡¨
    const OverviewCharts = ({ technicalHealth, experienceScore }) => {
        const overviewData = [
            { name: 'æŠ€è¡“å¥åº·åº¦', value: technicalHealth, fill: '#10b981' },
            { name: 'ç”¨æˆ¶é«”é©—åˆ†', value: experienceScore, fill: '#3b82f6' }
        ];
        
        return (
            <div className="grid grid-cols-1 md:grid-cols-2 gap-4 mb-6">
                <Card>
                    <CardHeader>
                        <CardTitle>ç¸½é«”è©•åˆ†</CardTitle>
                    </CardHeader>
                    <CardContent>
                        <ResponsiveContainer width="100%" height={200}>
                            <BarChart data={overviewData}>
                                <CartesianGrid strokeDasharray="3 3" />
                                <XAxis dataKey="name" />
                                <YAxis domain={[0, 100]} />
                                <Tooltip />
                                <Bar dataKey="value" />
                            </BarChart>
                        </ResponsiveContainer>
                    </CardContent>
                </Card>
                
                <Card>
                    <CardHeader>
                        <CardTitle>æ ¸å¿ƒæŒ‡æ¨™</CardTitle>
                    </CardHeader>
                    <CardContent className="flex items-center justify-center">
                        <div className="text-center">
                            <div className="text-5xl font-bold text-primary">
                                {((technicalHealth + experienceScore) / 2).toFixed(1)}%
                            </div>
                            <div className="text-muted-foreground mt-2">
                                PowerAutomation Core å¥åº·åº¦
                            </div>
                        </div>
                    </CardContent>
                </Card>
            </div>
        );
    };
    
    return (
        <div className="p-6 space-y-6">
            <h1 className="text-3xl font-bold mb-6">PowerAutomation v4.75 æŒ‡æ¨™å„€è¡¨æ¿</h1>
            
            {/* ç¸½è¦½ */}
            <OverviewCharts 
                technicalHealth={metricsData.overall_scores.technical_health}
                experienceScore={metricsData.overall_scores.experience_score}
            />
            
            {/* å‘Šè­¦ */}
            {metricsData.alerts.length > 0 && (
                <Card className="border-red-200 bg-red-50">
                    <CardHeader>
                        <CardTitle className="text-red-700">å‘Šè­¦</CardTitle>
                    </CardHeader>
                    <CardContent>
                        <div className="space-y-2">
                            {metricsData.alerts.map((alert, idx) => (
                                <div key={idx} className="flex items-center gap-2">
                                    <span className="text-2xl">
                                        {alert.severity === 'critical' ? 'ğŸš¨' : 'âš ï¸'}
                                    </span>
                                    <span className="text-sm">{alert.message}</span>
                                </div>
                            ))}
                        </div>
                    </CardContent>
                </Card>
            )}
            
            <Tabs defaultValue="technical">
                <TabsList>
                    <TabsTrigger value="technical">æŠ€è¡“æŒ‡æ¨™</TabsTrigger>
                    <TabsTrigger value="experience">é«”é©—æŒ‡æ¨™</TabsTrigger>
                    <TabsTrigger value="recommendations">å»ºè­°</TabsTrigger>
                </TabsList>
                
                <TabsContent value="technical" className="mt-4">
                    <Tabs value={selectedPriority} onValueChange={setSelectedPriority}>
                        <TabsList>
                            <TabsTrigger value="P0">P0 æ ¸å¿ƒ</TabsTrigger>
                            <TabsTrigger value="P1">P1 é‡è¦</TabsTrigger>
                            <TabsTrigger value="P2">P2 è¼”åŠ©</TabsTrigger>
                        </TabsList>
                        
                        <TabsContent value={selectedPriority} className="mt-4">
                            <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
                                {Object.entries(metricsData.technical_metrics[selectedPriority] || {}).map(([mcp, data]) => (
                                    <TechnicalMetricCard key={mcp} mcp={mcp} data={data} />
                                ))}
                            </div>
                        </TabsContent>
                    </Tabs>
                </TabsContent>
                
                <TabsContent value="experience" className="mt-4">
                    <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
                        {Object.entries(metricsData.experience_metrics).map(([area, data]) => (
                            <ExperienceMetricCard key={area} area={area} data={data} />
                        ))}
                    </div>
                </TabsContent>
                
                <TabsContent value="recommendations" className="mt-4">
                    <Card>
                        <CardHeader>
                            <CardTitle>æ”¹é€²å»ºè­°</CardTitle>
                        </CardHeader>
                        <CardContent>
                            <div className="space-y-3">
                                {metricsData.recommendations.map((rec, idx) => (
                                    <div key={idx} className="flex items-start gap-2">
                                        <span className="text-xl mt-0.5">{rec.charAt(0)}</span>
                                        <span>{rec.substring(2)}</span>
                                    </div>
                                ))}
                            </div>
                        </CardContent>
                    </Card>
                </TabsContent>
            </Tabs>
        </div>
    );
}
"""


# ä¸»å‡½æ•¸
async def main():
    """ä¸»å‡½æ•¸"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   PowerAutomation v4.75 æŒ‡æ¨™ç³»çµ±             â•‘
â•‘   æŠ€è¡“æŒ‡æ¨™ + é«”é©—æŒ‡æ¨™ = Core é©…å‹• Editor     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")
    
    system = MetricsSystem()
    
    # ç”Ÿæˆå„€è¡¨æ¿æ•¸æ“š
    print("\nğŸ“Š æ”¶é›†æŒ‡æ¨™æ•¸æ“š...")
    dashboard_data = await system.generate_dashboard_data()
    
    # é¡¯ç¤ºç¸½é«”è©•åˆ†
    print(f"\nç¸½é«”è©•åˆ†ï¼š")
    print(f"- æŠ€è¡“å¥åº·åº¦ï¼š{dashboard_data['overall_scores']['technical_health']}%")
    print(f"- ç”¨æˆ¶é«”é©—åˆ†ï¼š{dashboard_data['overall_scores']['experience_score']}%")
    
    # é¡¯ç¤ºå‘Šè­¦
    if dashboard_data["alerts"]:
        print(f"\nâš ï¸ ç™¼ç¾ {len(dashboard_data['alerts'])} å€‹å‘Šè­¦")
    
    # ä¿å­˜æ•¸æ“š
    data_path = Path("deploy/v4.75/metrics_dashboard_data.json")
    data_path.parent.mkdir(parents=True, exist_ok=True)
    with open(data_path, 'w', encoding='utf-8') as f:
        json.dump(dashboard_data, f, ensure_ascii=False, indent=2)
    print(f"\nâœ… å„€è¡¨æ¿æ•¸æ“šå·²ä¿å­˜ï¼š{data_path}")
    
    # ç”Ÿæˆå ±å‘Š
    report = system.export_metrics_report(dashboard_data)
    report_path = Path("deploy/v4.75/METRICS_REPORT.md")
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report)
    print(f"âœ… æŒ‡æ¨™å ±å‘Šå·²ç”Ÿæˆï¼š{report_path}")
    
    # ç”Ÿæˆ UI
    ui_path = Path("deploy/v4.75/MetricsDashboard.jsx")
    with open(ui_path, 'w', encoding='utf-8') as f:
        f.write(create_metrics_dashboard_ui())
    print(f"âœ… UI çµ„ä»¶å·²ç”Ÿæˆï¼š{ui_path}")
    
    print("\nğŸ’¡ PowerAutomation Core é€šéé€™äº›æŒ‡æ¨™é©…å‹• ClaudeEditor é«”é©—")


if __name__ == "__main__":
    asyncio.run(main())