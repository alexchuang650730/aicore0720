#!/usr/bin/env python3
"""
DeepSWE å¢å¼·çš„å­¸ç¿’é©é…å™¨
æ•´åˆ MemoryRAG çš„ learning_adapter èˆ‡ DeepSWE æ¨¡å¼
ç”¨æ–¼å¾å°è©±æ•¸æ“šä¸­å­¸ç¿’ä¸¦å„ªåŒ– K2 ä½¿ç”¨
"""

import json
import asyncio
from typing import List, Dict, Any, Optional
from pathlib import Path
from datetime import datetime
import numpy as np
from abc import ABC, abstractmethod


class DeepSWELearningAdapter:
    """DeepSWE å¢å¼·çš„å­¸ç¿’é©é…å™¨"""
    
    def __init__(self, memoryrag_instance):
        self.memoryrag = memoryrag_instance
        self.learning_patterns = []
        self.optimization_strategies = {}
        self.deepswe_models = {}
        self.learned_prompts = {}
        
    async def learn_from_conversations(self):
        """å¾ MemoryRAG çš„å°è©±æ­·å²ä¸­å­¸ç¿’"""
        print("ğŸ§  é–‹å§‹ DeepSWE å¢å¼·å­¸ç¿’...")
        
        # å¾ MemoryRAG ç²å–å°è©±æ•¸æ“š
        conversations = await self.memoryrag.get_all_conversations()
        
        # åˆ†æå°è©±æ¨¡å¼
        patterns = self._analyze_conversation_patterns(conversations)
        
        # å­¸ç¿’å„ªåŒ–ç­–ç•¥
        strategies = self._learn_optimization_strategies(patterns)
        
        # è¨“ç·´ DeepSWE é¢¨æ ¼çš„æç¤ºå„ªåŒ–å™¨
        await self._train_prompt_optimizer(conversations)
        
        # æ›´æ–°å­¸ç¿’çµæœ
        self.learning_patterns = patterns
        self.optimization_strategies = strategies
        
        return {
            'learned_patterns': len(patterns),
            'optimization_strategies': len(strategies),
            'training_examples': len(conversations)
        }
        
    def _analyze_conversation_patterns(self, conversations: List[Dict]) -> List[Dict]:
        """åˆ†æå°è©±æ¨¡å¼"""
        patterns = []
        
        # æŒ‰ä»»å‹™é¡å‹åˆ†çµ„
        task_groups = {}
        for conv in conversations:
            task_type = self._classify_task(conv)
            if task_type not in task_groups:
                task_groups[task_type] = []
            task_groups[task_type].append(conv)
            
        # ç‚ºæ¯å€‹ä»»å‹™é¡å‹æå–æ¨¡å¼
        for task_type, convs in task_groups.items():
            pattern = {
                'task_type': task_type,
                'common_elements': self._extract_common_elements(convs),
                'success_patterns': self._identify_success_patterns(convs),
                'optimization_opportunities': self._find_optimization_opportunities(convs)
            }
            patterns.append(pattern)
            
        return patterns
        
    def _classify_task(self, conv: Dict) -> str:
        """åˆ†é¡ä»»å‹™é¡å‹"""
        user_input = conv.get('user_input', '').lower()
        
        task_keywords = {
            'implementation': ['å¯¦ç¾', 'å‰µå»º', 'ç”Ÿæˆ', 'implement', 'create', 'build'],
            'debugging': ['éŒ¯èª¤', 'ä¿®å¾©', 'bug', 'error', 'fix', 'debug'],
            'optimization': ['å„ªåŒ–', 'æ”¹é€²', 'æå‡', 'optimize', 'improve', 'enhance'],
            'integration': ['é›†æˆ', 'æ•´åˆ', 'é€£æ¥', 'integrate', 'connect', 'combine'],
            'analysis': ['åˆ†æ', 'è§£é‡‹', 'ç†è§£', 'analyze', 'explain', 'understand']
        }
        
        for task_type, keywords in task_keywords.items():
            if any(keyword in user_input for keyword in keywords):
                return task_type
                
        return 'general'
        
    def _extract_common_elements(self, conversations: List[Dict]) -> Dict[str, Any]:
        """æå–å…±åŒå…ƒç´ """
        common_elements = {
            'input_patterns': [],
            'output_structures': [],
            'key_concepts': [],
            'technologies': set()
        }
        
        for conv in conversations:
            # æå–è¼¸å…¥æ¨¡å¼
            input_pattern = self._extract_input_pattern(conv['user_input'])
            if input_pattern:
                common_elements['input_patterns'].append(input_pattern)
                
            # æå–è¼¸å‡ºçµæ§‹
            output_structure = self._analyze_output_structure(conv['assistant_response'])
            common_elements['output_structures'].append(output_structure)
            
            # æå–æŠ€è¡“é—œéµè©
            tech_keywords = self._extract_technologies(conv)
            common_elements['technologies'].update(tech_keywords)
            
        return common_elements
        
    def _identify_success_patterns(self, conversations: List[Dict]) -> List[Dict]:
        """è­˜åˆ¥æˆåŠŸæ¨¡å¼"""
        success_patterns = []
        
        for conv in conversations:
            # å‡è¨­æœ‰è³ªé‡è©•åˆ†æˆ–ç”¨æˆ¶åé¥‹
            quality_score = conv.get('quality_score', 0.5)
            
            if quality_score > 0.8:  # é«˜è³ªé‡å°è©±
                pattern = {
                    'input_structure': self._analyze_input_structure(conv['user_input']),
                    'response_features': self._extract_response_features(conv['assistant_response']),
                    'key_success_factors': self._identify_success_factors(conv)
                }
                success_patterns.append(pattern)
                
        return success_patterns
        
    def _find_optimization_opportunities(self, conversations: List[Dict]) -> List[Dict]:
        """ç™¼ç¾å„ªåŒ–æ©Ÿæœƒ"""
        opportunities = []
        
        for conv in conversations:
            # åˆ†æå¯ä»¥å„ªåŒ–çš„åœ°æ–¹
            if self._can_be_optimized(conv):
                opportunity = {
                    'original_prompt': conv['user_input'],
                    'optimization_type': self._determine_optimization_type(conv),
                    'suggested_improvements': self._suggest_improvements(conv)
                }
                opportunities.append(opportunity)
                
        return opportunities
        
    def _learn_optimization_strategies(self, patterns: List[Dict]) -> Dict[str, Any]:
        """å­¸ç¿’å„ªåŒ–ç­–ç•¥"""
        strategies = {}
        
        for pattern in patterns:
            task_type = pattern['task_type']
            
            # åŸºæ–¼æˆåŠŸæ¨¡å¼å‰µå»ºå„ªåŒ–ç­–ç•¥
            strategy = {
                'prompt_template': self._create_optimal_prompt_template(pattern),
                'key_elements': pattern['common_elements']['key_concepts'],
                'best_practices': self._extract_best_practices(pattern),
                'avoid_patterns': self._identify_antipatterns(pattern)
            }
            
            strategies[task_type] = strategy
            
        return strategies
        
    async def _train_prompt_optimizer(self, conversations: List[Dict]):
        """è¨“ç·´æç¤ºå„ªåŒ–å™¨"""
        print("ğŸ”§ è¨“ç·´ DeepSWE é¢¨æ ¼çš„æç¤ºå„ªåŒ–å™¨...")
        
        # æº–å‚™è¨“ç·´æ•¸æ“š
        training_data = []
        for conv in conversations:
            # å‰µå»ºè¨“ç·´æ¨£æœ¬
            sample = {
                'original_prompt': conv['user_input'],
                'optimized_prompt': self._create_optimized_prompt(conv),
                'expected_output': conv['assistant_response'],
                'metadata': {
                    'task_type': self._classify_task(conv),
                    'quality_score': conv.get('quality_score', 0.5)
                }
            }
            training_data.append(sample)
            
        # è¨“ç·´å„ªåŒ–æ¨¡å‹ï¼ˆé€™è£¡æ˜¯ç°¡åŒ–ç‰ˆæœ¬ï¼‰
        self.learned_prompts = self._train_simple_optimizer(training_data)
        
    def _create_optimized_prompt(self, conv: Dict) -> str:
        """å‰µå»ºå„ªåŒ–çš„æç¤º"""
        task_type = self._classify_task(conv)
        original_prompt = conv['user_input']
        
        # DeepSWE é¢¨æ ¼çš„å„ªåŒ–
        optimized = f"""<thinking>
ä»»å‹™é¡å‹: {task_type}
æ ¸å¿ƒéœ€æ±‚: {self._extract_core_requirements(original_prompt)}
ä¸Šä¸‹æ–‡: PowerAutomation é–‹ç™¼
</thinking>

<task>
{original_prompt}
</task>

<requirements>
1. æä¾›å®Œæ•´çš„è§£æ±ºæ–¹æ¡ˆ
2. åŒ…å«éŒ¯èª¤è™•ç†
3. éµå¾ªæœ€ä½³å¯¦è¸
4. è€ƒæ…®é‚Šç•Œæƒ…æ³
</requirements>"""
        
        return optimized
        
    def _train_simple_optimizer(self, training_data: List[Dict]) -> Dict[str, Any]:
        """è¨“ç·´ç°¡å–®çš„å„ªåŒ–å™¨"""
        # é€™æ˜¯ä¸€å€‹ç°¡åŒ–çš„å¯¦ç¾
        # å¯¦éš›æ‡‰è©²ä½¿ç”¨æ©Ÿå™¨å­¸ç¿’æ¨¡å‹
        
        learned_templates = {}
        
        # æŒ‰ä»»å‹™é¡å‹åˆ†çµ„
        by_type = {}
        for sample in training_data:
            task_type = sample['metadata']['task_type']
            if task_type not in by_type:
                by_type[task_type] = []
            by_type[task_type].append(sample)
            
        # ç‚ºæ¯ç¨®é¡å‹å­¸ç¿’æœ€ä½³æ¨¡æ¿
        for task_type, samples in by_type.items():
            # é¸æ“‡è³ªé‡æœ€é«˜çš„æ¨£æœ¬ä½œç‚ºæ¨¡æ¿
            best_samples = sorted(
                samples, 
                key=lambda x: x['metadata']['quality_score'], 
                reverse=True
            )[:5]
            
            learned_templates[task_type] = {
                'templates': [s['optimized_prompt'] for s in best_samples],
                'average_quality': np.mean([s['metadata']['quality_score'] for s in best_samples])
            }
            
        return learned_templates
        
    def optimize_prompt_for_k2(self, user_input: str) -> str:
        """ä½¿ç”¨å­¸ç¿’çš„æ¨¡å¼å„ªåŒ– K2 æç¤º"""
        # åˆ†é¡ä»»å‹™
        task_type = self._classify_task({'user_input': user_input})
        
        # ç²å–å„ªåŒ–ç­–ç•¥
        strategy = self.optimization_strategies.get(task_type, {})
        
        # æ‡‰ç”¨å„ªåŒ–
        if task_type in self.learned_prompts:
            # ä½¿ç”¨å­¸ç¿’çš„æ¨¡æ¿
            templates = self.learned_prompts[task_type]['templates']
            if templates:
                # é¸æ“‡æœ€ç›¸ä¼¼çš„æ¨¡æ¿ä¸¦é©é…
                template = templates[0]  # ç°¡åŒ–ï¼šé¸æ“‡ç¬¬ä¸€å€‹
                optimized = self._adapt_template(template, user_input)
                return optimized
                
        # é»˜èªå„ªåŒ–
        return self._create_default_optimized_prompt(user_input, task_type)
        
    def _adapt_template(self, template: str, user_input: str) -> str:
        """é©é…æ¨¡æ¿åˆ°æ–°è¼¸å…¥"""
        # ç°¡å–®çš„æ¨¡æ¿é©é…
        # å¯¦éš›æ‡‰è©²ä½¿ç”¨æ›´æ™ºèƒ½çš„æ–¹æ³•
        
        # æå–æ ¸å¿ƒéœ€æ±‚
        core_requirements = self._extract_core_requirements(user_input)
        
        # æ›¿æ›æ¨¡æ¿ä¸­çš„ä½”ä½ç¬¦
        adapted = template.replace('<task>', f'<task>\n{user_input}\n</task>')
        adapted = adapted.replace('æ ¸å¿ƒéœ€æ±‚:', f'æ ¸å¿ƒéœ€æ±‚: {core_requirements}')
        
        return adapted
        
    def _create_default_optimized_prompt(self, user_input: str, task_type: str) -> str:
        """å‰µå»ºé»˜èªå„ªåŒ–æç¤º"""
        return f"""<context>
é …ç›®: PowerAutomation
ä»»å‹™é¡å‹: {task_type}
å„ªå…ˆç´š: é«˜è³ªé‡ã€å¯ç¶­è­·æ€§
</context>

<user_request>
{user_input}
</user_request>

è«‹æä¾›ï¼š
1. å®Œæ•´çš„è§£æ±ºæ–¹æ¡ˆ
2. è©³ç´°çš„å¯¦ç¾æ­¥é©Ÿ
3. å¿…è¦çš„éŒ¯èª¤è™•ç†
4. æœ€ä½³å¯¦è¸å»ºè­°"""
        
    def _extract_core_requirements(self, text: str) -> str:
        """æå–æ ¸å¿ƒéœ€æ±‚"""
        # ç°¡åŒ–å¯¦ç¾
        # æå–å‹•è©å’Œé—œéµåè©
        keywords = []
        
        action_words = ['å¯¦ç¾', 'å‰µå»º', 'ä¿®å¾©', 'å„ªåŒ–', 'é›†æˆ', 'éƒ¨ç½²']
        for word in action_words:
            if word in text:
                keywords.append(word)
                
        return ' '.join(keywords) if keywords else 'è™•ç†ç”¨æˆ¶è«‹æ±‚'
        
    def _extract_technologies(self, conv: Dict) -> set:
        """æå–æŠ€è¡“é—œéµè©"""
        tech_keywords = {
            'python', 'javascript', 'typescript', 'react', 'vue',
            'mcp', 'claude', 'api', 'database', 'docker', 'k2'
        }
        
        text = (conv['user_input'] + ' ' + conv['assistant_response']).lower()
        found_techs = set()
        
        for tech in tech_keywords:
            if tech in text:
                found_techs.add(tech)
                
        return found_techs
        
    def get_learning_report(self) -> Dict[str, Any]:
        """ç²å–å­¸ç¿’å ±å‘Š"""
        return {
            'learned_patterns': len(self.learning_patterns),
            'optimization_strategies': len(self.optimization_strategies),
            'prompt_templates': sum(
                len(v.get('templates', [])) 
                for v in self.learned_prompts.values()
            ),
            'supported_task_types': list(self.optimization_strategies.keys()),
            'last_updated': datetime.now().isoformat()
        }
        
    async def continuous_learning(self):
        """æŒçºŒå­¸ç¿’æ¨¡å¼"""
        print("ğŸ”„ å•Ÿå‹•æŒçºŒå­¸ç¿’æ¨¡å¼...")
        
        while True:
            try:
                # æ¯å°æ™‚å­¸ç¿’ä¸€æ¬¡æ–°å°è©±
                await asyncio.sleep(3600)
                
                # ç²å–æ–°å°è©±
                new_conversations = await self.memoryrag.get_recent_conversations(hours=1)
                
                if new_conversations:
                    # å¢é‡å­¸ç¿’
                    await self._incremental_learning(new_conversations)
                    
                    print(f"âœ… å­¸ç¿’äº† {len(new_conversations)} å€‹æ–°å°è©±")
                    
            except Exception as e:
                print(f"âŒ æŒçºŒå­¸ç¿’éŒ¯èª¤: {e}")
                await asyncio.sleep(300)  # 5åˆ†é˜å¾Œé‡è©¦
                
    async def _incremental_learning(self, new_conversations: List[Dict]):
        """å¢é‡å­¸ç¿’"""
        # åˆ†ææ–°æ¨¡å¼
        new_patterns = self._analyze_conversation_patterns(new_conversations)
        
        # æ›´æ–°ç¾æœ‰æ¨¡å¼
        for new_pattern in new_patterns:
            self._update_pattern(new_pattern)
            
        # æ›´æ–°å„ªåŒ–ç­–ç•¥
        self._update_optimization_strategies(new_patterns)
        
    def _update_pattern(self, new_pattern: Dict):
        """æ›´æ–°æ¨¡å¼"""
        # æŸ¥æ‰¾ç›¸åŒé¡å‹çš„æ¨¡å¼
        for i, pattern in enumerate(self.learning_patterns):
            if pattern['task_type'] == new_pattern['task_type']:
                # åˆä½µæ¨¡å¼
                self.learning_patterns[i] = self._merge_patterns(pattern, new_pattern)
                return
                
        # æ–°æ¨¡å¼
        self.learning_patterns.append(new_pattern)
        
    def _merge_patterns(self, old_pattern: Dict, new_pattern: Dict) -> Dict:
        """åˆä½µæ¨¡å¼"""
        merged = {
            'task_type': old_pattern['task_type'],
            'common_elements': self._merge_common_elements(
                old_pattern['common_elements'],
                new_pattern['common_elements']
            ),
            'success_patterns': old_pattern['success_patterns'] + new_pattern['success_patterns'],
            'optimization_opportunities': old_pattern['optimization_opportunities'] + new_pattern['optimization_opportunities']
        }
        
        return merged
        
    def _merge_common_elements(self, old: Dict, new: Dict) -> Dict:
        """åˆä½µå…±åŒå…ƒç´ """
        return {
            'input_patterns': old.get('input_patterns', []) + new.get('input_patterns', []),
            'output_structures': old.get('output_structures', []) + new.get('output_structures', []),
            'key_concepts': list(set(old.get('key_concepts', []) + new.get('key_concepts', []))),
            'technologies': old.get('technologies', set()) | new.get('technologies', set())
        }
        
    def _update_optimization_strategies(self, new_patterns: List[Dict]):
        """æ›´æ–°å„ªåŒ–ç­–ç•¥"""
        new_strategies = self._learn_optimization_strategies(new_patterns)
        
        # åˆä½µç­–ç•¥
        for task_type, strategy in new_strategies.items():
            if task_type in self.optimization_strategies:
                # æ›´æ–°ç¾æœ‰ç­–ç•¥
                self.optimization_strategies[task_type] = self._merge_strategies(
                    self.optimization_strategies[task_type],
                    strategy
                )
            else:
                # æ–°ç­–ç•¥
                self.optimization_strategies[task_type] = strategy
                
    def _merge_strategies(self, old_strategy: Dict, new_strategy: Dict) -> Dict:
        """åˆä½µç­–ç•¥"""
        return {
            'prompt_template': new_strategy['prompt_template'],  # ä½¿ç”¨æ–°æ¨¡æ¿
            'key_elements': list(set(
                old_strategy.get('key_elements', []) + 
                new_strategy.get('key_elements', [])
            )),
            'best_practices': old_strategy.get('best_practices', []) + new_strategy.get('best_practices', []),
            'avoid_patterns': list(set(
                old_strategy.get('avoid_patterns', []) + 
                new_strategy.get('avoid_patterns', [])
            ))
        }
        
    # ä»¥ä¸‹æ˜¯è¼”åŠ©æ–¹æ³•çš„ç°¡åŒ–å¯¦ç¾
    def _extract_input_pattern(self, text: str) -> Dict:
        return {'length': len(text), 'has_code': '```' in text}
        
    def _analyze_output_structure(self, text: str) -> Dict:
        return {
            'has_code_blocks': '```' in text,
            'has_numbered_steps': bool(re.search(r'\d+\.', text)),
            'length': len(text)
        }
        
    def _analyze_input_structure(self, text: str) -> Dict:
        return {'tokens': len(text.split()), 'lines': len(text.split('\n'))}
        
    def _extract_response_features(self, text: str) -> List[str]:
        features = []
        if '```' in text:
            features.append('contains_code')
        if re.search(r'\d+\.', text):
            features.append('structured_steps')
        return features
        
    def _identify_success_factors(self, conv: Dict) -> List[str]:
        return ['clear_structure', 'complete_solution', 'error_handling']
        
    def _can_be_optimized(self, conv: Dict) -> bool:
        return len(conv['user_input']) < 50 or conv.get('quality_score', 0) < 0.7
        
    def _determine_optimization_type(self, conv: Dict) -> str:
        if len(conv['user_input']) < 50:
            return 'needs_more_context'
        return 'needs_structure'
        
    def _suggest_improvements(self, conv: Dict) -> List[str]:
        return ['add_context', 'specify_requirements', 'clarify_constraints']
        
    def _create_optimal_prompt_template(self, pattern: Dict) -> str:
        return f"<task_type>{pattern['task_type']}</task_type>\n{{user_request}}"
        
    def _extract_best_practices(self, pattern: Dict) -> List[str]:
        return ['provide_examples', 'include_error_handling', 'follow_conventions']
        
    def _identify_antipatterns(self, pattern: Dict) -> List[str]:
        return ['vague_requirements', 'missing_context', 'ambiguous_terms']


# ä½¿ç”¨ç¤ºä¾‹
async def main():
    """ç¤ºä¾‹ç”¨æ³•"""
    # å‡è¨­å·²æœ‰ MemoryRAG å¯¦ä¾‹
    from core.memoryrag.memory_os import MemoryRAG
    
    memoryrag = MemoryRAG()
    
    # å‰µå»º DeepSWE å­¸ç¿’é©é…å™¨
    adapter = DeepSWELearningAdapter(memoryrag)
    
    # å¾å°è©±æ­·å²å­¸ç¿’
    result = await adapter.learn_from_conversations()
    print(f"å­¸ç¿’å®Œæˆ: {result}")
    
    # ä½¿ç”¨å­¸ç¿’çµæœå„ªåŒ–æç¤º
    user_input = "å¯¦ç¾ä¸€å€‹ MCP ä¾†è™•ç†æ¸¬è©¦è‡ªå‹•åŒ–"
    optimized = adapter.optimize_prompt_for_k2(user_input)
    print(f"\nå„ªåŒ–å¾Œçš„æç¤º:\n{optimized}")
    
    # ç²å–å­¸ç¿’å ±å‘Š
    report = adapter.get_learning_report()
    print(f"\nå­¸ç¿’å ±å‘Š: {report}")
    
    # å•Ÿå‹•æŒçºŒå­¸ç¿’ï¼ˆå¯é¸ï¼‰
    # await adapter.continuous_learning()


if __name__ == "__main__":
    import re
    asyncio.run(main())