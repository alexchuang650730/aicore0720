#!/usr/bin/env python3
"""
Manus Replay æ•¸æ“šæå–å™¨
å¾ Manus.im çš„ replay é€£çµä¸­æå–å°è©±æ•¸æ“šç”¨æ–¼è¨“ç·´
"""

import asyncio
import aiohttp
import json
import re
from typing import List, Dict, Any
from pathlib import Path
from datetime import datetime
import hashlib
from bs4 import BeautifulSoup
from urllib.parse import urlparse

class ManusReplayExtractor:
    """Manus Replay æ•¸æ“šæå–å™¨"""
    
    def __init__(self, output_dir: str = "./manus_training_data"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.session = None
        self.extracted_conversations = []
        
    async def extract_replay(self, replay_url: str) -> Dict[str, Any]:
        """å¾å–®å€‹ replay URL æå–å°è©±æ•¸æ“š"""
        print(f"ğŸ“¥ æå–: {replay_url}")
        
        try:
            # è§£æ replay ID
            replay_id = self._extract_replay_id(replay_url)
            
            # ç²å–å°è©±æ•¸æ“š
            conversation_data = await self._fetch_replay_data(replay_url)
            
            # è™•ç†å°è©±
            processed_data = self._process_conversation(conversation_data, replay_id)
            
            # ä¿å­˜åŸå§‹æ•¸æ“š
            self._save_raw_data(replay_id, conversation_data)
            
            return processed_data
            
        except Exception as e:
            print(f"âŒ æå–å¤±æ•— {replay_url}: {e}")
            return None
    
    def _extract_replay_id(self, url: str) -> str:
        """å¾ URL æå– replay ID"""
        # https://manus.im/share/xHbeFo8tzQV51VeTErhskc?replay=1
        parsed = urlparse(url)
        parts = parsed.path.split('/')
        return parts[-1] if parts[-1] else parts[-2]
    
    async def _fetch_replay_data(self, url: str) -> Dict[str, Any]:
        """ç²å– replay æ•¸æ“š"""
        if not self.session:
            self.session = aiohttp.ClientSession()
            
        async with self.session.get(url) as response:
            html = await response.text()
            
        # å¾ HTML ä¸­æå–æ•¸æ“š
        soup = BeautifulSoup(html, 'html.parser')
        
        # æŸ¥æ‰¾åŒ…å«å°è©±æ•¸æ“šçš„ script æ¨™ç±¤
        script_tags = soup.find_all('script')
        conversation_data = None
        
        for script in script_tags:
            if script.string and 'conversationData' in script.string:
                # æå– JSON æ•¸æ“š
                match = re.search(r'conversationData\s*=\s*({.*?});', script.string, re.DOTALL)
                if match:
                    conversation_data = json.loads(match.group(1))
                    break
                    
        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå˜—è©¦å…¶ä»–æ¨¡å¼
        if not conversation_data:
            # å¯èƒ½æ•¸æ“šåœ¨ window.__INITIAL_STATE__ ä¸­
            for script in script_tags:
                if script.string and '__INITIAL_STATE__' in script.string:
                    match = re.search(r'__INITIAL_STATE__\s*=\s*({.*?});', script.string, re.DOTALL)
                    if match:
                        initial_state = json.loads(match.group(1))
                        conversation_data = initial_state.get('conversation', {})
                        break
        
        return conversation_data
    
    def _process_conversation(self, data: Dict, replay_id: str) -> Dict[str, Any]:
        """è™•ç†å°è©±æ•¸æ“š"""
        messages = data.get('messages', [])
        processed_messages = []
        code_blocks = []
        
        for i, msg in enumerate(messages):
            processed_msg = {
                'role': msg.get('role', 'user'),
                'content': msg.get('content', ''),
                'timestamp': msg.get('timestamp', ''),
                'index': i
            }
            
            # æå–ä»£ç¢¼å¡Š
            code_blocks.extend(self._extract_code_blocks(msg.get('content', '')))
            
            processed_messages.append(processed_msg)
        
        # å‰µå»ºè¨“ç·´å°
        training_pairs = self._create_training_pairs(processed_messages)
        
        return {
            'replay_id': replay_id,
            'message_count': len(messages),
            'messages': processed_messages,
            'code_blocks': code_blocks,
            'training_pairs': training_pairs,
            'metadata': {
                'extracted_at': datetime.now().isoformat(),
                'has_code': len(code_blocks) > 0,
                'conversation_type': self._classify_conversation(messages)
            }
        }
    
    def _extract_code_blocks(self, content: str) -> List[Dict[str, str]]:
        """æå–ä»£ç¢¼å¡Š"""
        code_blocks = []
        
        # åŒ¹é… ```language\ncode\n``` æ ¼å¼
        pattern = r'```(\w+)?\n(.*?)\n```'
        matches = re.finditer(pattern, content, re.DOTALL)
        
        for match in matches:
            language = match.group(1) or 'plaintext'
            code = match.group(2)
            
            code_blocks.append({
                'language': language,
                'code': code,
                'length': len(code),
                'type': self._classify_code_type(code, language)
            })
            
        return code_blocks
    
    def _create_training_pairs(self, messages: List[Dict]) -> List[Dict]:
        """å‰µå»ºè¨“ç·´å°"""
        pairs = []
        
        for i in range(len(messages) - 1):
            if messages[i]['role'] == 'user' and messages[i + 1]['role'] == 'assistant':
                user_msg = messages[i]['content']
                assistant_msg = messages[i + 1]['content']
                
                # åˆ¤æ–·æ˜¯å¦ç‚ºé«˜è³ªé‡è¨“ç·´æ•¸æ“š
                if self._is_quality_pair(user_msg, assistant_msg):
                    pair = {
                        'input': user_msg,
                        'output': assistant_msg,
                        'type': self._classify_interaction_type(user_msg, assistant_msg),
                        'quality_score': self._calculate_quality_score(user_msg, assistant_msg),
                        'has_code': '```' in assistant_msg,
                        'deepswe_format': self._convert_to_deepswe_format(user_msg, assistant_msg)
                    }
                    pairs.append(pair)
                    
        return pairs
    
    def _convert_to_deepswe_format(self, user_input: str, assistant_output: str) -> Dict[str, str]:
        """è½‰æ›ç‚º DeepSWE è¨“ç·´æ ¼å¼"""
        
        # æå–æ€è€ƒéç¨‹ï¼ˆå¦‚æœæœ‰ï¼‰
        thinking_match = re.search(r'è®“æˆ‘.*?[ã€‚\n]|é¦–å…ˆ.*?[ã€‚\n]|é€™å€‹.*?éœ€è¦.*?[ã€‚\n]', assistant_output)
        thinking = thinking_match.group(0) if thinking_match else ""
        
        # æ§‹å»º DeepSWE æ ¼å¼
        deepswe_prompt = f"""<thinking>
{thinking if thinking else "åˆ†æç”¨æˆ¶éœ€æ±‚ï¼Œæº–å‚™ç”Ÿæˆç›¸æ‡‰çš„è§£æ±ºæ–¹æ¡ˆã€‚"}
</thinking>

ç”¨æˆ¶è«‹æ±‚ï¼š
{user_input}

è«‹æä¾›è§£æ±ºæ–¹æ¡ˆã€‚
"""
        
        return {
            'prompt': deepswe_prompt,
            'completion': assistant_output,
            'metadata': {
                'source': 'manus_replay',
                'has_thinking': bool(thinking)
            }
        }
    
    def _classify_code_type(self, code: str, language: str) -> str:
        """åˆ†é¡ä»£ç¢¼é¡å‹"""
        if language in ['python', 'py']:
            if 'class ' in code:
                return 'class_definition'
            elif 'def ' in code:
                return 'function_definition'
            elif 'import ' in code:
                return 'imports'
        elif language in ['javascript', 'js', 'jsx', 'tsx']:
            if 'function' in code or '=>' in code:
                return 'function_definition'
            elif 'class' in code:
                return 'class_definition'
            elif 'import' in code or 'require' in code:
                return 'imports'
        
        return 'general'
    
    def _classify_conversation(self, messages: List[Dict]) -> str:
        """åˆ†é¡å°è©±é¡å‹"""
        combined_text = ' '.join([msg.get('content', '') for msg in messages])
        
        if any(word in combined_text for word in ['éŒ¯èª¤', 'error', 'bug', 'ä¿®å¾©', 'fix']):
            return 'debugging'
        elif any(word in combined_text for word in ['å¯¦ç¾', 'implement', 'å‰µå»º', 'create', 'ç”Ÿæˆ']):
            return 'implementation'
        elif any(word in combined_text for word in ['å„ªåŒ–', 'optimize', 'æ”¹é€²', 'improve']):
            return 'optimization'
        elif any(word in combined_text for word in ['è§£é‡‹', 'explain', 'ç†è§£', 'understand']):
            return 'explanation'
        else:
            return 'general'
    
    def _classify_interaction_type(self, user_msg: str, assistant_msg: str) -> str:
        """åˆ†é¡äº¤äº’é¡å‹"""
        if '```' in assistant_msg:
            if 'éŒ¯èª¤' in user_msg or 'error' in user_msg:
                return 'error_fixing'
            elif 'å„ªåŒ–' in user_msg or 'optimize' in user_msg:
                return 'code_optimization'
            else:
                return 'code_generation'
        else:
            return 'explanation'
    
    def _is_quality_pair(self, user_msg: str, assistant_msg: str) -> bool:
        """åˆ¤æ–·æ˜¯å¦ç‚ºé«˜è³ªé‡è¨“ç·´å°"""
        # åŸºæœ¬é•·åº¦è¦æ±‚
        if len(user_msg) < 10 or len(assistant_msg) < 50:
            return False
            
        # å¿…é ˆæœ‰å¯¦è³ªå…§å®¹
        if not any(char.isalnum() for char in user_msg):
            return False
            
        # åŠ©æ‰‹å›æ‡‰æ‡‰è©²æœ‰ä»£ç¢¼æˆ–è©³ç´°è§£é‡‹
        has_code = '```' in assistant_msg
        has_explanation = len(assistant_msg) > 200
        
        return has_code or has_explanation
    
    def _calculate_quality_score(self, user_msg: str, assistant_msg: str) -> float:
        """è¨ˆç®—è³ªé‡åˆ†æ•¸"""
        score = 0.5  # åŸºç¤åˆ†
        
        # æœ‰ä»£ç¢¼åŠ åˆ†
        if '```' in assistant_msg:
            score += 0.2
            
        # æœ‰è§£é‡‹åŠ åˆ†
        if any(word in assistant_msg for word in ['å› ç‚º', 'æ‰€ä»¥', 'é¦–å…ˆ', 'ç„¶å¾Œ', 'because', 'therefore']):
            score += 0.1
            
        # é•·åº¦é©ä¸­åŠ åˆ†
        if 100 < len(assistant_msg) < 2000:
            score += 0.1
            
        # æœ‰å¤šå€‹æ­¥é©ŸåŠ åˆ†
        if any(pattern in assistant_msg for pattern in ['1.', '2.', 'æ­¥é©Ÿ', 'Step']):
            score += 0.1
            
        return min(score, 1.0)
    
    def _save_raw_data(self, replay_id: str, data: Dict):
        """ä¿å­˜åŸå§‹æ•¸æ“š"""
        output_file = self.output_dir / f"raw/{replay_id}.json"
        output_file.parent.mkdir(exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    
    async def process_batch(self, replay_urls: List[str], max_concurrent: int = 5):
        """æ‰¹é‡è™•ç† replay URLs"""
        print(f"ğŸš€ é–‹å§‹æ‰¹é‡è™•ç† {len(replay_urls)} å€‹ replays")
        
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def process_with_limit(url):
            async with semaphore:
                return await self.extract_replay(url)
        
        tasks = [process_with_limit(url) for url in replay_urls]
        results = await asyncio.gather(*tasks)
        
        # éæ¿¾æˆåŠŸçš„çµæœ
        successful = [r for r in results if r is not None]
        
        print(f"âœ… æˆåŠŸæå– {len(successful)}/{len(replay_urls)} å€‹å°è©±")
        
        # åˆä½µæ‰€æœ‰è¨“ç·´å°
        all_training_pairs = []
        for result in successful:
            all_training_pairs.extend(result['training_pairs'])
        
        # ä¿å­˜åˆä½µçš„è¨“ç·´æ•¸æ“š
        self._save_training_dataset(all_training_pairs)
        
        return {
            'total_processed': len(replay_urls),
            'successful': len(successful),
            'total_training_pairs': len(all_training_pairs),
            'training_data_path': str(self.output_dir / 'training_dataset.json')
        }
    
    def _save_training_dataset(self, training_pairs: List[Dict]):
        """ä¿å­˜è¨“ç·´æ•¸æ“šé›†"""
        # æŒ‰é¡å‹åˆ†çµ„
        by_type = {}
        for pair in training_pairs:
            pair_type = pair['type']
            if pair_type not in by_type:
                by_type[pair_type] = []
            by_type[pair_type].append(pair)
        
        # ä¿å­˜å®Œæ•´æ•¸æ“šé›†
        output_file = self.output_dir / 'training_dataset.json'
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump({
                'total_pairs': len(training_pairs),
                'by_type': {k: len(v) for k, v in by_type.items()},
                'pairs': training_pairs
            }, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜ DeepSWE æ ¼å¼
        deepswe_file = self.output_dir / 'deepswe_format.jsonl'
        with open(deepswe_file, 'w', encoding='utf-8') as f:
            for pair in training_pairs:
                if pair.get('deepswe_format'):
                    f.write(json.dumps(pair['deepswe_format'], ensure_ascii=False) + '\n')
        
        print(f"ğŸ’¾ è¨“ç·´æ•¸æ“šå·²ä¿å­˜:")
        print(f"   - å®Œæ•´æ•¸æ“šé›†: {output_file}")
        print(f"   - DeepSWE æ ¼å¼: {deepswe_file}")
        print(f"   - ç¸½è¨“ç·´å°: {len(training_pairs)}")
        for pair_type, pairs in by_type.items():
            print(f"   - {pair_type}: {len(pairs)} å°")
    
    async def close(self):
        """é—œé–‰æœƒè©±"""
        if self.session:
            await self.session.close()


async def main():
    """ä¸»å‡½æ•¸ç¤ºä¾‹"""
    # æº–å‚™ replay URLs
    replay_urls = [
        "https://manus.im/share/xHbeFo8tzQV51VeTErhskc?replay=1",
        # æ·»åŠ æ›´å¤š URLs...
    ]
    
    # æˆ–å¾æ–‡ä»¶è®€å–
    # with open('replay_urls.txt', 'r') as f:
    #     replay_urls = [line.strip() for line in f if line.strip()]
    
    extractor = ManusReplayExtractor()
    
    try:
        # æ‰¹é‡è™•ç†
        results = await extractor.process_batch(replay_urls)
        
        print("\nğŸ“Š è™•ç†å®Œæˆï¼")
        print(f"âœ… æˆåŠŸç‡: {results['successful']}/{results['total_processed']}")
        print(f"ğŸ“š ç¸½è¨“ç·´å°: {results['total_training_pairs']}")
        print(f"ğŸ’¾ æ•¸æ“šä¿å­˜ä½ç½®: {results['training_data_path']}")
        
    finally:
        await extractor.close()


if __name__ == "__main__":
    asyncio.run(main())