#!/usr/bin/env python3
"""
PowerAutomation v4.6.1 AIä»£ç¢¼åŠ©æ‰‹æ™ºèƒ½ä»‹å…¥ç³»çµ±
AI Code Assistant Intelligent Integration System

æ”¯æŒçš„AIä»£ç¢¼åŠ©æ‰‹ï¼š
1. Trae - AIç¨‹åºå“¡åŠ©æ‰‹
2. é€šç¾©é›¶ç¢¼ - é˜¿é‡Œå·´å·´AIç·¨ç¨‹åŠ©æ‰‹
3. é¨°è¨Šä»£ç¢¼åŠ©æ‰‹ - é¨°è¨ŠAIç·¨ç¨‹å·¥å…·
4. ç™¾åº¦ä»£ç¢¼åŠ©æ‰‹ - ç™¾åº¦AIç·¨ç¨‹å¹³å°
5. VSCode Copilot - GitHub Copilot
6. Winsurf - AIä»£ç¢¼è¡æµªåŠ©æ‰‹
7. Cursor - AIä»£ç¢¼ç·¨è¼¯å™¨
"""

import asyncio
import json
import logging
import os
import subprocess
import time
from datetime import datetime
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass, asdict, field
from enum import Enum
from pathlib import Path

logger = logging.getLogger(__name__)


class AIAssistantType(Enum):
    """AIåŠ©æ‰‹é¡å‹"""
    TRAE = "trae"
    TONGYI_LINGMA = "tongyi_lingma"  # é€šç¾©é›¶ç¢¼
    TENCENT_CODE_ASSISTANT = "tencent_code_assistant"  # é¨°è¨Šä»£ç¢¼åŠ©æ‰‹
    BAIDU_CODE_ASSISTANT = "baidu_code_assistant"  # ç™¾åº¦ä»£ç¢¼åŠ©æ‰‹
    VSCODE_COPILOT = "vscode_copilot"  # GitHub Copilot
    WINSURF = "winsurf"
    CURSOR = "cursor"


class IntegrationMode(Enum):
    """ä»‹å…¥æ¨¡å¼"""
    PASSIVE = "passive"  # è¢«å‹•æ¨¡å¼ï¼šåƒ…ç›£è½å’Œåˆ†æ
    ACTIVE = "active"   # ä¸»å‹•æ¨¡å¼ï¼šä¸»å‹•æä¾›å»ºè­°
    HYBRID = "hybrid"   # æ··åˆæ¨¡å¼ï¼šæ™ºèƒ½åˆ¤æ–·ä»‹å…¥æ™‚æ©Ÿ
    OVERRIDE = "override"  # è¦†è“‹æ¨¡å¼ï¼šæ›¿æ›åŸæœ‰åŠ©æ‰‹


class InterventionTrigger(Enum):
    """ä»‹å…¥è§¸ç™¼å™¨"""
    CODE_COMPLETION = "code_completion"
    ERROR_DETECTION = "error_detection"
    REFACTOR_SUGGESTION = "refactor_suggestion"
    CODE_REVIEW = "code_review"
    DOCUMENTATION = "documentation"
    TESTING = "testing"
    OPTIMIZATION = "optimization"


@dataclass
class AIAssistantConfig:
    """AIåŠ©æ‰‹é…ç½®"""
    assistant_type: AIAssistantType
    name: str
    version: str
    api_endpoint: Optional[str]
    auth_token: Optional[str]
    capabilities: List[str]
    integration_mode: IntegrationMode
    enabled_triggers: List[InterventionTrigger]
    priority: int  # 1-10, 10ç‚ºæœ€é«˜å„ªå…ˆç´š
    response_time_ms: int
    accuracy_rate: float
    is_active: bool = True


@dataclass
class InterventionEvent:
    """ä»‹å…¥äº‹ä»¶"""
    id: str
    trigger: InterventionTrigger
    assistant: AIAssistantType
    context: Dict[str, Any]
    suggestion: str
    confidence: float
    timestamp: str
    user_accepted: Optional[bool] = None


@dataclass
class IntegrationStats:
    """é›†æˆçµ±è¨ˆ"""
    assistant: AIAssistantType
    total_interventions: int
    successful_interventions: int
    user_acceptance_rate: float
    avg_response_time: float
    avg_confidence: float
    last_active: str


class TraeIntegration:
    """Trae AIåŠ©æ‰‹é›†æˆ"""
    
    def __init__(self):
        self.logger = logging.getLogger(self.__class__.__name__)
        self.api_endpoint = "https://api.trae.ai/v1"
        self.stats = IntegrationStats(
            assistant=AIAssistantType.TRAE,
            total_interventions=0,
            successful_interventions=0,
            user_acceptance_rate=0.0,
            avg_response_time=0.0,
            avg_confidence=0.0,
            last_active=""
        )
    
    async def get_code_completion(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """ç²å–ä»£ç¢¼è£œå…¨å»ºè­°"""
        code = context.get("code", "")
        language = context.get("language", "python")
        
        # æ¨¡æ“¬Trae APIèª¿ç”¨
        suggestions = []
        if language == "python":
            if "def " in code:
                suggestions = [
                    "return result",
                    "pass",
                    "raise NotImplementedError",
                    "yield value"
                ]
            elif "class " in code:
                suggestions = [
                    "__init__(self, *args, **kwargs):",
                    "__str__(self):",
                    "__repr__(self):"
                ]
        
        self.stats.total_interventions += 1
        
        return {
            "suggestions": suggestions[:3],
            "confidence": 0.92,
            "response_time": 120,
            "source": "trae"
        }
    
    async def detect_errors(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """æª¢æ¸¬ä»£ç¢¼éŒ¯èª¤"""
        code = context.get("code", "")
        
        errors = []
        # ç°¡å–®çš„éŒ¯èª¤æª¢æ¸¬é‚è¼¯
        if code.count("(") != code.count(")"):
            errors.append({
                "type": "syntax_error",
                "message": "æ‹¬è™Ÿä¸åŒ¹é…",
                "line": 1,
                "severity": "error"
            })
        
        return {
            "errors": errors,
            "confidence": 0.95,
            "response_time": 80,
            "source": "trae"
        }


class TongyiLingmaIntegration:
    """é€šç¾©é›¶ç¢¼é›†æˆ"""
    
    def __init__(self):
        self.logger = logging.getLogger(self.__class__.__name__)
        self.api_endpoint = "https://tongyi.aliyun.com/lingma/api/v1"
        self.stats = IntegrationStats(
            assistant=AIAssistantType.TONGYI_LINGMA,
            total_interventions=0,
            successful_interventions=0,
            user_acceptance_rate=0.0,
            avg_response_time=0.0,
            avg_confidence=0.0,
            last_active=""
        )
    
    async def get_code_completion(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """é€šç¾©é›¶ç¢¼ä»£ç¢¼è£œå…¨"""
        code = context.get("code", "")
        language = context.get("language", "python")
        
        suggestions = []
        if language == "python":
            if "import " in code:
                suggestions = [
                    "import numpy as np",
                    "import pandas as pd", 
                    "import torch",
                    "import tensorflow as tf"
                ]
            elif "def " in code:
                suggestions = [
                    "\"\"\"å‡½æ•¸æ–‡æª”å­—ç¬¦ä¸²\"\"\"",
                    "try:",
                    "if not args:",
                    "return None"
                ]
        
        self.stats.total_interventions += 1
        
        return {
            "suggestions": suggestions[:3],
            "confidence": 0.89,
            "response_time": 150,
            "source": "tongyi_lingma"
        }
    
    async def generate_documentation(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆæ–‡æª”"""
        function_code = context.get("function_code", "")
        
        doc_template = '''"""
        {description}
        
        Args:
            {args}
        
        Returns:
            {returns}
        
        Examples:
            {examples}
        """'''
        
        return {
            "documentation": doc_template,
            "confidence": 0.88,
            "response_time": 200,
            "source": "tongyi_lingma"
        }


class TencentCodeAssistantIntegration:
    """é¨°è¨Šä»£ç¢¼åŠ©æ‰‹é›†æˆ"""
    
    def __init__(self):
        self.logger = logging.getLogger(self.__class__.__name__)
        self.api_endpoint = "https://cloud.tencent.com/product/tai-code"
        self.stats = IntegrationStats(
            assistant=AIAssistantType.TENCENT_CODE_ASSISTANT,
            total_interventions=0,
            successful_interventions=0,
            user_acceptance_rate=0.0,
            avg_response_time=0.0,
            avg_confidence=0.0,
            last_active=""
        )
    
    async def get_refactor_suggestions(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """ç²å–é‡æ§‹å»ºè­°"""
        code = context.get("code", "")
        
        suggestions = [
            {
                "type": "extract_method",
                "description": "æå–é‡è¤‡ä»£ç¢¼ç‚ºç¨ç«‹æ–¹æ³•",
                "confidence": 0.85
            },
            {
                "type": "rename_variable",
                "description": "é‡å‘½åè®Šé‡ä»¥æé«˜å¯è®€æ€§",
                "confidence": 0.78
            },
            {
                "type": "simplify_expression",
                "description": "ç°¡åŒ–è¤‡é›œè¡¨é”å¼",
                "confidence": 0.82
            }
        ]
        
        self.stats.total_interventions += 1
        
        return {
            "suggestions": suggestions,
            "confidence": 0.82,
            "response_time": 180,
            "source": "tencent_code_assistant"
        }


class BaiduCodeAssistantIntegration:
    """ç™¾åº¦ä»£ç¢¼åŠ©æ‰‹é›†æˆ"""
    
    def __init__(self):
        self.logger = logging.getLogger(self.__class__.__name__)
        self.api_endpoint = "https://cloud.baidu.com/product/comate"
        self.stats = IntegrationStats(
            assistant=AIAssistantType.BAIDU_CODE_ASSISTANT,
            total_interventions=0,
            successful_interventions=0,
            user_acceptance_rate=0.0,
            avg_response_time=0.0,
            avg_confidence=0.0,
            last_active=""
        )
    
    async def get_code_review(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """ç²å–ä»£ç¢¼å¯©æŸ¥å»ºè­°"""
        code = context.get("code", "")
        
        review_items = [
            {
                "category": "performance",
                "message": "å»ºè­°ä½¿ç”¨åˆ—è¡¨æ¨å°å¼ä»¥æé«˜æ€§èƒ½",
                "severity": "suggestion",
                "line": 5
            },
            {
                "category": "security",
                "message": "é¿å…ä½¿ç”¨eval()å‡½æ•¸ï¼Œå­˜åœ¨å®‰å…¨é¢¨éšª",
                "severity": "warning",
                "line": 12
            },
            {
                "category": "style",
                "message": "è®Šé‡å‘½åæ‡‰éµå¾ªsnake_caseè¦ç¯„",
                "severity": "info",
                "line": 8
            }
        ]
        
        self.stats.total_interventions += 1
        
        return {
            "review_items": review_items,
            "overall_score": 7.5,
            "confidence": 0.87,
            "response_time": 220,
            "source": "baidu_code_assistant"
        }


class VSCodeCopilotIntegration:
    """VSCode Copiloté›†æˆ"""
    
    def __init__(self):
        self.logger = logging.getLogger(self.__class__.__name__)
        self.stats = IntegrationStats(
            assistant=AIAssistantType.VSCODE_COPILOT,
            total_interventions=0,
            successful_interventions=0,
            user_acceptance_rate=0.0,
            avg_response_time=0.0,
            avg_confidence=0.0,
            last_active=""
        )
    
    async def get_inline_completion(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """ç²å–è¡Œå…§è£œå…¨"""
        prefix = context.get("prefix", "")
        suffix = context.get("suffix", "")
        language = context.get("language", "python")
        
        # æ¨¡æ“¬Copilotè¡Œç‚º
        completions = []
        if "function" in prefix.lower():
            completions = [
                "main():\n    return 0",
                "calculate(x, y):\n    return x + y",
                "process_data(data):\n    return processed_data"
            ]
        
        self.stats.total_interventions += 1
        
        return {
            "completions": completions[:3],
            "confidence": 0.91,
            "response_time": 95,
            "source": "vscode_copilot"
        }


class WinsurfIntegration:
    """Winsurf AIä»£ç¢¼è¡æµªåŠ©æ‰‹é›†æˆ"""
    
    def __init__(self):
        self.logger = logging.getLogger(self.__class__.__name__)
        self.stats = IntegrationStats(
            assistant=AIAssistantType.WINSURF,
            total_interventions=0,
            successful_interventions=0,
            user_acceptance_rate=0.0,
            avg_response_time=0.0,
            avg_confidence=0.0,
            last_active=""
        )
    
    async def get_smart_navigation(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ™ºèƒ½ä»£ç¢¼å°èˆª"""
        current_file = context.get("current_file", "")
        cursor_position = context.get("cursor_position", {"line": 1, "column": 1})
        
        navigation_suggestions = [
            {
                "type": "related_function",
                "description": "è·³è½‰åˆ°ç›¸é—œå‡½æ•¸å®šç¾©",
                "target": "utils.py:42",
                "confidence": 0.89
            },
            {
                "type": "usage_example",
                "description": "æŸ¥çœ‹ä½¿ç”¨ç¤ºä¾‹",
                "target": "examples/demo.py:15",
                "confidence": 0.76
            },
            {
                "type": "test_file",
                "description": "æ‰“é–‹å°æ‡‰æ¸¬è©¦æ–‡ä»¶",
                "target": "tests/test_main.py:8",
                "confidence": 0.92
            }
        ]
        
        self.stats.total_interventions += 1
        
        return {
            "navigation_suggestions": navigation_suggestions,
            "confidence": 0.86,
            "response_time": 110,
            "source": "winsurf"
        }


class CursorIntegration:
    """Cursor AIä»£ç¢¼ç·¨è¼¯å™¨é›†æˆ"""
    
    def __init__(self):
        self.logger = logging.getLogger(self.__class__.__name__)
        self.stats = IntegrationStats(
            assistant=AIAssistantType.CURSOR,
            total_interventions=0,
            successful_interventions=0,
            user_acceptance_rate=0.0,
            avg_response_time=0.0,
            avg_confidence=0.0,
            last_active=""
        )
    
    async def get_contextual_chat(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """ç²å–ä¸Šä¸‹æ–‡èŠå¤©å»ºè­°"""
        user_query = context.get("query", "")
        code_context = context.get("code_context", "")
        
        chat_responses = [
            {
                "type": "explanation",
                "content": "é€™æ®µä»£ç¢¼å¯¦ç¾äº†æ•¸æ“šè™•ç†é‚è¼¯ï¼Œä¸»è¦åŠŸèƒ½åŒ…æ‹¬æ•¸æ“šæ¸…æ´—å’Œæ ¼å¼åŒ–ã€‚",
                "confidence": 0.88
            },
            {
                "type": "improvement",
                "content": "å»ºè­°æ·»åŠ ç•°å¸¸è™•ç†ä¾†æé«˜ä»£ç¢¼çš„å¥å£¯æ€§ã€‚",
                "confidence": 0.82
            },
            {
                "type": "alternative",
                "content": "å¯ä»¥è€ƒæ…®ä½¿ç”¨pandasä¾†ç°¡åŒ–æ•¸æ“šæ“ä½œæµç¨‹ã€‚",
                "confidence": 0.75
            }
        ]
        
        self.stats.total_interventions += 1
        
        return {
            "chat_responses": chat_responses,
            "confidence": 0.82,
            "response_time": 160,
            "source": "cursor"
        }


class AIAssistantOrchestrator:
    """AIåŠ©æ‰‹ç·¨æ’å™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(self.__class__.__name__)
        self.assistants = {}
        self.integration_configs = {}
        self.intervention_history = []
        self.global_stats = {
            "total_interventions": 0,
            "successful_interventions": 0,
            "avg_response_time": 0.0,
            "user_satisfaction": 0.0
        }
    
    async def initialize(self):
        """åˆå§‹åŒ–AIåŠ©æ‰‹ç·¨æ’å™¨"""
        self.logger.info("ğŸ¤– åˆå§‹åŒ–AIåŠ©æ‰‹ç·¨æ’å™¨")
        
        # åˆå§‹åŒ–æ‰€æœ‰AIåŠ©æ‰‹é›†æˆ
        self.assistants = {
            AIAssistantType.TRAE: TraeIntegration(),
            AIAssistantType.TONGYI_LINGMA: TongyiLingmaIntegration(),
            AIAssistantType.TENCENT_CODE_ASSISTANT: TencentCodeAssistantIntegration(),
            AIAssistantType.BAIDU_CODE_ASSISTANT: BaiduCodeAssistantIntegration(),
            AIAssistantType.VSCODE_COPILOT: VSCodeCopilotIntegration(),
            AIAssistantType.WINSURF: WinsurfIntegration(),
            AIAssistantType.CURSOR: CursorIntegration()
        }
        
        # è¨­ç½®åŠ©æ‰‹é…ç½®
        self.integration_configs = {
            AIAssistantType.TRAE: AIAssistantConfig(
                assistant_type=AIAssistantType.TRAE,
                name="Trae AIåŠ©æ‰‹",
                version="2.1.0",
                api_endpoint="https://api.trae.ai/v1",
                auth_token=None,
                capabilities=["code_completion", "error_detection", "refactoring"],
                integration_mode=IntegrationMode.HYBRID,
                enabled_triggers=[
                    InterventionTrigger.CODE_COMPLETION,
                    InterventionTrigger.ERROR_DETECTION
                ],
                priority=8,
                response_time_ms=120,
                accuracy_rate=0.92
            ),
            
            AIAssistantType.TONGYI_LINGMA: AIAssistantConfig(
                assistant_type=AIAssistantType.TONGYI_LINGMA,
                name="é€šç¾©é›¶ç¢¼",
                version="1.5.2",
                api_endpoint="https://tongyi.aliyun.com/lingma/api/v1",
                auth_token=None,
                capabilities=["code_completion", "documentation", "translation"],
                integration_mode=IntegrationMode.ACTIVE,
                enabled_triggers=[
                    InterventionTrigger.CODE_COMPLETION,
                    InterventionTrigger.DOCUMENTATION
                ],
                priority=7,
                response_time_ms=150,
                accuracy_rate=0.89
            ),
            
            AIAssistantType.TENCENT_CODE_ASSISTANT: AIAssistantConfig(
                assistant_type=AIAssistantType.TENCENT_CODE_ASSISTANT,
                name="é¨°è¨Šä»£ç¢¼åŠ©æ‰‹",
                version="3.0.1",
                api_endpoint="https://cloud.tencent.com/product/tai-code",
                auth_token=None,
                capabilities=["refactoring", "optimization", "code_review"],
                integration_mode=IntegrationMode.PASSIVE,
                enabled_triggers=[
                    InterventionTrigger.REFACTOR_SUGGESTION,
                    InterventionTrigger.OPTIMIZATION
                ],
                priority=6,
                response_time_ms=180,
                accuracy_rate=0.82
            ),
            
            AIAssistantType.BAIDU_CODE_ASSISTANT: AIAssistantConfig(
                assistant_type=AIAssistantType.BAIDU_CODE_ASSISTANT,
                name="ç™¾åº¦ä»£ç¢¼åŠ©æ‰‹",
                version="2.8.0",
                api_endpoint="https://cloud.baidu.com/product/comate",
                auth_token=None,
                capabilities=["code_review", "security_check", "performance_analysis"],
                integration_mode=IntegrationMode.ACTIVE,
                enabled_triggers=[
                    InterventionTrigger.CODE_REVIEW,
                    InterventionTrigger.OPTIMIZATION
                ],
                priority=6,
                response_time_ms=220,
                accuracy_rate=0.87
            ),
            
            AIAssistantType.VSCODE_COPILOT: AIAssistantConfig(
                assistant_type=AIAssistantType.VSCODE_COPILOT,
                name="GitHub Copilot",
                version="1.142.0",
                api_endpoint=None,
                auth_token=None,
                capabilities=["inline_completion", "chat", "explanation"],
                integration_mode=IntegrationMode.HYBRID,
                enabled_triggers=[
                    InterventionTrigger.CODE_COMPLETION
                ],
                priority=9,
                response_time_ms=95,
                accuracy_rate=0.91
            ),
            
            AIAssistantType.WINSURF: AIAssistantConfig(
                assistant_type=AIAssistantType.WINSURF,
                name="Winsurfä»£ç¢¼è¡æµª",
                version="1.0.5",
                api_endpoint=None,
                auth_token=None,
                capabilities=["smart_navigation", "code_surfing", "context_aware"],
                integration_mode=IntegrationMode.ACTIVE,
                enabled_triggers=[
                    InterventionTrigger.CODE_COMPLETION,
                    InterventionTrigger.REFACTOR_SUGGESTION
                ],
                priority=5,
                response_time_ms=110,
                accuracy_rate=0.86
            ),
            
            AIAssistantType.CURSOR: AIAssistantConfig(
                assistant_type=AIAssistantType.CURSOR,
                name="Cursor AIç·¨è¼¯å™¨",
                version="0.29.1",
                api_endpoint=None,
                auth_token=None,
                capabilities=["contextual_chat", "code_editing", "ai_pair_programming"],
                integration_mode=IntegrationMode.HYBRID,
                enabled_triggers=[
                    InterventionTrigger.CODE_COMPLETION,
                    InterventionTrigger.CODE_REVIEW
                ],
                priority=8,
                response_time_ms=160,
                accuracy_rate=0.82
            )
        }
        
        self.logger.info(f"âœ… å·²åˆå§‹åŒ– {len(self.assistants)} å€‹AIåŠ©æ‰‹é›†æˆ")
    
    async def handle_intervention(self, trigger: InterventionTrigger, context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """è™•ç†æ™ºèƒ½ä»‹å…¥"""
        eligible_assistants = []
        
        # æ‰¾å‡ºèƒ½è™•ç†æ­¤è§¸ç™¼å™¨çš„åŠ©æ‰‹
        for assistant_type, config in self.integration_configs.items():
            if config.is_active and trigger in config.enabled_triggers:
                eligible_assistants.append((assistant_type, config))
        
        # æŒ‰å„ªå…ˆç´šæ’åº
        eligible_assistants.sort(key=lambda x: x[1].priority, reverse=True)
        
        results = []
        
        # ä¸¦è¡Œèª¿ç”¨æ‰€æœ‰ç¬¦åˆæ¢ä»¶çš„åŠ©æ‰‹
        tasks = []
        for assistant_type, config in eligible_assistants[:3]:  # æœ€å¤šèª¿ç”¨å‰3å€‹åŠ©æ‰‹
            assistant = self.assistants[assistant_type]
            if trigger == InterventionTrigger.CODE_COMPLETION:
                if hasattr(assistant, 'get_code_completion'):
                    tasks.append(assistant.get_code_completion(context))
                elif hasattr(assistant, 'get_inline_completion'):
                    tasks.append(assistant.get_inline_completion(context))
            elif trigger == InterventionTrigger.ERROR_DETECTION:
                if hasattr(assistant, 'detect_errors'):
                    tasks.append(assistant.detect_errors(context))
            elif trigger == InterventionTrigger.CODE_REVIEW:
                if hasattr(assistant, 'get_code_review'):
                    tasks.append(assistant.get_code_review(context))
            elif trigger == InterventionTrigger.REFACTOR_SUGGESTION:
                if hasattr(assistant, 'get_refactor_suggestions'):
                    tasks.append(assistant.get_refactor_suggestions(context))
        
        if tasks:
            assistant_results = await asyncio.gather(*tasks, return_exceptions=True)
            
            for i, result in enumerate(assistant_results):
                if not isinstance(result, Exception):
                    assistant_type = eligible_assistants[i][0]
                    
                    # è¨˜éŒ„ä»‹å…¥äº‹ä»¶
                    intervention = InterventionEvent(
                        id=f"intervention_{int(time.time())}_{i}",
                        trigger=trigger,
                        assistant=assistant_type,
                        context=context,
                        suggestion=str(result),
                        confidence=result.get("confidence", 0.0),
                        timestamp=datetime.now().isoformat()
                    )
                    
                    self.intervention_history.append(intervention)
                    results.append({
                        "assistant": assistant_type.value,
                        "result": result,
                        "intervention_id": intervention.id
                    })
        
        # æ›´æ–°å…¨å±€çµ±è¨ˆ
        self.global_stats["total_interventions"] += len(results)
        
        return results
    
    def get_assistant_stats(self) -> Dict[str, Any]:
        """ç²å–åŠ©æ‰‹çµ±è¨ˆä¿¡æ¯"""
        stats = {}
        
        for assistant_type, assistant in self.assistants.items():
            if hasattr(assistant, 'stats'):
                stats[assistant_type.value] = asdict(assistant.stats)
        
        return stats
    
    def get_integration_summary(self) -> Dict[str, Any]:
        """ç²å–é›†æˆæ‘˜è¦"""
        active_assistants = sum(1 for config in self.integration_configs.values() if config.is_active)
        
        capability_coverage = set()
        for config in self.integration_configs.values():
            if config.is_active:
                capability_coverage.update(config.capabilities)
        
        return {
            "total_assistants": len(self.assistants),
            "active_assistants": active_assistants,
            "supported_capabilities": list(capability_coverage),
            "intervention_history": len(self.intervention_history),
            "global_stats": self.global_stats,
            "integration_modes": {
                mode.value: sum(1 for config in self.integration_configs.values() 
                              if config.integration_mode == mode and config.is_active)
                for mode in IntegrationMode
            }
        }
    
    def get_status(self) -> Dict[str, Any]:
        """ç²å–ç³»çµ±ç‹€æ…‹"""
        return {
            "component": "AI Assistant Orchestrator",
            "version": "4.6.1",
            "supported_assistants": [assistant.value for assistant in AIAssistantType],
            "active_integrations": len([c for c in self.integration_configs.values() if c.is_active]),
            "intervention_triggers": [trigger.value for trigger in InterventionTrigger],
            "integration_modes": [mode.value for mode in IntegrationMode],
            "total_interventions": self.global_stats["total_interventions"],
            "capabilities": [
                "multi_assistant_orchestration",
                "intelligent_trigger_detection",
                "priority_based_routing",
                "parallel_processing",
                "confidence_scoring",
                "usage_analytics"
            ]
        }


# å–®ä¾‹å¯¦ä¾‹
ai_assistant_orchestrator = AIAssistantOrchestrator()