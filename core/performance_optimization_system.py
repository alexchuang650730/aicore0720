#!/usr/bin/env python3
"""
PowerAutomation Core v4.6.9.4 æ€§èƒ½å„ªåŒ–å’Œç³»çµ±èª¿å„ª
å…¨é¢å„ªåŒ– MemoryOS MCP é›†æˆã€å­¸ç¿’ç³»çµ±ã€æ•¸æ“šæ”¶é›†å’Œä¸Šä¸‹æ–‡å¢å¼·æ€§èƒ½
"""

import asyncio
import json
import logging
import time
import psutil
import gc
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
from pathlib import Path
import threading
from collections import defaultdict, deque
import numpy as np
from concurrent.futures import ThreadPoolExecutor
import cProfile
import pstats
import tracemalloc
from memory_profiler import profile
import sys
import weakref

# å°å…¥éœ€è¦å„ªåŒ–çš„çµ„ä»¶
from .memoryos_mcp_adapter import MemoryOSMCPAdapter
from .learning_integration import PowerAutomationLearningIntegration
from .data_collection_system import DataCollectionSystem
from .intelligent_context_enhancement import IntelligentContextEnhancement

logger = logging.getLogger(__name__)

class OptimizationType(Enum):
    """å„ªåŒ–é¡å‹"""
    MEMORY_OPTIMIZATION = "memory_optimization"
    CPU_OPTIMIZATION = "cpu_optimization"
    IO_OPTIMIZATION = "io_optimization"
    NETWORK_OPTIMIZATION = "network_optimization"
    DATABASE_OPTIMIZATION = "database_optimization"
    CACHE_OPTIMIZATION = "cache_optimization"
    CONCURRENCY_OPTIMIZATION = "concurrency_optimization"
    GARBAGE_COLLECTION_OPTIMIZATION = "gc_optimization"

class PerformanceMetricType(Enum):
    """æ€§èƒ½æŒ‡æ¨™é¡å‹"""
    RESPONSE_TIME = "response_time"
    THROUGHPUT = "throughput"
    MEMORY_USAGE = "memory_usage"
    CPU_USAGE = "cpu_usage"
    DISK_IO = "disk_io"
    NETWORK_IO = "network_io"
    ERROR_RATE = "error_rate"
    AVAILABILITY = "availability"

@dataclass
class PerformanceMetric:
    """æ€§èƒ½æŒ‡æ¨™"""
    metric_type: PerformanceMetricType
    value: float
    timestamp: float
    component: str
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}

@dataclass
class OptimizationResult:
    """å„ªåŒ–çµæœ"""
    optimization_type: OptimizationType
    before_metrics: Dict[str, float]
    after_metrics: Dict[str, float]
    improvement_percentage: float
    execution_time: float
    recommendations: List[str]
    timestamp: float
    
    def calculate_improvement(self) -> float:
        """è¨ˆç®—æ”¹é€²ç™¾åˆ†æ¯”"""
        if not self.before_metrics or not self.after_metrics:
            return 0.0
        
        improvements = []
        for metric_name in self.before_metrics:
            if metric_name in self.after_metrics:
                before = self.before_metrics[metric_name]
                after = self.after_metrics[metric_name]
                
                # å°æ–¼æŸäº›æŒ‡æ¨™ï¼Œæ•¸å€¼è¶Šå°è¶Šå¥½ï¼ˆå¦‚éŸ¿æ‡‰æ™‚é–“ã€éŒ¯èª¤ç‡ï¼‰
                if metric_name in ['response_time', 'error_rate', 'memory_usage']:
                    if before > 0:
                        improvement = ((before - after) / before) * 100
                        improvements.append(improvement)
                else:
                    # å°æ–¼æŸäº›æŒ‡æ¨™ï¼Œæ•¸å€¼è¶Šå¤§è¶Šå¥½ï¼ˆå¦‚ååé‡ï¼‰
                    if before > 0:
                        improvement = ((after - before) / before) * 100
                        improvements.append(improvement)
        
        return np.mean(improvements) if improvements else 0.0

@dataclass
class SystemResourceUsage:
    """ç³»çµ±è³‡æºä½¿ç”¨æƒ…æ³"""
    cpu_percent: float
    memory_percent: float
    disk_io_read: float
    disk_io_write: float
    network_sent: float
    network_recv: float
    active_threads: int
    open_files: int
    timestamp: float

class PerformanceOptimizationSystem:
    """æ€§èƒ½å„ªåŒ–ç³»çµ±"""
    
    def __init__(self):
        self.optimization_history = deque(maxlen=100)
        self.performance_metrics = defaultdict(lambda: deque(maxlen=1000))
        self.system_resources = deque(maxlen=1000)
        self.optimization_schedules = {}
        self.cache_pools = {}
        self.thread_pools = {}
        
        # æ€§èƒ½ç›£æ§
        self.monitoring_active = False
        self.monitoring_tasks = []
        self.optimization_tasks = []
        
        # ç·©å­˜é…ç½®
        self.cache_config = {
            "memory_cache_size": 1000,
            "context_cache_size": 500,
            "learning_cache_size": 200,
            "ttl_seconds": 3600
        }
        
        # ä¸¦ç™¼é…ç½®
        self.concurrency_config = {
            "max_workers": min(32, (psutil.cpu_count() or 1) + 4),
            "io_bound_workers": min(64, (psutil.cpu_count() or 1) * 2),
            "cpu_bound_workers": psutil.cpu_count() or 1
        }
        
        # å„ªåŒ–é–¾å€¼
        self.optimization_thresholds = {
            "memory_usage": 80.0,  # 80%
            "cpu_usage": 90.0,     # 90%
            "response_time": 5000,  # 5ç§’
            "error_rate": 5.0,     # 5%
            "disk_io": 80.0        # 80%
        }
        
        # çµ±è¨ˆä¿¡æ¯
        self.optimization_stats = {
            "total_optimizations": 0,
            "successful_optimizations": 0,
            "failed_optimizations": 0,
            "average_improvement": 0.0,
            "total_time_saved": 0.0,
            "memory_freed": 0,
            "cpu_cycles_saved": 0
        }
        
        self.start_time = time.time()
        self.is_initialized = False
    
    async def initialize(self):
        """åˆå§‹åŒ–æ€§èƒ½å„ªåŒ–ç³»çµ±"""
        logger.info("ğŸš€ åˆå§‹åŒ–æ€§èƒ½å„ªåŒ–ç³»çµ±...")
        
        try:
            # å•Ÿå‹•å…§å­˜è·Ÿè¹¤
            tracemalloc.start()
            
            # è¨­ç½®å„ªåŒ–è¨ˆåŠƒ
            await self._setup_optimization_schedules()
            
            # åˆå§‹åŒ–ç·šç¨‹æ± 
            await self._initialize_thread_pools()
            
            # åˆå§‹åŒ–ç·©å­˜æ± 
            await self._initialize_cache_pools()
            
            # å•Ÿå‹•æ€§èƒ½ç›£æ§
            await self._start_performance_monitoring()
            
            # å•Ÿå‹•è‡ªå‹•å„ªåŒ–
            await self._start_auto_optimization()
            
            self.is_initialized = True
            logger.info("âœ… æ€§èƒ½å„ªåŒ–ç³»çµ±åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ æ€§èƒ½å„ªåŒ–ç³»çµ±åˆå§‹åŒ–å¤±æ•—: {e}")
            raise
    
    async def _setup_optimization_schedules(self):
        """è¨­ç½®å„ªåŒ–è¨ˆåŠƒ"""
        self.optimization_schedules = {
            OptimizationType.MEMORY_OPTIMIZATION: {
                "interval": 300,  # 5åˆ†é˜
                "last_run": 0,
                "enabled": True,
                "priority": "high"
            },
            OptimizationType.CPU_OPTIMIZATION: {
                "interval": 600,  # 10åˆ†é˜
                "last_run": 0,
                "enabled": True,
                "priority": "medium"
            },
            OptimizationType.IO_OPTIMIZATION: {
                "interval": 900,  # 15åˆ†é˜
                "last_run": 0,
                "enabled": True,
                "priority": "medium"
            },
            OptimizationType.CACHE_OPTIMIZATION: {
                "interval": 1800,  # 30åˆ†é˜
                "last_run": 0,
                "enabled": True,
                "priority": "low"
            },
            OptimizationType.GARBAGE_COLLECTION_OPTIMIZATION: {
                "interval": 120,  # 2åˆ†é˜
                "last_run": 0,
                "enabled": True,
                "priority": "high"
            },
            OptimizationType.DATABASE_OPTIMIZATION: {
                "interval": 3600,  # 1å°æ™‚
                "last_run": 0,
                "enabled": True,
                "priority": "low"
            },
            OptimizationType.CONCURRENCY_OPTIMIZATION: {
                "interval": 1200,  # 20åˆ†é˜
                "last_run": 0,
                "enabled": True,
                "priority": "medium"
            }
        }
    
    async def _initialize_thread_pools(self):
        """åˆå§‹åŒ–ç·šç¨‹æ± """
        self.thread_pools = {
            "io_bound": ThreadPoolExecutor(
                max_workers=self.concurrency_config["io_bound_workers"],
                thread_name_prefix="io_bound"
            ),
            "cpu_bound": ThreadPoolExecutor(
                max_workers=self.concurrency_config["cpu_bound_workers"],
                thread_name_prefix="cpu_bound"
            ),
            "general": ThreadPoolExecutor(
                max_workers=self.concurrency_config["max_workers"],
                thread_name_prefix="general"
            )
        }
    
    async def _initialize_cache_pools(self):
        """åˆå§‹åŒ–ç·©å­˜æ± """
        self.cache_pools = {
            "memory_cache": {},
            "context_cache": {},
            "learning_cache": {},
            "query_cache": {},
            "result_cache": {}
        }
    
    async def _start_performance_monitoring(self):
        """å•Ÿå‹•æ€§èƒ½ç›£æ§"""
        self.monitoring_active = True
        
        # ç³»çµ±è³‡æºç›£æ§
        resource_task = asyncio.create_task(self._monitor_system_resources())
        self.monitoring_tasks.append(resource_task)
        
        # æ€§èƒ½æŒ‡æ¨™ç›£æ§
        metrics_task = asyncio.create_task(self._monitor_performance_metrics())
        self.monitoring_tasks.append(metrics_task)
    
    async def _start_auto_optimization(self):
        """å•Ÿå‹•è‡ªå‹•å„ªåŒ–"""
        optimization_task = asyncio.create_task(self._auto_optimization_loop())
        self.optimization_tasks.append(optimization_task)
    
    async def _monitor_system_resources(self):
        """ç›£æ§ç³»çµ±è³‡æº"""
        while self.monitoring_active:
            try:
                # æ”¶é›†ç³»çµ±è³‡æºä½¿ç”¨æƒ…æ³
                cpu_percent = psutil.cpu_percent(interval=1)
                memory = psutil.virtual_memory()
                disk_io = psutil.disk_io_counters()
                network_io = psutil.net_io_counters()
                
                # é€²ç¨‹ä¿¡æ¯
                process = psutil.Process()
                process_info = process.as_dict(attrs=['num_threads', 'num_fds'])
                
                resource_usage = SystemResourceUsage(
                    cpu_percent=cpu_percent,
                    memory_percent=memory.percent,
                    disk_io_read=disk_io.read_bytes if disk_io else 0,
                    disk_io_write=disk_io.write_bytes if disk_io else 0,
                    network_sent=network_io.bytes_sent if network_io else 0,
                    network_recv=network_io.bytes_recv if network_io else 0,
                    active_threads=process_info.get('num_threads', 0),
                    open_files=process_info.get('num_fds', 0),
                    timestamp=time.time()
                )
                
                self.system_resources.append(resource_usage)
                
                # æª¢æŸ¥æ˜¯å¦éœ€è¦è§¸ç™¼å„ªåŒ–
                await self._check_optimization_triggers(resource_usage)
                
                await asyncio.sleep(5)  # æ¯5ç§’ç›£æ§ä¸€æ¬¡
                
            except Exception as e:
                logger.error(f"âŒ ç³»çµ±è³‡æºç›£æ§éŒ¯èª¤: {e}")
                await asyncio.sleep(30)  # éŒ¯èª¤æ™‚ç­‰å¾…30ç§’
    
    async def _monitor_performance_metrics(self):
        """ç›£æ§æ€§èƒ½æŒ‡æ¨™"""
        while self.monitoring_active:
            try:
                # æ”¶é›†å„çµ„ä»¶æ€§èƒ½æŒ‡æ¨™
                await self._collect_component_metrics()
                
                await asyncio.sleep(10)  # æ¯10ç§’æ”¶é›†ä¸€æ¬¡
                
            except Exception as e:
                logger.error(f"âŒ æ€§èƒ½æŒ‡æ¨™ç›£æ§éŒ¯èª¤: {e}")
                await asyncio.sleep(30)
    
    async def _collect_component_metrics(self):
        """æ”¶é›†çµ„ä»¶æ€§èƒ½æŒ‡æ¨™"""
        try:
            # æ”¶é›†å…§å­˜ä½¿ç”¨æƒ…æ³
            current, peak = tracemalloc.get_traced_memory()
            
            memory_metric = PerformanceMetric(
                metric_type=PerformanceMetricType.MEMORY_USAGE,
                value=current / 1024 / 1024,  # MB
                timestamp=time.time(),
                component="system",
                metadata={"peak_memory": peak / 1024 / 1024}
            )
            
            self.performance_metrics["memory_usage"].append(memory_metric)
            
            # æ”¶é›† GC çµ±è¨ˆ
            gc_stats = gc.get_stats()
            if gc_stats:
                for i, stat in enumerate(gc_stats):
                    gc_metric = PerformanceMetric(
                        metric_type=PerformanceMetricType.MEMORY_USAGE,
                        value=stat.get('collections', 0),
                        timestamp=time.time(),
                        component=f"gc_generation_{i}",
                        metadata=stat
                    )
                    self.performance_metrics["gc_stats"].append(gc_metric)
            
        except Exception as e:
            logger.error(f"âŒ æ”¶é›†çµ„ä»¶æŒ‡æ¨™å¤±æ•—: {e}")
    
    async def _check_optimization_triggers(self, resource_usage: SystemResourceUsage):
        """æª¢æŸ¥å„ªåŒ–è§¸ç™¼æ¢ä»¶"""
        try:
            # æª¢æŸ¥å…§å­˜ä½¿ç”¨ç‡
            if resource_usage.memory_percent > self.optimization_thresholds["memory_usage"]:
                await self._trigger_optimization(OptimizationType.MEMORY_OPTIMIZATION)
            
            # æª¢æŸ¥ CPU ä½¿ç”¨ç‡
            if resource_usage.cpu_percent > self.optimization_thresholds["cpu_usage"]:
                await self._trigger_optimization(OptimizationType.CPU_OPTIMIZATION)
            
            # æª¢æŸ¥ç·šç¨‹æ•¸
            if resource_usage.active_threads > self.concurrency_config["max_workers"] * 2:
                await self._trigger_optimization(OptimizationType.CONCURRENCY_OPTIMIZATION)
            
        except Exception as e:
            logger.error(f"âŒ æª¢æŸ¥å„ªåŒ–è§¸ç™¼æ¢ä»¶å¤±æ•—: {e}")
    
    async def _trigger_optimization(self, optimization_type: OptimizationType):
        """è§¸ç™¼å„ªåŒ–"""
        try:
            schedule = self.optimization_schedules.get(optimization_type)
            if not schedule or not schedule["enabled"]:
                return
            
            current_time = time.time()
            
            # æª¢æŸ¥æ˜¯å¦åˆ°äº†åŸ·è¡Œæ™‚é–“
            if current_time - schedule["last_run"] < schedule["interval"]:
                return
            
            # åŸ·è¡Œå„ªåŒ–
            await self._execute_optimization(optimization_type)
            
            # æ›´æ–°æœ€å¾ŒåŸ·è¡Œæ™‚é–“
            schedule["last_run"] = current_time
            
        except Exception as e:
            logger.error(f"âŒ è§¸ç™¼å„ªåŒ–å¤±æ•— ({optimization_type.value}): {e}")
    
    async def _auto_optimization_loop(self):
        """è‡ªå‹•å„ªåŒ–å¾ªç’°"""
        while self.monitoring_active:
            try:
                current_time = time.time()
                
                # æª¢æŸ¥æ‰€æœ‰å„ªåŒ–è¨ˆåŠƒ
                for opt_type, schedule in self.optimization_schedules.items():
                    if (schedule["enabled"] and 
                        current_time - schedule["last_run"] >= schedule["interval"]):
                        
                        await self._execute_optimization(opt_type)
                        schedule["last_run"] = current_time
                
                await asyncio.sleep(60)  # æ¯åˆ†é˜æª¢æŸ¥ä¸€æ¬¡
                
            except Exception as e:
                logger.error(f"âŒ è‡ªå‹•å„ªåŒ–å¾ªç’°éŒ¯èª¤: {e}")
                await asyncio.sleep(120)  # éŒ¯èª¤æ™‚ç­‰å¾…2åˆ†é˜
    
    async def _execute_optimization(self, optimization_type: OptimizationType):
        """åŸ·è¡Œå„ªåŒ–"""
        logger.info(f"ğŸ”§ åŸ·è¡Œå„ªåŒ–: {optimization_type.value}")
        
        start_time = time.time()
        
        try:
            # æ”¶é›†å„ªåŒ–å‰æŒ‡æ¨™
            before_metrics = await self._collect_current_metrics()
            
            # åŸ·è¡Œç‰¹å®šé¡å‹å„ªåŒ–
            recommendations = []
            
            if optimization_type == OptimizationType.MEMORY_OPTIMIZATION:
                recommendations = await self._optimize_memory()
            elif optimization_type == OptimizationType.CPU_OPTIMIZATION:
                recommendations = await self._optimize_cpu()
            elif optimization_type == OptimizationType.IO_OPTIMIZATION:
                recommendations = await self._optimize_io()
            elif optimization_type == OptimizationType.CACHE_OPTIMIZATION:
                recommendations = await self._optimize_cache()
            elif optimization_type == OptimizationType.GARBAGE_COLLECTION_OPTIMIZATION:
                recommendations = await self._optimize_garbage_collection()
            elif optimization_type == OptimizationType.DATABASE_OPTIMIZATION:
                recommendations = await self._optimize_database()
            elif optimization_type == OptimizationType.CONCURRENCY_OPTIMIZATION:
                recommendations = await self._optimize_concurrency()
            
            # æ”¶é›†å„ªåŒ–å¾ŒæŒ‡æ¨™
            after_metrics = await self._collect_current_metrics()
            
            # è¨ˆç®—å„ªåŒ–çµæœ
            optimization_result = OptimizationResult(
                optimization_type=optimization_type,
                before_metrics=before_metrics,
                after_metrics=after_metrics,
                improvement_percentage=0.0,
                execution_time=time.time() - start_time,
                recommendations=recommendations,
                timestamp=time.time()
            )
            
            optimization_result.improvement_percentage = optimization_result.calculate_improvement()
            
            # è¨˜éŒ„å„ªåŒ–çµæœ
            self.optimization_history.append(optimization_result)
            
            # æ›´æ–°çµ±è¨ˆ
            self.optimization_stats["total_optimizations"] += 1
            if optimization_result.improvement_percentage > 0:
                self.optimization_stats["successful_optimizations"] += 1
            else:
                self.optimization_stats["failed_optimizations"] += 1
            
            # é‡æ–°è¨ˆç®—å¹³å‡æ”¹é€²
            if self.optimization_history:
                improvements = [opt.improvement_percentage for opt in self.optimization_history]
                self.optimization_stats["average_improvement"] = np.mean(improvements)
            
            logger.info(f"âœ… å„ªåŒ–å®Œæˆ: {optimization_type.value} (æ”¹é€²: {optimization_result.improvement_percentage:.2f}%)")
            
        except Exception as e:
            logger.error(f"âŒ å„ªåŒ–åŸ·è¡Œå¤±æ•— ({optimization_type.value}): {e}")
            self.optimization_stats["failed_optimizations"] += 1
    
    async def _collect_current_metrics(self) -> Dict[str, float]:
        """æ”¶é›†ç•¶å‰æŒ‡æ¨™"""
        try:
            metrics = {}
            
            # ç³»çµ±è³‡æºæŒ‡æ¨™
            if self.system_resources:
                latest_resource = self.system_resources[-1]
                metrics["cpu_usage"] = latest_resource.cpu_percent
                metrics["memory_usage"] = latest_resource.memory_percent
                metrics["active_threads"] = latest_resource.active_threads
                metrics["open_files"] = latest_resource.open_files
            
            # å…§å­˜è¿½è¹¤æŒ‡æ¨™
            if tracemalloc.is_tracing():
                current, peak = tracemalloc.get_traced_memory()
                metrics["traced_memory"] = current / 1024 / 1024  # MB
                metrics["peak_memory"] = peak / 1024 / 1024  # MB
            
            # GC çµ±è¨ˆ
            gc_stats = gc.get_stats()
            if gc_stats:
                total_collections = sum(stat.get('collections', 0) for stat in gc_stats)
                metrics["gc_collections"] = total_collections
            
            # ç·©å­˜å‘½ä¸­ç‡
            cache_stats = await self._get_cache_statistics()
            metrics.update(cache_stats)
            
            return metrics
            
        except Exception as e:
            logger.error(f"âŒ æ”¶é›†ç•¶å‰æŒ‡æ¨™å¤±æ•—: {e}")
            return {}
    
    async def _optimize_memory(self) -> List[str]:
        """å„ªåŒ–å…§å­˜ä½¿ç”¨"""
        recommendations = []
        
        try:
            # 1. åŸ·è¡Œåƒåœ¾å›æ”¶
            collected = gc.collect()
            if collected > 0:
                recommendations.append(f"åƒåœ¾å›æ”¶æ¸…ç†äº† {collected} å€‹å°è±¡")
            
            # 2. æ¸…ç†ç·©å­˜
            cache_cleared = await self._clear_expired_cache()
            if cache_cleared > 0:
                recommendations.append(f"æ¸…ç†äº† {cache_cleared} å€‹éæœŸç·©å­˜é …")
            
            # 3. å„ªåŒ–æ•¸æ“šçµæ§‹
            await self._optimize_data_structures()
            recommendations.append("å„ªåŒ–äº†æ•¸æ“šçµæ§‹ä½¿ç”¨")
            
            # 4. èª¿æ•´ç·©å­˜å¤§å°
            await self._adjust_cache_sizes()
            recommendations.append("èª¿æ•´äº†ç·©å­˜å¤§å°é…ç½®")
            
        except Exception as e:
            logger.error(f"âŒ å…§å­˜å„ªåŒ–å¤±æ•—: {e}")
            recommendations.append(f"å…§å­˜å„ªåŒ–å¤±æ•—: {e}")
        
        return recommendations
    
    async def _optimize_cpu(self) -> List[str]:
        """å„ªåŒ– CPU ä½¿ç”¨"""
        recommendations = []
        
        try:
            # 1. èª¿æ•´ç·šç¨‹æ± å¤§å°
            await self._adjust_thread_pool_sizes()
            recommendations.append("èª¿æ•´äº†ç·šç¨‹æ± å¤§å°")
            
            # 2. å„ªåŒ–ç®—æ³•å¾©é›œåº¦
            await self._optimize_algorithms()
            recommendations.append("å„ªåŒ–äº†ç®—æ³•åŸ·è¡Œ")
            
            # 3. å•Ÿç”¨ç•°æ­¥è™•ç†
            await self._enable_async_processing()
            recommendations.append("å•Ÿç”¨äº†ç•°æ­¥è™•ç†")
            
        except Exception as e:
            logger.error(f"âŒ CPU å„ªåŒ–å¤±æ•—: {e}")
            recommendations.append(f"CPU å„ªåŒ–å¤±æ•—: {e}")
        
        return recommendations
    
    async def _optimize_io(self) -> List[str]:
        """å„ªåŒ– I/O æ“ä½œ"""
        recommendations = []
        
        try:
            # 1. æ‰¹é‡è™•ç†
            await self._enable_batch_processing()
            recommendations.append("å•Ÿç”¨äº†æ‰¹é‡è™•ç†")
            
            # 2. ç•°æ­¥ I/O
            await self._optimize_async_io()
            recommendations.append("å„ªåŒ–äº†ç•°æ­¥ I/O")
            
            # 3. é€£æ¥æ± å„ªåŒ–
            await self._optimize_connection_pools()
            recommendations.append("å„ªåŒ–äº†é€£æ¥æ± é…ç½®")
            
        except Exception as e:
            logger.error(f"âŒ I/O å„ªåŒ–å¤±æ•—: {e}")
            recommendations.append(f"I/O å„ªåŒ–å¤±æ•—: {e}")
        
        return recommendations
    
    async def _optimize_cache(self) -> List[str]:
        """å„ªåŒ–ç·©å­˜ç³»çµ±"""
        recommendations = []
        
        try:
            # 1. æ¸…ç†éæœŸç·©å­˜
            cleared = await self._clear_expired_cache()
            recommendations.append(f"æ¸…ç†äº† {cleared} å€‹éæœŸç·©å­˜é …")
            
            # 2. å„ªåŒ–ç·©å­˜ç­–ç•¥
            await self._optimize_cache_strategy()
            recommendations.append("å„ªåŒ–äº†ç·©å­˜ç­–ç•¥")
            
            # 3. é ç†±ç†±é»æ•¸æ“š
            await self._warm_up_cache()
            recommendations.append("é ç†±äº†ç†±é»æ•¸æ“š")
            
        except Exception as e:
            logger.error(f"âŒ ç·©å­˜å„ªåŒ–å¤±æ•—: {e}")
            recommendations.append(f"ç·©å­˜å„ªåŒ–å¤±æ•—: {e}")
        
        return recommendations
    
    async def _optimize_garbage_collection(self) -> List[str]:
        """å„ªåŒ–åƒåœ¾å›æ”¶"""
        recommendations = []
        
        try:
            # 1. åŸ·è¡Œå®Œæ•´ GC
            before_stats = gc.get_stats()
            collected = gc.collect()
            after_stats = gc.get_stats()
            
            if collected > 0:
                recommendations.append(f"åƒåœ¾å›æ”¶æ¸…ç†äº† {collected} å€‹å°è±¡")
            
            # 2. èª¿æ•´ GC é–¾å€¼
            await self._adjust_gc_thresholds()
            recommendations.append("èª¿æ•´äº† GC é–¾å€¼")
            
            # 3. æ¸…ç†å¼±å¼•ç”¨
            await self._cleanup_weak_references()
            recommendations.append("æ¸…ç†äº†å¼±å¼•ç”¨")
            
        except Exception as e:
            logger.error(f"âŒ åƒåœ¾å›æ”¶å„ªåŒ–å¤±æ•—: {e}")
            recommendations.append(f"åƒåœ¾å›æ”¶å„ªåŒ–å¤±æ•—: {e}")
        
        return recommendations
    
    async def _optimize_database(self) -> List[str]:
        """å„ªåŒ–æ•¸æ“šåº«æ“ä½œ"""
        recommendations = []
        
        try:
            # 1. å„ªåŒ–æŸ¥è©¢
            await self._optimize_database_queries()
            recommendations.append("å„ªåŒ–äº†æ•¸æ“šåº«æŸ¥è©¢")
            
            # 2. ç´¢å¼•å„ªåŒ–
            await self._optimize_database_indexes()
            recommendations.append("å„ªåŒ–äº†æ•¸æ“šåº«ç´¢å¼•")
            
            # 3. é€£æ¥æ± å„ªåŒ–
            await self._optimize_database_connections()
            recommendations.append("å„ªåŒ–äº†æ•¸æ“šåº«é€£æ¥æ± ")
            
        except Exception as e:
            logger.error(f"âŒ æ•¸æ“šåº«å„ªåŒ–å¤±æ•—: {e}")
            recommendations.append(f"æ•¸æ“šåº«å„ªåŒ–å¤±æ•—: {e}")
        
        return recommendations
    
    async def _optimize_concurrency(self) -> List[str]:
        """å„ªåŒ–ä¸¦ç™¼è™•ç†"""
        recommendations = []
        
        try:
            # 1. èª¿æ•´ç·šç¨‹æ± 
            await self._adjust_thread_pool_sizes()
            recommendations.append("èª¿æ•´äº†ç·šç¨‹æ± å¤§å°")
            
            # 2. å„ªåŒ–é–æ©Ÿåˆ¶
            await self._optimize_locking_mechanisms()
            recommendations.append("å„ªåŒ–äº†é–æ©Ÿåˆ¶")
            
            # 3. ç•°æ­¥ä»»å‹™èª¿åº¦
            await self._optimize_async_scheduling()
            recommendations.append("å„ªåŒ–äº†ç•°æ­¥ä»»å‹™èª¿åº¦")
            
        except Exception as e:
            logger.error(f"âŒ ä¸¦ç™¼å„ªåŒ–å¤±æ•—: {e}")
            recommendations.append(f"ä¸¦ç™¼å„ªåŒ–å¤±æ•—: {e}")
        
        return recommendations
    
    # å…·é«”å„ªåŒ–æ–¹æ³•å¯¦ç¾
    async def _clear_expired_cache(self) -> int:
        """æ¸…ç†éæœŸç·©å­˜"""
        cleared_count = 0
        current_time = time.time()
        
        for cache_name, cache in self.cache_pools.items():
            if isinstance(cache, dict):
                expired_keys = []
                for key, value in cache.items():
                    if isinstance(value, dict) and 'timestamp' in value:
                        if current_time - value['timestamp'] > self.cache_config["ttl_seconds"]:
                            expired_keys.append(key)
                
                for key in expired_keys:
                    del cache[key]
                    cleared_count += 1
        
        return cleared_count
    
    async def _optimize_data_structures(self):
        """å„ªåŒ–æ•¸æ“šçµæ§‹"""
        # å°‡åˆ—è¡¨è½‰æ›ç‚º dequeï¼ˆå¦‚æœé©ç”¨ï¼‰
        # å„ªåŒ–å­—å…¸ä½¿ç”¨
        # ä½¿ç”¨ç”Ÿæˆå™¨æ›¿ä»£åˆ—è¡¨ï¼ˆå¦‚æœé©ç”¨ï¼‰
        pass
    
    async def _adjust_cache_sizes(self):
        """èª¿æ•´ç·©å­˜å¤§å°"""
        # æ ¹æ“šå…§å­˜ä½¿ç”¨æƒ…æ³å‹•æ…‹èª¿æ•´ç·©å­˜å¤§å°
        if self.system_resources:
            latest_resource = self.system_resources[-1]
            
            if latest_resource.memory_percent > 85:
                # é«˜å…§å­˜ä½¿ç”¨æ™‚æ¸›å°‘ç·©å­˜
                self.cache_config["memory_cache_size"] = max(100, self.cache_config["memory_cache_size"] * 0.8)
                self.cache_config["context_cache_size"] = max(50, self.cache_config["context_cache_size"] * 0.8)
            elif latest_resource.memory_percent < 50:
                # ä½å…§å­˜ä½¿ç”¨æ™‚å¢åŠ ç·©å­˜
                self.cache_config["memory_cache_size"] = min(2000, self.cache_config["memory_cache_size"] * 1.2)
                self.cache_config["context_cache_size"] = min(1000, self.cache_config["context_cache_size"] * 1.2)
    
    async def _adjust_thread_pool_sizes(self):
        """èª¿æ•´ç·šç¨‹æ± å¤§å°"""
        if self.system_resources:
            latest_resource = self.system_resources[-1]
            
            if latest_resource.cpu_percent > 80:
                # é«˜ CPU ä½¿ç”¨æ™‚æ¸›å°‘ç·šç¨‹
                for pool_name, pool in self.thread_pools.items():
                    if hasattr(pool, '_max_workers'):
                        new_size = max(1, int(pool._max_workers * 0.8))
                        # æ³¨æ„ï¼šThreadPoolExecutor ä¸æ”¯æŒå‹•æ…‹èª¿æ•´ï¼Œé€™è£¡åƒ…ä½œç¤ºä¾‹
            elif latest_resource.cpu_percent < 30:
                # ä½ CPU ä½¿ç”¨æ™‚å¢åŠ ç·šç¨‹
                for pool_name, pool in self.thread_pools.items():
                    if hasattr(pool, '_max_workers'):
                        new_size = min(64, int(pool._max_workers * 1.2))
                        # æ³¨æ„ï¼šThreadPoolExecutor ä¸æ”¯æŒå‹•æ…‹èª¿æ•´ï¼Œé€™è£¡åƒ…ä½œç¤ºä¾‹
    
    async def _optimize_algorithms(self):
        """å„ªåŒ–ç®—æ³•åŸ·è¡Œ"""
        # é€™è£¡å¯ä»¥å¯¦ç¾ç®—æ³•å„ªåŒ–é‚è¼¯
        pass
    
    async def _enable_async_processing(self):
        """å•Ÿç”¨ç•°æ­¥è™•ç†"""
        # é€™è£¡å¯ä»¥å¯¦ç¾ç•°æ­¥è™•ç†å„ªåŒ–
        pass
    
    async def _enable_batch_processing(self):
        """å•Ÿç”¨æ‰¹é‡è™•ç†"""
        # é€™è£¡å¯ä»¥å¯¦ç¾æ‰¹é‡è™•ç†å„ªåŒ–
        pass
    
    async def _optimize_async_io(self):
        """å„ªåŒ–ç•°æ­¥ I/O"""
        # é€™è£¡å¯ä»¥å¯¦ç¾ç•°æ­¥ I/O å„ªåŒ–
        pass
    
    async def _optimize_connection_pools(self):
        """å„ªåŒ–é€£æ¥æ± """
        # é€™è£¡å¯ä»¥å¯¦ç¾é€£æ¥æ± å„ªåŒ–
        pass
    
    async def _optimize_cache_strategy(self):
        """å„ªåŒ–ç·©å­˜ç­–ç•¥"""
        # é€™è£¡å¯ä»¥å¯¦ç¾ç·©å­˜ç­–ç•¥å„ªåŒ–
        pass
    
    async def _warm_up_cache(self):
        """é ç†±ç·©å­˜"""
        # é€™è£¡å¯ä»¥å¯¦ç¾ç·©å­˜é ç†±
        pass
    
    async def _adjust_gc_thresholds(self):
        """èª¿æ•´ GC é–¾å€¼"""
        # æ ¹æ“šç³»çµ±è² è¼‰èª¿æ•´ GC é–¾å€¼
        current_thresholds = gc.get_threshold()
        
        if self.system_resources:
            latest_resource = self.system_resources[-1]
            
            if latest_resource.memory_percent > 85:
                # é«˜å…§å­˜ä½¿ç”¨æ™‚æ›´é »ç¹ GC
                new_thresholds = tuple(max(100, int(t * 0.8)) for t in current_thresholds)
                gc.set_threshold(*new_thresholds)
            elif latest_resource.memory_percent < 50:
                # ä½å…§å­˜ä½¿ç”¨æ™‚æ¸›å°‘ GC é »ç‡
                new_thresholds = tuple(min(2000, int(t * 1.2)) for t in current_thresholds)
                gc.set_threshold(*new_thresholds)
    
    async def _cleanup_weak_references(self):
        """æ¸…ç†å¼±å¼•ç”¨"""
        # é€™è£¡å¯ä»¥å¯¦ç¾å¼±å¼•ç”¨æ¸…ç†
        pass
    
    async def _optimize_database_queries(self):
        """å„ªåŒ–æ•¸æ“šåº«æŸ¥è©¢"""
        # é€™è£¡å¯ä»¥å¯¦ç¾æ•¸æ“šåº«æŸ¥è©¢å„ªåŒ–
        pass
    
    async def _optimize_database_indexes(self):
        """å„ªåŒ–æ•¸æ“šåº«ç´¢å¼•"""
        # é€™è£¡å¯ä»¥å¯¦ç¾æ•¸æ“šåº«ç´¢å¼•å„ªåŒ–
        pass
    
    async def _optimize_database_connections(self):
        """å„ªåŒ–æ•¸æ“šåº«é€£æ¥"""
        # é€™è£¡å¯ä»¥å¯¦ç¾æ•¸æ“šåº«é€£æ¥å„ªåŒ–
        pass
    
    async def _optimize_locking_mechanisms(self):
        """å„ªåŒ–é–æ©Ÿåˆ¶"""
        # é€™è£¡å¯ä»¥å¯¦ç¾é–æ©Ÿåˆ¶å„ªåŒ–
        pass
    
    async def _optimize_async_scheduling(self):
        """å„ªåŒ–ç•°æ­¥ä»»å‹™èª¿åº¦"""
        # é€™è£¡å¯ä»¥å¯¦ç¾ç•°æ­¥ä»»å‹™èª¿åº¦å„ªåŒ–
        pass
    
    async def _get_cache_statistics(self) -> Dict[str, float]:
        """ç²å–ç·©å­˜çµ±è¨ˆ"""
        stats = {}
        
        for cache_name, cache in self.cache_pools.items():
            if isinstance(cache, dict):
                stats[f"{cache_name}_size"] = len(cache)
                stats[f"{cache_name}_capacity"] = self.cache_config.get(f"{cache_name}_size", 1000)
                
                # è¨ˆç®—ç·©å­˜ä½¿ç”¨ç‡
                capacity = self.cache_config.get(f"{cache_name}_size", 1000)
                stats[f"{cache_name}_usage"] = (len(cache) / capacity) * 100 if capacity > 0 else 0
        
        return stats
    
    async def get_optimization_statistics(self) -> Dict[str, Any]:
        """ç²å–å„ªåŒ–çµ±è¨ˆ"""
        try:
            stats = {
                "optimization_stats": self.optimization_stats.copy(),
                "system_stats": {},
                "cache_stats": await self._get_cache_statistics(),
                "recent_optimizations": [],
                "performance_trends": {}
            }
            
            # ç³»çµ±çµ±è¨ˆ
            if self.system_resources:
                latest_resource = self.system_resources[-1]
                stats["system_stats"] = {
                    "cpu_percent": latest_resource.cpu_percent,
                    "memory_percent": latest_resource.memory_percent,
                    "active_threads": latest_resource.active_threads,
                    "open_files": latest_resource.open_files,
                    "uptime": time.time() - self.start_time
                }
            
            # æœ€è¿‘å„ªåŒ–
            if self.optimization_history:
                stats["recent_optimizations"] = [
                    {
                        "type": opt.optimization_type.value,
                        "improvement": opt.improvement_percentage,
                        "execution_time": opt.execution_time,
                        "timestamp": opt.timestamp,
                        "recommendations": opt.recommendations
                    }
                    for opt in list(self.optimization_history)[-10:]  # æœ€è¿‘10æ¬¡å„ªåŒ–
                ]
            
            # æ€§èƒ½è¶¨å‹¢
            if self.performance_metrics:
                for metric_name, metrics in self.performance_metrics.items():
                    if metrics:
                        recent_metrics = list(metrics)[-10:]  # æœ€è¿‘10å€‹æŒ‡æ¨™
                        stats["performance_trends"][metric_name] = {
                            "current": recent_metrics[-1].value if recent_metrics else 0,
                            "average": np.mean([m.value for m in recent_metrics]),
                            "trend": "improving" if len(recent_metrics) > 1 and recent_metrics[-1].value < recent_metrics[0].value else "stable"
                        }
            
            return stats
            
        except Exception as e:
            logger.error(f"âŒ ç²å–å„ªåŒ–çµ±è¨ˆå¤±æ•—: {e}")
            return {"error": str(e)}
    
    async def cleanup(self):
        """æ¸…ç†è³‡æº"""
        logger.info("ğŸ§¹ æ¸…ç†æ€§èƒ½å„ªåŒ–ç³»çµ±...")
        
        # åœæ­¢ç›£æ§
        self.monitoring_active = False
        
        # å–æ¶ˆç›£æ§ä»»å‹™
        for task in self.monitoring_tasks + self.optimization_tasks:
            task.cancel()
            try:
                await task
            except asyncio.CancelledError:
                pass
        
        # é—œé–‰ç·šç¨‹æ± 
        for pool_name, pool in self.thread_pools.items():
            pool.shutdown(wait=True)
        
        # æ¸…ç†ç·©å­˜
        for cache in self.cache_pools.values():
            if isinstance(cache, dict):
                cache.clear()
        
        # åœæ­¢å…§å­˜è·Ÿè¹¤
        if tracemalloc.is_tracing():
            tracemalloc.stop()
        
        # æ¸…ç†æ•¸æ“šçµæ§‹
        self.optimization_history.clear()
        self.performance_metrics.clear()
        self.system_resources.clear()
        
        logger.info("âœ… æ€§èƒ½å„ªåŒ–ç³»çµ±æ¸…ç†å®Œæˆ")

# å…¨å±€å„ªåŒ–ç³»çµ±å¯¦ä¾‹
performance_optimizer = None

async def get_performance_optimizer() -> PerformanceOptimizationSystem:
    """ç²å–æ€§èƒ½å„ªåŒ–ç³»çµ±å¯¦ä¾‹"""
    global performance_optimizer
    
    if performance_optimizer is None:
        performance_optimizer = PerformanceOptimizationSystem()
        await performance_optimizer.initialize()
    
    return performance_optimizer

async def initialize_performance_optimizer() -> PerformanceOptimizationSystem:
    """åˆå§‹åŒ–æ€§èƒ½å„ªåŒ–ç³»çµ±"""
    global performance_optimizer
    
    if performance_optimizer is not None:
        await performance_optimizer.cleanup()
    
    performance_optimizer = PerformanceOptimizationSystem()
    await performance_optimizer.initialize()
    
    return performance_optimizer

# æ¸¬è©¦å‡½æ•¸
async def main():
    """æ¸¬è©¦æ€§èƒ½å„ªåŒ–ç³»çµ±"""
    print("ğŸ§ª æ¸¬è©¦æ€§èƒ½å„ªåŒ–ç³»çµ±...")
    
    # åˆå§‹åŒ–å„ªåŒ–ç³»çµ±
    optimizer = await initialize_performance_optimizer()
    
    # é‹è¡Œä¸€æ®µæ™‚é–“è§€å¯Ÿå„ªåŒ–æ•ˆæœ
    await asyncio.sleep(10)
    
    # æ‰‹å‹•è§¸ç™¼å„ªåŒ–
    await optimizer._execute_optimization(OptimizationType.MEMORY_OPTIMIZATION)
    await optimizer._execute_optimization(OptimizationType.GARBAGE_COLLECTION_OPTIMIZATION)
    
    # ç²å–çµ±è¨ˆä¿¡æ¯
    stats = await optimizer.get_optimization_statistics()
    print(f"ğŸ“Š å„ªåŒ–çµ±è¨ˆ: {json.dumps(stats, indent=2, ensure_ascii=False)}")
    
    # æ¸…ç†
    await optimizer.cleanup()
    print("âœ… æ¸¬è©¦å®Œæˆ")

if __name__ == "__main__":
    asyncio.run(main())