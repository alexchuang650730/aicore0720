#!/usr/bin/env python3
"""
PowerAutomation End-to-End Test Workflow System
ç«¯åˆ°ç«¯æ¸¬è©¦å·¥ä½œæµç³»çµ±

åŠŸèƒ½ï¼š
- å®Œæ•´çš„E2Eæ¸¬è©¦ç·¨æ’å’ŒåŸ·è¡Œ
- è·¨å¹³å°æ¸¬è©¦ç’°å¢ƒç®¡ç†
- è‡ªå‹•åŒ–æ¸¬è©¦æ•¸æ“šæº–å‚™
- æ¸¬è©¦çµæœæ”¶é›†å’Œåˆ†æ
- èˆ‡CI/CDç®¡é“æ·±åº¦é›†æˆ
- æ¸¬è©¦å ±å‘Šå’Œå¯è¦–åŒ–

Author: PowerAutomation Team
Version: 1.0.0
"""

import asyncio
import json
import logging
import os
import sys
import time
import uuid
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple, Union
from dataclasses import dataclass, asdict
from enum import Enum
import subprocess
import tempfile
import shutil

import pytest
import selenium
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service as ChromeService
from selenium.webdriver.firefox.service import Service as FirefoxService
import requests
import docker
import yaml


class TestEnvironment(Enum):
    """æ¸¬è©¦ç’°å¢ƒæšèˆ‰"""
    LOCAL = "local"
    DOCKER = "docker"
    STAGING = "staging"
    PRODUCTION = "production"
    CLOUD = "cloud"


class TestType(Enum):
    """æ¸¬è©¦é¡å‹æšèˆ‰"""
    UNIT = "unit"
    INTEGRATION = "integration"
    E2E = "e2e"
    PERFORMANCE = "performance"
    SECURITY = "security"
    COMPATIBILITY = "compatibility"


class TestStatus(Enum):
    """æ¸¬è©¦ç‹€æ…‹æšèˆ‰"""
    PENDING = "pending"
    RUNNING = "running"
    PASSED = "passed"
    FAILED = "failed"
    SKIPPED = "skipped"
    ERROR = "error"


@dataclass
class TestCase:
    """æ¸¬è©¦ç”¨ä¾‹æ•¸æ“šé¡"""
    id: str
    name: str
    description: str
    test_type: TestType
    environment: TestEnvironment
    tags: List[str]
    priority: int  # 1-5, 5 ç‚ºæœ€é«˜å„ªå…ˆç´š
    estimated_duration: int  # é ä¼°åŸ·è¡Œæ™‚é–“(ç§’)
    dependencies: List[str]
    preconditions: List[str]
    steps: List[Dict[str, Any]]
    expected_results: List[str]
    test_data: Dict[str, Any]
    status: TestStatus
    start_time: Optional[datetime]
    end_time: Optional[datetime]
    error_message: Optional[str]
    screenshots: List[str]
    logs: List[str]
    
    def to_dict(self) -> Dict[str, Any]:
        """è½‰æ›ç‚ºå­—å…¸æ ¼å¼"""
        return {
            **asdict(self),
            'test_type': self.test_type.value,
            'environment': self.environment.value,
            'status': self.status.value,
            'start_time': self.start_time.isoformat() if self.start_time else None,
            'end_time': self.end_time.isoformat() if self.end_time else None
        }


@dataclass
class TestSuite:
    """æ¸¬è©¦å¥—ä»¶æ•¸æ“šé¡"""
    id: str
    name: str
    description: str
    test_cases: List[TestCase]
    environment: TestEnvironment
    parallel_execution: bool
    max_workers: int
    timeout: int  # å¥—ä»¶ç¸½è¶…æ™‚æ™‚é–“(ç§’)
    setup_scripts: List[str]
    teardown_scripts: List[str]
    status: TestStatus
    start_time: Optional[datetime]
    end_time: Optional[datetime]
    passed_count: int
    failed_count: int
    skipped_count: int
    
    def to_dict(self) -> Dict[str, Any]:
        """è½‰æ›ç‚ºå­—å…¸æ ¼å¼"""
        return {
            'id': self.id,
            'name': self.name,
            'description': self.description,
            'test_cases': [tc.to_dict() for tc in self.test_cases],
            'environment': self.environment.value,
            'parallel_execution': self.parallel_execution,
            'max_workers': self.max_workers,
            'timeout': self.timeout,
            'setup_scripts': self.setup_scripts,
            'teardown_scripts': self.teardown_scripts,
            'status': self.status.value,
            'start_time': self.start_time.isoformat() if self.start_time else None,
            'end_time': self.end_time.isoformat() if self.end_time else None,
            'passed_count': self.passed_count,
            'failed_count': self.failed_count,
            'skipped_count': self.skipped_count
        }


class EnvironmentManager:
    """æ¸¬è©¦ç’°å¢ƒç®¡ç†å™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.docker_client = docker.from_env() if self._is_docker_available() else None
        self.active_containers = {}
        
    def _is_docker_available(self) -> bool:
        """æª¢æŸ¥Dockeræ˜¯å¦å¯ç”¨"""
        try:
            docker.from_env().ping()
            return True
        except:
            return False
    
    async def setup_environment(self, environment: TestEnvironment, config: Dict[str, Any]) -> Dict[str, Any]:
        """è¨­ç½®æ¸¬è©¦ç’°å¢ƒ"""
        self.logger.info(f"æ­£åœ¨è¨­ç½®æ¸¬è©¦ç’°å¢ƒ: {environment.value}")
        
        if environment == TestEnvironment.LOCAL:
            return await self._setup_local_environment(config)
        elif environment == TestEnvironment.DOCKER:
            return await self._setup_docker_environment(config)
        elif environment == TestEnvironment.STAGING:
            return await self._setup_staging_environment(config)
        elif environment == TestEnvironment.CLOUD:
            return await self._setup_cloud_environment(config)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ç’°å¢ƒé¡å‹: {environment}")
    
    async def _setup_local_environment(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """è¨­ç½®æœ¬åœ°æ¸¬è©¦ç’°å¢ƒ"""
        env_info = {
            'type': 'local',
            'base_url': config.get('base_url', 'http://localhost:3000'),
            'api_url': config.get('api_url', 'http://localhost:8000'),
            'database_url': config.get('database_url', 'sqlite:///test.db'),
            'browser': config.get('browser', 'chrome')
        }
        
        # å•Ÿå‹•æœ¬åœ°æœå‹™
        services = config.get('services', [])
        for service in services:
            await self._start_local_service(service)
        
        # ç­‰å¾…æœå‹™å°±ç·’
        await self._wait_for_services(env_info)
        
        return env_info
    
    async def _setup_docker_environment(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """è¨­ç½®Dockeræ¸¬è©¦ç’°å¢ƒ"""
        if not self.docker_client:
            raise RuntimeError("Dockerä¸å¯ç”¨")
        
        compose_file = config.get('compose_file', 'docker-compose.test.yml')
        network_name = f"test_network_{uuid.uuid4().hex[:8]}"
        
        # å‰µå»ºæ¸¬è©¦ç¶²çµ¡
        network = self.docker_client.networks.create(network_name)
        
        # å•Ÿå‹•å®¹å™¨
        containers = []
        for service_config in config.get('services', []):
            container = await self._start_docker_container(service_config, network_name)
            containers.append(container)
            self.active_containers[container.id] = container
        
        # ç²å–æœå‹™ç«¯é»
        env_info = {
            'type': 'docker',
            'network': network_name,
            'containers': [c.id for c in containers],
            'base_url': await self._get_service_url('web', containers),
            'api_url': await self._get_service_url('api', containers),
            'database_url': await self._get_service_url('database', containers)
        }
        
        # ç­‰å¾…æœå‹™å°±ç·’
        await self._wait_for_services(env_info)
        
        return env_info
    
    async def _start_docker_container(self, service_config: Dict[str, Any], network_name: str):
        """å•Ÿå‹•Dockerå®¹å™¨"""
        container = self.docker_client.containers.run(
            image=service_config['image'],
            name=f"{service_config['name']}_{uuid.uuid4().hex[:8]}",
            environment=service_config.get('environment', {}),
            ports=service_config.get('ports', {}),
            volumes=service_config.get('volumes', {}),
            network=network_name,
            detach=True,
            remove=True
        )
        
        self.logger.info(f"å•Ÿå‹•å®¹å™¨: {container.name}")
        return container
    
    async def _wait_for_services(self, env_info: Dict[str, Any]):
        """ç­‰å¾…æœå‹™å°±ç·’"""
        max_retries = 30
        retry_interval = 2
        
        for i in range(max_retries):
            try:
                # æª¢æŸ¥Webæœå‹™
                if 'base_url' in env_info:
                    response = requests.get(f"{env_info['base_url']}/health", timeout=5)
                    if response.status_code != 200:
                        raise requests.RequestException()
                
                # æª¢æŸ¥APIæœå‹™
                if 'api_url' in env_info:
                    response = requests.get(f"{env_info['api_url']}/health", timeout=5)
                    if response.status_code != 200:
                        raise requests.RequestException()
                
                self.logger.info("æ‰€æœ‰æœå‹™å·²å°±ç·’")
                return
                
            except Exception as e:
                if i == max_retries - 1:
                    raise RuntimeError(f"æœå‹™å•Ÿå‹•è¶…æ™‚: {e}")
                
                await asyncio.sleep(retry_interval)
    
    async def cleanup_environment(self, env_info: Dict[str, Any]):
        """æ¸…ç†æ¸¬è©¦ç’°å¢ƒ"""
        env_type = env_info.get('type')
        
        if env_type == 'docker':
            # æ¸…ç†Dockerå®¹å™¨å’Œç¶²çµ¡
            for container_id in env_info.get('containers', []):
                try:
                    container = self.docker_client.containers.get(container_id)
                    container.stop(timeout=10)
                    container.remove()
                    self.logger.info(f"æ¸…ç†å®¹å™¨: {container_id}")
                except Exception as e:
                    self.logger.warning(f"æ¸…ç†å®¹å™¨å¤±æ•—: {e}")
            
            # æ¸…ç†ç¶²çµ¡
            if 'network' in env_info:
                try:
                    network = self.docker_client.networks.get(env_info['network'])
                    network.remove()
                    self.logger.info(f"æ¸…ç†ç¶²çµ¡: {env_info['network']}")
                except Exception as e:
                    self.logger.warning(f"æ¸…ç†ç¶²çµ¡å¤±æ•—: {e}")


class WebDriverManager:
    """WebDriverç®¡ç†å™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.drivers = {}
        self.logger = logging.getLogger(__name__)
    
    def get_driver(self, browser: str = "chrome", headless: bool = True) -> webdriver.Remote:
        """ç²å–WebDriverå¯¦ä¾‹"""
        driver_key = f"{browser}_{headless}"
        
        if driver_key in self.drivers:
            return self.drivers[driver_key]
        
        if browser.lower() == "chrome":
            options = webdriver.ChromeOptions()
            if headless:
                options.add_argument("--headless")
            options.add_argument("--no-sandbox")
            options.add_argument("--disable-dev-shm-usage")
            options.add_argument("--disable-gpu")
            options.add_argument("--window-size=1920,1080")
            
            driver = webdriver.Chrome(options=options)
            
        elif browser.lower() == "firefox":
            options = webdriver.FirefoxOptions()
            if headless:
                options.add_argument("--headless")
            
            driver = webdriver.Firefox(options=options)
            
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ç€è¦½å™¨: {browser}")
        
        # è¨­ç½®éš±å¼ç­‰å¾…
        driver.implicitly_wait(10)
        
        self.drivers[driver_key] = driver
        return driver
    
    def cleanup_drivers(self):
        """æ¸…ç†æ‰€æœ‰WebDriver"""
        for driver_key, driver in self.drivers.items():
            try:
                driver.quit()
                self.logger.info(f"æ¸…ç†WebDriver: {driver_key}")
            except Exception as e:
                self.logger.warning(f"æ¸…ç†WebDriverå¤±æ•—: {e}")
        
        self.drivers.clear()


class TestDataManager:
    """æ¸¬è©¦æ•¸æ“šç®¡ç†å™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.test_data_dir = Path(config.get('test_data_dir', 'test_data'))
        self.test_data_dir.mkdir(exist_ok=True)
        self.logger = logging.getLogger(__name__)
    
    def load_test_data(self, test_case_id: str) -> Dict[str, Any]:
        """åŠ è¼‰æ¸¬è©¦æ•¸æ“š"""
        data_file = self.test_data_dir / f"{test_case_id}.json"
        
        if data_file.exists():
            with open(data_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        
        # ç”Ÿæˆé»˜èªæ¸¬è©¦æ•¸æ“š
        return self._generate_default_data(test_case_id)
    
    def _generate_default_data(self, test_case_id: str) -> Dict[str, Any]:
        """ç”Ÿæˆé»˜èªæ¸¬è©¦æ•¸æ“š"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        return {
            'user': {
                'username': f'test_user_{timestamp}',
                'email': f'test_{timestamp}@example.com',
                'password': 'Test123!@#',
                'name': f'Test User {timestamp}'
            },
            'project': {
                'name': f'Test Project {timestamp}',
                'description': f'Automated test project created at {timestamp}',
                'type': 'web_application'
            },
            'file': {
                'name': f'test_file_{timestamp}.txt',
                'content': f'Test content generated at {timestamp}',
                'size': 1024
            }
        }
    
    def save_test_data(self, test_case_id: str, data: Dict[str, Any]):
        """ä¿å­˜æ¸¬è©¦æ•¸æ“š"""
        data_file = self.test_data_dir / f"{test_case_id}.json"
        
        with open(data_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)


class E2ETestExecutor:
    """ç«¯åˆ°ç«¯æ¸¬è©¦åŸ·è¡Œå™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = self._setup_logging()
        self.env_manager = EnvironmentManager(config)
        self.driver_manager = WebDriverManager(config)
        self.data_manager = TestDataManager(config)
        self.results_dir = Path(config.get('results_dir', 'test_results'))
        self.results_dir.mkdir(exist_ok=True)
        self.screenshots_dir = self.results_dir / 'screenshots'
        self.screenshots_dir.mkdir(exist_ok=True)
    
    def _setup_logging(self) -> logging.Logger:
        """è¨­ç½®æ—¥å¿—ç³»çµ±"""
        logger = logging.getLogger('e2e_test_executor')
        logger.setLevel(logging.INFO)
        
        # æ–‡ä»¶è™•ç†å™¨
        log_dir = Path('logs')
        log_dir.mkdir(exist_ok=True)
        
        file_handler = logging.FileHandler(
            log_dir / f'e2e_tests_{datetime.now().strftime("%Y%m%d")}.log',
            encoding='utf-8'
        )
        file_handler.setLevel(logging.INFO)
        
        # æ§åˆ¶å°è™•ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # æ ¼å¼åŒ–å™¨
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        logger.addHandler(file_handler)
        logger.addHandler(console_handler)
        
        return logger
    
    async def execute_test_suite(self, test_suite: TestSuite) -> TestSuite:
        """åŸ·è¡Œæ¸¬è©¦å¥—ä»¶"""
        self.logger.info(f"é–‹å§‹åŸ·è¡Œæ¸¬è©¦å¥—ä»¶: {test_suite.name}")
        test_suite.start_time = datetime.now()
        test_suite.status = TestStatus.RUNNING
        
        try:
            # è¨­ç½®æ¸¬è©¦ç’°å¢ƒ
            env_info = await self.env_manager.setup_environment(
                test_suite.environment,
                self.config.get('environments', {}).get(test_suite.environment.value, {})
            )
            
            # åŸ·è¡Œè¨­ç½®è…³æœ¬
            await self._run_setup_scripts(test_suite.setup_scripts, env_info)
            
            # åŸ·è¡Œæ¸¬è©¦ç”¨ä¾‹
            if test_suite.parallel_execution:
                await self._execute_tests_parallel(test_suite, env_info)
            else:
                await self._execute_tests_sequential(test_suite, env_info)
            
            # åŸ·è¡Œæ¸…ç†è…³æœ¬
            await self._run_teardown_scripts(test_suite.teardown_scripts, env_info)
            
            # æ›´æ–°å¥—ä»¶ç‹€æ…‹
            test_suite.passed_count = sum(1 for tc in test_suite.test_cases if tc.status == TestStatus.PASSED)
            test_suite.failed_count = sum(1 for tc in test_suite.test_cases if tc.status == TestStatus.FAILED)
            test_suite.skipped_count = sum(1 for tc in test_suite.test_cases if tc.status == TestStatus.SKIPPED)
            
            if test_suite.failed_count > 0:
                test_suite.status = TestStatus.FAILED
            else:
                test_suite.status = TestStatus.PASSED
            
        except Exception as e:
            self.logger.error(f"æ¸¬è©¦å¥—ä»¶åŸ·è¡Œå¤±æ•—: {e}")
            test_suite.status = TestStatus.ERROR
            
        finally:
            test_suite.end_time = datetime.now()
            
            # æ¸…ç†ç’°å¢ƒ
            try:
                await self.env_manager.cleanup_environment(env_info)
            except Exception as e:
                self.logger.warning(f"ç’°å¢ƒæ¸…ç†å¤±æ•—: {e}")
        
        self.logger.info(f"æ¸¬è©¦å¥—ä»¶åŸ·è¡Œå®Œæˆ: {test_suite.name}")
        return test_suite
    
    async def _execute_tests_sequential(self, test_suite: TestSuite, env_info: Dict[str, Any]):
        """é †åºåŸ·è¡Œæ¸¬è©¦ç”¨ä¾‹"""
        for test_case in test_suite.test_cases:
            if self._should_skip_test(test_case, test_suite):
                test_case.status = TestStatus.SKIPPED
                continue
            
            await self._execute_test_case(test_case, env_info)
    
    async def _execute_tests_parallel(self, test_suite: TestSuite, env_info: Dict[str, Any]):
        """ä¸¦è¡ŒåŸ·è¡Œæ¸¬è©¦ç”¨ä¾‹"""
        # æ ¹æ“šä¾è³´é—œä¿‚åˆ†çµ„æ¸¬è©¦ç”¨ä¾‹
        test_groups = self._group_tests_by_dependencies(test_suite.test_cases)
        
        for group in test_groups:
            # æ¯çµ„å…§ä¸¦è¡ŒåŸ·è¡Œ
            semaphore = asyncio.Semaphore(test_suite.max_workers)
            tasks = []
            
            for test_case in group:
                if not self._should_skip_test(test_case, test_suite):
                    task = self._execute_test_case_with_semaphore(test_case, env_info, semaphore)
                    tasks.append(task)
                else:
                    test_case.status = TestStatus.SKIPPED
            
            if tasks:
                await asyncio.gather(*tasks, return_exceptions=True)
    
    async def _execute_test_case_with_semaphore(self, test_case: TestCase, env_info: Dict[str, Any], semaphore: asyncio.Semaphore):
        """å¸¶ä¿¡è™Ÿé‡çš„æ¸¬è©¦ç”¨ä¾‹åŸ·è¡Œ"""
        async with semaphore:
            await self._execute_test_case(test_case, env_info)
    
    async def _execute_test_case(self, test_case: TestCase, env_info: Dict[str, Any]):
        """åŸ·è¡Œå–®å€‹æ¸¬è©¦ç”¨ä¾‹"""
        self.logger.info(f"åŸ·è¡Œæ¸¬è©¦ç”¨ä¾‹: {test_case.name}")
        test_case.start_time = datetime.now()
        test_case.status = TestStatus.RUNNING
        
        try:
            # åŠ è¼‰æ¸¬è©¦æ•¸æ“š
            test_data = self.data_manager.load_test_data(test_case.id)
            test_case.test_data.update(test_data)
            
            # æª¢æŸ¥å‰ç½®æ¢ä»¶
            if not await self._check_preconditions(test_case, env_info):
                test_case.status = TestStatus.SKIPPED
                test_case.error_message = "å‰ç½®æ¢ä»¶ä¸æ»¿è¶³"
                return
            
            # åŸ·è¡Œæ¸¬è©¦æ­¥é©Ÿ
            driver = None
            if test_case.test_type in [TestType.E2E, TestType.INTEGRATION]:
                browser = env_info.get('browser', 'chrome')
                driver = self.driver_manager.get_driver(browser, headless=True)
            
            for i, step in enumerate(test_case.steps):
                await self._execute_test_step(step, test_case, env_info, driver, i)
            
            # é©—è­‰æ¸¬è©¦çµæœ
            await self._verify_test_results(test_case, env_info, driver)
            
            test_case.status = TestStatus.PASSED
            
        except Exception as e:
            self.logger.error(f"æ¸¬è©¦ç”¨ä¾‹åŸ·è¡Œå¤±æ•—: {test_case.name}, éŒ¯èª¤: {e}")
            test_case.status = TestStatus.FAILED
            test_case.error_message = str(e)
            
            # æˆªåœ–ä¿å­˜éŒ¯èª¤å ´æ™¯
            if driver:
                screenshot_path = await self._take_screenshot(driver, test_case.id, "error")
                if screenshot_path:
                    test_case.screenshots.append(screenshot_path)
        
        finally:
            test_case.end_time = datetime.now()
    
    async def _execute_test_step(self, step: Dict[str, Any], test_case: TestCase, env_info: Dict[str, Any], driver, step_index: int):
        """åŸ·è¡Œæ¸¬è©¦æ­¥é©Ÿ"""
        action = step.get('action')
        params = step.get('params', {})
        
        self.logger.debug(f"åŸ·è¡Œæ­¥é©Ÿ {step_index + 1}: {action}")
        
        if action == 'navigate':
            url = params['url'].format(**test_case.test_data, **env_info)
            driver.get(url)
            
        elif action == 'click':
            locator = params['locator']
            element = self._find_element(driver, locator)
            element.click()
            
        elif action == 'input':
            locator = params['locator']
            value = params['value'].format(**test_case.test_data)
            element = self._find_element(driver, locator)
            element.clear()
            element.send_keys(value)
            
        elif action == 'wait':
            wait_time = params.get('time', 1)
            await asyncio.sleep(wait_time)
            
        elif action == 'wait_for_element':
            locator = params['locator']
            timeout = params.get('timeout', 10)
            WebDriverWait(driver, timeout).until(
                EC.presence_of_element_located(self._parse_locator(locator))
            )
            
        elif action == 'screenshot':
            screenshot_path = await self._take_screenshot(driver, test_case.id, f"step_{step_index + 1}")
            if screenshot_path:
                test_case.screenshots.append(screenshot_path)
        
        elif action == 'api_call':
            await self._make_api_call(params, test_case, env_info)
            
        elif action == 'validate':
            await self._validate_condition(params, test_case, driver, env_info)
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ“ä½œ: {action}")
    
    def _find_element(self, driver, locator: str):
        """æŸ¥æ‰¾é é¢å…ƒç´ """
        by, value = self._parse_locator(locator)
        return driver.find_element(by, value)
    
    def _parse_locator(self, locator: str) -> Tuple[str, str]:
        """è§£æå®šä½å™¨"""
        if locator.startswith('id='):
            return By.ID, locator[3:]
        elif locator.startswith('class='):
            return By.CLASS_NAME, locator[6:]
        elif locator.startswith('css='):
            return By.CSS_SELECTOR, locator[4:]
        elif locator.startswith('xpath='):
            return By.XPATH, locator[6:]
        elif locator.startswith('name='):
            return By.NAME, locator[5:]
        else:
            # é»˜èªä½¿ç”¨CSSé¸æ“‡å™¨
            return By.CSS_SELECTOR, locator
    
    async def _take_screenshot(self, driver, test_case_id: str, suffix: str = "") -> Optional[str]:
        """æˆªåœ–"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"{test_case_id}_{suffix}_{timestamp}.png"
            filepath = self.screenshots_dir / filename
            
            driver.save_screenshot(str(filepath))
            return str(filepath)
            
        except Exception as e:
            self.logger.warning(f"æˆªåœ–å¤±æ•—: {e}")
            return None
    
    async def _make_api_call(self, params: Dict[str, Any], test_case: TestCase, env_info: Dict[str, Any]):
        """é€²è¡ŒAPIèª¿ç”¨"""
        method = params['method'].upper()
        url = params['url'].format(**test_case.test_data, **env_info)
        headers = params.get('headers', {})
        data = params.get('data', {})
        
        # æ ¼å¼åŒ–è«‹æ±‚æ•¸æ“š
        if isinstance(data, dict):
            for key, value in data.items():
                if isinstance(value, str):
                    data[key] = value.format(**test_case.test_data)
        
        response = requests.request(method, url, headers=headers, json=data, timeout=30)
        
        # ä¿å­˜éŸ¿æ‡‰åˆ°æ¸¬è©¦æ•¸æ“š
        test_case.test_data['last_api_response'] = {
            'status_code': response.status_code,
            'headers': dict(response.headers),
            'json': response.json() if response.headers.get('content-type', '').startswith('application/json') else None,
            'text': response.text
        }
        
        # æª¢æŸ¥éŸ¿æ‡‰ç‹€æ…‹
        expected_status = params.get('expected_status', 200)
        if response.status_code != expected_status:
            raise AssertionError(f"APIèª¿ç”¨å¤±æ•—: æœŸæœ›ç‹€æ…‹ç¢¼ {expected_status}, å¯¦éš› {response.status_code}")
    
    async def _validate_condition(self, params: Dict[str, Any], test_case: TestCase, driver, env_info: Dict[str, Any]):
        """é©—è­‰æ¢ä»¶"""
        condition_type = params['type']
        
        if condition_type == 'element_text':
            locator = params['locator']
            expected_text = params['expected'].format(**test_case.test_data)
            element = self._find_element(driver, locator)
            actual_text = element.text
            
            if actual_text != expected_text:
                raise AssertionError(f"æ–‡æœ¬é©—è­‰å¤±æ•—: æœŸæœ› '{expected_text}', å¯¦éš› '{actual_text}'")
        
        elif condition_type == 'element_exists':
            locator = params['locator']
            try:
                self._find_element(driver, locator)
            except:
                raise AssertionError(f"å…ƒç´ ä¸å­˜åœ¨: {locator}")
        
        elif condition_type == 'api_response':
            field_path = params['field']
            expected_value = params['expected']
            
            response_data = test_case.test_data.get('last_api_response', {})
            actual_value = self._get_nested_value(response_data, field_path)
            
            if actual_value != expected_value:
                raise AssertionError(f"APIéŸ¿æ‡‰é©—è­‰å¤±æ•—: æœŸæœ› {expected_value}, å¯¦éš› {actual_value}")
    
    def _get_nested_value(self, data: Dict[str, Any], path: str) -> Any:
        """ç²å–åµŒå¥—å­—å…¸å€¼"""
        keys = path.split('.')
        current = data
        
        for key in keys:
            if isinstance(current, dict) and key in current:
                current = current[key]
            else:
                return None
        
        return current
    
    def _should_skip_test(self, test_case: TestCase, test_suite: TestSuite) -> bool:
        """åˆ¤æ–·æ˜¯å¦æ‡‰è©²è·³éæ¸¬è©¦"""
        # æª¢æŸ¥ä¾è³´çš„æ¸¬è©¦æ˜¯å¦å·²å®Œæˆ
        for dep_id in test_case.dependencies:
            dep_test = next((tc for tc in test_suite.test_cases if tc.id == dep_id), None)
            if dep_test and dep_test.status != TestStatus.PASSED:
                return True
        
        return False
    
    def _group_tests_by_dependencies(self, test_cases: List[TestCase]) -> List[List[TestCase]]:
        """æ ¹æ“šä¾è³´é—œä¿‚å°æ¸¬è©¦ç”¨ä¾‹åˆ†çµ„"""
        groups = []
        remaining = test_cases.copy()
        processed = set()
        
        while remaining:
            current_group = []
            
            # æ‰¾åˆ°æ²’æœ‰æœªè™•ç†ä¾è³´çš„æ¸¬è©¦ç”¨ä¾‹
            for test_case in remaining.copy():
                deps_satisfied = all(dep_id in processed for dep_id in test_case.dependencies)
                if deps_satisfied:
                    current_group.append(test_case)
                    remaining.remove(test_case)
                    processed.add(test_case.id)
            
            if not current_group:
                # å¦‚æœæ²’æœ‰æ‰¾åˆ°å¯åŸ·è¡Œçš„æ¸¬è©¦ç”¨ä¾‹ï¼Œå¯èƒ½å­˜åœ¨å¾ªç’°ä¾è³´
                # å°‡å‰©é¤˜çš„æ¸¬è©¦ç”¨ä¾‹å¼·åˆ¶åŠ å…¥ç•¶å‰çµ„
                current_group = remaining.copy()
                remaining.clear()
                for tc in current_group:
                    processed.add(tc.id)
            
            groups.append(current_group)
        
        return groups
    
    async def _check_preconditions(self, test_case: TestCase, env_info: Dict[str, Any]) -> bool:
        """æª¢æŸ¥å‰ç½®æ¢ä»¶"""
        for condition in test_case.preconditions:
            if condition.startswith('service_available:'):
                service_url = condition.split(':', 1)[1].format(**env_info)
                try:
                    response = requests.get(service_url, timeout=5)
                    if response.status_code != 200:
                        return False
                except:
                    return False
            
            elif condition.startswith('file_exists:'):
                file_path = condition.split(':', 1)[1]
                if not Path(file_path).exists():
                    return False
        
        return True
    
    async def _verify_test_results(self, test_case: TestCase, env_info: Dict[str, Any], driver):
        """é©—è­‰æ¸¬è©¦çµæœ"""
        for expected_result in test_case.expected_results:
            # æ ¹æ“šæœŸæœ›çµæœé¡å‹é€²è¡Œé©—è­‰
            if expected_result.startswith('page_title:'):
                expected_title = expected_result.split(':', 1)[1]
                actual_title = driver.title
                if actual_title != expected_title:
                    raise AssertionError(f"é é¢æ¨™é¡Œé©—è­‰å¤±æ•—: æœŸæœ› '{expected_title}', å¯¦éš› '{actual_title}'")
            
            elif expected_result.startswith('url_contains:'):
                expected_url_part = expected_result.split(':', 1)[1]
                current_url = driver.current_url
                if expected_url_part not in current_url:
                    raise AssertionError(f"URLé©—è­‰å¤±æ•—: '{expected_url_part}' ä¸åœ¨ '{current_url}' ä¸­")
    
    async def _run_setup_scripts(self, scripts: List[str], env_info: Dict[str, Any]):
        """é‹è¡Œè¨­ç½®è…³æœ¬"""
        for script in scripts:
            self.logger.info(f"é‹è¡Œè¨­ç½®è…³æœ¬: {script}")
            try:
                result = subprocess.run(script, shell=True, capture_output=True, text=True, timeout=300)
                if result.returncode != 0:
                    raise RuntimeError(f"è¨­ç½®è…³æœ¬å¤±æ•—: {result.stderr}")
            except subprocess.TimeoutExpired:
                raise RuntimeError(f"è¨­ç½®è…³æœ¬è¶…æ™‚: {script}")
    
    async def _run_teardown_scripts(self, scripts: List[str], env_info: Dict[str, Any]):
        """é‹è¡Œæ¸…ç†è…³æœ¬"""
        for script in scripts:
            self.logger.info(f"é‹è¡Œæ¸…ç†è…³æœ¬: {script}")
            try:
                result = subprocess.run(script, shell=True, capture_output=True, text=True, timeout=300)
                if result.returncode != 0:
                    self.logger.warning(f"æ¸…ç†è…³æœ¬å¤±æ•—: {result.stderr}")
            except subprocess.TimeoutExpired:
                self.logger.warning(f"æ¸…ç†è…³æœ¬è¶…æ™‚: {script}")


class E2ETestWorkflow:
    """ç«¯åˆ°ç«¯æ¸¬è©¦å·¥ä½œæµä¸»é¡"""
    
    def __init__(self, config_path: str = "e2e_config.yaml"):
        self.config_path = Path(config_path)
        self.config = self._load_config()
        self.executor = E2ETestExecutor(self.config)
        self.logger = logging.getLogger(__name__)
    
    def _load_config(self) -> Dict[str, Any]:
        """åŠ è¼‰é…ç½®æ–‡ä»¶"""
        if not self.config_path.exists():
            # å‰µå»ºé»˜èªé…ç½®
            default_config = {
                'environments': {
                    'local': {
                        'base_url': 'http://localhost:3000',
                        'api_url': 'http://localhost:8000',
                        'browser': 'chrome',
                        'services': []
                    },
                    'docker': {
                        'compose_file': 'docker-compose.test.yml',
                        'services': [
                            {
                                'name': 'web',
                                'image': 'powerautomation:latest',
                                'ports': {'3000/tcp': 3000},
                                'environment': {'NODE_ENV': 'test'}
                            }
                        ]
                    }
                },
                'test_data_dir': 'test_data',
                'results_dir': 'test_results',
                'parallel_execution': True,
                'max_workers': 4,
                'default_timeout': 300
            }
            
            with open(self.config_path, 'w', encoding='utf-8') as f:
                yaml.dump(default_config, f, default_flow_style=False, allow_unicode=True)
            
            return default_config
        
        with open(self.config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def create_default_test_suite(self) -> TestSuite:
        """å‰µå»ºé»˜èªæ¸¬è©¦å¥—ä»¶"""
        
        # PowerAutomation æ ¸å¿ƒåŠŸèƒ½æ¸¬è©¦ç”¨ä¾‹
        test_cases = [
            TestCase(
                id="pa_login_test",
                name="ç”¨æˆ¶ç™»éŒ„æ¸¬è©¦",
                description="æ¸¬è©¦PowerAutomationç”¨æˆ¶ç™»éŒ„åŠŸèƒ½",
                test_type=TestType.E2E,
                environment=TestEnvironment.LOCAL,
                tags=["auth", "critical"],
                priority=5,
                estimated_duration=30,
                dependencies=[],
                preconditions=["service_available:{base_url}/health"],
                steps=[
                    {
                        "action": "navigate",
                        "params": {"url": "{base_url}/login"}
                    },
                    {
                        "action": "input",
                        "params": {
                            "locator": "id=username",
                            "value": "{user[username]}"
                        }
                    },
                    {
                        "action": "input",
                        "params": {
                            "locator": "id=password",
                            "value": "{user[password]}"
                        }
                    },
                    {
                        "action": "click",
                        "params": {"locator": "id=login-button"}
                    },
                    {
                        "action": "wait_for_element",
                        "params": {
                            "locator": "class=dashboard",
                            "timeout": 10
                        }
                    },
                    {
                        "action": "screenshot",
                        "params": {}
                    }
                ],
                expected_results=[
                    "url_contains:/dashboard",
                    "page_title:PowerAutomation Dashboard"
                ],
                test_data={},
                status=TestStatus.PENDING,
                start_time=None,
                end_time=None,
                error_message=None,
                screenshots=[],
                logs=[]
            ),
            
            TestCase(
                id="pa_project_creation_test",
                name="é …ç›®å‰µå»ºæ¸¬è©¦",
                description="æ¸¬è©¦PowerAutomationé …ç›®å‰µå»ºåŠŸèƒ½",
                test_type=TestType.E2E,
                environment=TestEnvironment.LOCAL,
                tags=["project", "core"],
                priority=4,
                estimated_duration=60,
                dependencies=["pa_login_test"],
                preconditions=[],
                steps=[
                    {
                        "action": "click",
                        "params": {"locator": "id=new-project-btn"}
                    },
                    {
                        "action": "input",
                        "params": {
                            "locator": "id=project-name",
                            "value": "{project[name]}"
                        }
                    },
                    {
                        "action": "input",
                        "params": {
                            "locator": "id=project-description",
                            "value": "{project[description]}"
                        }
                    },
                    {
                        "action": "click",
                        "params": {"locator": "id=create-project-btn"}
                    },
                    {
                        "action": "wait_for_element",
                        "params": {
                            "locator": "class=project-created-message",
                            "timeout": 15
                        }
                    },
                    {
                        "action": "validate",
                        "params": {
                            "type": "element_text",
                            "locator": "id=project-title",
                            "expected": "{project[name]}"
                        }
                    }
                ],
                expected_results=[
                    "url_contains:/project/",
                    "page_title:PowerAutomation - {project[name]}"
                ],
                test_data={},
                status=TestStatus.PENDING,
                start_time=None,
                end_time=None,
                error_message=None,
                screenshots=[],
                logs=[]
            ),
            
            TestCase(
                id="pa_ai_assistant_test",
                name="AIåŠ©æ‰‹åŠŸèƒ½æ¸¬è©¦",
                description="æ¸¬è©¦PowerAutomation AIåŠ©æ‰‹çš„å°è©±å’Œä»£ç¢¼ç”ŸæˆåŠŸèƒ½",
                test_type=TestType.E2E,
                environment=TestEnvironment.LOCAL,
                tags=["ai", "assistant", "core"],
                priority=4,
                estimated_duration=90,
                dependencies=["pa_project_creation_test"],
                preconditions=[],
                steps=[
                    {
                        "action": "click",
                        "params": {"locator": "id=ai-assistant-tab"}
                    },
                    {
                        "action": "input",
                        "params": {
                            "locator": "id=ai-chat-input",
                            "value": "è«‹å¹«æˆ‘ç”Ÿæˆä¸€å€‹Reactçµ„ä»¶"
                        }
                    },
                    {
                        "action": "click",
                        "params": {"locator": "id=send-message-btn"}
                    },
                    {
                        "action": "wait_for_element",
                        "params": {
                            "locator": "class=ai-response",
                            "timeout": 30
                        }
                    },
                    {
                        "action": "validate",
                        "params": {
                            "type": "element_exists",
                            "locator": "class=code-block"
                        }
                    },
                    {
                        "action": "screenshot",
                        "params": {}
                    }
                ],
                expected_results=[],
                test_data={},
                status=TestStatus.PENDING,
                start_time=None,
                end_time=None,
                error_message=None,
                screenshots=[],
                logs=[]
            ),
            
            TestCase(
                id="pa_api_integration_test",
                name="APIé›†æˆæ¸¬è©¦",
                description="æ¸¬è©¦PowerAutomation APIç«¯é»çš„æ­£å¸¸åŠŸèƒ½",
                test_type=TestType.INTEGRATION,
                environment=TestEnvironment.LOCAL,
                tags=["api", "integration"],
                priority=3,
                estimated_duration=45,
                dependencies=[],
                preconditions=["service_available:{api_url}/health"],
                steps=[
                    {
                        "action": "api_call",
                        "params": {
                            "method": "POST",
                            "url": "{api_url}/auth/login",
                            "data": {
                                "username": "{user[username]}",
                                "password": "{user[password]}"
                            },
                            "expected_status": 200
                        }
                    },
                    {
                        "action": "validate",
                        "params": {
                            "type": "api_response",
                            "field": "json.token",
                            "expected": "not_null"
                        }
                    },
                    {
                        "action": "api_call",
                        "params": {
                            "method": "GET",
                            "url": "{api_url}/projects",
                            "headers": {
                                "Authorization": "Bearer {last_api_response[json][token]}"
                            },
                            "expected_status": 200
                        }
                    }
                ],
                expected_results=[],
                test_data={},
                status=TestStatus.PENDING,
                start_time=None,
                end_time=None,
                error_message=None,
                screenshots=[],
                logs=[]
            )
        ]
        
        return TestSuite(
            id="powerautomation_e2e_suite",
            name="PowerAutomation ç«¯åˆ°ç«¯æ¸¬è©¦å¥—ä»¶",
            description="å®Œæ•´çš„PowerAutomationå¹³å°åŠŸèƒ½æ¸¬è©¦",
            test_cases=test_cases,
            environment=TestEnvironment.LOCAL,
            parallel_execution=self.config.get('parallel_execution', True),
            max_workers=self.config.get('max_workers', 4),
            timeout=self.config.get('default_timeout', 300),
            setup_scripts=[],
            teardown_scripts=[],
            status=TestStatus.PENDING,
            start_time=None,
            end_time=None,
            passed_count=0,
            failed_count=0,
            skipped_count=0
        )
    
    async def run_test_workflow(self, test_suite: TestSuite = None) -> TestSuite:
        """é‹è¡Œæ¸¬è©¦å·¥ä½œæµ"""
        if test_suite is None:
            test_suite = self.create_default_test_suite()
        
        self.logger.info("é–‹å§‹åŸ·è¡Œç«¯åˆ°ç«¯æ¸¬è©¦å·¥ä½œæµ")
        
        try:
            # åŸ·è¡Œæ¸¬è©¦å¥—ä»¶
            result_suite = await self.executor.execute_test_suite(test_suite)
            
            # ç”Ÿæˆæ¸¬è©¦å ±å‘Š
            await self._generate_test_report(result_suite)
            
            # ä¿å­˜æ¸¬è©¦çµæœ
            await self._save_test_results(result_suite)
            
            return result_suite
            
        except Exception as e:
            self.logger.error(f"æ¸¬è©¦å·¥ä½œæµåŸ·è¡Œå¤±æ•—: {e}")
            raise
        
        finally:
            # æ¸…ç†è³‡æº
            self.executor.driver_manager.cleanup_drivers()
    
    async def _generate_test_report(self, test_suite: TestSuite):
        """ç”Ÿæˆæ¸¬è©¦å ±å‘Š"""
        report_lines = [
            "# PowerAutomation ç«¯åˆ°ç«¯æ¸¬è©¦å ±å‘Š",
            f"**ç”Ÿæˆæ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "",
            "## ğŸ“Š æ¸¬è©¦ç¸½è¦½",
            f"**æ¸¬è©¦å¥—ä»¶**: {test_suite.name}",
            f"**æ¸¬è©¦ç’°å¢ƒ**: {test_suite.environment.value}",
            f"**åŸ·è¡Œç‹€æ…‹**: {test_suite.status.value}",
            f"**é–‹å§‹æ™‚é–“**: {test_suite.start_time.strftime('%Y-%m-%d %H:%M:%S') if test_suite.start_time else 'N/A'}",
            f"**çµæŸæ™‚é–“**: {test_suite.end_time.strftime('%Y-%m-%d %H:%M:%S') if test_suite.end_time else 'N/A'}",
            "",
            "## ğŸ“ˆ æ¸¬è©¦çµ±è¨ˆ",
            f"- **ç¸½æ¸¬è©¦æ•¸**: {len(test_suite.test_cases)}",
            f"- **é€šé**: {test_suite.passed_count} âœ…",
            f"- **å¤±æ•—**: {test_suite.failed_count} âŒ",
            f"- **è·³é**: {test_suite.skipped_count} â­ï¸",
            f"- **æˆåŠŸç‡**: {(test_suite.passed_count / len(test_suite.test_cases) * 100):.1f}%" if test_suite.test_cases else "0%",
            "",
            "## ğŸ“‹ æ¸¬è©¦ç”¨ä¾‹è©³æƒ…",
            ""
        ]
        
        for test_case in test_suite.test_cases:
            status_emoji = {
                TestStatus.PASSED: "âœ…",
                TestStatus.FAILED: "âŒ",
                TestStatus.SKIPPED: "â­ï¸",
                TestStatus.ERROR: "ğŸ’¥"
            }.get(test_case.status, "â“")
            
            duration = ""
            if test_case.start_time and test_case.end_time:
                duration = f" ({(test_case.end_time - test_case.start_time).total_seconds():.1f}s)"
            
            report_lines.extend([
                f"### {status_emoji} {test_case.name}{duration}",
                f"**ID**: {test_case.id}",
                f"**æè¿°**: {test_case.description}",
                f"**é¡å‹**: {test_case.test_type.value}",
                f"**æ¨™ç±¤**: {', '.join(test_case.tags)}",
                f"**ç‹€æ…‹**: {test_case.status.value}",
            ])
            
            if test_case.error_message:
                report_lines.append(f"**éŒ¯èª¤ä¿¡æ¯**: {test_case.error_message}")
            
            if test_case.screenshots:
                report_lines.append("**æˆªåœ–**:")
                for screenshot in test_case.screenshots:
                    report_lines.append(f"  - ![Screenshot]({screenshot})")
            
            report_lines.append("")
        
        # ä¿å­˜å ±å‘Š
        report_path = self.executor.results_dir / f"test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("\n".join(report_lines))
        
        self.logger.info(f"æ¸¬è©¦å ±å‘Šå·²ç”Ÿæˆ: {report_path}")
    
    async def _save_test_results(self, test_suite: TestSuite):
        """ä¿å­˜æ¸¬è©¦çµæœ"""
        results_path = self.executor.results_dir / f"test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        with open(results_path, 'w', encoding='utf-8') as f:
            json.dump(test_suite.to_dict(), f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"æ¸¬è©¦çµæœå·²ä¿å­˜: {results_path}")


async def main():
    """ä¸»å‡½æ•¸"""
    workflow = E2ETestWorkflow()
    
    # å‰µå»ºä¸¦é‹è¡Œé»˜èªæ¸¬è©¦å¥—ä»¶
    test_suite = workflow.create_default_test_suite()
    result = await workflow.run_test_workflow(test_suite)
    
    print(f"\nğŸ¯ æ¸¬è©¦åŸ·è¡Œå®Œæˆ!")
    print(f"ç¸½æ¸¬è©¦æ•¸: {len(result.test_cases)}")
    print(f"é€šé: {result.passed_count}")
    print(f"å¤±æ•—: {result.failed_count}")
    print(f"è·³é: {result.skipped_count}")
    print(f"æˆåŠŸç‡: {(result.passed_count / len(result.test_cases) * 100):.1f}%")


if __name__ == "__main__":
    asyncio.run(main())