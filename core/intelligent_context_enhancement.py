#!/usr/bin/env python3
"""
PowerAutomation Core æ™ºèƒ½ä¸Šä¸‹æ–‡å¢å¼·ç³»çµ±
v4.6.9.4 - ç‚º Claude Code æä¾›æ™ºèƒ½ä¸Šä¸‹æ–‡å¢å¼·
"""

import asyncio
import json
import logging
import time
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
import numpy as np
from collections import defaultdict, deque
import re
from pathlib import Path

# é›†æˆ MemoryOS MCP å’Œæ•¸æ“šæ”¶é›†ç³»çµ±
from .components.memoryos_mcp import MemoryEngine, ContextManager, LearningAdapter
from .components.memoryos_mcp import PersonalizationManager, MemoryOptimizer
from .data_collection_system import DataCollectionSystem, DataType, DataPriority
from .learning_integration import PowerAutomationLearningIntegration

logger = logging.getLogger(__name__)

class ContextType(Enum):
    """ä¸Šä¸‹æ–‡é¡å‹"""
    HISTORICAL = "historical"
    SEMANTIC = "semantic"
    PROCEDURAL = "procedural"
    PERSONAL = "personal"
    DOMAIN_SPECIFIC = "domain_specific"
    TEMPORAL = "temporal"
    COLLABORATIVE = "collaborative"
    ADAPTIVE = "adaptive"

class EnhancementStrategy(Enum):
    """å¢å¼·ç­–ç•¥"""
    SIMILAR_CONTEXT = "similar_context"
    LEARNING_PATTERN = "learning_pattern"
    USER_PREFERENCE = "user_preference"
    DOMAIN_KNOWLEDGE = "domain_knowledge"
    TEMPORAL_CONTEXT = "temporal_context"
    COLLABORATIVE_FILTER = "collaborative_filter"
    ADAPTIVE_WEIGHTING = "adaptive_weighting"

@dataclass
class ContextEnhancement:
    """ä¸Šä¸‹æ–‡å¢å¼·"""
    id: str
    query: str
    enhancement_type: ContextType
    strategy: EnhancementStrategy
    content: str
    relevance_score: float
    confidence: float
    source: str
    metadata: Dict[str, Any]
    created_at: float
    
    def to_dict(self) -> Dict[str, Any]:
        """è½‰æ›ç‚ºå­—å…¸"""
        return asdict(self)

@dataclass
class EnhancementResult:
    """å¢å¼·çµæœ"""
    query: str
    enhancements: List[ContextEnhancement]
    total_score: float
    processing_time: float
    strategies_used: List[str]
    metadata: Dict[str, Any]
    
    def to_dict(self) -> Dict[str, Any]:
        """è½‰æ›ç‚ºå­—å…¸"""
        return asdict(self)

class IntelligentContextEnhancement:
    """æ™ºèƒ½ä¸Šä¸‹æ–‡å¢å¼·ç³»çµ±"""
    
    def __init__(self, learning_integration: PowerAutomationLearningIntegration):
        self.learning_integration = learning_integration
        self.memory_engine = learning_integration.memory_engine
        self.context_manager = learning_integration.context_manager
        self.learning_adapter = learning_integration.learning_adapter
        self.personalization_manager = learning_integration.personalization_manager
        self.memory_optimizer = learning_integration.memory_optimizer
        
        # å¢å¼·ç­–ç•¥
        self.enhancement_strategies = {}
        self.strategy_weights = {}
        self.adaptive_weights = defaultdict(float)
        
        # ä¸Šä¸‹æ–‡åˆ†æå™¨
        self.context_analyzers = {}
        
        # æ€§èƒ½çµ±è¨ˆ
        self.enhancement_stats = {
            "total_enhancements": 0,
            "successful_enhancements": 0,
            "average_processing_time": 0.0,
            "strategy_usage": defaultdict(int),
            "user_feedback": defaultdict(list)
        }
        
        # å¯¦æ™‚å­¸ç¿’
        self.recent_enhancements = deque(maxlen=100)
        self.feedback_buffer = deque(maxlen=50)
        
        # æ˜¯å¦åˆå§‹åŒ–
        self.is_initialized = False
    
    async def initialize(self):
        """åˆå§‹åŒ–æ™ºèƒ½ä¸Šä¸‹æ–‡å¢å¼·ç³»çµ±"""
        logger.info("ğŸ§  åˆå§‹åŒ–æ™ºèƒ½ä¸Šä¸‹æ–‡å¢å¼·ç³»çµ±...")
        
        try:
            # 1. åˆå§‹åŒ–å¢å¼·ç­–ç•¥
            await self._initialize_enhancement_strategies()
            
            # 2. åˆå§‹åŒ–ä¸Šä¸‹æ–‡åˆ†æå™¨
            await self._initialize_context_analyzers()
            
            # 3. è¼‰å…¥ç­–ç•¥æ¬Šé‡
            await self._load_strategy_weights()
            
            # 4. å•Ÿå‹•è‡ªé©æ‡‰å­¸ç¿’
            await self._start_adaptive_learning()
            
            self.is_initialized = True
            logger.info("âœ… æ™ºèƒ½ä¸Šä¸‹æ–‡å¢å¼·ç³»çµ±åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ æ™ºèƒ½ä¸Šä¸‹æ–‡å¢å¼·ç³»çµ±åˆå§‹åŒ–å¤±æ•—: {e}")
            raise
    
    async def _initialize_enhancement_strategies(self):
        """åˆå§‹åŒ–å¢å¼·ç­–ç•¥"""
        # ç›¸ä¼¼ä¸Šä¸‹æ–‡ç­–ç•¥
        self.enhancement_strategies[EnhancementStrategy.SIMILAR_CONTEXT] = {
            "function": self._enhance_with_similar_context,
            "weight": 0.25,
            "enabled": True,
            "description": "åŸºæ–¼ç›¸ä¼¼ä¸Šä¸‹æ–‡çš„å¢å¼·"
        }
        
        # å­¸ç¿’æ¨¡å¼ç­–ç•¥
        self.enhancement_strategies[EnhancementStrategy.LEARNING_PATTERN] = {
            "function": self._enhance_with_learning_patterns,
            "weight": 0.20,
            "enabled": True,
            "description": "åŸºæ–¼å­¸ç¿’æ¨¡å¼çš„å¢å¼·"
        }
        
        # ç”¨æˆ¶åå¥½ç­–ç•¥
        self.enhancement_strategies[EnhancementStrategy.USER_PREFERENCE] = {
            "function": self._enhance_with_user_preferences,
            "weight": 0.15,
            "enabled": True,
            "description": "åŸºæ–¼ç”¨æˆ¶åå¥½çš„å¢å¼·"
        }
        
        # é ˜åŸŸçŸ¥è­˜ç­–ç•¥
        self.enhancement_strategies[EnhancementStrategy.DOMAIN_KNOWLEDGE] = {
            "function": self._enhance_with_domain_knowledge,
            "weight": 0.20,
            "enabled": True,
            "description": "åŸºæ–¼é ˜åŸŸçŸ¥è­˜çš„å¢å¼·"
        }
        
        # æ™‚é–“ä¸Šä¸‹æ–‡ç­–ç•¥
        self.enhancement_strategies[EnhancementStrategy.TEMPORAL_CONTEXT] = {
            "function": self._enhance_with_temporal_context,
            "weight": 0.10,
            "enabled": True,
            "description": "åŸºæ–¼æ™‚é–“ä¸Šä¸‹æ–‡çš„å¢å¼·"
        }
        
        # å”ä½œéæ¿¾ç­–ç•¥
        self.enhancement_strategies[EnhancementStrategy.COLLABORATIVE_FILTER] = {
            "function": self._enhance_with_collaborative_filtering,
            "weight": 0.05,
            "enabled": True,
            "description": "åŸºæ–¼å”ä½œéæ¿¾çš„å¢å¼·"
        }
        
        # è‡ªé©æ‡‰æ¬Šé‡ç­–ç•¥
        self.enhancement_strategies[EnhancementStrategy.ADAPTIVE_WEIGHTING] = {
            "function": self._enhance_with_adaptive_weighting,
            "weight": 0.05,
            "enabled": True,
            "description": "åŸºæ–¼è‡ªé©æ‡‰æ¬Šé‡çš„å¢å¼·"
        }
        
        logger.info(f"ğŸ“‹ åˆå§‹åŒ– {len(self.enhancement_strategies)} å€‹å¢å¼·ç­–ç•¥")
    
    async def _initialize_context_analyzers(self):
        """åˆå§‹åŒ–ä¸Šä¸‹æ–‡åˆ†æå™¨"""
        # èªç¾©åˆ†æå™¨
        self.context_analyzers[ContextType.SEMANTIC] = {
            "function": self._analyze_semantic_context,
            "enabled": True
        }
        
        # ç¨‹åºåŒ–åˆ†æå™¨
        self.context_analyzers[ContextType.PROCEDURAL] = {
            "function": self._analyze_procedural_context,
            "enabled": True
        }
        
        # å€‹äººåŒ–åˆ†æå™¨
        self.context_analyzers[ContextType.PERSONAL] = {
            "function": self._analyze_personal_context,
            "enabled": True
        }
        
        # é ˜åŸŸç‰¹å®šåˆ†æå™¨
        self.context_analyzers[ContextType.DOMAIN_SPECIFIC] = {
            "function": self._analyze_domain_specific_context,
            "enabled": True
        }
        
        # æ™‚é–“åˆ†æå™¨
        self.context_analyzers[ContextType.TEMPORAL] = {
            "function": self._analyze_temporal_context,
            "enabled": True
        }
        
        # å”ä½œåˆ†æå™¨
        self.context_analyzers[ContextType.COLLABORATIVE] = {
            "function": self._analyze_collaborative_context,
            "enabled": True
        }
        
        logger.info(f"ğŸ” åˆå§‹åŒ– {len(self.context_analyzers)} å€‹ä¸Šä¸‹æ–‡åˆ†æå™¨")
    
    async def _load_strategy_weights(self):
        """è¼‰å…¥ç­–ç•¥æ¬Šé‡"""
        try:
            # å¾å­¸ç¿’é©é…å™¨ç²å–ç­–ç•¥æ¬Šé‡
            if self.learning_adapter:
                learning_stats = await self.learning_adapter.get_learning_statistics()
                
                # åŸºæ–¼å­¸ç¿’çµ±è¨ˆèª¿æ•´æ¬Šé‡
                success_rate = learning_stats.get("success_rate", 0.0)
                
                # æˆåŠŸç‡é«˜çš„ç­–ç•¥å¢åŠ æ¬Šé‡
                if success_rate > 0.8:
                    self.strategy_weights[EnhancementStrategy.SIMILAR_CONTEXT] = 0.3
                    self.strategy_weights[EnhancementStrategy.LEARNING_PATTERN] = 0.25
                elif success_rate > 0.6:
                    self.strategy_weights[EnhancementStrategy.USER_PREFERENCE] = 0.2
                    self.strategy_weights[EnhancementStrategy.DOMAIN_KNOWLEDGE] = 0.25
                else:
                    # ä½¿ç”¨é»˜èªæ¬Šé‡
                    for strategy, config in self.enhancement_strategies.items():
                        self.strategy_weights[strategy] = config["weight"]
            
            logger.info("ğŸ“Š è¼‰å…¥ç­–ç•¥æ¬Šé‡å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ è¼‰å…¥ç­–ç•¥æ¬Šé‡å¤±æ•—: {e}")
            # ä½¿ç”¨é»˜èªæ¬Šé‡
            for strategy, config in self.enhancement_strategies.items():
                self.strategy_weights[strategy] = config["weight"]
    
    async def _start_adaptive_learning(self):
        """å•Ÿå‹•è‡ªé©æ‡‰å­¸ç¿’"""
        asyncio.create_task(self._adaptive_learning_loop())
    
    async def _adaptive_learning_loop(self):
        """è‡ªé©æ‡‰å­¸ç¿’å¾ªç’°"""
        while True:
            try:
                # åˆ†ææœ€è¿‘çš„å¢å¼·æ•ˆæœ
                await self._analyze_recent_enhancements()
                
                # èª¿æ•´ç­–ç•¥æ¬Šé‡
                await self._adjust_strategy_weights()
                
                # ç­‰å¾…ä¸‹ä¸€æ¬¡åˆ†æ
                await asyncio.sleep(300)  # 5åˆ†é˜
                
            except Exception as e:
                logger.error(f"âŒ è‡ªé©æ‡‰å­¸ç¿’å¾ªç’°å¤±æ•—: {e}")
                await asyncio.sleep(60)
    
    async def enhance_context(self, 
                            query: str,
                            user_id: str = "default_user",
                            context_type: str = "claude_interaction",
                            max_enhancements: int = 5) -> EnhancementResult:
        """å¢å¼·ä¸Šä¸‹æ–‡"""
        start_time = time.time()
        
        try:
            # 1. åˆ†ææŸ¥è©¢
            query_analysis = await self._analyze_query(query)
            
            # 2. æ”¶é›†åŸºç¤ä¸Šä¸‹æ–‡
            base_contexts = await self._collect_base_contexts(query, context_type)
            
            # 3. æ‡‰ç”¨å¢å¼·ç­–ç•¥
            enhancements = []
            strategies_used = []
            
            for strategy, config in self.enhancement_strategies.items():
                if config["enabled"]:
                    try:
                        strategy_enhancements = await config["function"](
                            query, query_analysis, base_contexts, user_id
                        )
                        
                        if strategy_enhancements:
                            enhancements.extend(strategy_enhancements)
                            strategies_used.append(strategy.value)
                            
                            # æ›´æ–°ç­–ç•¥ä½¿ç”¨çµ±è¨ˆ
                            self.enhancement_stats["strategy_usage"][strategy.value] += 1
                            
                    except Exception as e:
                        logger.error(f"âŒ å¢å¼·ç­–ç•¥å¤±æ•— ({strategy.value}): {e}")
                        continue
            
            # 4. æ’åºå’Œç¯©é¸å¢å¼·
            enhancements = await self._rank_enhancements(enhancements, query_analysis)
            enhancements = enhancements[:max_enhancements]
            
            # 5. è¨ˆç®—ç¸½åˆ†
            total_score = sum(e.relevance_score * e.confidence for e in enhancements)
            
            # 6. å‰µå»ºçµæœ
            processing_time = time.time() - start_time
            
            result = EnhancementResult(
                query=query,
                enhancements=enhancements,
                total_score=total_score,
                processing_time=processing_time,
                strategies_used=strategies_used,
                metadata={
                    "user_id": user_id,
                    "context_type": context_type,
                    "query_analysis": query_analysis,
                    "base_contexts_count": len(base_contexts)
                }
            )
            
            # 7. è¨˜éŒ„çµ±è¨ˆ
            await self._record_enhancement_stats(result)
            
            # 8. æ”¶é›†æ•¸æ“š
            await self._collect_enhancement_data(result)
            
            logger.debug(f"ğŸ§  ä¸Šä¸‹æ–‡å¢å¼·å®Œæˆ: {len(enhancements)} å€‹å¢å¼· ({processing_time:.3f}s)")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ ä¸Šä¸‹æ–‡å¢å¼·å¤±æ•—: {e}")
            
            # è¿”å›ç©ºçµæœ
            return EnhancementResult(
                query=query,
                enhancements=[],
                total_score=0.0,
                processing_time=time.time() - start_time,
                strategies_used=[],
                metadata={"error": str(e)}
            )
    
    async def _analyze_query(self, query: str) -> Dict[str, Any]:
        """åˆ†ææŸ¥è©¢"""
        analysis = {
            "length": len(query),
            "word_count": len(query.split()),
            "language": "chinese" if re.search(r'[\u4e00-\u9fff]', query) else "english",
            "complexity": "high" if len(query) > 100 else "medium" if len(query) > 50 else "low",
            "keywords": [],
            "topics": [],
            "intent": "unknown",
            "technical_level": "intermediate"
        }
        
        # æå–é—œéµè©
        words = query.lower().split()
        programming_keywords = {
            "python", "javascript", "java", "c++", "html", "css", "sql",
            "react", "vue", "angular", "nodejs", "django", "flask",
            "function", "class", "variable", "loop", "condition",
            "debug", "error", "exception", "test", "api", "database",
            "machine learning", "data analysis", "web development"
        }
        
        for word in words:
            if word in programming_keywords:
                analysis["keywords"].append(word)
        
        # æ¨æ–·ä¸»é¡Œ
        if any(keyword in query.lower() for keyword in ["python", "data", "analysis"]):
            analysis["topics"].append("data_science")
        if any(keyword in query.lower() for keyword in ["web", "html", "css", "javascript"]):
            analysis["topics"].append("web_development")
        if any(keyword in query.lower() for keyword in ["machine learning", "ai", "ml"]):
            analysis["topics"].append("machine_learning")
        
        # æ¨æ–·æ„åœ–
        if any(word in query.lower() for word in ["how", "å¦‚ä½•", "æ€éº¼"]):
            analysis["intent"] = "how_to"
        elif any(word in query.lower() for word in ["what", "ä»€éº¼", "æ˜¯ä»€éº¼"]):
            analysis["intent"] = "definition"
        elif any(word in query.lower() for word in ["error", "bug", "å•é¡Œ", "éŒ¯èª¤"]):
            analysis["intent"] = "troubleshooting"
        elif any(word in query.lower() for word in ["best", "recommend", "æ¨è–¦", "æœ€å¥½"]):
            analysis["intent"] = "recommendation"
        
        return analysis
    
    async def _collect_base_contexts(self, query: str, context_type: str) -> List[Dict[str, Any]]:
        """æ”¶é›†åŸºç¤ä¸Šä¸‹æ–‡"""
        base_contexts = []
        
        try:
            # å¾è¨˜æ†¶å¼•æ“ç²å–ç›¸ä¼¼è¨˜æ†¶
            if self.memory_engine:
                similar_memories = await self.memory_engine.get_similar_memories(
                    content=query,
                    limit=10
                )
                
                for memory in similar_memories:
                    base_contexts.append({
                        "type": "memory",
                        "content": memory.content,
                        "importance": memory.importance_score,
                        "timestamp": memory.created_at,
                        "source": "memory_engine"
                    })
            
            # å¾ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç²å–ç›¸é—œä¸Šä¸‹æ–‡
            if self.context_manager:
                context_recommendations = await self.context_manager.get_context_recommendations(
                    query=query,
                    limit=5
                )
                
                for context in context_recommendations:
                    base_contexts.append({
                        "type": "context",
                        "content": context.content,
                        "relevance": context.relevance_score,
                        "timestamp": context.created_at,
                        "source": "context_manager"
                    })
            
            logger.debug(f"ğŸ” æ”¶é›†åŸºç¤ä¸Šä¸‹æ–‡: {len(base_contexts)} å€‹")
            
        except Exception as e:
            logger.error(f"âŒ æ”¶é›†åŸºç¤ä¸Šä¸‹æ–‡å¤±æ•—: {e}")
        
        return base_contexts
    
    # å¢å¼·ç­–ç•¥å¯¦ç¾
    async def _enhance_with_similar_context(self, 
                                          query: str, 
                                          query_analysis: Dict[str, Any],
                                          base_contexts: List[Dict[str, Any]],
                                          user_id: str) -> List[ContextEnhancement]:
        """åŸºæ–¼ç›¸ä¼¼ä¸Šä¸‹æ–‡çš„å¢å¼·"""
        enhancements = []
        
        try:
            # å¾åŸºç¤ä¸Šä¸‹æ–‡ä¸­é¸æ“‡æœ€ç›¸ä¼¼çš„
            similar_contexts = sorted(
                base_contexts,
                key=lambda x: x.get("importance", 0) * x.get("relevance", 0),
                reverse=True
            )[:3]
            
            for i, context in enumerate(similar_contexts):
                enhancement = ContextEnhancement(
                    id=f"similar_{i}_{int(time.time())}",
                    query=query,
                    enhancement_type=ContextType.HISTORICAL,
                    strategy=EnhancementStrategy.SIMILAR_CONTEXT,
                    content=context["content"][:500],  # é™åˆ¶é•·åº¦
                    relevance_score=context.get("relevance", context.get("importance", 0.5)),
                    confidence=0.8,
                    source=context["source"],
                    metadata={
                        "context_type": context["type"],
                        "timestamp": context["timestamp"]
                    },
                    created_at=time.time()
                )
                
                enhancements.append(enhancement)
        
        except Exception as e:
            logger.error(f"âŒ ç›¸ä¼¼ä¸Šä¸‹æ–‡å¢å¼·å¤±æ•—: {e}")
        
        return enhancements
    
    async def _enhance_with_learning_patterns(self,
                                            query: str,
                                            query_analysis: Dict[str, Any],
                                            base_contexts: List[Dict[str, Any]],
                                            user_id: str) -> List[ContextEnhancement]:
        """åŸºæ–¼å­¸ç¿’æ¨¡å¼çš„å¢å¼·"""
        enhancements = []
        
        try:
            if self.learning_adapter:
                # ç²å–æœ€ä½³å¯¦è¸
                best_practices = await self.learning_adapter.get_best_practices(
                    query=query,
                    domain="software_engineering"
                )
                
                for i, practice in enumerate(best_practices[:2]):
                    enhancement = ContextEnhancement(
                        id=f"learning_{i}_{int(time.time())}",
                        query=query,
                        enhancement_type=ContextType.PROCEDURAL,
                        strategy=EnhancementStrategy.LEARNING_PATTERN,
                        content=practice["content"],
                        relevance_score=practice["quality_score"],
                        confidence=0.9,
                        source="learning_adapter",
                        metadata={
                            "practice_id": practice["id"],
                            "domain": practice["domain"],
                            "tags": practice["tags"]
                        },
                        created_at=time.time()
                    )
                    
                    enhancements.append(enhancement)
        
        except Exception as e:
            logger.error(f"âŒ å­¸ç¿’æ¨¡å¼å¢å¼·å¤±æ•—: {e}")
        
        return enhancements
    
    async def _enhance_with_user_preferences(self,
                                           query: str,
                                           query_analysis: Dict[str, Any],
                                           base_contexts: List[Dict[str, Any]],
                                           user_id: str) -> List[ContextEnhancement]:
        """åŸºæ–¼ç”¨æˆ¶åå¥½çš„å¢å¼·"""
        enhancements = []
        
        try:
            if self.personalization_manager:
                # ç²å–ç”¨æˆ¶åå¥½
                user_preferences = await self.personalization_manager.get_user_preferences(
                    user_id=user_id,
                    context=query
                )
                
                preferences = user_preferences.get("preferences", {})
                
                # åŸºæ–¼åå¥½ç”Ÿæˆå¢å¼·
                if preferences:
                    # æŠ€è¡“æ°´å¹³åå¥½
                    if "technical_level" in preferences:
                        tech_level = preferences["technical_level"]["value"]
                        
                        enhancement = ContextEnhancement(
                            id=f"user_pref_{int(time.time())}",
                            query=query,
                            enhancement_type=ContextType.PERSONAL,
                            strategy=EnhancementStrategy.USER_PREFERENCE,
                            content=f"æ ¹æ“šæ‚¨çš„æŠ€è¡“æ°´å¹³ ({tech_level})ï¼Œå»ºè­°ä»¥ä¸‹æ–¹æ³•...",
                            relevance_score=0.7,
                            confidence=preferences["technical_level"]["confidence"],
                            source="personalization_manager",
                            metadata={
                                "user_id": user_id,
                                "preference_type": "technical_level",
                                "preference_value": tech_level
                            },
                            created_at=time.time()
                        )
                        
                        enhancements.append(enhancement)
                    
                    # éŸ¿æ‡‰æ ¼å¼åå¥½
                    if "response_format" in preferences:
                        format_pref = preferences["response_format"]["value"]
                        
                        enhancement = ContextEnhancement(
                            id=f"format_pref_{int(time.time())}",
                            query=query,
                            enhancement_type=ContextType.PERSONAL,
                            strategy=EnhancementStrategy.USER_PREFERENCE,
                            content=f"æ ¹æ“šæ‚¨åå¥½çš„éŸ¿æ‡‰æ ¼å¼ ({format_pref})ï¼Œå°‡ä»¥çµæ§‹åŒ–æ–¹å¼å›ç­”...",
                            relevance_score=0.6,
                            confidence=preferences["response_format"]["confidence"],
                            source="personalization_manager",
                            metadata={
                                "user_id": user_id,
                                "preference_type": "response_format",
                                "preference_value": format_pref
                            },
                            created_at=time.time()
                        )
                        
                        enhancements.append(enhancement)
        
        except Exception as e:
            logger.error(f"âŒ ç”¨æˆ¶åå¥½å¢å¼·å¤±æ•—: {e}")
        
        return enhancements
    
    async def _enhance_with_domain_knowledge(self,
                                           query: str,
                                           query_analysis: Dict[str, Any],
                                           base_contexts: List[Dict[str, Any]],
                                           user_id: str) -> List[ContextEnhancement]:
        """åŸºæ–¼é ˜åŸŸçŸ¥è­˜çš„å¢å¼·"""
        enhancements = []
        
        try:
            # åŸºæ–¼æŸ¥è©¢åˆ†æçš„ä¸»é¡Œæä¾›é ˜åŸŸçŸ¥è­˜
            topics = query_analysis.get("topics", [])
            
            domain_knowledge = {
                "data_science": {
                    "libraries": ["pandas", "numpy", "matplotlib", "seaborn", "scikit-learn"],
                    "concepts": ["data cleaning", "feature engineering", "model validation"],
                    "best_practices": ["use vectorized operations", "handle missing data", "cross-validation"]
                },
                "web_development": {
                    "technologies": ["HTML5", "CSS3", "JavaScript ES6", "React", "Vue"],
                    "concepts": ["responsive design", "accessibility", "performance optimization"],
                    "best_practices": ["semantic HTML", "mobile-first design", "code splitting"]
                },
                "machine_learning": {
                    "algorithms": ["linear regression", "random forest", "neural networks"],
                    "concepts": ["overfitting", "bias-variance tradeoff", "feature selection"],
                    "best_practices": ["data preprocessing", "model evaluation", "hyperparameter tuning"]
                }
            }
            
            for topic in topics:
                if topic in domain_knowledge:
                    knowledge = domain_knowledge[topic]
                    
                    enhancement = ContextEnhancement(
                        id=f"domain_{topic}_{int(time.time())}",
                        query=query,
                        enhancement_type=ContextType.DOMAIN_SPECIFIC,
                        strategy=EnhancementStrategy.DOMAIN_KNOWLEDGE,
                        content=f"åœ¨ {topic} é ˜åŸŸä¸­ï¼Œç›¸é—œçš„å·¥å…·å’Œæ¦‚å¿µåŒ…æ‹¬: {', '.join(knowledge.get('libraries', knowledge.get('technologies', [])))}",
                        relevance_score=0.8,
                        confidence=0.9,
                        source="domain_knowledge_base",
                        metadata={
                            "domain": topic,
                            "knowledge_type": "domain_specific",
                            "libraries": knowledge.get("libraries", []),
                            "concepts": knowledge.get("concepts", []),
                            "best_practices": knowledge.get("best_practices", [])
                        },
                        created_at=time.time()
                    )
                    
                    enhancements.append(enhancement)
        
        except Exception as e:
            logger.error(f"âŒ é ˜åŸŸçŸ¥è­˜å¢å¼·å¤±æ•—: {e}")
        
        return enhancements
    
    async def _enhance_with_temporal_context(self,
                                           query: str,
                                           query_analysis: Dict[str, Any],
                                           base_contexts: List[Dict[str, Any]],
                                           user_id: str) -> List[ContextEnhancement]:
        """åŸºæ–¼æ™‚é–“ä¸Šä¸‹æ–‡çš„å¢å¼·"""
        enhancements = []
        
        try:
            # åˆ†ææ™‚é–“æ¨¡å¼
            current_time = time.time()
            current_hour = time.localtime(current_time).tm_hour
            
            # åŸºæ–¼æ™‚é–“æä¾›ç›¸é—œå»ºè­°
            if 9 <= current_hour <= 17:
                time_context = "å·¥ä½œæ™‚é–“ï¼Œå»ºè­°å°ˆæ³¨æ–¼æ•ˆç‡å’Œæœ€ä½³å¯¦è¸"
            elif 18 <= current_hour <= 22:
                time_context = "æ™šé–“æ™‚é–“ï¼Œé©åˆå­¸ç¿’å’Œæ·±å…¥ç ”ç©¶"
            else:
                time_context = "éå¸¸è¦æ™‚é–“ï¼Œå»ºè­°é—œæ³¨åŸºç¤æ¦‚å¿µ"
            
            # æŸ¥æ‰¾æœ€è¿‘çš„ç›¸é—œä¸Šä¸‹æ–‡
            recent_contexts = [
                ctx for ctx in base_contexts
                if current_time - ctx.get("timestamp", 0) < 3600  # æœ€è¿‘1å°æ™‚
            ]
            
            if recent_contexts:
                enhancement = ContextEnhancement(
                    id=f"temporal_{int(time.time())}",
                    query=query,
                    enhancement_type=ContextType.TEMPORAL,
                    strategy=EnhancementStrategy.TEMPORAL_CONTEXT,
                    content=f"åŸºæ–¼ç•¶å‰æ™‚é–“ä¸Šä¸‹æ–‡: {time_context}ã€‚æ‚¨æœ€è¿‘æŸ¥è©¢äº†ç›¸é—œä¸»é¡Œï¼Œå¯èƒ½éœ€è¦æ·±å…¥äº†è§£...",
                    relevance_score=0.6,
                    confidence=0.7,
                    source="temporal_analyzer",
                    metadata={
                        "current_hour": current_hour,
                        "time_context": time_context,
                        "recent_contexts_count": len(recent_contexts)
                    },
                    created_at=time.time()
                )
                
                enhancements.append(enhancement)
        
        except Exception as e:
            logger.error(f"âŒ æ™‚é–“ä¸Šä¸‹æ–‡å¢å¼·å¤±æ•—: {e}")
        
        return enhancements
    
    async def _enhance_with_collaborative_filtering(self,
                                                  query: str,
                                                  query_analysis: Dict[str, Any],
                                                  base_contexts: List[Dict[str, Any]],
                                                  user_id: str) -> List[ContextEnhancement]:
        """åŸºæ–¼å”ä½œéæ¿¾çš„å¢å¼·"""
        enhancements = []
        
        try:
            # ç°¡åŒ–çš„å”ä½œéæ¿¾å¯¦ç¾
            # åœ¨å¯¦éš›æ‡‰ç”¨ä¸­ï¼Œé€™è£¡æœƒåˆ†æå…¶ä»–ç”¨æˆ¶çš„é¡ä¼¼æŸ¥è©¢å’Œåé¥‹
            
            similar_user_queries = [
                "å…¶ä»–ç”¨æˆ¶åœ¨é¡ä¼¼å•é¡Œä¸Šä¹Ÿé—œæ³¨äº†æ€§èƒ½å„ªåŒ–",
                "é¡ä¼¼æŸ¥è©¢çš„ç”¨æˆ¶é€šå¸¸ä¹Ÿæœƒå•åŠéŒ¯èª¤è™•ç†",
                "ç›¸é—œä¸»é¡Œçš„ç”¨æˆ¶å»ºè­°å…ˆäº†è§£åŸºç¤æ¦‚å¿µ"
            ]
            
            if similar_user_queries:
                enhancement = ContextEnhancement(
                    id=f"collaborative_{int(time.time())}",
                    query=query,
                    enhancement_type=ContextType.COLLABORATIVE,
                    strategy=EnhancementStrategy.COLLABORATIVE_FILTER,
                    content=f"åŸºæ–¼å…¶ä»–ç”¨æˆ¶çš„ç¶“é©—: {similar_user_queries[0]}",
                    relevance_score=0.5,
                    confidence=0.6,
                    source="collaborative_filter",
                    metadata={
                        "similar_queries": similar_user_queries,
                        "user_similarity_score": 0.7
                    },
                    created_at=time.time()
                )
                
                enhancements.append(enhancement)
        
        except Exception as e:
            logger.error(f"âŒ å”ä½œéæ¿¾å¢å¼·å¤±æ•—: {e}")
        
        return enhancements
    
    async def _enhance_with_adaptive_weighting(self,
                                             query: str,
                                             query_analysis: Dict[str, Any],
                                             base_contexts: List[Dict[str, Any]],
                                             user_id: str) -> List[ContextEnhancement]:
        """åŸºæ–¼è‡ªé©æ‡‰æ¬Šé‡çš„å¢å¼·"""
        enhancements = []
        
        try:
            # åŸºæ–¼æœ€è¿‘çš„å¢å¼·æ•ˆæœèª¿æ•´æ¬Šé‡
            recent_feedback = list(self.feedback_buffer)
            
            if recent_feedback:
                avg_satisfaction = np.mean([f.get("satisfaction", 0) for f in recent_feedback])
                
                if avg_satisfaction > 0.8:
                    weight_suggestion = "ç•¶å‰å¢å¼·ç­–ç•¥æ•ˆæœè‰¯å¥½ï¼Œå»ºè­°ç¹¼çºŒä½¿ç”¨"
                elif avg_satisfaction > 0.6:
                    weight_suggestion = "å¢å¼·ç­–ç•¥è¡¨ç¾ä¸­ç­‰ï¼Œå¯è€ƒæ…®èª¿æ•´"
                else:
                    weight_suggestion = "å¢å¼·ç­–ç•¥éœ€è¦å„ªåŒ–ï¼Œå»ºè­°é‡æ–°è©•ä¼°"
                
                enhancement = ContextEnhancement(
                    id=f"adaptive_{int(time.time())}",
                    query=query,
                    enhancement_type=ContextType.ADAPTIVE,
                    strategy=EnhancementStrategy.ADAPTIVE_WEIGHTING,
                    content=f"åŸºæ–¼è‡ªé©æ‡‰åˆ†æ: {weight_suggestion}",
                    relevance_score=0.4,
                    confidence=0.8,
                    source="adaptive_weighting",
                    metadata={
                        "avg_satisfaction": avg_satisfaction,
                        "feedback_count": len(recent_feedback),
                        "weight_adjustment": weight_suggestion
                    },
                    created_at=time.time()
                )
                
                enhancements.append(enhancement)
        
        except Exception as e:
            logger.error(f"âŒ è‡ªé©æ‡‰æ¬Šé‡å¢å¼·å¤±æ•—: {e}")
        
        return enhancements
    
    async def _rank_enhancements(self, 
                               enhancements: List[ContextEnhancement],
                               query_analysis: Dict[str, Any]) -> List[ContextEnhancement]:
        """æ’åºå¢å¼·"""
        try:
            # è¨ˆç®—ç¶œåˆåˆ†æ•¸
            for enhancement in enhancements:
                # åŸºç¤åˆ†æ•¸
                base_score = enhancement.relevance_score * enhancement.confidence
                
                # ç­–ç•¥æ¬Šé‡
                strategy_weight = self.strategy_weights.get(enhancement.strategy, 0.1)
                
                # æŸ¥è©¢åŒ¹é…åº¦
                query_match = self._calculate_query_match(enhancement, query_analysis)
                
                # æ™‚é–“è¡°æ¸›
                time_decay = self._calculate_time_decay(enhancement)
                
                # ç¶œåˆåˆ†æ•¸
                final_score = base_score * strategy_weight * query_match * time_decay
                
                enhancement.relevance_score = final_score
            
            # æ’åº
            enhancements.sort(key=lambda x: x.relevance_score, reverse=True)
            
            return enhancements
            
        except Exception as e:
            logger.error(f"âŒ æ’åºå¢å¼·å¤±æ•—: {e}")
            return enhancements
    
    def _calculate_query_match(self, enhancement: ContextEnhancement, query_analysis: Dict[str, Any]) -> float:
        """è¨ˆç®—æŸ¥è©¢åŒ¹é…åº¦"""
        try:
            # ç°¡åŒ–çš„åŒ¹é…åº¦è¨ˆç®—
            keywords = query_analysis.get("keywords", [])
            enhancement_text = enhancement.content.lower()
            
            match_count = sum(1 for keyword in keywords if keyword in enhancement_text)
            
            if keywords:
                return min(1.0, match_count / len(keywords))
            else:
                return 0.5
        
        except Exception:
            return 0.5
    
    def _calculate_time_decay(self, enhancement: ContextEnhancement) -> float:
        """è¨ˆç®—æ™‚é–“è¡°æ¸›"""
        try:
            current_time = time.time()
            age = current_time - enhancement.created_at
            
            # æ™‚é–“è¡°æ¸›å› å­ (1å°æ™‚å…§ç‚º1.0ï¼Œä¹‹å¾ŒæŒ‡æ•¸è¡°æ¸›)
            if age < 3600:
                return 1.0
            else:
                return max(0.1, 0.5 ** (age / 3600))
        
        except Exception:
            return 1.0
    
    async def _record_enhancement_stats(self, result: EnhancementResult):
        """è¨˜éŒ„å¢å¼·çµ±è¨ˆ"""
        try:
            self.enhancement_stats["total_enhancements"] += 1
            
            if result.total_score > 0:
                self.enhancement_stats["successful_enhancements"] += 1
            
            # æ›´æ–°å¹³å‡è™•ç†æ™‚é–“
            current_avg = self.enhancement_stats["average_processing_time"]
            new_avg = (current_avg * (self.enhancement_stats["total_enhancements"] - 1) + 
                      result.processing_time) / self.enhancement_stats["total_enhancements"]
            self.enhancement_stats["average_processing_time"] = new_avg
            
            # æ·»åŠ åˆ°æœ€è¿‘å¢å¼·è¨˜éŒ„
            self.recent_enhancements.append(result)
            
        except Exception as e:
            logger.error(f"âŒ è¨˜éŒ„å¢å¼·çµ±è¨ˆå¤±æ•—: {e}")
    
    async def _collect_enhancement_data(self, result: EnhancementResult):
        """æ”¶é›†å¢å¼·æ•¸æ“š"""
        try:
            # æ”¶é›†åˆ°æ•¸æ“šæ”¶é›†ç³»çµ±
            data_collection = self.learning_integration.data_collection_system
            
            if data_collection:
                await data_collection.collect_data(
                    data_type=DataType.CONTEXT_USAGE,
                    source="intelligent_context_enhancement",
                    data={
                        "query": result.query,
                        "enhancement_count": len(result.enhancements),
                        "total_score": result.total_score,
                        "processing_time": result.processing_time,
                        "strategies_used": result.strategies_used
                    },
                    priority=DataPriority.NORMAL,
                    metadata=result.metadata
                )
        
        except Exception as e:
            logger.error(f"âŒ æ”¶é›†å¢å¼·æ•¸æ“šå¤±æ•—: {e}")
    
    async def _analyze_recent_enhancements(self):
        """åˆ†ææœ€è¿‘çš„å¢å¼·æ•ˆæœ"""
        try:
            if not self.recent_enhancements:
                return
            
            # åˆ†ææˆåŠŸç‡
            recent_results = list(self.recent_enhancements)
            success_rate = sum(1 for r in recent_results if r.total_score > 0) / len(recent_results)
            
            # åˆ†æå¹³å‡è™•ç†æ™‚é–“
            avg_time = np.mean([r.processing_time for r in recent_results])
            
            # åˆ†æç­–ç•¥æ•ˆæœ
            strategy_effectiveness = defaultdict(list)
            for result in recent_results:
                for strategy in result.strategies_used:
                    strategy_effectiveness[strategy].append(result.total_score)
            
            # è¨˜éŒ„åˆ†æçµæœ
            logger.info(f"ğŸ“Š æœ€è¿‘å¢å¼·åˆ†æ: æˆåŠŸç‡={success_rate:.2f}, å¹³å‡æ™‚é–“={avg_time:.3f}s")
            
        except Exception as e:
            logger.error(f"âŒ åˆ†ææœ€è¿‘å¢å¼·å¤±æ•—: {e}")
    
    async def _adjust_strategy_weights(self):
        """èª¿æ•´ç­–ç•¥æ¬Šé‡"""
        try:
            # åŸºæ–¼æœ€è¿‘çš„æ•ˆæœèª¿æ•´ç­–ç•¥æ¬Šé‡
            if not self.recent_enhancements:
                return
            
            strategy_performance = defaultdict(list)
            
            for result in self.recent_enhancements:
                for strategy in result.strategies_used:
                    strategy_performance[strategy].append(result.total_score)
            
            # èª¿æ•´æ¬Šé‡
            for strategy_name, scores in strategy_performance.items():
                if scores:
                    avg_score = np.mean(scores)
                    
                    # æ‰¾åˆ°å°æ‡‰çš„ç­–ç•¥æšèˆ‰
                    strategy_enum = None
                    for strategy in EnhancementStrategy:
                        if strategy.value == strategy_name:
                            strategy_enum = strategy
                            break
                    
                    if strategy_enum:
                        current_weight = self.strategy_weights.get(strategy_enum, 0.1)
                        
                        # åŸºæ–¼å¹³å‡åˆ†æ•¸èª¿æ•´æ¬Šé‡
                        if avg_score > 0.8:
                            new_weight = min(0.5, current_weight * 1.1)
                        elif avg_score > 0.6:
                            new_weight = current_weight
                        else:
                            new_weight = max(0.05, current_weight * 0.9)
                        
                        self.strategy_weights[strategy_enum] = new_weight
            
            logger.debug("ğŸ”§ ç­–ç•¥æ¬Šé‡èª¿æ•´å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ èª¿æ•´ç­–ç•¥æ¬Šé‡å¤±æ•—: {e}")
    
    async def record_feedback(self, 
                            query: str,
                            enhancement_result: EnhancementResult,
                            user_satisfaction: float,
                            used_enhancements: List[str] = None):
        """è¨˜éŒ„åé¥‹"""
        try:
            feedback = {
                "query": query,
                "enhancement_count": len(enhancement_result.enhancements),
                "total_score": enhancement_result.total_score,
                "processing_time": enhancement_result.processing_time,
                "user_satisfaction": user_satisfaction,
                "used_enhancements": used_enhancements or [],
                "strategies_used": enhancement_result.strategies_used,
                "timestamp": time.time()
            }
            
            # æ·»åŠ åˆ°åé¥‹ç·©è¡å€
            self.feedback_buffer.append(feedback)
            
            # æ›´æ–°çµ±è¨ˆ
            for strategy in enhancement_result.strategies_used:
                self.enhancement_stats["user_feedback"][strategy].append(user_satisfaction)
            
            # æ”¶é›†åé¥‹æ•¸æ“š
            data_collection = self.learning_integration.data_collection_system
            if data_collection:
                await data_collection.collect_data(
                    data_type=DataType.FEEDBACK_RESPONSE,
                    source="intelligent_context_enhancement",
                    data=feedback,
                    priority=DataPriority.HIGH
                )
            
            logger.debug(f"âœ… è¨˜éŒ„åé¥‹: æ»¿æ„åº¦={user_satisfaction:.2f}")
            
        except Exception as e:
            logger.error(f"âŒ è¨˜éŒ„åé¥‹å¤±æ•—: {e}")
    
    async def get_enhancement_statistics(self) -> Dict[str, Any]:
        """ç²å–å¢å¼·çµ±è¨ˆ"""
        try:
            stats = {
                "enhancement_stats": self.enhancement_stats.copy(),
                "strategy_weights": {
                    strategy.value: weight
                    for strategy, weight in self.strategy_weights.items()
                },
                "recent_enhancements": len(self.recent_enhancements),
                "feedback_buffer": len(self.feedback_buffer),
                "system_status": {
                    "initialized": self.is_initialized,
                    "strategies_count": len(self.enhancement_strategies),
                    "analyzers_count": len(self.context_analyzers)
                }
            }
            
            # è¨ˆç®—ç­–ç•¥æ•ˆæœ
            strategy_effectiveness = {}
            for strategy, feedback_list in self.enhancement_stats["user_feedback"].items():
                if feedback_list:
                    strategy_effectiveness[strategy] = {
                        "average_satisfaction": np.mean(feedback_list),
                        "feedback_count": len(feedback_list)
                    }
            
            stats["strategy_effectiveness"] = strategy_effectiveness
            
            return stats
            
        except Exception as e:
            logger.error(f"âŒ ç²å–å¢å¼·çµ±è¨ˆå¤±æ•—: {e}")
            return {}
    
    # ä¸Šä¸‹æ–‡åˆ†æå™¨å¯¦ç¾
    async def _analyze_semantic_context(self, query: str) -> Dict[str, Any]:
        """åˆ†æèªç¾©ä¸Šä¸‹æ–‡"""
        # å¯¦ç¾èªç¾©åˆ†æé‚è¼¯
        return {"semantic_analysis": "completed"}
    
    async def _analyze_procedural_context(self, query: str) -> Dict[str, Any]:
        """åˆ†æç¨‹åºåŒ–ä¸Šä¸‹æ–‡"""
        # å¯¦ç¾ç¨‹åºåŒ–åˆ†æé‚è¼¯
        return {"procedural_analysis": "completed"}
    
    async def _analyze_personal_context(self, query: str) -> Dict[str, Any]:
        """åˆ†æå€‹äººåŒ–ä¸Šä¸‹æ–‡"""
        # å¯¦ç¾å€‹äººåŒ–åˆ†æé‚è¼¯
        return {"personal_analysis": "completed"}
    
    async def _analyze_domain_specific_context(self, query: str) -> Dict[str, Any]:
        """åˆ†æé ˜åŸŸç‰¹å®šä¸Šä¸‹æ–‡"""
        # å¯¦ç¾é ˜åŸŸç‰¹å®šåˆ†æé‚è¼¯
        return {"domain_analysis": "completed"}
    
    async def _analyze_temporal_context(self, query: str) -> Dict[str, Any]:
        """åˆ†ææ™‚é–“ä¸Šä¸‹æ–‡"""
        # å¯¦ç¾æ™‚é–“åˆ†æé‚è¼¯
        return {"temporal_analysis": "completed"}
    
    async def _analyze_collaborative_context(self, query: str) -> Dict[str, Any]:
        """åˆ†æå”ä½œä¸Šä¸‹æ–‡"""
        # å¯¦ç¾å”ä½œåˆ†æé‚è¼¯
        return {"collaborative_analysis": "completed"}

# å‰µå»ºå…¨å±€æ™ºèƒ½ä¸Šä¸‹æ–‡å¢å¼·ç³»çµ±å¯¦ä¾‹
intelligent_context_enhancement = None

async def initialize_intelligent_context_enhancement(learning_integration: PowerAutomationLearningIntegration):
    """åˆå§‹åŒ–æ™ºèƒ½ä¸Šä¸‹æ–‡å¢å¼·ç³»çµ±"""
    global intelligent_context_enhancement
    
    if intelligent_context_enhancement is None:
        intelligent_context_enhancement = IntelligentContextEnhancement(learning_integration)
        await intelligent_context_enhancement.initialize()
    
    return intelligent_context_enhancement

async def get_intelligent_context_enhancement():
    """ç²å–æ™ºèƒ½ä¸Šä¸‹æ–‡å¢å¼·ç³»çµ±å¯¦ä¾‹"""
    global intelligent_context_enhancement
    
    if intelligent_context_enhancement is None:
        raise RuntimeError("æ™ºèƒ½ä¸Šä¸‹æ–‡å¢å¼·ç³»çµ±å°šæœªåˆå§‹åŒ–")
    
    return intelligent_context_enhancement

# æ¸¬è©¦å‡½æ•¸
async def main():
    """æ¸¬è©¦æ™ºèƒ½ä¸Šä¸‹æ–‡å¢å¼·ç³»çµ±"""
    print("ğŸ§ª æ¸¬è©¦æ™ºèƒ½ä¸Šä¸‹æ–‡å¢å¼·ç³»çµ±...")
    
    # é€™è£¡éœ€è¦æ¨¡æ“¬ learning_integrationï¼Œåœ¨å¯¦éš›ä½¿ç”¨ä¸­æœƒå¾çœŸå¯¦å¯¦ä¾‹ç²å–
    # æ¸¬è©¦ä»£ç¢¼ç•¥
    
    print("âœ… æ¸¬è©¦å®Œæˆ")

if __name__ == "__main__":
    asyncio.run(main())