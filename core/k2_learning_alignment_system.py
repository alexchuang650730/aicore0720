#!/usr/bin/env python3
"""
K2 å­¸ç¿’å°é½Šç³»çµ± - å¾ Claude Code Tool çš„ä½¿ç”¨è¨˜éŒ„ä¸­å­¸ç¿’
æ¯å¤©16å°æ™‚çš„ç·¨ç¨‹è¨˜éŒ„å°‡è¢«åˆ†æã€æå–ä¸¦ç”¨æ–¼è¨“ç·´K2æ¨¡å‹çš„å°é½Š
"""

import os
import json
import asyncio
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
import numpy as np
from dataclasses import dataclass, asdict
from collections import defaultdict
import hashlib

@dataclass
class CodingSession:
    """ç·¨ç¨‹æœƒè©±è¨˜éŒ„"""
    session_id: str
    start_time: str
    end_time: str
    duration_hours: float
    user_id: str
    interactions: List[Dict[str, Any]]
    files_created: List[str]
    files_modified: List[str]
    commands_used: List[str]
    errors_encountered: List[Dict[str, Any]]
    successful_patterns: List[str]

@dataclass
class LearningPattern:
    """å­¸ç¿’åˆ°çš„æ¨¡å¼"""
    pattern_id: str
    pattern_type: str  # command, code_generation, error_fix, refactoring
    trigger: str  # è§¸ç™¼æ¢ä»¶
    claude_response: str  # Claudeçš„éŸ¿æ‡‰
    k2_response: str  # K2çš„éŸ¿æ‡‰ï¼ˆç”¨æ–¼å°æ¯”ï¼‰
    success_rate: float
    usage_count: int
    context_requirements: Dict[str, Any]

class K2LearningAlignmentSystem:
    """K2 å­¸ç¿’å°é½Šç³»çµ±"""
    
    def __init__(self):
        self.data_path = Path.home() / ".powerautomation" / "k2_learning"
        self.data_path.mkdir(parents=True, exist_ok=True)
        
        # æ•¸æ“šå­˜å„²
        self.sessions_db = self.data_path / "coding_sessions.json"
        self.patterns_db = self.data_path / "learned_patterns.json"
        self.alignment_db = self.data_path / "k2_alignment.json"
        
        # å­¸ç¿’é…ç½®
        self.learning_config = {
            "min_pattern_occurrences": 3,  # æ¨¡å¼æœ€å°‘å‡ºç¾æ¬¡æ•¸
            "confidence_threshold": 0.8,   # ç½®ä¿¡åº¦é–¾å€¼
            "batch_size": 100,            # æ‰¹æ¬¡å¤§å°
            "learning_interval_hours": 4   # å­¸ç¿’é–“éš”
        }
        
        # è¼‰å…¥ç¾æœ‰æ•¸æ“š
        self._load_data()
        
        # å•Ÿå‹•èƒŒæ™¯å­¸ç¿’ä»»å‹™
        self.learning_task = None
        
    def _load_data(self):
        """è¼‰å…¥ç¾æœ‰æ•¸æ“š"""
        self.sessions = {}
        self.patterns = {}
        self.alignment_data = {
            "total_hours_analyzed": 0,
            "patterns_learned": 0,
            "alignment_score": 0.0,
            "last_update": None
        }
        
        if self.sessions_db.exists():
            with open(self.sessions_db, 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.sessions = {k: CodingSession(**v) for k, v in data.items()}
                
        if self.patterns_db.exists():
            with open(self.patterns_db, 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.patterns = {k: LearningPattern(**v) for k, v in data.items()}
                
        if self.alignment_db.exists():
            with open(self.alignment_db, 'r', encoding='utf-8') as f:
                self.alignment_data = json.load(f)
                
    def _save_data(self):
        """ä¿å­˜æ•¸æ“š"""
        # ä¿å­˜æœƒè©±
        sessions_data = {k: asdict(v) for k, v in self.sessions.items()}
        with open(self.sessions_db, 'w', encoding='utf-8') as f:
            json.dump(sessions_data, f, ensure_ascii=False, indent=2)
            
        # ä¿å­˜æ¨¡å¼
        patterns_data = {k: asdict(v) for k, v in self.patterns.items()}
        with open(self.patterns_db, 'w', encoding='utf-8') as f:
            json.dump(patterns_data, f, ensure_ascii=False, indent=2)
            
        # ä¿å­˜å°é½Šæ•¸æ“š
        with open(self.alignment_db, 'w', encoding='utf-8') as f:
            json.dump(self.alignment_data, f, ensure_ascii=False, indent=2)
            
    async def start_continuous_learning(self):
        """å•Ÿå‹•æŒçºŒå­¸ç¿’"""
        print("ğŸ§  å•Ÿå‹• K2 æŒçºŒå­¸ç¿’ç³»çµ±...")
        self.learning_task = asyncio.create_task(self._continuous_learning_loop())
        
    async def _continuous_learning_loop(self):
        """æŒçºŒå­¸ç¿’å¾ªç’°"""
        while True:
            try:
                # æ”¶é›†æœ€è¿‘çš„ç·¨ç¨‹æœƒè©±
                recent_sessions = await self._collect_recent_sessions()
                
                if recent_sessions:
                    print(f"ğŸ“Š ç™¼ç¾ {len(recent_sessions)} å€‹æ–°æœƒè©±å¾…åˆ†æ")
                    
                    # åˆ†ææœƒè©±æå–æ¨¡å¼
                    new_patterns = await self._analyze_sessions(recent_sessions)
                    
                    # å°é½Š K2 éŸ¿æ‡‰
                    await self._align_k2_responses(new_patterns)
                    
                    # æ›´æ–°çµ±è¨ˆ
                    self._update_statistics(recent_sessions, new_patterns)
                    
                    print(f"âœ… å­¸ç¿’å®Œæˆï¼Œæ–°å¢ {len(new_patterns)} å€‹æ¨¡å¼")
                    
                # ç­‰å¾…ä¸‹ä¸€å€‹å­¸ç¿’é€±æœŸ
                await asyncio.sleep(self.learning_config["learning_interval_hours"] * 3600)
                
            except Exception as e:
                print(f"âŒ å­¸ç¿’éç¨‹å‡ºéŒ¯: {e}")
                await asyncio.sleep(300)  # 5åˆ†é˜å¾Œé‡è©¦
                
    async def _collect_recent_sessions(self) -> List[CodingSession]:
        """æ”¶é›†æœ€è¿‘çš„ç·¨ç¨‹æœƒè©±"""
        # å¾ Claude Code Tool æ—¥èªŒæ”¶é›†
        claude_logs_path = Path.home() / ".claude-code" / "logs"
        recent_sessions = []
        
        if claude_logs_path.exists():
            cutoff_time = datetime.now() - timedelta(
                hours=self.learning_config["learning_interval_hours"]
            )
            
            for log_file in claude_logs_path.glob("*.json"):
                try:
                    with open(log_file, 'r', encoding='utf-8') as f:
                        log_data = json.load(f)
                        
                    # è½‰æ›ç‚ºæœƒè©±æ ¼å¼
                    session = self._parse_claude_log(log_data)
                    
                    if session and datetime.fromisoformat(session.start_time) > cutoff_time:
                        recent_sessions.append(session)
                        
                except Exception as e:
                    print(f"âš ï¸ è§£ææ—¥èªŒå¤±æ•— {log_file}: {e}")
                    
        return recent_sessions
        
    def _parse_claude_log(self, log_data: Dict[str, Any]) -> Optional[CodingSession]:
        """è§£æ Claude æ—¥èªŒ"""
        try:
            interactions = []
            files_created = []
            files_modified = []
            commands_used = []
            errors = []
            patterns = []
            
            # æå–äº¤äº’è¨˜éŒ„
            for entry in log_data.get("entries", []):
                if entry["type"] == "interaction":
                    interactions.append({
                        "timestamp": entry["timestamp"],
                        "user_input": entry["user_input"],
                        "claude_response": entry["response"],
                        "execution_time": entry.get("execution_time", 0)
                    })
                    
                    # æå–å‘½ä»¤
                    if entry["user_input"].startswith("/"):
                        commands_used.append(entry["user_input"].split()[0])
                        
                    # æå–æ–‡ä»¶æ“ä½œ
                    if "files" in entry:
                        for file_op in entry["files"]:
                            if file_op["action"] == "create":
                                files_created.append(file_op["path"])
                            elif file_op["action"] == "modify":
                                files_modified.append(file_op["path"])
                                
                    # æå–éŒ¯èª¤
                    if "error" in entry:
                        errors.append({
                            "error": entry["error"],
                            "context": entry.get("context", {})
                        })
                        
                    # è­˜åˆ¥æˆåŠŸæ¨¡å¼
                    if entry.get("success", False):
                        pattern = self._extract_pattern(entry)
                        if pattern:
                            patterns.append(pattern)
                            
            # å‰µå»ºæœƒè©±å°è±¡
            session_id = self._generate_id(f"session_{log_data.get('session_id', '')}")
            
            return CodingSession(
                session_id=session_id,
                start_time=log_data.get("start_time", datetime.now().isoformat()),
                end_time=log_data.get("end_time", datetime.now().isoformat()),
                duration_hours=log_data.get("duration_hours", 0),
                user_id=log_data.get("user_id", "unknown"),
                interactions=interactions,
                files_created=files_created,
                files_modified=files_modified,
                commands_used=commands_used,
                errors_encountered=errors,
                successful_patterns=patterns
            )
            
        except Exception as e:
            print(f"âš ï¸ è§£ææœƒè©±å¤±æ•—: {e}")
            return None
            
    def _extract_pattern(self, interaction: Dict[str, Any]) -> Optional[str]:
        """å¾äº¤äº’ä¸­æå–æ¨¡å¼"""
        user_input = interaction.get("user_input", "")
        response = interaction.get("response", "")
        
        # è­˜åˆ¥å¸¸è¦‹æ¨¡å¼
        if "generate" in user_input and "component" in user_input:
            return "component_generation"
        elif "fix" in user_input and "error" in user_input:
            return "error_fixing"
        elif "refactor" in user_input:
            return "code_refactoring"
        elif "test" in user_input:
            return "test_creation"
        elif "deploy" in user_input:
            return "deployment_task"
            
        return None
        
    async def _analyze_sessions(self, sessions: List[CodingSession]) -> List[LearningPattern]:
        """åˆ†ææœƒè©±æå–å­¸ç¿’æ¨¡å¼"""
        pattern_candidates = defaultdict(list)
        
        for session in sessions:
            # åˆ†ææ¯å€‹äº¤äº’
            for interaction in session.interactions:
                # æå–è§¸ç™¼æ¢ä»¶å’ŒéŸ¿æ‡‰
                trigger = interaction["user_input"]
                response = interaction["claude_response"]
                
                # è­˜åˆ¥æ¨¡å¼é¡å‹
                pattern_type = self._classify_pattern_type(trigger, response)
                
                if pattern_type:
                    pattern_key = f"{pattern_type}:{self._normalize_trigger(trigger)}"
                    pattern_candidates[pattern_key].append({
                        "trigger": trigger,
                        "response": response,
                        "context": {
                            "files": session.files_created + session.files_modified,
                            "previous_commands": session.commands_used[-5:],
                            "errors": session.errors_encountered
                        }
                    })
                    
        # ç¯©é¸é«˜é »æ¨¡å¼
        learned_patterns = []
        
        for pattern_key, instances in pattern_candidates.items():
            if len(instances) >= self.learning_config["min_pattern_occurrences"]:
                # å‰µå»ºå­¸ç¿’æ¨¡å¼
                pattern_type, normalized_trigger = pattern_key.split(":", 1)
                
                pattern = LearningPattern(
                    pattern_id=self._generate_id(pattern_key),
                    pattern_type=pattern_type,
                    trigger=normalized_trigger,
                    claude_response=self._merge_responses(instances),
                    k2_response="",  # å¾…ç”Ÿæˆ
                    success_rate=self._calculate_success_rate(instances),
                    usage_count=len(instances),
                    context_requirements=self._extract_context_requirements(instances)
                )
                
                learned_patterns.append(pattern)
                
        return learned_patterns
        
    def _classify_pattern_type(self, trigger: str, response: str) -> Optional[str]:
        """åˆ†é¡æ¨¡å¼é¡å‹"""
        trigger_lower = trigger.lower()
        
        if trigger_lower.startswith("/"):
            return "command"
        elif "generate" in trigger_lower or "create" in trigger_lower:
            return "code_generation"
        elif "fix" in trigger_lower or "error" in trigger_lower:
            return "error_fix"
        elif "refactor" in trigger_lower or "optimize" in trigger_lower:
            return "refactoring"
        elif "explain" in trigger_lower or "what" in trigger_lower:
            return "explanation"
            
        return "general"
        
    def _normalize_trigger(self, trigger: str) -> str:
        """æ¨™æº–åŒ–è§¸ç™¼æ¢ä»¶"""
        # ç§»é™¤ç‰¹å®šå€¼ï¼Œä¿ç•™æ¨¡å¼
        import re
        
        # æ›¿æ›æ–‡ä»¶è·¯å¾‘
        normalized = re.sub(r'[./\w-]+\.\w+', '<FILE>', trigger)
        
        # æ›¿æ›æ•¸å­—
        normalized = re.sub(r'\b\d+\b', '<NUM>', normalized)
        
        # æ›¿æ›å­—ç¬¦ä¸²
        normalized = re.sub(r'"[^"]*"', '<STR>', normalized)
        normalized = re.sub(r"'[^']*'", '<STR>', normalized)
        
        return normalized.strip()
        
    def _merge_responses(self, instances: List[Dict[str, Any]]) -> str:
        """åˆä½µå¤šå€‹éŸ¿æ‡‰ç‚ºæ¨¡æ¿"""
        # ç°¡å–®å¯¦ç¾ï¼šå–æœ€å¸¸è¦‹çš„éŸ¿æ‡‰çµæ§‹
        # å¯¦éš›æ‡‰è©²ä½¿ç”¨æ›´æ™ºèƒ½çš„æ¨¡æ¿æå–
        if instances:
            return instances[0]["response"]
        return ""
        
    def _calculate_success_rate(self, instances: List[Dict[str, Any]]) -> float:
        """è¨ˆç®—æˆåŠŸç‡"""
        # åŸºæ–¼éŒ¯èª¤æ•¸é‡è¨ˆç®—
        total = len(instances)
        errors = sum(1 for inst in instances if inst.get("context", {}).get("errors"))
        
        return (total - errors) / total if total > 0 else 0.0
        
    def _extract_context_requirements(self, instances: List[Dict[str, Any]]) -> Dict[str, Any]:
        """æå–ä¸Šä¸‹æ–‡éœ€æ±‚"""
        requirements = {
            "required_files": [],
            "required_commands": [],
            "common_errors": []
        }
        
        # çµ±è¨ˆå…±åŒå…ƒç´ 
        file_counts = defaultdict(int)
        command_counts = defaultdict(int)
        error_counts = defaultdict(int)
        
        for inst in instances:
            context = inst.get("context", {})
            
            for file in context.get("files", []):
                file_counts[self._get_file_type(file)] += 1
                
            for cmd in context.get("previous_commands", []):
                command_counts[cmd] += 1
                
            for error in context.get("errors", []):
                error_counts[error.get("error", "")] += 1
                
        # æå–é«˜é »éœ€æ±‚
        threshold = len(instances) * 0.5
        
        requirements["required_files"] = [
            file_type for file_type, count in file_counts.items()
            if count >= threshold
        ]
        
        requirements["required_commands"] = [
            cmd for cmd, count in command_counts.items()
            if count >= threshold
        ]
        
        requirements["common_errors"] = [
            error for error, count in error_counts.items()
            if count >= 2
        ]
        
        return requirements
        
    def _get_file_type(self, file_path: str) -> str:
        """ç²å–æ–‡ä»¶é¡å‹"""
        return Path(file_path).suffix or "unknown"
        
    async def _align_k2_responses(self, patterns: List[LearningPattern]):
        """å°é½Š K2 éŸ¿æ‡‰"""
        print("ğŸ”„ é–‹å§‹ K2 éŸ¿æ‡‰å°é½Š...")
        
        for pattern in patterns:
            # ç”Ÿæˆ K2 éŸ¿æ‡‰æ¨¡æ¿
            k2_response = await self._generate_k2_response(pattern)
            pattern.k2_response = k2_response
            
            # ä¿å­˜åˆ°æ¨¡å¼åº«
            self.patterns[pattern.pattern_id] = pattern
            
        self._save_data()
        
    async def _generate_k2_response(self, pattern: LearningPattern) -> str:
        """ç”Ÿæˆ K2 éŸ¿æ‡‰æ¨¡æ¿"""
        # åŸºæ–¼ Claude éŸ¿æ‡‰ç”Ÿæˆ K2 ç‰ˆæœ¬
        # å¯¦éš›å¯¦ç¾æ‡‰è©²èª¿ç”¨ K2 API é€²è¡Œå¾®èª¿
        
        # ç°¡åŒ–éŸ¿æ‡‰ï¼Œæé«˜æ•ˆç‡
        claude_response = pattern.claude_response
        
        # æå–é—œéµå‹•ä½œ
        k2_response = f"[K2 Optimized]\n"
        
        if pattern.pattern_type == "code_generation":
            k2_response += "å¿«é€Ÿç”Ÿæˆä»£ç¢¼...\n"
        elif pattern.pattern_type == "error_fix":
            k2_response += "è¨ºæ–·ä¸¦ä¿®å¾©éŒ¯èª¤...\n"
        elif pattern.pattern_type == "command":
            k2_response += "åŸ·è¡Œå‘½ä»¤...\n"
            
        # ä¿ç•™æ ¸å¿ƒå…§å®¹ï¼Œç§»é™¤å†—é¤˜è§£é‡‹
        k2_response += self._simplify_response(claude_response)
        
        return k2_response
        
    def _simplify_response(self, response: str) -> str:
        """ç°¡åŒ–éŸ¿æ‡‰å…§å®¹"""
        # ç§»é™¤éå¤šçš„è§£é‡‹
        lines = response.split('\n')
        
        # ä¿ç•™ä»£ç¢¼å¡Šå’Œé—œéµä¿¡æ¯
        simplified = []
        in_code_block = False
        
        for line in lines:
            if line.strip().startswith("```"):
                in_code_block = not in_code_block
                simplified.append(line)
            elif in_code_block:
                simplified.append(line)
            elif any(keyword in line.lower() for keyword in ["error", "warning", "success", "created", "fixed"]):
                simplified.append(line)
                
        return '\n'.join(simplified)
        
    def _update_statistics(self, sessions: List[CodingSession], patterns: List[LearningPattern]):
        """æ›´æ–°çµ±è¨ˆæ•¸æ“š"""
        # è¨ˆç®—ç¸½å­¸ç¿’æ™‚é–“
        total_hours = sum(session.duration_hours for session in sessions)
        self.alignment_data["total_hours_analyzed"] += total_hours
        
        # æ›´æ–°æ¨¡å¼æ•¸é‡
        self.alignment_data["patterns_learned"] = len(self.patterns)
        
        # è¨ˆç®—å°é½Šåˆ†æ•¸
        if self.patterns:
            avg_success_rate = sum(p.success_rate for p in self.patterns.values()) / len(self.patterns)
            self.alignment_data["alignment_score"] = avg_success_rate
            
        self.alignment_data["last_update"] = datetime.now().isoformat()
        
        self._save_data()
        
        # ç”Ÿæˆå ±å‘Š
        self._generate_learning_report()
        
    def _generate_learning_report(self):
        """ç”Ÿæˆå­¸ç¿’å ±å‘Š"""
        report = f"""
ğŸ“Š K2 å­¸ç¿’å°é½Šå ±å‘Š
ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ğŸ“ˆ å­¸ç¿’çµ±è¨ˆ:
- ç¸½åˆ†ææ™‚é–“: {self.alignment_data['total_hours_analyzed']:.1f} å°æ™‚
- å­¸ç¿’æ¨¡å¼æ•¸: {self.alignment_data['patterns_learned']}
- å°é½Šåˆ†æ•¸: {self.alignment_data['alignment_score']:.2%}

ğŸ¯ é«˜é »æ¨¡å¼ Top 5:
"""
        
        # æ’åºæ¨¡å¼
        sorted_patterns = sorted(
            self.patterns.values(), 
            key=lambda p: p.usage_count, 
            reverse=True
        )[:5]
        
        for i, pattern in enumerate(sorted_patterns, 1):
            report += f"{i}. {pattern.pattern_type}: {pattern.trigger} (ä½¿ç”¨ {pattern.usage_count} æ¬¡)\n"
            
        # ä¿å­˜å ±å‘Š
        report_path = self.data_path / "learning_report.md"
        report_path.write_text(report, encoding='utf-8')
        
        print(f"\n{report}")
        
    def _generate_id(self, content: str) -> str:
        """ç”Ÿæˆå”¯ä¸€ID"""
        return hashlib.md5(f"{content}_{datetime.now()}".encode()).hexdigest()[:16]
        
    async def get_k2_response_template(self, user_input: str) -> Optional[Dict[str, Any]]:
        """ç²å– K2 éŸ¿æ‡‰æ¨¡æ¿"""
        # æ¨™æº–åŒ–è¼¸å…¥
        normalized = self._normalize_trigger(user_input)
        
        # æŸ¥æ‰¾åŒ¹é…çš„æ¨¡å¼
        for pattern in self.patterns.values():
            if pattern.trigger == normalized or self._is_similar(pattern.trigger, normalized):
                return {
                    "pattern_id": pattern.pattern_id,
                    "k2_response": pattern.k2_response,
                    "confidence": pattern.success_rate,
                    "context_requirements": pattern.context_requirements,
                    "usage_count": pattern.usage_count
                }
                
        return None
        
    def _is_similar(self, pattern: str, input: str) -> bool:
        """æª¢æŸ¥ç›¸ä¼¼æ€§"""
        # ç°¡å–®çš„ç›¸ä¼¼æ€§æª¢æŸ¥
        pattern_tokens = set(pattern.lower().split())
        input_tokens = set(input.lower().split())
        
        intersection = pattern_tokens.intersection(input_tokens)
        union = pattern_tokens.union(input_tokens)
        
        if not union:
            return False
            
        similarity = len(intersection) / len(union)
        return similarity > 0.7


# å‰µå»ºå…¨å±€å¯¦ä¾‹
k2_learning_system = K2LearningAlignmentSystem()


async def start_k2_learning():
    """å•Ÿå‹• K2 å­¸ç¿’"""
    await k2_learning_system.start_continuous_learning()


async def get_k2_aligned_response(user_input: str) -> Optional[Dict[str, Any]]:
    """ç²å– K2 å°é½Šçš„éŸ¿æ‡‰"""
    return await k2_learning_system.get_k2_response_template(user_input)