#!/usr/bin/env python3
"""
Business MCP é©…å‹•çš„ç¶²ç«™å¢é‡å„ªåŒ–å¼•æ“
åŸºæ–¼æˆ°ç•¥æ¼”ç¤ºç³»çµ±ä¾†æŒçºŒå„ªåŒ–ç¶²ç«™æ€§èƒ½å’Œè½‰æ›ç‡
"""

import asyncio
import json
import logging
import time
import random
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from enum import Enum
import hashlib

from .strategic_demo_engine import strategic_demo_engine
from .business_manager import business_manager

logger = logging.getLogger(__name__)

class OptimizationType(Enum):
    """å„ªåŒ–é¡å‹"""
    CONVERSION_RATE = "conversion_rate"      # è½‰æ›ç‡å„ªåŒ–
    USER_ENGAGEMENT = "user_engagement"      # ç”¨æˆ¶åƒèˆ‡åº¦
    RETENTION = "retention"                  # ç”¨æˆ¶ç•™å­˜
    MONETIZATION = "monetization"            # è®Šç¾å„ªåŒ–
    PERFORMANCE = "performance"              # æ€§èƒ½å„ªåŒ–

class TestStatus(Enum):
    """æ¸¬è©¦ç‹€æ…‹"""
    DRAFT = "draft"                         # è‰ç¨¿
    RUNNING = "running"                     # é‹è¡Œä¸­
    COMPLETED = "completed"                 # å·²å®Œæˆ
    PAUSED = "paused"                      # æš«åœ
    FAILED = "failed"                      # å¤±æ•—

@dataclass
class OptimizationMetric:
    """å„ªåŒ–æŒ‡æ¨™"""
    metric_name: str
    current_value: float
    target_value: float
    improvement_percentage: float
    confidence_level: float
    statistical_significance: bool

@dataclass
class ABTestVariant:
    """A/B æ¸¬è©¦è®Šé«”"""
    variant_id: str
    name: str
    description: str
    traffic_allocation: float               # æµé‡åˆ†é…ç™¾åˆ†æ¯”
    changes: Dict[str, Any]                # è®Šæ›´å…§å®¹
    performance_metrics: Dict[str, float]   # æ€§èƒ½æŒ‡æ¨™
    conversion_rate: float
    sample_size: int
    created_at: datetime

@dataclass
class WebsiteOptimizationExperiment:
    """ç¶²ç«™å„ªåŒ–å¯¦é©—"""
    experiment_id: str
    name: str
    description: str
    optimization_type: OptimizationType
    target_segment: str                     # ç›®æ¨™ç”¨æˆ¶ç¾¤é«”
    hypothesis: str                         # å‡è¨­
    variants: List[ABTestVariant]
    control_group: ABTestVariant
    status: TestStatus
    start_date: datetime
    end_date: Optional[datetime]
    expected_impact: Dict[str, float]
    actual_results: Optional[Dict[str, float]]
    business_rationale: str                 # å•†æ¥­é‚è¼¯

class WebsiteOptimizationEngine:
    """ç¶²ç«™å„ªåŒ–å¼•æ“"""
    
    def __init__(self):
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # å¯¦é©—ç®¡ç†
        self.active_experiments: Dict[str, WebsiteOptimizationExperiment] = {}
        self.completed_experiments: List[WebsiteOptimizationExperiment] = []
        
        # å„ªåŒ–ç­–ç•¥åº«
        self.optimization_strategies = self._create_optimization_strategies()
        
        # ç”¨æˆ¶è¡Œç‚ºè¿½è¹¤
        self.user_behavior_data: Dict[str, List[Dict]] = {}
        
        # æ€§èƒ½åŸºç·š
        self.performance_baseline = {
            "conversion_rate": 0.05,          # 5% åŸºç·šè½‰æ›ç‡
            "bounce_rate": 0.65,              # 65% è·³å‡ºç‡
            "average_session_duration": 180,  # 3åˆ†é˜
            "pages_per_session": 2.5,
            "demo_completion_rate": 0.25,     # 25% æ¼”ç¤ºå®Œæˆç‡
            "signup_rate": 0.12,              # 12% è¨»å†Šç‡
            "trial_to_paid_rate": 0.30        # 30% è©¦ç”¨è½‰ä»˜è²»ç‡
        }
        
    def _create_optimization_strategies(self) -> Dict[str, Dict[str, Any]]:
        """å‰µå»ºå„ªåŒ–ç­–ç•¥åº«"""
        return {
            "hero_section_optimization": {
                "type": OptimizationType.CONVERSION_RATE,
                "target_metrics": ["signup_rate", "demo_request_rate"],
                "variants": [
                    {
                        "name": "åƒ¹å€¼ä¸»å¼µå¼·åŒ–",
                        "changes": {
                            "headline": "10å€ç·¨ç¨‹æ•ˆç‡ï¼Œ60%æˆæœ¬ç¯€çœ - PowerAuto.ai",
                            "subheadline": "Claude + K2é›™AIæ¶æ§‹ï¼Œè®“æ¯å€‹é–‹ç™¼è€…éƒ½èƒ½äº«å—AIè¶…èƒ½åŠ›",
                            "cta_text": "ç«‹å³å…è²»é«”é©—10å€æ•ˆç‡",
                            "hero_image": "efficiency_visualization.png"
                        }
                    },
                    {
                        "name": "ROIç„¦é»",
                        "changes": {
                            "headline": "æ¯æœˆç¯€çœÂ¥50,000é–‹ç™¼æˆæœ¬",
                            "subheadline": "æ™ºèƒ½AIåŠ©æ‰‹è®“ä½ çš„åœ˜éšŠç”Ÿç”¢åŠ›æå‡250%",
                            "cta_text": "è¨ˆç®—æˆ‘çš„ROI",
                            "hero_image": "roi_calculator.png"
                        }
                    },
                    {
                        "name": "ç¤¾æœƒè­‰æ˜",
                        "changes": {
                            "headline": "1000+é–‹ç™¼åœ˜éšŠçš„å…±åŒé¸æ“‡",
                            "subheadline": "å¾å‰µæ¥­å…¬å¸åˆ°Fortune 500ï¼Œéƒ½åœ¨ç”¨PowerAuto.aiæå‡æ•ˆç‡",
                            "cta_text": "åŠ å…¥æˆåŠŸçš„é–‹ç™¼è€…",
                            "hero_image": "social_proof.png"
                        }
                    }
                ]
            },
            "pricing_page_optimization": {
                "type": OptimizationType.MONETIZATION,
                "target_metrics": ["trial_to_paid_rate", "plan_upgrade_rate"],
                "variants": [
                    {
                        "name": "åƒ¹å€¼å°å‘å®šåƒ¹",
                        "changes": {
                            "pricing_model": "value_based",
                            "highlight_savings": True,
                            "show_roi_calculator": True,
                            "testimonials": "customer_success_stories"
                        }
                    },
                    {
                        "name": "éŒ¨å®šæ•ˆæ‡‰",
                        "changes": {
                            "pricing_model": "anchoring",
                            "enterprise_plan_prominent": True,
                            "discount_badges": True,
                            "urgency_elements": "limited_time_offer"
                        }
                    }
                ]
            },
            "demo_flow_optimization": {
                "type": OptimizationType.USER_ENGAGEMENT,
                "target_metrics": ["demo_completion_rate", "demo_to_signup_rate"],
                "variants": [
                    {
                        "name": "å€‹æ€§åŒ–æ¼”ç¤ºè·¯å¾‘",
                        "changes": {
                            "demo_type": "personalized",
                            "user_segmentation": True,
                            "adaptive_content": True,
                            "real_time_roi": True
                        }
                    },
                    {
                        "name": "äº’å‹•å¼æ¼”ç¤º",
                        "changes": {
                            "demo_type": "interactive",
                            "hands_on_experience": True,
                            "progress_indicators": True,
                            "gamification": True
                        }
                    }
                ]
            },
            "onboarding_optimization": {
                "type": OptimizationType.RETENTION,
                "target_metrics": ["user_activation_rate", "day7_retention"],
                "variants": [
                    {
                        "name": "æ¼¸é€²å¼å…¥é–€",
                        "changes": {
                            "onboarding_type": "progressive",
                            "step_by_step_guidance": True,
                            "achievement_system": True,
                            "personal_assistant": True
                        }
                    },
                    {
                        "name": "å¿«é€ŸæˆåŠŸé«”é©—",
                        "changes": {
                            "onboarding_type": "quick_wins",
                            "immediate_value": True,
                            "template_gallery": True,
                            "one_click_setup": True
                        }
                    }
                ]
            }
        }
    
    async def analyze_optimization_opportunities(self) -> List[Dict[str, Any]]:
        """åˆ†æå„ªåŒ–æ©Ÿæœƒ"""
        self.logger.info("åˆ†æç¶²ç«™å„ªåŒ–æ©Ÿæœƒ")
        
        # ç²å– Business MCP æ•¸æ“š
        market_analysis = await business_manager.generate_market_analysis()
        acquisition_strategy = await business_manager.generate_customer_acquisition_strategy()
        
        # åˆ†æç•¶å‰æ€§èƒ½
        current_metrics = await self._get_current_performance_metrics()
        
        # è­˜åˆ¥å„ªåŒ–æ©Ÿæœƒ
        opportunities = []
        
        for strategy_name, strategy in self.optimization_strategies.items():
            opportunity_score = await self._calculate_opportunity_score(
                strategy, current_metrics, market_analysis
            )
            
            if opportunity_score > 0.6:  # é«˜æ½›åŠ›æ©Ÿæœƒ
                opportunities.append({
                    "strategy_name": strategy_name,
                    "opportunity_score": opportunity_score,
                    "expected_impact": await self._estimate_impact(strategy, current_metrics),
                    "implementation_complexity": self._assess_complexity(strategy),
                    "business_rationale": await self._generate_business_rationale(
                        strategy, market_analysis, acquisition_strategy
                    ),
                    "recommended_variants": strategy["variants"][:2]  # æ¨è–¦å‰2å€‹è®Šé«”
                })
        
        # æŒ‰æ©Ÿæœƒåˆ†æ•¸æ’åº
        opportunities.sort(key=lambda x: x["opportunity_score"], reverse=True)
        
        self.logger.info(f"è­˜åˆ¥å‡º {len(opportunities)} å€‹å„ªåŒ–æ©Ÿæœƒ")
        return opportunities
    
    async def _get_current_performance_metrics(self) -> Dict[str, float]:
        """ç²å–ç•¶å‰æ€§èƒ½æŒ‡æ¨™"""
        # åœ¨å¯¦éš›ç’°å¢ƒä¸­ï¼Œé€™è£¡æœƒå¾åˆ†æå·¥å…·ç²å–çœŸå¯¦æ•¸æ“š
        # é€™è£¡ä½¿ç”¨æ¨¡æ“¬æ•¸æ“š + ä¸€äº›éš¨æ©Ÿè®ŠåŒ–
        base_metrics = self.performance_baseline.copy()
        
        # æ·»åŠ ä¸€äº›éš¨æ©Ÿè®ŠåŒ–ä¾†æ¨¡æ“¬çœŸå¯¦æ³¢å‹•
        for metric, value in base_metrics.items():
            variation = random.uniform(-0.1, 0.1)  # Â±10% è®ŠåŒ–
            base_metrics[metric] = value * (1 + variation)
        
        return base_metrics
    
    async def _calculate_opportunity_score(self, strategy: Dict[str, Any], 
                                         current_metrics: Dict[str, float],
                                         market_analysis: Dict[str, Any]) -> float:
        """è¨ˆç®—å„ªåŒ–æ©Ÿæœƒåˆ†æ•¸"""
        score = 0.0
        
        # åŸºæ–¼ç•¶å‰æ€§èƒ½å·®è·
        target_metrics = strategy.get("target_metrics", [])
        for metric in target_metrics:
            if metric in current_metrics:
                current_value = current_metrics[metric]
                # å‡è¨­è¡Œæ¥­å¹³å‡æ°´å¹³
                industry_benchmark = self.performance_baseline[metric] * 1.2
                if current_value < industry_benchmark:
                    gap_score = (industry_benchmark - current_value) / industry_benchmark
                    score += gap_score * 0.4
        
        # åŸºæ–¼å¸‚å ´æ½›åŠ›
        market_size = market_analysis.get("market_size", {})
        if "serviceable_obtainable_market" in market_size:
            market_potential = 0.3  # å‡è¨­æˆ‘å€‘èƒ½ç²å–30%çš„SOM
            score += market_potential * 0.3
        
        # åŸºæ–¼ç«¶çˆ­å„ªå‹¢
        advantages = market_analysis.get("competitive_landscape", {}).get("our_advantages", [])
        if len(advantages) > 3:
            score += 0.3
        
        return min(score, 1.0)  # é™åˆ¶åœ¨0-1ä¹‹é–“
    
    async def _estimate_impact(self, strategy: Dict[str, Any], 
                             current_metrics: Dict[str, float]) -> Dict[str, float]:
        """ä¼°ç®—å„ªåŒ–å½±éŸ¿"""
        impact = {}
        target_metrics = strategy.get("target_metrics", [])
        
        for metric in target_metrics:
            if metric in current_metrics:
                current_value = current_metrics[metric]
                # åŸºæ–¼å„ªåŒ–é¡å‹ä¼°ç®—æå‡å¹…åº¦
                if strategy["type"] == OptimizationType.CONVERSION_RATE:
                    improvement = 0.15  # 15% æå‡
                elif strategy["type"] == OptimizationType.USER_ENGAGEMENT:
                    improvement = 0.25  # 25% æå‡
                elif strategy["type"] == OptimizationType.RETENTION:
                    improvement = 0.20  # 20% æå‡
                elif strategy["type"] == OptimizationType.MONETIZATION:
                    improvement = 0.30  # 30% æå‡
                else:
                    improvement = 0.10  # 10% æå‡
                
                impact[metric] = {
                    "current": current_value,
                    "estimated": current_value * (1 + improvement),
                    "improvement_percentage": improvement * 100
                }
        
        return impact
    
    def _assess_complexity(self, strategy: Dict[str, Any]) -> str:
        """è©•ä¼°å¯¦æ–½è¤‡é›œåº¦"""
        variants_count = len(strategy.get("variants", []))
        
        if variants_count <= 2:
            return "ä½"
        elif variants_count <= 4:
            return "ä¸­"
        else:
            return "é«˜"
    
    async def _generate_business_rationale(self, strategy: Dict[str, Any],
                                         market_analysis: Dict[str, Any],
                                         acquisition_strategy: Dict[str, Any]) -> str:
        """ç”Ÿæˆå•†æ¥­é‚è¼¯èªªæ˜"""
        strategy_type = strategy["type"]
        
        if strategy_type == OptimizationType.CONVERSION_RATE:
            return f"åŸºæ–¼å¸‚å ´åˆ†æï¼Œæˆ‘å€‘åœ¨{market_analysis.get('target_segments', [])[0].get('segment', 'ç›®æ¨™å¸‚å ´')}æœ‰å·¨å¤§æ½›åŠ›ã€‚é€šéå„ªåŒ–è½‰æ›ç‡ï¼Œé è¨ˆèƒ½å°‡{acquisition_strategy.get('conversion_funnel', {}).get('purchase', {}).get('target', '600')}æœˆåº¦ä»˜è²»ç”¨æˆ¶æå‡30%ã€‚"
        elif strategy_type == OptimizationType.USER_ENGAGEMENT:
            return "æå‡ç”¨æˆ¶åƒèˆ‡åº¦èƒ½ç›´æ¥å½±éŸ¿ç•™å­˜ç‡å’ŒLTVã€‚æ ¹æ“šBusiness MCPåˆ†æï¼Œé«˜åƒèˆ‡åº¦ç”¨æˆ¶çš„LTVæ˜¯æ™®é€šç”¨æˆ¶çš„3å€ã€‚"
        elif strategy_type == OptimizationType.RETENTION:
            return f"ç”¨æˆ¶ç•™å­˜ç›´æ¥å½±éŸ¿LTV/CACæ¯”ç‡ã€‚ç›®æ¨™LTV/CACæ¯”ç‡ç‚º{acquisition_strategy.get('key_metrics', {}).get('ltv_cac_ratio', 20)}ï¼Œå„ªåŒ–ç•™å­˜èƒ½é¡¯è‘—æ”¹å–„å–®ä½ç¶“æ¿Ÿæ•ˆç›Šã€‚"
        elif strategy_type == OptimizationType.MONETIZATION:
            return "æ ¹æ“šå®šåƒ¹ç­–ç•¥åˆ†æï¼Œå„ªåŒ–è®Šç¾æµç¨‹èƒ½æå‡ARPUã€‚ç«¶çˆ­å„ªå‹¢åœ¨æ–¼æˆ‘å€‘çš„æˆæœ¬ç¯€çœåƒ¹å€¼ä¸»å¼µï¼Œéœ€è¦åœ¨å®šåƒ¹é é¢å¼·åŒ–é€™ä¸€é»ã€‚"
        else:
            return "æ€§èƒ½å„ªåŒ–èƒ½æ”¹å–„ç”¨æˆ¶é«”é©—ï¼Œé–“æ¥æå‡æ‰€æœ‰æ¼æ–—æŒ‡æ¨™ã€‚"
    
    async def create_ab_test_experiment(self, strategy_name: str, 
                                      variants_to_test: List[str]) -> WebsiteOptimizationExperiment:
        """å‰µå»º A/B æ¸¬è©¦å¯¦é©—"""
        self.logger.info(f"å‰µå»º A/B æ¸¬è©¦å¯¦é©—: {strategy_name}")
        
        strategy = self.optimization_strategies[strategy_name]
        experiment_id = f"exp_{int(time.time())}_{strategy_name}"
        
        # å‰µå»ºæ§åˆ¶çµ„
        control_group = ABTestVariant(
            variant_id=f"{experiment_id}_control",
            name="æ§åˆ¶çµ„ï¼ˆç•¶å‰ç‰ˆæœ¬ï¼‰",
            description="ç•¶å‰ç¶²ç«™ç‰ˆæœ¬ï¼Œä½œç‚ºåŸºç·šå°æ¯”",
            traffic_allocation=0.5,
            changes={},
            performance_metrics={},
            conversion_rate=0.0,
            sample_size=0,
            created_at=datetime.now()
        )
        
        # å‰µå»ºæ¸¬è©¦è®Šé«”
        variants = []
        traffic_per_variant = 0.5 / len(variants_to_test)
        
        for i, variant_name in enumerate(variants_to_test):
            variant_config = next(
                (v for v in strategy["variants"] if v["name"] == variant_name), 
                strategy["variants"][0]
            )
            
            variant = ABTestVariant(
                variant_id=f"{experiment_id}_variant_{i+1}",
                name=variant_config["name"],
                description=f"æ¸¬è©¦è®Šé«”: {variant_config['name']}",
                traffic_allocation=traffic_per_variant,
                changes=variant_config["changes"],
                performance_metrics={},
                conversion_rate=0.0,
                sample_size=0,
                created_at=datetime.now()
            )
            variants.append(variant)
        
        # ç²å–å•†æ¥­é‚è¼¯
        market_analysis = await business_manager.generate_market_analysis()
        acquisition_strategy = await business_manager.generate_customer_acquisition_strategy()
        business_rationale = await self._generate_business_rationale(
            strategy, market_analysis, acquisition_strategy
        )
        
        # å‰µå»ºå¯¦é©—
        experiment = WebsiteOptimizationExperiment(
            experiment_id=experiment_id,
            name=f"{strategy_name} å„ªåŒ–å¯¦é©—",
            description=f"æ¸¬è©¦ {strategy_name} çš„ä¸åŒå„ªåŒ–æ–¹æ¡ˆ",
            optimization_type=strategy["type"],
            target_segment="all_users",
            hypothesis=f"é€šéå„ªåŒ– {strategy_name}ï¼Œèƒ½å¤ æå‡ {', '.join(strategy['target_metrics'])}",
            variants=variants,
            control_group=control_group,
            status=TestStatus.DRAFT,
            start_date=datetime.now(),
            end_date=None,
            expected_impact=await self._estimate_impact(strategy, await self._get_current_performance_metrics()),
            actual_results=None,
            business_rationale=business_rationale
        )
        
        self.active_experiments[experiment_id] = experiment
        
        self.logger.info(f"A/B æ¸¬è©¦å¯¦é©—å·²å‰µå»º: {experiment_id}")
        return experiment
    
    async def start_experiment(self, experiment_id: str) -> bool:
        """å•Ÿå‹•å¯¦é©—"""
        if experiment_id not in self.active_experiments:
            return False
        
        experiment = self.active_experiments[experiment_id]
        experiment.status = TestStatus.RUNNING
        experiment.start_date = datetime.now()
        
        self.logger.info(f"å¯¦é©—å·²å•Ÿå‹•: {experiment_id}")
        return True
    
    async def collect_experiment_data(self, experiment_id: str, 
                                    user_data: Dict[str, Any]) -> bool:
        """æ”¶é›†å¯¦é©—æ•¸æ“š"""
        if experiment_id not in self.active_experiments:
            return False
        
        experiment = self.active_experiments[experiment_id]
        user_id = user_data.get("user_id", "anonymous")
        variant_id = user_data.get("variant_id")
        action = user_data.get("action")  # 'view', 'click', 'signup', 'purchase'
        
        # è¨˜éŒ„ç”¨æˆ¶è¡Œç‚º
        if user_id not in self.user_behavior_data:
            self.user_behavior_data[user_id] = []
        
        self.user_behavior_data[user_id].append({
            "experiment_id": experiment_id,
            "variant_id": variant_id,
            "action": action,
            "timestamp": datetime.now().isoformat(),
            "metadata": user_data.get("metadata", {})
        })
        
        # æ›´æ–°è®Šé«”çµ±è¨ˆ
        if variant_id == experiment.control_group.variant_id:
            target_variant = experiment.control_group
        else:
            target_variant = next(
                (v for v in experiment.variants if v.variant_id == variant_id), 
                None
            )
        
        if target_variant:
            target_variant.sample_size += 1
            if action == "conversion":
                target_variant.conversion_rate = (
                    target_variant.conversion_rate * (target_variant.sample_size - 1) + 1
                ) / target_variant.sample_size
        
        return True
    
    async def analyze_experiment_results(self, experiment_id: str) -> Dict[str, Any]:
        """åˆ†æå¯¦é©—çµæœ"""
        if experiment_id not in self.active_experiments:
            return {}
        
        experiment = self.active_experiments[experiment_id]
        
        # è¨ˆç®—çµ±è¨ˆé¡¯è‘—æ€§
        results = {
            "experiment_id": experiment_id,
            "status": experiment.status.value,
            "runtime_days": (datetime.now() - experiment.start_date).days,
            "control_group": {
                "variant_id": experiment.control_group.variant_id,
                "sample_size": experiment.control_group.sample_size,
                "conversion_rate": experiment.control_group.conversion_rate,
                "confidence_interval": self._calculate_confidence_interval(
                    experiment.control_group.conversion_rate,
                    experiment.control_group.sample_size
                )
            },
            "test_variants": []
        }
        
        best_variant = experiment.control_group
        best_performance = experiment.control_group.conversion_rate
        
        for variant in experiment.variants:
            # è¨ˆç®—ç›¸å°æ–¼æ§åˆ¶çµ„çš„æå‡
            lift = 0.0
            if experiment.control_group.conversion_rate > 0:
                lift = (variant.conversion_rate - experiment.control_group.conversion_rate) / experiment.control_group.conversion_rate
            
            # è¨ˆç®—çµ±è¨ˆé¡¯è‘—æ€§
            significance = self._calculate_statistical_significance(
                experiment.control_group, variant
            )
            
            variant_result = {
                "variant_id": variant.variant_id,
                "name": variant.name,
                "sample_size": variant.sample_size,
                "conversion_rate": variant.conversion_rate,
                "lift_percentage": lift * 100,
                "statistical_significance": significance,
                "confidence_interval": self._calculate_confidence_interval(
                    variant.conversion_rate, variant.sample_size
                ),
                "changes": variant.changes
            }
            
            results["test_variants"].append(variant_result)
            
            # è¿½è¹¤æœ€ä½³è®Šé«”
            if variant.conversion_rate > best_performance:
                best_variant = variant
                best_performance = variant.conversion_rate
        
        # ç”Ÿæˆå»ºè­°
        results["recommendation"] = await self._generate_recommendation(
            experiment, best_variant, results
        )
        
        return results
    
    def _calculate_confidence_interval(self, conversion_rate: float, 
                                     sample_size: int, confidence: float = 0.95) -> Dict[str, float]:
        """è¨ˆç®—ç½®ä¿¡å€é–“"""
        if sample_size == 0:
            return {"lower": 0.0, "upper": 0.0}
        
        import math
        z_score = 1.96  # 95% ç½®ä¿¡åº¦
        margin_of_error = z_score * math.sqrt((conversion_rate * (1 - conversion_rate)) / sample_size)
        
        return {
            "lower": max(0.0, conversion_rate - margin_of_error),
            "upper": min(1.0, conversion_rate + margin_of_error)
        }
    
    def _calculate_statistical_significance(self, control: ABTestVariant, 
                                          test: ABTestVariant) -> bool:
        """è¨ˆç®—çµ±è¨ˆé¡¯è‘—æ€§"""
        # ç°¡åŒ–çš„çµ±è¨ˆé¡¯è‘—æ€§è¨ˆç®—
        if control.sample_size < 100 or test.sample_size < 100:
            return False
        
        # ä½¿ç”¨Zæª¢é©—çš„ç°¡åŒ–ç‰ˆæœ¬
        p1, n1 = control.conversion_rate, control.sample_size
        p2, n2 = test.conversion_rate, test.sample_size
        
        if p1 == 0 and p2 == 0:
            return False
        
        p_pool = (p1 * n1 + p2 * n2) / (n1 + n2)
        se = (p_pool * (1 - p_pool) * (1/n1 + 1/n2)) ** 0.5
        
        if se == 0:
            return False
        
        z = abs(p1 - p2) / se
        return z > 1.96  # 95% ç½®ä¿¡åº¦
    
    async def _generate_recommendation(self, experiment: WebsiteOptimizationExperiment,
                                     best_variant: ABTestVariant,
                                     results: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆå„ªåŒ–å»ºè­°"""
        if best_variant == experiment.control_group:
            return {
                "action": "keep_current",
                "reasoning": "æ²’æœ‰è®Šé«”é¡¯è‘—å„ªæ–¼ç•¶å‰ç‰ˆæœ¬ï¼Œå»ºè­°ä¿æŒç¾ç‹€ä¸¦å˜—è©¦å…¶ä»–å„ªåŒ–æ–¹å‘",
                "next_steps": ["åˆ†æç”¨æˆ¶åé¥‹", "å˜—è©¦å…¶ä»–å„ªåŒ–ç­–ç•¥", "å¢åŠ æ¨£æœ¬é‡é‡æ–°æ¸¬è©¦"]
            }
        
        # æ‰¾åˆ°æœ€ä½³æ¸¬è©¦è®Šé«”çš„çµæœ
        best_test_result = next(
            (r for r in results["test_variants"] if r["variant_id"] == best_variant.variant_id),
            None
        )
        
        if best_test_result and best_test_result["statistical_significance"]:
            return {
                "action": "implement_winner",
                "winning_variant": best_test_result["name"],
                "expected_improvement": f"{best_test_result['lift_percentage']:.1f}%",
                "reasoning": f"è®Šé«” '{best_test_result['name']}' é¡¯è‘—å„ªæ–¼æ§åˆ¶çµ„ï¼Œæå‡ {best_test_result['lift_percentage']:.1f}%",
                "next_steps": [
                    "å…¨é‡ç™¼å¸ƒç²å‹è®Šé«”",
                    "ç›£æ§å¯¦æ–½å¾Œçš„æ€§èƒ½æŒ‡æ¨™",
                    "è¦åŠƒä¸‹ä¸€è¼ªå„ªåŒ–å¯¦é©—"
                ],
                "implementation_details": best_variant.changes
            }
        else:
            return {
                "action": "continue_testing",
                "reasoning": "é›–ç„¶æœ‰è®Šé«”è¡¨ç¾æ›´å¥½ï¼Œä½†çµ±è¨ˆé¡¯è‘—æ€§ä¸è¶³ï¼Œéœ€è¦æ›´å¤šæ•¸æ“š",
                "next_steps": ["å»¶é•·æ¸¬è©¦æ™‚é–“", "å¢åŠ æµé‡åˆ†é…", "å„ªåŒ–è®Šé«”è¨­è¨ˆ"]
            }
    
    async def generate_optimization_roadmap(self) -> Dict[str, Any]:
        """ç”Ÿæˆå„ªåŒ–è·¯ç·šåœ–"""
        self.logger.info("ç”Ÿæˆç¶²ç«™å„ªåŒ–è·¯ç·šåœ–")
        
        # åˆ†æå„ªåŒ–æ©Ÿæœƒ
        opportunities = await self.analyze_optimization_opportunities()
        
        # ç²å– Business MCP æŒ‡å°
        market_analysis = await business_manager.generate_market_analysis()
        acquisition_strategy = await business_manager.generate_customer_acquisition_strategy()
        financial_projection = await business_manager.generate_financial_projection(1)
        
        # å‰µå»ºå„ªåŒ–è·¯ç·šåœ–
        roadmap = {
            "executive_summary": {
                "total_opportunities": len(opportunities),
                "high_impact_opportunities": len([o for o in opportunities if o["opportunity_score"] > 0.8]),
                "estimated_annual_impact": sum(
                    self._calculate_annual_value(o["expected_impact"]) for o in opportunities
                ),
                "recommended_timeline": "3å€‹æœˆæ¼¸é€²å¼å¯¦æ–½"
            },
            "quarter_plan": {
                "Q1": {
                    "focus": "è½‰æ›ç‡åŸºç¤å„ªåŒ–",
                    "experiments": opportunities[:2],
                    "expected_impact": "15-25% è½‰æ›ç‡æå‡",
                    "resource_requirement": "1 å‰ç«¯å·¥ç¨‹å¸« + 1 æ•¸æ“šåˆ†æå¸«"
                },
                "Q2": {
                    "focus": "ç”¨æˆ¶é«”é©—æ·±åº¦å„ªåŒ–",
                    "experiments": opportunities[2:4] if len(opportunities) > 2 else [],
                    "expected_impact": "20-30% ç”¨æˆ¶ç•™å­˜æå‡",
                    "resource_requirement": "1 UXè¨­è¨ˆå¸« + 1 å‰ç«¯å·¥ç¨‹å¸«"
                },
                "Q3": {
                    "focus": "è®Šç¾æµç¨‹å„ªåŒ–",
                    "experiments": opportunities[4:] if len(opportunities) > 4 else [],
                    "expected_impact": "10-20% ARPU æå‡",
                    "resource_requirement": "1 ç”¢å“ç¶“ç† + 1 æ•¸æ“šç§‘å­¸å®¶"
                }
            },
            "success_metrics": {
                "primary_kpis": [
                    "æ•´é«”è½‰æ›ç‡",
                    "ç”¨æˆ¶ç”Ÿå‘½é€±æœŸåƒ¹å€¼",
                    "ç²å®¢æˆæœ¬",
                    "æœˆåº¦ç¶“å¸¸æ€§æ”¶å…¥"
                ],
                "secondary_kpis": [
                    "é é¢åœç•™æ™‚é–“",
                    "è·³å‡ºç‡",
                    "åŠŸèƒ½æ¡ç”¨ç‡",
                    "å®¢æˆ¶æ»¿æ„åº¦"
                ]
            },
            "risk_mitigation": {
                "technical_risks": [
                    "A/Bæ¸¬è©¦æ¡†æ¶ç©©å®šæ€§",
                    "æ€§èƒ½å½±éŸ¿ç›£æ§",
                    "æ•¸æ“šæ”¶é›†åˆè¦æ€§"
                ],
                "business_risks": [
                    "ç”¨æˆ¶é«”é©—è² é¢å½±éŸ¿",
                    "å“ç‰Œä¸€è‡´æ€§ç¶­è­·",
                    "ç«¶çˆ­å°æ‰‹å¿«é€Ÿè·Ÿé€²"
                ]
            },
            "business_alignment": {
                "market_strategy": market_analysis.get("growth_strategy", {}),
                "acquisition_channels": acquisition_strategy.get("channels", []),
                "financial_targets": financial_projection.get("projections", [])
            }
        }
        
        return roadmap
    
    def _calculate_annual_value(self, expected_impact: Dict[str, Any]) -> float:
        """è¨ˆç®—å¹´åº¦åƒ¹å€¼å½±éŸ¿"""
        total_value = 0.0
        
        for metric, impact in expected_impact.items():
            if isinstance(impact, dict) and "improvement_percentage" in impact:
                improvement = impact["improvement_percentage"] / 100
                
                # æ ¹æ“šæŒ‡æ¨™é¡å‹ä¼°ç®—å•†æ¥­åƒ¹å€¼
                if "conversion" in metric:
                    # å‡è¨­æ¯1%è½‰æ›ç‡æå‡åƒ¹å€¼Â¥10,000/æœˆ
                    total_value += improvement * 10000 * 12
                elif "retention" in metric:
                    # å‡è¨­æ¯1%ç•™å­˜æå‡åƒ¹å€¼Â¥5,000/æœˆ
                    total_value += improvement * 5000 * 12
                elif "engagement" in metric:
                    # å‡è¨­æ¯1%åƒèˆ‡åº¦æå‡åƒ¹å€¼Â¥3,000/æœˆ
                    total_value += improvement * 3000 * 12
        
        return total_value

# å…¨å±€å„ªåŒ–å¼•æ“å¯¦ä¾‹
website_optimization_engine = WebsiteOptimizationEngine()

# æ¼”ç¤ºåŠŸèƒ½
async def demo_website_optimization():
    """ç¶²ç«™å„ªåŒ–å¼•æ“æ¼”ç¤º"""
    print("ğŸš€ Business MCP é©…å‹•çš„ç¶²ç«™å¢é‡å„ªåŒ–ç³»çµ±æ¼”ç¤º")
    print("=" * 70)
    
    # 1. åˆ†æå„ªåŒ–æ©Ÿæœƒ
    print("\n1. åˆ†æå„ªåŒ–æ©Ÿæœƒ")
    opportunities = await website_optimization_engine.analyze_optimization_opportunities()
    
    print(f"è­˜åˆ¥å‡º {len(opportunities)} å€‹å„ªåŒ–æ©Ÿæœƒ:")
    for i, opp in enumerate(opportunities[:3], 1):
        print(f"\n{i}. {opp['strategy_name']}")
        print(f"   æ©Ÿæœƒåˆ†æ•¸: {opp['opportunity_score']:.2f}")
        print(f"   å¯¦æ–½è¤‡é›œåº¦: {opp['implementation_complexity']}")
        print(f"   å•†æ¥­é‚è¼¯: {opp['business_rationale'][:100]}...")
        
        if opp['expected_impact']:
            print("   é æœŸå½±éŸ¿:")
            for metric, impact in list(opp['expected_impact'].items())[:2]:
                if isinstance(impact, dict):
                    print(f"     - {metric}: +{impact.get('improvement_percentage', 0):.1f}%")
    
    # 2. å‰µå»º A/B æ¸¬è©¦å¯¦é©—
    print("\n2. å‰µå»º A/B æ¸¬è©¦å¯¦é©—")
    if opportunities:
        best_opportunity = opportunities[0]
        experiment = await website_optimization_engine.create_ab_test_experiment(
            best_opportunity['strategy_name'],
            [var['name'] for var in best_opportunity['recommended_variants']]
        )
        
        print(f"å¯¦é©—ID: {experiment.experiment_id}")
        print(f"å¯¦é©—åç¨±: {experiment.name}")
        print(f"å‡è¨­: {experiment.hypothesis}")
        print(f"æ¸¬è©¦è®Šé«”æ•¸é‡: {len(experiment.variants)}")
        
        # 3. å•Ÿå‹•å¯¦é©—
        print("\n3. å•Ÿå‹•å¯¦é©—")
        success = await website_optimization_engine.start_experiment(experiment.experiment_id)
        print(f"å¯¦é©—å•Ÿå‹•: {'æˆåŠŸ' if success else 'å¤±æ•—'}")
        
        # 4. æ¨¡æ“¬æ•¸æ“šæ”¶é›†
        print("\n4. æ¨¡æ“¬æ•¸æ“šæ”¶é›†")
        for i in range(1000):  # æ¨¡æ“¬1000å€‹ç”¨æˆ¶
            variant = random.choice([experiment.control_group] + experiment.variants)
            conversion = random.random() < (0.05 + random.random() * 0.03)  # 5-8% è½‰æ›ç‡
            
            await website_optimization_engine.collect_experiment_data(
                experiment.experiment_id,
                {
                    "user_id": f"user_{i}",
                    "variant_id": variant.variant_id,
                    "action": "conversion" if conversion else "view"
                }
            )
        
        # 5. åˆ†æå¯¦é©—çµæœ
        print("\n5. åˆ†æå¯¦é©—çµæœ")
        results = await website_optimization_engine.analyze_experiment_results(experiment.experiment_id)
        
        print(f"é‹è¡Œå¤©æ•¸: {results.get('runtime_days', 0)}")
        print(f"æ§åˆ¶çµ„è½‰æ›ç‡: {results['control_group']['conversion_rate']:.3f}")
        
        for variant in results['test_variants']:
            print(f"\nè®Šé«”: {variant['name']}")
            print(f"  è½‰æ›ç‡: {variant['conversion_rate']:.3f}")
            print(f"  æå‡: {variant['lift_percentage']:.1f}%")
            print(f"  çµ±è¨ˆé¡¯è‘—æ€§: {'æ˜¯' if variant['statistical_significance'] else 'å¦'}")
        
        print(f"\næ¨è–¦è¡Œå‹•: {results['recommendation']['action']}")
        print(f"æ¨è–¦ç†ç”±: {results['recommendation']['reasoning']}")
    
    # 6. ç”Ÿæˆå„ªåŒ–è·¯ç·šåœ–
    print("\n6. ç”Ÿæˆå„ªåŒ–è·¯ç·šåœ–")
    roadmap = await website_optimization_engine.generate_optimization_roadmap()
    
    print(f"ç¸½å„ªåŒ–æ©Ÿæœƒ: {roadmap['executive_summary']['total_opportunities']}")
    print(f"é«˜å½±éŸ¿æ©Ÿæœƒ: {roadmap['executive_summary']['high_impact_opportunities']}")
    print(f"é ä¼°å¹´åº¦å½±éŸ¿: Â¥{roadmap['executive_summary']['estimated_annual_impact']:,.0f}")
    
    print("\nQ1 è¨ˆåŠƒ:")
    q1 = roadmap['quarter_plan']['Q1']
    print(f"  ç„¦é»: {q1['focus']}")
    print(f"  é æœŸå½±éŸ¿: {q1['expected_impact']}")
    print(f"  è³‡æºéœ€æ±‚: {q1['resource_requirement']}")
    
    print("\nä¸»è¦æˆåŠŸæŒ‡æ¨™:")
    for kpi in roadmap['success_metrics']['primary_kpis']:
        print(f"  - {kpi}")
    
    return {
        "opportunities_identified": len(opportunities),
        "experiments_created": 1 if opportunities else 0,
        "roadmap_generated": True,
        "system_ready": True
    }

if __name__ == "__main__":
    result = asyncio.run(demo_website_optimization())
    print(f"\nğŸ‰ ç¶²ç«™å„ªåŒ–å¼•æ“æ¼”ç¤ºå®Œæˆï¼")