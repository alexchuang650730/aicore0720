#!/usr/bin/env python3
"""
PowerAutomation å°é–‰æ¸¬è©¦è¨ˆåŠƒ
çµ„ç¹”å’ŒåŸ·è¡Œå°é–‰æ¸¬è©¦ï¼Œæ”¶é›†æ¸¬è©¦æ•¸æ“š
"""

import json
import os
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from dataclasses import dataclass, asdict
from pathlib import Path
import uuid
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class TestUser:
    """æ¸¬è©¦ç”¨æˆ¶ä¿¡æ¯"""
    user_id: str
    name: str
    email: str
    role: str  # developer, designer, tester, business_user
    experience_level: str  # beginner, intermediate, advanced
    test_group: str  # A/B test group
    registration_date: str
    
@dataclass
class TestScenario:
    """æ¸¬è©¦å ´æ™¯å®šç¾©"""
    scenario_id: str
    name: str
    category: str  # code_generation, ui_design, api_development, etc.
    difficulty: str  # easy, medium, hard
    expected_duration: int  # minutes
    required_mcps: List[str]
    test_steps: List[str]
    success_criteria: Dict[str, Any]
    
@dataclass
class TestResult:
    """æ¸¬è©¦çµæœè¨˜éŒ„"""
    test_id: str
    user_id: str
    scenario_id: str
    start_time: str
    end_time: str
    duration: int  # seconds
    status: str  # success, partial_success, failed
    performance_metrics: Dict[str, float]
    user_feedback: Dict[str, Any]
    errors: List[str]
    mcp_usage: Dict[str, int]
    
@dataclass
class BetaTestConfig:
    """å°é–‰æ¸¬è©¦é…ç½®"""
    test_name: str = "PowerAutomation v4.6.8 å°é–‰æ¸¬è©¦"
    start_date: str = "2025-07-20"
    end_date: str = "2025-07-27"
    max_users: int = 100
    test_groups: List[str] = None
    scenarios_per_user: int = 10
    data_collection_interval: int = 300  # 5 minutes
    
    def __post_init__(self):
        if self.test_groups is None:
            self.test_groups = ["control", "k2_enabled", "full_features"]

class ClosedBetaTesting:
    def __init__(self, config: BetaTestConfig = None):
        self.config = config or BetaTestConfig()
        self.users: List[TestUser] = []
        self.scenarios: List[TestScenario] = []
        self.results: List[TestResult] = []
        self.analytics = {}
        
        # å‰µå»ºæ¸¬è©¦ç›®éŒ„
        self.test_dir = Path("beta_test_data")
        self.test_dir.mkdir(exist_ok=True)
        
    def setup_test_scenarios(self):
        """è¨­ç½®æ¸¬è©¦å ´æ™¯"""
        logger.info("ğŸ¯ è¨­ç½®æ¸¬è©¦å ´æ™¯...")
        
        scenarios = [
            # ä»£ç¢¼ç”Ÿæˆå ´æ™¯
            TestScenario(
                scenario_id="CG001",
                name="å‰µå»º React çµ„ä»¶",
                category="code_generation",
                difficulty="easy",
                expected_duration=10,
                required_mcps=["codeflow", "smartui"],
                test_steps=[
                    "ä½¿ç”¨è‡ªç„¶èªè¨€æè¿°çµ„ä»¶éœ€æ±‚",
                    "ç”Ÿæˆ React çµ„ä»¶ä»£ç¢¼",
                    "æ·»åŠ æ¨£å¼å’Œäº¤äº’",
                    "ç”Ÿæˆå–®å…ƒæ¸¬è©¦"
                ],
                success_criteria={
                    "code_quality": "> 90%",
                    "test_coverage": "> 80%",
                    "user_satisfaction": "> 4/5"
                }
            ),
            
            # UI è¨­è¨ˆå ´æ™¯
            TestScenario(
                scenario_id="UI001",
                name="è¨­è¨ˆéŸ¿æ‡‰å¼ç™»éŒ„é é¢",
                category="ui_design",
                difficulty="medium",
                expected_duration=15,
                required_mcps=["smartui", "ag-ui"],
                test_steps=[
                    "æè¿°ç™»éŒ„é é¢éœ€æ±‚",
                    "ç”ŸæˆéŸ¿æ‡‰å¼ä½ˆå±€",
                    "æ·»åŠ è¡¨å–®é©—è­‰",
                    "æ¸¬è©¦è·¨è¨­å‚™å…¼å®¹æ€§"
                ],
                success_criteria={
                    "responsive_score": "> 95%",
                    "accessibility": "WCAG 2.1 AA",
                    "performance": "< 3s load time"
                }
            ),
            
            # API é–‹ç™¼å ´æ™¯
            TestScenario(
                scenario_id="API001",
                name="å‰µå»º RESTful API",
                category="api_development",
                difficulty="medium",
                expected_duration=20,
                required_mcps=["codeflow", "test", "security"],
                test_steps=[
                    "å®šç¾© API è¦æ ¼",
                    "ç”Ÿæˆ API ä»£ç¢¼",
                    "æ·»åŠ èªè­‰å’Œæˆæ¬Š",
                    "ç”Ÿæˆ API æ–‡æª”",
                    "åŸ·è¡Œå®‰å…¨æ¸¬è©¦"
                ],
                success_criteria={
                    "api_coverage": "100%",
                    "security_score": "> 95%",
                    "response_time": "< 100ms"
                }
            ),
            
            # ç«¯åˆ°ç«¯æ¸¬è©¦å ´æ™¯
            TestScenario(
                scenario_id="E2E001",
                name="å®Œæ•´é›»å•†æµç¨‹æ¸¬è©¦",
                category="e2e_testing",
                difficulty="hard",
                expected_duration=30,
                required_mcps=["stagewise", "ag-ui", "test"],
                test_steps=[
                    "è¨­è¨ˆç”¨æˆ¶è³¼ç‰©æµç¨‹",
                    "å‰µå»ºæ¸¬è©¦å ´æ™¯",
                    "åŸ·è¡Œè‡ªå‹•åŒ–æ¸¬è©¦",
                    "åˆ†ææ¸¬è©¦çµæœ",
                    "ç”Ÿæˆæ¸¬è©¦å ±å‘Š"
                ],
                success_criteria={
                    "flow_completion": "100%",
                    "test_coverage": "> 90%",
                    "bug_detection": "> 95%"
                }
            ),
            
            # K2 å„ªåŒ–å ´æ™¯
            TestScenario(
                scenario_id="K2001",
                name="K2 æ¨¡å‹å„ªåŒ–ä»»å‹™",
                category="k2_optimization",
                difficulty="medium",
                expected_duration=25,
                required_mcps=["codeflow", "xmasters"],
                test_steps=[
                    "æäº¤è¤‡é›œç·¨ç¨‹å•é¡Œ",
                    "ä½¿ç”¨ K2 å„ªåŒ–å™¨ç”Ÿæˆè§£æ±ºæ–¹æ¡ˆ",
                    "æ¯”è¼ƒå„ªåŒ–å‰å¾Œçš„æ€§èƒ½",
                    "è©•ä¼°æˆæœ¬æ•ˆç›Š"
                ],
                success_criteria={
                    "performance_improvement": "> 30%",
                    "cost_reduction": "> 40%",
                    "solution_quality": "> 4.5/5"
                }
            )
        ]
        
        self.scenarios = scenarios
        logger.info(f"âœ… å‰µå»ºäº† {len(scenarios)} å€‹æ¸¬è©¦å ´æ™¯")
        
    def recruit_test_users(self):
        """æ‹›å‹Ÿæ¸¬è©¦ç”¨æˆ¶"""
        logger.info("ğŸ‘¥ æ‹›å‹Ÿæ¸¬è©¦ç”¨æˆ¶...")
        
        # æ¨¡æ“¬æ‹›å‹Ÿä¸åŒé¡å‹çš„ç”¨æˆ¶
        user_profiles = [
            {"role": "developer", "count": 40, "exp_distribution": [0.2, 0.5, 0.3]},
            {"role": "designer", "count": 20, "exp_distribution": [0.3, 0.4, 0.3]},
            {"role": "tester", "count": 20, "exp_distribution": [0.1, 0.4, 0.5]},
            {"role": "business_user", "count": 20, "exp_distribution": [0.5, 0.3, 0.2]}
        ]
        
        for profile in user_profiles:
            for i in range(profile["count"]):
                exp_rand = i / profile["count"]
                if exp_rand < profile["exp_distribution"][0]:
                    exp_level = "beginner"
                elif exp_rand < sum(profile["exp_distribution"][:2]):
                    exp_level = "intermediate"
                else:
                    exp_level = "advanced"
                
                user = TestUser(
                    user_id=f"{profile['role'][:3]}_{str(uuid.uuid4())[:8]}",
                    name=f"Test User {profile['role']} {i+1}",
                    email=f"user_{i+1}@{profile['role']}.test",
                    role=profile["role"],
                    experience_level=exp_level,
                    test_group=self.config.test_groups[i % len(self.config.test_groups)],
                    registration_date=datetime.now().isoformat()
                )
                self.users.append(user)
        
        logger.info(f"âœ… æ‹›å‹Ÿäº† {len(self.users)} åæ¸¬è©¦ç”¨æˆ¶")
        
    def create_test_dashboard(self):
        """å‰µå»ºæ¸¬è©¦ç›£æ§å„€è¡¨æ¿"""
        dashboard_html = """<!DOCTYPE html>
<html>
<head>
    <title>PowerAutomation å°é–‰æ¸¬è©¦å„€è¡¨æ¿</title>
    <meta charset="UTF-8">
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }
        .header { background: #2c3e50; color: white; padding: 20px; border-radius: 10px; }
        .metrics { display: grid; grid-template-columns: repeat(4, 1fr); gap: 20px; margin: 20px 0; }
        .metric-card { background: white; padding: 20px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
        .metric-value { font-size: 36px; font-weight: bold; color: #3498db; }
        .metric-label { color: #7f8c8d; margin-top: 10px; }
        .chart-container { background: white; padding: 20px; border-radius: 10px; margin: 20px 0; }
        .progress-bar { background: #ecf0f1; height: 20px; border-radius: 10px; overflow: hidden; }
        .progress-fill { background: #3498db; height: 100%; transition: width 0.3s; }
        table { width: 100%; border-collapse: collapse; background: white; }
        th, td { padding: 12px; text-align: left; border-bottom: 1px solid #ecf0f1; }
        th { background: #34495e; color: white; }
        .status-success { color: #27ae60; }
        .status-failed { color: #e74c3c; }
        .status-partial { color: #f39c12; }
    </style>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
</head>
<body>
    <div class="header">
        <h1>ğŸš€ PowerAutomation v4.6.8 å°é–‰æ¸¬è©¦å„€è¡¨æ¿</h1>
        <p>å¯¦æ™‚ç›£æ§æ¸¬è©¦é€²åº¦å’Œçµæœ</p>
    </div>
    
    <div class="metrics">
        <div class="metric-card">
            <div class="metric-value" id="total-users">0</div>
            <div class="metric-label">æ¸¬è©¦ç”¨æˆ¶</div>
        </div>
        <div class="metric-card">
            <div class="metric-value" id="total-tests">0</div>
            <div class="metric-label">å®Œæˆæ¸¬è©¦</div>
        </div>
        <div class="metric-card">
            <div class="metric-value" id="success-rate">0%</div>
            <div class="metric-label">æˆåŠŸç‡</div>
        </div>
        <div class="metric-card">
            <div class="metric-value" id="avg-satisfaction">0.0</div>
            <div class="metric-label">æ»¿æ„åº¦è©•åˆ†</div>
        </div>
    </div>
    
    <div class="chart-container">
        <h3>æ¸¬è©¦é€²åº¦</h3>
        <div class="progress-bar">
            <div class="progress-fill" id="progress" style="width: 0%"></div>
        </div>
        <p id="progress-text">0 / 0 æ¸¬è©¦å®Œæˆ</p>
    </div>
    
    <div class="chart-container">
        <h3>å ´æ™¯å®Œæˆæƒ…æ³</h3>
        <canvas id="scenario-chart"></canvas>
    </div>
    
    <div class="chart-container">
        <h3>æœ€æ–°æ¸¬è©¦çµæœ</h3>
        <table id="results-table">
            <thead>
                <tr>
                    <th>æ¸¬è©¦ID</th>
                    <th>ç”¨æˆ¶</th>
                    <th>å ´æ™¯</th>
                    <th>ç‹€æ…‹</th>
                    <th>è€—æ™‚</th>
                    <th>æ»¿æ„åº¦</th>
                </tr>
            </thead>
            <tbody id="results-body">
            </tbody>
        </table>
    </div>
    
    <script>
        // æ¨¡æ“¬å¯¦æ™‚æ•¸æ“šæ›´æ–°
        function updateDashboard() {
            fetch('/api/test-stats')
                .then(response => response.json())
                .then(data => {
                    document.getElementById('total-users').textContent = data.total_users;
                    document.getElementById('total-tests').textContent = data.total_tests;
                    document.getElementById('success-rate').textContent = data.success_rate + '%';
                    document.getElementById('avg-satisfaction').textContent = data.avg_satisfaction.toFixed(1);
                    
                    // æ›´æ–°é€²åº¦æ¢
                    const progress = (data.completed_tests / data.total_planned_tests) * 100;
                    document.getElementById('progress').style.width = progress + '%';
                    document.getElementById('progress-text').textContent = 
                        `${data.completed_tests} / ${data.total_planned_tests} æ¸¬è©¦å®Œæˆ`;
                });
        }
        
        // åˆå§‹åŒ–åœ–è¡¨
        const ctx = document.getElementById('scenario-chart').getContext('2d');
        const scenarioChart = new Chart(ctx, {
            type: 'bar',
            data: {
                labels: ['ä»£ç¢¼ç”Ÿæˆ', 'UIè¨­è¨ˆ', 'APIé–‹ç™¼', 'E2Eæ¸¬è©¦', 'K2å„ªåŒ–'],
                datasets: [{
                    label: 'å®Œæˆæ•¸',
                    data: [0, 0, 0, 0, 0],
                    backgroundColor: '#3498db'
                }]
            },
            options: {
                responsive: true,
                scales: {
                    y: {
                        beginAtZero: true
                    }
                }
            }
        });
        
        // æ¯5ç§’æ›´æ–°ä¸€æ¬¡
        setInterval(updateDashboard, 5000);
        updateDashboard();
    </script>
</body>
</html>"""
        
        dashboard_path = self.test_dir / "dashboard.html"
        with open(dashboard_path, 'w', encoding='utf-8') as f:
            f.write(dashboard_html)
        
        logger.info(f"âœ… æ¸¬è©¦å„€è¡¨æ¿å·²å‰µå»º: {dashboard_path}")
        
    def generate_test_data_collectors(self):
        """ç”Ÿæˆæ¸¬è©¦æ•¸æ“šæ”¶é›†å™¨"""
        collectors = {
            "performance_collector": """
class PerformanceCollector:
    '''æ”¶é›†æ€§èƒ½æ•¸æ“š'''
    def __init__(self):
        self.metrics = []
    
    def collect(self, test_id: str, metrics: Dict):
        self.metrics.append({
            'test_id': test_id,
            'timestamp': datetime.now().isoformat(),
            'cpu_usage': metrics.get('cpu_usage'),
            'memory_usage': metrics.get('memory_usage'),
            'response_time': metrics.get('response_time'),
            'token_usage': metrics.get('token_usage')
        })
""",
            
            "user_feedback_collector": """
class UserFeedbackCollector:
    '''æ”¶é›†ç”¨æˆ¶åé¥‹'''
    def __init__(self):
        self.feedback = []
    
    def collect(self, user_id: str, scenario_id: str, feedback: Dict):
        self.feedback.append({
            'user_id': user_id,
            'scenario_id': scenario_id,
            'timestamp': datetime.now().isoformat(),
            'satisfaction': feedback.get('satisfaction', 0),
            'ease_of_use': feedback.get('ease_of_use', 0),
            'would_recommend': feedback.get('would_recommend', False),
            'comments': feedback.get('comments', ''),
            'improvement_suggestions': feedback.get('suggestions', [])
        })
""",
            
            "error_collector": """
class ErrorCollector:
    '''æ”¶é›†éŒ¯èª¤ä¿¡æ¯'''
    def __init__(self):
        self.errors = []
    
    def collect(self, test_id: str, error: Exception, context: Dict):
        self.errors.append({
            'test_id': test_id,
            'timestamp': datetime.now().isoformat(),
            'error_type': type(error).__name__,
            'error_message': str(error),
            'stack_trace': traceback.format_exc(),
            'context': context,
            'mcp_involved': context.get('mcp_name'),
            'user_action': context.get('user_action')
        })
"""
        }
        
        # ä¿å­˜æ”¶é›†å™¨ä»£ç¢¼
        for name, code in collectors.items():
            collector_path = self.test_dir / f"{name}.py"
            with open(collector_path, 'w', encoding='utf-8') as f:
                f.write(f"#!/usr/bin/env python3\n{code}")
        
        logger.info(f"âœ… ç”Ÿæˆäº† {len(collectors)} å€‹æ•¸æ“šæ”¶é›†å™¨")
        
    def create_test_report_template(self):
        """å‰µå»ºæ¸¬è©¦å ±å‘Šæ¨¡æ¿"""
        report_template = {
            "executive_summary": {
                "test_period": f"{self.config.start_date} - {self.config.end_date}",
                "total_participants": 0,
                "total_tests_completed": 0,
                "overall_success_rate": 0,
                "average_satisfaction": 0,
                "key_findings": [],
                "recommendations": []
            },
            
            "detailed_results": {
                "by_scenario": {},
                "by_user_role": {},
                "by_test_group": {},
                "by_experience_level": {}
            },
            
            "performance_metrics": {
                "average_response_time": 0,
                "token_efficiency": 0,
                "error_rate": 0,
                "system_stability": 0
            },
            
            "user_feedback": {
                "satisfaction_scores": {},
                "common_issues": [],
                "feature_requests": [],
                "testimonials": []
            },
            
            "technical_findings": {
                "mcp_usage_statistics": {},
                "error_analysis": {},
                "performance_bottlenecks": [],
                "scalability_assessment": {}
            },
            
            "k2_model_evaluation": {
                "cost_savings": 0,
                "performance_comparison": {},
                "user_preference": 0,
                "optimization_effectiveness": 0
            },
            
            "conclusions": {
                "success_criteria_met": {},
                "ready_for_production": False,
                "required_improvements": [],
                "next_steps": []
            }
        }
        
        report_path = self.test_dir / "test_report_template.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report_template, f, ensure_ascii=False, indent=2)
        
        logger.info(f"âœ… æ¸¬è©¦å ±å‘Šæ¨¡æ¿å·²å‰µå»º: {report_path}")
        
    def setup_data_pipeline(self):
        """è¨­ç½®æ•¸æ“šè™•ç†ç®¡é“"""
        pipeline_config = {
            "ingestion": {
                "sources": [
                    "test_results",
                    "performance_metrics",
                    "user_feedback",
                    "error_logs",
                    "mcp_usage"
                ],
                "format": "json",
                "validation": True
            },
            
            "processing": {
                "aggregations": [
                    "hourly_stats",
                    "daily_summaries",
                    "user_cohorts",
                    "scenario_performance"
                ],
                "real_time_analysis": True
            },
            
            "storage": {
                "primary": "local_json",
                "backup": "cloud_storage",
                "retention_days": 90
            },
            
            "visualization": {
                "dashboards": ["main", "performance", "user_feedback"],
                "reports": ["daily", "weekly", "final"],
                "alerts": {
                    "error_threshold": 0.1,
                    "performance_degradation": 0.2,
                    "low_satisfaction": 3.5
                }
            }
        }
        
        pipeline_path = self.test_dir / "data_pipeline_config.json"
        with open(pipeline_path, 'w', encoding='utf-8') as f:
            json.dump(pipeline_config, f, ensure_ascii=False, indent=2)
        
        logger.info("âœ… æ•¸æ“šè™•ç†ç®¡é“å·²é…ç½®")
        
    def generate_test_invitation(self):
        """ç”Ÿæˆæ¸¬è©¦é‚€è«‹å‡½"""
        invitation = f"""
è¦ªæ„›çš„æ¸¬è©¦ç”¨æˆ¶ï¼š

æ„Ÿè¬æ‚¨åƒåŠ  PowerAutomation v4.6.8 çš„å°é–‰æ¸¬è©¦ï¼

## æ¸¬è©¦ä¿¡æ¯
- æ¸¬è©¦æœŸé–“ï¼š{self.config.start_date} è‡³ {self.config.end_date}
- é è¨ˆæ™‚é•·ï¼šæ¯å€‹å ´æ™¯ 10-30 åˆ†é˜
- æ¸¬è©¦å ´æ™¯ï¼š{len(self.scenarios)} å€‹
- çå‹µï¼šå®Œæˆæ‰€æœ‰æ¸¬è©¦å¯ç²å¾— 6 å€‹æœˆå…è²»ä½¿ç”¨æ¬Š

## æ¸¬è©¦æ­¥é©Ÿ
1. ç™»éŒ„æ¸¬è©¦å¹³å°ï¼šhttps://beta.powerautomation.ai
2. å®ŒæˆæŒ‡å®šçš„æ¸¬è©¦å ´æ™¯
3. æä¾›è©³ç´°çš„åé¥‹æ„è¦‹
4. å ±å‘Šç™¼ç¾çš„å•é¡Œ

## é‡é»æ¸¬è©¦å…§å®¹
- å…­å¤§å·¥ä½œæµçš„æ˜“ç”¨æ€§
- K2 æ¨¡å‹çš„æ€§èƒ½è¡¨ç¾
- MCP çµ„ä»¶çš„ç©©å®šæ€§
- æ•´é«”ç”¨æˆ¶é«”é©—

## è¯ç¹«æ–¹å¼
- æŠ€è¡“æ”¯æŒï¼šsupport@powerautomation.ai
- å•é¡Œåé¥‹ï¼šfeedback@powerautomation.ai
- ç·Šæ€¥è¯ç¹«ï¼šWeChat: PowerAuto_Support

æœŸå¾…æ‚¨çš„å¯¶è²´æ„è¦‹ï¼

PowerAutomation åœ˜éšŠ
"""
        
        invitation_path = self.test_dir / "test_invitation.md"
        with open(invitation_path, 'w', encoding='utf-8') as f:
            f.write(invitation)
        
        logger.info("âœ… æ¸¬è©¦é‚€è«‹å‡½å·²ç”Ÿæˆ")
        
    def run(self):
        """åŸ·è¡Œå°é–‰æ¸¬è©¦è¨­ç½®"""
        logger.info("ğŸš€ é–‹å§‹è¨­ç½® PowerAutomation å°é–‰æ¸¬è©¦")
        
        # 1. è¨­ç½®æ¸¬è©¦å ´æ™¯
        self.setup_test_scenarios()
        
        # 2. æ‹›å‹Ÿæ¸¬è©¦ç”¨æˆ¶
        self.recruit_test_users()
        
        # 3. å‰µå»ºæ¸¬è©¦å„€è¡¨æ¿
        self.create_test_dashboard()
        
        # 4. ç”Ÿæˆæ•¸æ“šæ”¶é›†å™¨
        self.generate_test_data_collectors()
        
        # 5. å‰µå»ºå ±å‘Šæ¨¡æ¿
        self.create_test_report_template()
        
        # 6. è¨­ç½®æ•¸æ“šç®¡é“
        self.setup_data_pipeline()
        
        # 7. ç”Ÿæˆé‚€è«‹å‡½
        self.generate_test_invitation()
        
        # ä¿å­˜æ¸¬è©¦é…ç½®
        config_path = self.test_dir / "beta_test_config.json"
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump({
                'config': asdict(self.config),
                'users': [asdict(u) for u in self.users],
                'scenarios': [asdict(s) for s in self.scenarios],
                'setup_time': datetime.now().isoformat()
            }, f, ensure_ascii=False, indent=2)
        
        logger.info(f"""
âœ… å°é–‰æ¸¬è©¦è¨­ç½®å®Œæˆï¼

ğŸ“Š æ¸¬è©¦æ¦‚è¦½ï¼š
- æ¸¬è©¦ç”¨æˆ¶ï¼š{len(self.users)} å
- æ¸¬è©¦å ´æ™¯ï¼š{len(self.scenarios)} å€‹
- æ¸¬è©¦é€±æœŸï¼š7 å¤©
- é è¨ˆæ”¶é›†æ•¸æ“šé»ï¼š{len(self.users) * self.config.scenarios_per_user * 10} å€‹

ğŸ“ ç”Ÿæˆæ–‡ä»¶ï¼š
- æ¸¬è©¦é…ç½®ï¼š{config_path}
- ç›£æ§å„€è¡¨æ¿ï¼š{self.test_dir}/dashboard.html
- æ•¸æ“šæ”¶é›†å™¨ï¼š{self.test_dir}/*_collector.py
- å ±å‘Šæ¨¡æ¿ï¼š{self.test_dir}/test_report_template.json

ğŸš€ ä¸‹ä¸€æ­¥ï¼š
1. éƒ¨ç½²æ¸¬è©¦ç’°å¢ƒ
2. ç™¼é€æ¸¬è©¦é‚€è«‹
3. å•Ÿå‹•æ•¸æ“šæ”¶é›†
4. å¯¦æ™‚ç›£æ§é€²åº¦
""")

def main():
    """ä¸»å‡½æ•¸"""
    beta_test = ClosedBetaTesting()
    beta_test.run()

if __name__ == "__main__":
    main()