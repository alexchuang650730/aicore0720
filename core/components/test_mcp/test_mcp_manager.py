"""
Test MCP - Master Control Platform for Testing
PowerAutomation v4.6.1 çµ±ä¸€æ¸¬è©¦ç®¡ç†å¹³å°

åŸºæ–¼aicore0707çš„Test MCPå¯¦ç¾ï¼Œæä¾›ï¼š
- çµ±ä¸€æ¸¬è©¦ç®¡ç†
- AIé©…å‹•æ¸¬è©¦ç”Ÿæˆ
- å¤šæ¡†æ¶æ”¯æŒ
- å¯¦æ™‚ç›£æ§
"""

import asyncio
import logging
import time
import uuid
from datetime import datetime
from typing import Dict, List, Any, Optional, Union
from dataclasses import dataclass, asdict
from enum import Enum
import json
from pathlib import Path

# å°å…¥æ¸¬è©¦æ¡ˆä¾‹ç”Ÿæˆå™¨å’ŒåŸ·è¡Œå™¨
from .test_case_generator import test_case_generator, GeneratedTestCase
from .test_executors import test_executor_manager, TestExecutionResult

logger = logging.getLogger(__name__)


class TestType(Enum):
    """æ¸¬è©¦é¡å‹æšèˆ‰"""
    UNIT = "unit"
    INTEGRATION = "integration"
    E2E = "e2e"
    UI = "ui"
    API = "api"
    PERFORMANCE = "performance"
    VISUAL = "visual"


class TestStatus(Enum):
    """æ¸¬è©¦ç‹€æ…‹æšèˆ‰"""
    PENDING = "pending"
    RUNNING = "running"
    PASSED = "passed"
    FAILED = "failed"
    SKIPPED = "skipped"
    ERROR = "error"


@dataclass
class TestCase:
    """æ¸¬è©¦ç”¨ä¾‹"""
    id: str
    name: str
    description: str
    test_type: TestType
    test_file: str
    test_method: str
    priority: int = 1
    timeout: int = 30
    tags: List[str] = None
    dependencies: List[str] = None
    
    def __post_init__(self):
        if self.tags is None:
            self.tags = []
        if self.dependencies is None:
            self.dependencies = []


@dataclass
class TestResult:
    """æ¸¬è©¦çµæœ"""
    test_id: str
    test_name: str
    status: TestStatus
    execution_time: float
    start_time: str
    end_time: str
    error_message: Optional[str] = None
    output: Optional[str] = None
    screenshots: List[str] = None
    artifacts: List[str] = None
    
    def __post_init__(self):
        if self.screenshots is None:
            self.screenshots = []
        if self.artifacts is None:
            self.artifacts = []


@dataclass
class TestSuite:
    """æ¸¬è©¦å¥—ä»¶"""
    id: str
    name: str
    description: str
    test_cases: List[TestCase]
    setup_script: Optional[str] = None
    teardown_script: Optional[str] = None
    parallel_execution: bool = False
    max_parallel: int = 4


class TestExecutor:
    """æ¸¬è©¦åŸ·è¡Œå™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(self.__class__.__name__)
        self.running_tests = {}
        self.test_results = []
    
    async def execute_test_case(self, test_case: TestCase) -> TestResult:
        """åŸ·è¡Œå–®å€‹æ¸¬è©¦ç”¨ä¾‹"""
        self.logger.info(f"åŸ·è¡Œæ¸¬è©¦: {test_case.name}")
        
        # æº–å‚™æ¸¬è©¦é…ç½®
        test_config = {
            "test_file": test_case.test_file,
            "test_method": test_case.test_method,
            "name": test_case.name,
            "timeout": test_case.timeout
        }
        
        # ä½¿ç”¨æ–°çš„åŸ·è¡Œå™¨
        test_type_map = {
            TestType.UNIT: "unit",
            TestType.INTEGRATION: "integration",
            TestType.PERFORMANCE: "performance",
            TestType.UI: "ui_operation",
            TestType.API: "integration",
            TestType.E2E: "ui_operation",
            TestType.VISUAL: "ui_operation"
        }
        
        executor_type = test_type_map.get(test_case.test_type, "unit")
        
        # åŸ·è¡Œæ¸¬è©¦
        execution_result = await test_executor_manager.execute_test(executor_type, test_config)
        
        # è½‰æ›ç‚º TestResult
        test_result = TestResult(
            test_id=test_case.id,
            test_name=test_case.name,
            status=TestStatus(execution_result.status.upper()) if execution_result.status.upper() in [s.value for s in TestStatus] else TestStatus.ERROR,
            execution_time=execution_result.execution_time,
            start_time=execution_result.start_time,
            end_time=execution_result.end_time,
            output=execution_result.output,
            error_message=execution_result.error,
            artifacts=execution_result.artifacts
        )
        
        self.test_results.append(test_result)
        return test_result
    
    
    async def execute_test_suite(self, test_suite: TestSuite) -> List[TestResult]:
        """åŸ·è¡Œæ¸¬è©¦å¥—ä»¶"""
        self.logger.info(f"åŸ·è¡Œæ¸¬è©¦å¥—ä»¶: {test_suite.name}")
        
        results = []
        
        if test_suite.parallel_execution:
            # ä¸¦è¡ŒåŸ·è¡Œ
            semaphore = asyncio.Semaphore(test_suite.max_parallel)
            
            async def run_with_semaphore(test_case):
                async with semaphore:
                    return await self.execute_test_case(test_case)
            
            tasks = [run_with_semaphore(tc) for tc in test_suite.test_cases]
            results = await asyncio.gather(*tasks)
        else:
            # ä¸²è¡ŒåŸ·è¡Œ
            for test_case in test_suite.test_cases:
                result = await self.execute_test_case(test_case)
                results.append(result)
        
        return results


class TestMCPManager:
    """Test MCPç®¡ç†å™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(self.__class__.__name__)
        self.executor = TestExecutor()
        self.test_suites = {}
        self.test_sessions = {}
        
        # AIçµ„ä»¶é›†æˆ
        self.ai_test_generator = None
        self.stagewise_integration = None
        self.ag_ui_integration = None
    
    async def initialize(self):
        """åˆå§‹åŒ–Test MCP"""
        self.logger.info("ğŸ§ª åˆå§‹åŒ–Test MCP - çµ±ä¸€æ¸¬è©¦ç®¡ç†å¹³å°")
        
        # åˆå§‹åŒ–AIæ¸¬è©¦ç”Ÿæˆå™¨
        await self._initialize_ai_components()
        
        # è¼‰å…¥é»˜èªæ¸¬è©¦å¥—ä»¶
        await self._load_default_test_suites()
        
        self.logger.info("âœ… Test MCPåˆå§‹åŒ–å®Œæˆ")
    
    async def _initialize_ai_components(self):
        """åˆå§‹åŒ–AIçµ„ä»¶"""
        try:
            # å˜—è©¦é›†æˆStagewise MCP
            self.stagewise_integration = "stagewise_available"
            
            # å˜—è©¦é›†æˆAG-UI MCP
            self.ag_ui_integration = "ag_ui_available"
            
            self.logger.info("âœ… AIçµ„ä»¶é›†æˆæˆåŠŸ")
        except Exception as e:
            self.logger.warning(f"âš ï¸ AIçµ„ä»¶é›†æˆéƒ¨åˆ†å¤±æ•—: {e}")
    
    async def _load_default_test_suites(self):
        """è¼‰å…¥é»˜èªæ¸¬è©¦å¥—ä»¶"""
        # å‰µå»ºPowerAutomationæ ¸å¿ƒæ¸¬è©¦å¥—ä»¶
        core_test_suite = TestSuite(
            id="powerautomation_core",
            name="PowerAutomationæ ¸å¿ƒåŠŸèƒ½æ¸¬è©¦",
            description="æ¸¬è©¦PowerAutomationçš„æ ¸å¿ƒåŠŸèƒ½",
            test_cases=[
                TestCase(
                    id="test_001",
                    name="ç³»çµ±å•Ÿå‹•æ¸¬è©¦",
                    description="é©—è­‰PowerAutomationèƒ½å¤ æ­£å¸¸å•Ÿå‹•",
                    test_type=TestType.UNIT,
                    test_file="test_system_startup.py",
                    test_method="test_startup",
                    tags=["core", "startup"]
                ),
                TestCase(
                    id="test_002",
                    name="MCPçµ„ä»¶è¼‰å…¥æ¸¬è©¦",
                    description="é©—è­‰æ‰€æœ‰MCPçµ„ä»¶èƒ½å¤ æ­£å¸¸è¼‰å…¥",
                    test_type=TestType.INTEGRATION,
                    test_file="test_mcp_loading.py",
                    test_method="test_mcp_loading",
                    tags=["mcp", "integration"]
                ),
                TestCase(
                    id="test_003",
                    name="APIç«¯é»æ¸¬è©¦",
                    description="æ¸¬è©¦REST APIç«¯é»åŠŸèƒ½",
                    test_type=TestType.API,
                    test_file="test_api_endpoints.py",
                    test_method="test_all_endpoints",
                    tags=["api", "rest"]
                )
            ],
            parallel_execution=True,
            max_parallel=3
        )
        
        self.test_suites["powerautomation_core"] = core_test_suite
    
    async def create_test_session(self, session_name: str, test_suite_ids: List[str]) -> str:
        """å‰µå»ºæ¸¬è©¦æœƒè©±"""
        session_id = str(uuid.uuid4())
        
        session = {
            "id": session_id,
            "name": session_name,
            "test_suite_ids": test_suite_ids,
            "status": "created",
            "created_at": datetime.now().isoformat(),
            "results": []
        }
        
        self.test_sessions[session_id] = session
        self.logger.info(f"å‰µå»ºæ¸¬è©¦æœƒè©±: {session_name} ({session_id})")
        
        return session_id
    
    async def run_test_session(self, session_id: str) -> Dict[str, Any]:
        """é‹è¡Œæ¸¬è©¦æœƒè©±"""
        if session_id not in self.test_sessions:
            raise ValueError(f"æ¸¬è©¦æœƒè©±ä¸å­˜åœ¨: {session_id}")
        
        session = self.test_sessions[session_id]
        session["status"] = "running"
        session["started_at"] = datetime.now().isoformat()
        
        self.logger.info(f"é–‹å§‹é‹è¡Œæ¸¬è©¦æœƒè©±: {session['name']}")
        
        all_results = []
        
        for suite_id in session["test_suite_ids"]:
            if suite_id in self.test_suites:
                suite_results = await self.executor.execute_test_suite(self.test_suites[suite_id])
                all_results.extend(suite_results)
        
        session["results"] = [asdict(result) for result in all_results]
        session["status"] = "completed"
        session["completed_at"] = datetime.now().isoformat()
        
        # è¨ˆç®—çµ±è¨ˆä¿¡æ¯
        total_tests = len(all_results)
        passed_tests = sum(1 for r in all_results if r.status == TestStatus.PASSED)
        failed_tests = sum(1 for r in all_results if r.status == TestStatus.FAILED)
        
        session["statistics"] = {
            "total_tests": total_tests,
            "passed_tests": passed_tests,
            "failed_tests": failed_tests,
            "success_rate": (passed_tests / total_tests * 100) if total_tests > 0 else 0,
            "total_execution_time": sum(r.execution_time for r in all_results)
        }
        
        self.logger.info(f"æ¸¬è©¦æœƒè©±å®Œæˆ: {passed_tests}/{total_tests} é€šé")
        
        return session
    
    async def generate_ai_test_cases(self, component_name: str, test_type: TestType) -> List[TestCase]:
        """AIç”Ÿæˆæ¸¬è©¦ç”¨ä¾‹"""
        self.logger.info(f"ç‚º {component_name} ç”Ÿæˆ {test_type.value} æ¸¬è©¦ç”¨ä¾‹")
        
        # ä½¿ç”¨æ¸¬è©¦æ¡ˆä¾‹ç”Ÿæˆå™¨
        mcp_info = {
            "name": component_name,
            "priority": "P1",
            "category": "component",
            "description": f"{component_name} MCP çµ„ä»¶"
        }
        
        # ç”Ÿæˆæ¸¬è©¦æ¡ˆä¾‹ä¸¦ä¿å­˜åˆ°æ–‡ä»¶
        generated_test_cases = await test_case_generator.generate_mcp_test_cases(component_name, mcp_info)
        
        # è½‰æ›ç‚º TestCase æ ¼å¼
        generated_tests = []
        for gtc in generated_test_cases:
            test_case = TestCase(
                id=gtc.id,
                name=gtc.name,
                description=gtc.description,
                test_type=TestType(gtc.category) if gtc.category in [t.value for t in TestType] else TestType.UNIT,
                test_file=str(gtc.to_file_path(test_case_generator.output_dir)),
                test_method=f"test_{gtc.name}",
                tags=gtc.tags
            )
            generated_tests.append(test_case)
        
        return generated_tests
    
    async def integrate_with_stagewise(self, recording_session_id: str) -> TestSuite:
        """èˆ‡Stagewise MCPé›†æˆï¼Œå¾éŒ„è£½æœƒè©±ç”Ÿæˆæ¸¬è©¦"""
        self.logger.info(f"å¾StagewiseéŒ„è£½æœƒè©± {recording_session_id} ç”Ÿæˆæ¸¬è©¦å¥—ä»¶")
        
        # æ¨¡æ“¬å¾Stagewiseç”Ÿæˆæ¸¬è©¦
        test_cases = [
            TestCase(
                id=f"stagewise_{recording_session_id}_1",
                name="StagewiseéŒ„è£½å›æ”¾æ¸¬è©¦",
                description="åŸºæ–¼ç”¨æˆ¶éŒ„è£½æ“ä½œç”Ÿæˆçš„è‡ªå‹•åŒ–æ¸¬è©¦",
                test_type=TestType.UI,
                test_file="stagewise_generated.py",
                test_method="test_recorded_scenario",
                tags=["stagewise", "recorded", "ui"]
            )
        ]
        
        suite = TestSuite(
            id=f"stagewise_suite_{recording_session_id}",
            name=f"Stagewiseç”Ÿæˆæ¸¬è©¦å¥—ä»¶",
            description="åŸºæ–¼StagewiseéŒ„è£½ç”Ÿæˆçš„æ¸¬è©¦å¥—ä»¶",
            test_cases=test_cases
        )
        
        self.test_suites[suite.id] = suite
        return suite
    
    async def generate_ui_test_dashboard(self) -> Dict[str, Any]:
        """ç”ŸæˆUIæ¸¬è©¦å„€è¡¨æ¿"""
        if not self.ag_ui_integration:
            return {"error": "AG-UI MCPæœªé›†æˆ"}
        
        # æ¨¡æ“¬AG-UIç”Ÿæˆæ¸¬è©¦å„€è¡¨æ¿
        dashboard = {
            "type": "test_dashboard",
            "components": [
                {
                    "type": "test_execution_panel",
                    "title": "æ¸¬è©¦åŸ·è¡Œé¢æ¿",
                    "features": ["start_test", "stop_test", "view_progress"]
                },
                {
                    "type": "test_results_viewer", 
                    "title": "æ¸¬è©¦çµæœæŸ¥çœ‹å™¨",
                    "features": ["results_table", "charts", "export"]
                },
                {
                    "type": "test_suite_manager",
                    "title": "æ¸¬è©¦å¥—ä»¶ç®¡ç†å™¨",
                    "features": ["create_suite", "edit_suite", "import_suite"]
                }
            ],
            "theme": "dark",
            "layout": "grid"
        }
        
        return dashboard
    
    async def generate_mcp_zero_test_suite(self) -> Dict[str, Any]:
        """ç”Ÿæˆ MCP-Zero å®Œæ•´æ¸¬è©¦å¥—ä»¶"""
        self.logger.info("ç”Ÿæˆ MCP-Zero å®Œæ•´æ¸¬è©¦å¥—ä»¶")
        
        # ä½¿ç”¨æ¸¬è©¦æ¡ˆä¾‹ç”Ÿæˆå™¨ç”Ÿæˆæ‰€æœ‰æ¸¬è©¦
        summary_report = await test_case_generator.generate_mcp_zero_test_suite()
        
        # å‰µå»ºæ¸¬è©¦å¥—ä»¶
        test_suite = TestSuite(
            id="mcp_zero_complete",
            name="MCP-Zero å®Œæ•´æ¸¬è©¦å¥—ä»¶",
            description="æ¶µè“‹æ‰€æœ‰ MCP çµ„ä»¶çš„å®Œæ•´æ¸¬è©¦",
            test_cases=[],  # å¾ç”Ÿæˆçš„æ–‡ä»¶å‹•æ…‹åŠ è¼‰
            parallel_execution=True,
            max_parallel=4
        )
        
        self.test_suites[test_suite.id] = test_suite
        
        return summary_report
    
    async def run_test_with_results(self, test_suite_id: str) -> Dict[str, Any]:
        """é‹è¡Œæ¸¬è©¦ä¸¦ç”Ÿæˆçµæœå ±å‘Š"""
        if test_suite_id not in self.test_suites:
            raise ValueError(f"æ¸¬è©¦å¥—ä»¶ä¸å­˜åœ¨: {test_suite_id}")
        
        # å‰µå»ºæ¸¬è©¦æœƒè©±
        session_id = await self.create_test_session(
            f"Test Run - {datetime.now().strftime('%Y%m%d_%H%M%S')}",
            [test_suite_id]
        )
        
        # é‹è¡Œæ¸¬è©¦
        session_result = await self.run_test_session(session_id)
        
        # ç”Ÿæˆæ¸¬è©¦çµæœå ±å‘Š
        report_path = test_case_generator.output_dir / f"test_results_{session_id}.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(session_result, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"æ¸¬è©¦çµæœå·²ä¿å­˜: {report_path}")
        
        return session_result
    
    async def execute_unit_tests(self, mcp_name: Optional[str] = None) -> Dict[str, Any]:
        """åŸ·è¡Œå–®å…ƒæ¸¬è©¦"""
        self.logger.info(f"åŸ·è¡Œå–®å…ƒæ¸¬è©¦: {mcp_name or 'æ‰€æœ‰çµ„ä»¶'}")
        
        # ç”Ÿæˆå–®å…ƒæ¸¬è©¦æ¡ˆä¾‹
        test_cases = []
        if mcp_name:
            # ç‰¹å®š MCP çš„å–®å…ƒæ¸¬è©¦
            unit_tests = await self.generate_ai_test_cases(mcp_name, TestType.UNIT)
            test_cases.extend(unit_tests)
        else:
            # æ‰€æœ‰ MCP çš„å–®å…ƒæ¸¬è©¦
            from core.mcp_zero import mcp_registry
            for name in mcp_registry.mcp_catalog.keys():
                unit_tests = await self.generate_ai_test_cases(name, TestType.UNIT)
                test_cases.extend(unit_tests)
        
        # å‰µå»ºæ¸¬è©¦å¥—ä»¶
        test_suite = TestSuite(
            id=f"unit_tests_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            name="å–®å…ƒæ¸¬è©¦å¥—ä»¶",
            description="è‡ªå‹•ç”Ÿæˆçš„å–®å…ƒæ¸¬è©¦",
            test_cases=test_cases,
            parallel_execution=True,
            max_parallel=4
        )
        
        # åŸ·è¡Œæ¸¬è©¦
        results = await self.execute_test_suite(test_suite)
        
        return {
            "test_type": "unit",
            "total_tests": len(results),
            "passed": sum(1 for r in results if r.status == TestStatus.PASSED),
            "failed": sum(1 for r in results if r.status == TestStatus.FAILED),
            "results": [asdict(r) for r in results]
        }
    
    async def execute_integration_tests(self, test_scenarios: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åŸ·è¡Œé›†æˆæ¸¬è©¦"""
        self.logger.info("åŸ·è¡Œé›†æˆæ¸¬è©¦")
        
        results = []
        for scenario in test_scenarios:
            test_config = {
                "name": scenario.get("name", "integration_test"),
                "test_file": scenario.get("test_file"),
                "services": scenario.get("services", [])
            }
            
            result = await test_executor_manager.execute_test("integration", test_config)
            results.append(result)
        
        return {
            "test_type": "integration",
            "total_tests": len(results),
            "passed": sum(1 for r in results if r.status == "passed"),
            "failed": sum(1 for r in results if r.status == "failed"),
            "results": [asdict(r) for r in results]
        }
    
    async def execute_performance_tests(self, performance_configs: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åŸ·è¡Œæ€§èƒ½æ¸¬è©¦"""
        self.logger.info("åŸ·è¡Œæ€§èƒ½æ¸¬è©¦")
        
        results = []
        for config in performance_configs:
            result = await test_executor_manager.execute_test("performance", config)
            results.append(result)
        
        return {
            "test_type": "performance",
            "total_tests": len(results),
            "passed": sum(1 for r in results if r.status == "passed"),
            "failed": sum(1 for r in results if r.status == "failed"),
            "metrics": {
                "average_response_time": sum(r.metrics.get("average_response_time", 0) for r in results) / len(results) if results else 0,
                "average_rps": sum(r.metrics.get("requests_per_second", 0) for r in results) / len(results) if results else 0
            },
            "results": [asdict(r) for r in results]
        }
    
    async def execute_ui_operation_tests(self, ui_test_configs: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åŸ·è¡Œ UI æ“ä½œæ¸¬è©¦"""
        self.logger.info("åŸ·è¡Œ UI æ“ä½œæ¸¬è©¦")
        
        results = []
        for config in ui_test_configs:
            result = await test_executor_manager.execute_test("ui_operation", config)
            results.append(result)
        
        # æ”¶é›†æ‰€æœ‰æˆªåœ–
        all_artifacts = []
        for result in results:
            if result.artifacts:
                all_artifacts.extend(result.artifacts)
        
        return {
            "test_type": "ui_operation",
            "total_tests": len(results),
            "passed": sum(1 for r in results if r.status == "passed"),
            "failed": sum(1 for r in results if r.status == "failed"),
            "artifacts": all_artifacts,
            "results": [asdict(r) for r in results]
        }
    
    def get_status(self) -> Dict[str, Any]:
        """ç²å–Test MCPç‹€æ…‹"""
        return {
            "component": "Test MCP",
            "version": "4.7.3",
            "status": "running",
            "test_suites": len(self.test_suites),
            "active_sessions": len([s for s in self.test_sessions.values() if s["status"] == "running"]),
            "total_sessions": len(self.test_sessions),
            "test_output_dir": str(test_case_generator.output_dir),
            "integrations": {
                "stagewise_mcp": self.stagewise_integration is not None,
                "ag_ui_mcp": self.ag_ui_integration is not None,
                "test_case_generator": True
            }
        }


# å–®ä¾‹å¯¦ä¾‹
test_mcp = TestMCPManager()