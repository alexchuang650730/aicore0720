#!/usr/bin/env python3
"""
MemoryOS MCP - å­¸ç¿’é©é…å™¨
è™•ç†ä¸åŒä¾†æºçš„å­¸ç¿’æ•¸æ“šä¸¦é€²è¡Œé©é…
æ”¯æŒæ¨¡å¼æ„ŸçŸ¥çš„ä¸ªæ€§åŒ–å¤„ç†
"""

import asyncio
import json
import logging
import time
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from enum import Enum
import numpy as np
from collections import defaultdict, deque

logger = logging.getLogger(__name__)

class LearningType(Enum):
    """å­¸ç¿’é¡å‹"""
    CLAUDE_INTERACTION = "claude_interaction"
    USER_BEHAVIOR = "user_behavior"
    PERFORMANCE_OPTIMIZATION = "performance_optimization"
    ERROR_CORRECTION = "error_correction"
    CONTEXT_ENHANCEMENT = "context_enhancement"

class InteractionMode(Enum):
    """äº¤äº’æ¨¡å¼"""
    TEACHER_MODE = "teacher_mode"      # Claude Code Tool + Claude æ¨¡å‹
    ASSISTANT_MODE = "assistant_mode"  # å…¶ä»–å·¥å…·å’Œæ¨¡å‹

@dataclass
class QueryContext:
    """æŸ¥è¯¢ä¸Šä¸‹æ–‡"""
    current_tool: str
    current_model: str
    user_id: Optional[str] = None
    session_id: Optional[str] = None
    interaction_history: List[Dict[str, Any]] = None
    user_preferences: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.interaction_history is None:
            self.interaction_history = []
        if self.user_preferences is None:
            self.user_preferences = {}

@dataclass
class LearningData:
    """å­¸ç¿’æ•¸æ“š"""
    id: str
    source: str
    learning_type: LearningType
    interaction_mode: InteractionMode
    data: Dict[str, Any]
    performance_metrics: Dict[str, float]
    timestamp: float
    success: bool = True
    
    def to_dict(self) -> Dict[str, Any]:
        """è½‰æ›ç‚ºå­—å…¸"""
        result = asdict(self)
        result['learning_type'] = self.learning_type.value
        result['interaction_mode'] = self.interaction_mode.value
        return result

class LearningAdapter:
    """å­¸ç¿’é©é…å™¨ - æ”¯æŒæ¨¡å¼æ„ŸçŸ¥çš„ä¸ªæ€§åŒ–å¤„ç†"""
    
    def __init__(self, memory_engine, context_manager):
        self.memory_engine = memory_engine
        self.context_manager = context_manager
        self.learning_history = deque(maxlen=1000)
        self.performance_tracker = defaultdict(list)
        self.learning_patterns = defaultdict(dict)
        self.adaptation_rules = {}
        self.user_profiles = defaultdict(dict)  # ç”¨æˆ·ä¸ªæ€§åŒ–é…ç½®
        self.mode_preferences = defaultdict(dict)  # æ¨¡å¼åå¥½è®¾ç½®
        self.is_initialized = False
        
    async def initialize(self):
        """åˆå§‹åŒ–å­¸ç¿’é©é…å™¨"""
        logger.info("ğŸ§  åˆå§‹åŒ– Learning Adapter...")
        
        # è¼‰å…¥é©é…è¦å‰‡
        await self._load_adaptation_rules()
        
        # åˆå§‹åŒ–æ€§èƒ½è¿½è¹¤å™¨
        await self._initialize_performance_tracker()
        
        # åˆå§‹åŒ–æ¨¡å¼æ„ŸçŸ¥é…ç½®
        await self._initialize_mode_awareness()
        
        self.is_initialized = True
        logger.info("âœ… Learning Adapter åˆå§‹åŒ–å®Œæˆ")
    
    async def _initialize_mode_awareness(self):
        """åˆå§‹åŒ–æ¨¡å¼æ„ŸçŸ¥é…ç½®"""
        # æ•™å¸ˆæ¨¡å¼é…ç½®
        self.mode_preferences[InteractionMode.TEACHER_MODE] = {
            "response_style": "detailed_technical",
            "explanation_depth": "comprehensive",
            "code_review_level": "strict",
            "best_practices_emphasis": True,
            "academic_tone": True,
            "example_complexity": "advanced",
            "error_handling_focus": True
        }
        
        # åŠ©æ‰‹æ¨¡å¼é…ç½®
        self.mode_preferences[InteractionMode.ASSISTANT_MODE] = {
            "response_style": "concise_practical",
            "explanation_depth": "essential",
            "code_review_level": "moderate",
            "best_practices_emphasis": False,
            "academic_tone": False,
            "example_complexity": "simple",
            "error_handling_focus": False
        }
        
        logger.info("âœ… æ¨¡å¼æ„ŸçŸ¥é…ç½®åˆå§‹åŒ–å®Œæˆ")
    
    def detect_interaction_mode(self, context: QueryContext) -> InteractionMode:
        """æ£€æµ‹äº¤äº’æ¨¡å¼"""
        if (context.current_tool == "claude_code_tool" and 
            context.current_model == "claude"):
            return InteractionMode.TEACHER_MODE
        else:
            return InteractionMode.ASSISTANT_MODE
    
    async def personalize_response(self, response: str, context: QueryContext) -> str:
        """ä¸ªæ€§åŒ–å“åº”å¤„ç†"""
        try:
            # æ£€æµ‹å½“å‰æ¨¡å¼
            current_mode = self.detect_interaction_mode(context)
            
            # æ ¹æ®æ¨¡å¼è°ƒæ•´ä¸ªæ€§åŒ–ç­–ç•¥
            if current_mode == InteractionMode.TEACHER_MODE:
                return await self._teacher_mode_personalization(response, context)
            else:
                return await self._assistant_mode_personalization(response, context)
                
        except Exception as e:
            logger.error(f"âŒ ä¸ªæ€§åŒ–å¤„ç†å¤±è´¥: {e}")
            return response
    
    async def _teacher_mode_personalization(self, response: str, context: QueryContext) -> str:
        """æ•™å¸ˆæ¨¡å¼ä¸ªæ€§åŒ–å¤„ç†"""
        try:
            # è·å–ç”¨æˆ·æŠ€æœ¯æ ˆåå¥½
            user_preferences = await self._get_user_preferences(context.user_id)
            tech_stack = user_preferences.get("tech_stack", [])
            
            # è°ƒæ•´æŠ€æœ¯æ·±åº¦
            if user_preferences.get("experience_level") == "beginner":
                response = await self._add_detailed_explanations(response)
            elif user_preferences.get("experience_level") == "expert":
                response = await self._add_advanced_insights(response)
            
            # åŒ¹é…ç”¨æˆ·åå¥½çš„ä»£ç é£æ ¼
            preferred_style = user_preferences.get("code_style", "standard")
            if preferred_style != "standard":
                response = await self._adjust_code_style(response, preferred_style)
            
            # æ¨èç›¸å…³çš„é¡¹ç›®èµ„æº
            if tech_stack:
                response = await self._add_resource_recommendations(response, tech_stack)
            
            # ä¼˜åŒ–è§£é‡Šæ–¹å¼
            learning_style = user_preferences.get("learning_style", "visual")
            response = await self._optimize_explanation_style(response, learning_style)
            
            return response
            
        except Exception as e:
            logger.error(f"âŒ æ•™å¸ˆæ¨¡å¼ä¸ªæ€§åŒ–å¤±è´¥: {e}")
            return response
    
    async def _assistant_mode_personalization(self, response: str, context: QueryContext) -> str:
        """åŠ©æ‰‹æ¨¡å¼ä¸ªæ€§åŒ–å¤„ç†"""
        try:
            # è·å–ç”¨æˆ·åå¥½
            user_preferences = await self._get_user_preferences(context.user_id)
            
            # å¿«é€Ÿå®ç”¨çš„å›ç­”é£æ ¼
            if user_preferences.get("prefer_concise", True):
                response = await self._make_response_concise(response)
            
            # ç®€æ´çš„ä»£ç ç¤ºä¾‹
            response = await self._simplify_code_examples(response)
            
            # æ•ˆç‡ä¼˜å…ˆçš„å»ºè®®
            response = await self._add_efficiency_tips(response)
            
            # è½»æ¾çš„äº¤æµé£æ ¼
            response = await self._adjust_tone_casual(response)
            
            return response
            
        except Exception as e:
            logger.error(f"âŒ åŠ©æ‰‹æ¨¡å¼ä¸ªæ€§åŒ–å¤±è´¥: {e}")
            return response
    
    async def _get_user_preferences(self, user_id: Optional[str]) -> Dict[str, Any]:
        """è·å–ç”¨æˆ·åå¥½è®¾ç½®"""
        if not user_id:
            return {}
        
        if user_id not in self.user_profiles:
            # ä»è®°å¿†ä¸­åŠ è½½ç”¨æˆ·åå¥½
            user_memories = await self.memory_engine.search_memories(
                query=f"user_preferences_{user_id}",
                memory_type=self.memory_engine.MemoryType.SYSTEM_STATE,
                limit=1
            )
            
            if user_memories:
                self.user_profiles[user_id] = user_memories[0].metadata.get("preferences", {})
            else:
                # é»˜è®¤åå¥½è®¾ç½®
                self.user_profiles[user_id] = {
                    "experience_level": "intermediate",
                    "tech_stack": ["python", "javascript"],
                    "code_style": "standard",
                    "learning_style": "visual",
                    "prefer_concise": True
                }
        
        return self.user_profiles[user_id]
    
    async def learn_user_preferences(self, context: QueryContext, feedback: Dict[str, Any]):
        """å­¦ä¹ ç”¨æˆ·åå¥½"""
        try:
            if not context.user_id:
                return
            
            current_mode = self.detect_interaction_mode(context)
            user_preferences = await self._get_user_preferences(context.user_id)
            
            # æ ¹æ®åé¦ˆè°ƒæ•´åå¥½
            if feedback.get("too_detailed"):
                if current_mode == InteractionMode.TEACHER_MODE:
                    user_preferences["experience_level"] = "expert"
                else:
                    user_preferences["prefer_concise"] = True
            
            if feedback.get("too_simple"):
                if current_mode == InteractionMode.TEACHER_MODE:
                    user_preferences["experience_level"] = "beginner"
                else:
                    user_preferences["prefer_concise"] = False
            
            # å­¦ä¹ æŠ€æœ¯æ ˆåå¥½
            mentioned_tech = feedback.get("mentioned_technologies", [])
            if mentioned_tech:
                current_tech = set(user_preferences.get("tech_stack", []))
                current_tech.update(mentioned_tech)
                user_preferences["tech_stack"] = list(current_tech)
            
            # å­¦ä¹ äº¤æµé£æ ¼åå¥½
            if feedback.get("preferred_tone"):
                user_preferences["preferred_tone"] = feedback["preferred_tone"]
            
            # æ›´æ–°ç”¨æˆ·é…ç½®
            self.user_profiles[context.user_id] = user_preferences
            
            # å­˜å‚¨åˆ°è®°å¿†ç³»ç»Ÿ
            await self._save_user_preferences(context.user_id, user_preferences)
            
            logger.info(f"âœ… å­¦ä¹ ç”¨æˆ·åå¥½: {context.user_id}")
            
        except Exception as e:
            logger.error(f"âŒ å­¦ä¹ ç”¨æˆ·åå¥½å¤±è´¥: {e}")
    
    async def _save_user_preferences(self, user_id: str, preferences: Dict[str, Any]):
        """ä¿å­˜ç”¨æˆ·åå¥½åˆ°è®°å¿†ç³»ç»Ÿ"""
        from .memory_engine import Memory, MemoryType
        
        memory = Memory(
            id=f"user_preferences_{user_id}",
            memory_type=MemoryType.SYSTEM_STATE,
            content=f"ç”¨æˆ· {user_id} çš„åå¥½è®¾ç½®",
            metadata={
                "preferences": preferences,
                "last_updated": time.time()
            },
            created_at=time.time(),
            accessed_at=time.time(),
            access_count=0,
            importance_score=0.9,
            tags=["user_preferences", "personalization"]
        )
        
        await self.memory_engine.store_memory(memory)
    
    # ä¸ªæ€§åŒ–å¤„ç†çš„å…·ä½“å®ç°æ–¹æ³•
    async def _add_detailed_explanations(self, response: str) -> str:
        """ä¸ºåˆå­¦è€…æ·»åŠ è¯¦ç»†è§£é‡Š"""
        # ç®€å•çš„å®ç°ï¼Œå®é™…åº”ç”¨ä¸­å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„NLPå¤„ç†
        if "def " in response or "function" in response:
            response += "\n\nğŸ’¡ **è¯¦ç»†è§£é‡Š**: è¿™ä¸ªå‡½æ•°çš„ä½œç”¨æ˜¯..."
        return response
    
    async def _add_advanced_insights(self, response: str) -> str:
        """ä¸ºä¸“å®¶æ·»åŠ é«˜çº§è§è§£"""
        if "import " in response:
            response += "\n\nğŸ”¬ **é«˜çº§æç¤º**: è€ƒè™‘ä½¿ç”¨æ›´é«˜æ•ˆçš„å®ç°æ–¹å¼..."
        return response
    
    async def _adjust_code_style(self, response: str, style: str) -> str:
        """è°ƒæ•´ä»£ç é£æ ¼"""
        # æ ¹æ®ç”¨æˆ·åå¥½è°ƒæ•´ä»£ç é£æ ¼
        return response
    
    async def _add_resource_recommendations(self, response: str, tech_stack: List[str]) -> str:
        """æ·»åŠ èµ„æºæ¨è"""
        if tech_stack:
            response += f"\n\nğŸ“š **ç›¸å…³èµ„æº**: åŸºäºæ‚¨çš„æŠ€æœ¯æ ˆ {', '.join(tech_stack)}..."
        return response
    
    async def _optimize_explanation_style(self, response: str, learning_style: str) -> str:
        """ä¼˜åŒ–è§£é‡Šæ–¹å¼"""
        if learning_style == "visual" and "```" in response:
            response += "\n\nğŸ“Š **å¯è§†åŒ–æç¤º**: å»ºè®®ç»˜åˆ¶æµç¨‹å›¾æ¥ç†è§£..."
        return response
    
    async def _make_response_concise(self, response: str) -> str:
        """ä½¿å›ç­”æ›´ç®€æ´"""
        # ç®€åŒ–å®ç°
        lines = response.split('\n')
        if len(lines) > 10:
            response = '\n'.join(lines[:8]) + "\n\n... (ç®€åŒ–æ˜¾ç¤º)"
        return response
    
    async def _simplify_code_examples(self, response: str) -> str:
        """ç®€åŒ–ä»£ç ç¤ºä¾‹"""
        return response
    
    async def _add_efficiency_tips(self, response: str) -> str:
        """æ·»åŠ æ•ˆç‡æç¤º"""
        if "for " in response or "while " in response:
            response += "\n\nâš¡ **æ•ˆç‡æç¤º**: è€ƒè™‘ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼..."
        return response
    
    async def _adjust_tone_casual(self, response: str) -> str:
        """è°ƒæ•´ä¸ºè½»æ¾è¯­è°ƒ"""
        return response.replace("æ‚¨", "ä½ ").replace("è¯·æ³¨æ„", "æ³¨æ„")
    
    async def get_personalization_statistics(self, user_id: Optional[str] = None) -> Dict[str, Any]:
        """è·å–ä¸ªæ€§åŒ–ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "total_users": len(self.user_profiles),
            "mode_distribution": defaultdict(int),
            "preference_trends": defaultdict(int)
        }
        
        # ç»Ÿè®¡æ¨¡å¼åˆ†å¸ƒ
        for learning_data in self.learning_history:
            stats["mode_distribution"][learning_data.interaction_mode.value] += 1
        
        # ç»Ÿè®¡åå¥½è¶‹åŠ¿
        for user_prefs in self.user_profiles.values():
            for key, value in user_prefs.items():
                if isinstance(value, (str, bool)):
                    stats["preference_trends"][f"{key}_{value}"] += 1
        
        if user_id and user_id in self.user_profiles:
            stats["user_preferences"] = self.user_profiles[user_id]
        
        return dict(stats)
    async def _load_adaptation_rules(self):
        """è¼‰å…¥é©é…è¦å‰‡"""
        self.adaptation_rules = {
            LearningType.CLAUDE_INTERACTION: {
                "weight": 1.0,
                "adaptation_rate": 0.1,
                "success_threshold": 0.7,
                "features": ["user_satisfaction", "response_time", "context_relevance"]
            },
            LearningType.USER_BEHAVIOR: {
                "weight": 0.8,
                "adaptation_rate": 0.15,
                "success_threshold": 0.6,
                "features": ["interaction_frequency", "preference_consistency", "workflow_efficiency"]
            },
            LearningType.PERFORMANCE_OPTIMIZATION: {
                "weight": 0.9,
                "adaptation_rate": 0.05,
                "success_threshold": 0.8,
                "features": ["response_time", "accuracy", "resource_usage"]
            },
            LearningType.ERROR_CORRECTION: {
                "weight": 1.2,
                "adaptation_rate": 0.2,
                "success_threshold": 0.9,
                "features": ["error_rate", "correction_accuracy", "learning_speed"]
            },
            LearningType.CONTEXT_ENHANCEMENT: {
                "weight": 0.7,
                "adaptation_rate": 0.12,
                "success_threshold": 0.65,
                "features": ["context_relevance", "enhancement_quality", "user_acceptance"]
            }
        }
    
    async def _initialize_performance_tracker(self):
        """åˆå§‹åŒ–æ€§èƒ½è¿½è¹¤å™¨"""
        for learning_type in LearningType:
            self.performance_tracker[learning_type] = []
    
    async def process_interaction(self, interaction_data: Dict[str, Any]):
        """è™•ç†äº¤äº’æ•¸æ“š"""
        try:
            # æå–å­¸ç¿’ç‰¹å¾µ
            features = await self._extract_learning_features(interaction_data)
            
            # è©•ä¼°äº¤äº’è³ªé‡
            quality_score = await self._evaluate_interaction_quality(interaction_data, features)
            
            # æ›´æ–°å­¸ç¿’æ¨¡å¼
            await self._update_learning_patterns(interaction_data, features, quality_score)
            
            # å­˜å„²å­¸ç¿’æ•¸æ“š
            learning_data = LearningData(
                id=f"learning_{int(time.time())}_{hash(str(interaction_data)) % 10000}",
                source="claude_interaction",
                learning_type=LearningType.CLAUDE_INTERACTION,
                data={
                    "interaction": interaction_data,
                    "features": features,
                    "quality_score": quality_score
                },
                performance_metrics={
                    "response_time": interaction_data.get("response_time", 0),
                    "user_satisfaction": interaction_data.get("user_satisfaction", 0),
                    "context_relevance": features.get("context_relevance", 0)
                },
                timestamp=time.time(),
                success=quality_score > 0.5
            )
            
            await self._store_learning_data(learning_data)
            
            logger.debug(f"âœ… è™•ç†äº¤äº’å­¸ç¿’: {learning_data.id} (è³ªé‡: {quality_score:.3f})")
            
        except Exception as e:
            logger.error(f"âŒ è™•ç†äº¤äº’å­¸ç¿’å¤±æ•—: {e}")
    
    async def _extract_learning_features(self, interaction_data: Dict[str, Any]) -> Dict[str, float]:
        """æå–å­¸ç¿’ç‰¹å¾µ"""
        features = {}
        
        # åŸºæœ¬ç‰¹å¾µ
        features["response_time"] = min(1.0, 5000.0 / max(1.0, interaction_data.get("response_time", 5000)))
        features["user_satisfaction"] = interaction_data.get("user_satisfaction", 0.5)
        features["input_length"] = min(1.0, len(interaction_data.get("user_input", "")) / 1000.0)
        features["output_length"] = min(1.0, len(interaction_data.get("claude_response", "")) / 2000.0)
        
        # ä¸Šä¸‹æ–‡ç‰¹å¾µ
        context_id = interaction_data.get("context_id")
        if context_id:
            context = await self.context_manager.get_context(context_id)
            if context:
                features["context_relevance"] = context.relevance_score
                features["context_age"] = min(1.0, (time.time() - context.created_at) / 3600.0)
        
        # æ­·å²ç‰¹å¾µ
        user_input = interaction_data.get("user_input", "")
        similar_interactions = await self.memory_engine.get_similar_memories(
            content=user_input,
            memory_type=self.memory_engine.MemoryType.CLAUDE_INTERACTION,
            limit=3
        )
        
        if similar_interactions:
            features["similarity_score"] = np.mean([mem.importance_score for mem in similar_interactions])
            features["repetition_factor"] = len(similar_interactions) / 10.0
        else:
            features["similarity_score"] = 0.0
            features["repetition_factor"] = 0.0
        
        return features
    
    async def _evaluate_interaction_quality(self, 
                                          interaction_data: Dict[str, Any], 
                                          features: Dict[str, float]) -> float:
        """è©•ä¼°äº¤äº’è³ªé‡"""
        quality_components = []
        
        # ç”¨æˆ¶æ»¿æ„åº¦ (40%)
        user_satisfaction = interaction_data.get("user_satisfaction", 0.5)
        quality_components.append(user_satisfaction * 0.4)
        
        # éŸ¿æ‡‰æ•ˆç‡ (25%)
        response_efficiency = features.get("response_time", 0.5)
        quality_components.append(response_efficiency * 0.25)
        
        # å…§å®¹ç›¸é—œæ€§ (20%)
        content_relevance = features.get("context_relevance", 0.5)
        quality_components.append(content_relevance * 0.2)
        
        # è¼¸å‡ºè³ªé‡ (15%)
        output_quality = min(1.0, features.get("output_length", 0.5) * 2.0)
        quality_components.append(output_quality * 0.15)
        
        return sum(quality_components)
    
    async def _update_learning_patterns(self, 
                                      interaction_data: Dict[str, Any], 
                                      features: Dict[str, float], 
                                      quality_score: float):
        """æ›´æ–°å­¸ç¿’æ¨¡å¼"""
        user_input = interaction_data.get("user_input", "")
        
        # æå–é—œéµè©
        keywords = self._extract_keywords(user_input)
        
        # æ›´æ–°æ¨¡å¼
        for keyword in keywords:
            if keyword not in self.learning_patterns[LearningType.CLAUDE_INTERACTION]:
                self.learning_patterns[LearningType.CLAUDE_INTERACTION][keyword] = {
                    "count": 0,
                    "total_quality": 0.0,
                    "avg_quality": 0.0,
                    "features": defaultdict(list)
                }
            
            pattern = self.learning_patterns[LearningType.CLAUDE_INTERACTION][keyword]
            pattern["count"] += 1
            pattern["total_quality"] += quality_score
            pattern["avg_quality"] = pattern["total_quality"] / pattern["count"]
            
            # æ›´æ–°ç‰¹å¾µ
            for feature, value in features.items():
                pattern["features"][feature].append(value)
                # ä¿æŒæœ€è¿‘çš„ç‰¹å¾µå€¼
                if len(pattern["features"][feature]) > 20:
                    pattern["features"][feature] = pattern["features"][feature][-20:]
    
    def _extract_keywords(self, text: str) -> List[str]:
        """æå–é—œéµè©"""
        # ç°¡åŒ–çš„é—œéµè©æå–
        words = text.lower().split()
        keywords = []
        
        # ç·¨ç¨‹ç›¸é—œé—œéµè©
        programming_keywords = {
            "python", "javascript", "java", "c++", "html", "css", "sql",
            "react", "vue", "angular", "nodejs", "django", "flask",
            "function", "class", "variable", "loop", "condition",
            "debug", "error", "exception", "test", "api", "database"
        }
        
        for word in words:
            if word in programming_keywords or len(word) > 3:
                keywords.append(word)
        
        return keywords[:10]  # é™åˆ¶é—œéµè©æ•¸é‡
    
    async def record_learning_data(self, 
                                 source: str, 
                                 data: Dict[str, Any], 
                                 learning_type: str, 
                                 timestamp: float):
        """è¨˜éŒ„å­¸ç¿’æ•¸æ“š"""
        try:
            # è½‰æ›å­¸ç¿’é¡å‹
            learning_type_enum = LearningType(learning_type)
            
            # æå–æ€§èƒ½æŒ‡æ¨™
            performance_metrics = data.get("performance_metrics", {})
            
            # å‰µå»ºå­¸ç¿’æ•¸æ“š
            learning_data = LearningData(
                id=f"learning_{int(timestamp)}_{hash(str(data)) % 10000}",
                source=source,
                learning_type=learning_type_enum,
                data=data,
                performance_metrics=performance_metrics,
                timestamp=timestamp,
                success=data.get("success", True)
            )
            
            await self._store_learning_data(learning_data)
            
            # æ›´æ–°æ€§èƒ½è¿½è¹¤
            await self._update_performance_tracker(learning_data)
            
            logger.debug(f"âœ… è¨˜éŒ„å­¸ç¿’æ•¸æ“š: {learning_data.id} ({source})")
            
        except Exception as e:
            logger.error(f"âŒ è¨˜éŒ„å­¸ç¿’æ•¸æ“šå¤±æ•—: {e}")
    
    async def _store_learning_data(self, learning_data: LearningData):
        """å­˜å„²å­¸ç¿’æ•¸æ“š"""
        # æ·»åŠ åˆ°æ­·å²è¨˜éŒ„
        self.learning_history.append(learning_data)
        
        # å­˜å„²åˆ°è¨˜æ†¶å¼•æ“
        memory_id = f"learning_{learning_data.id}"
        
        memory = self.memory_engine.Memory(
            id=memory_id,
            memory_type=self.memory_engine.MemoryType.PROCEDURAL,
            content=json.dumps(learning_data.to_dict()),
            metadata={
                "source": learning_data.source,
                "learning_type": learning_data.learning_type.value,
                "success": learning_data.success,
                "performance_metrics": learning_data.performance_metrics
            },
            created_at=learning_data.timestamp,
            accessed_at=learning_data.timestamp,
            access_count=1,
            importance_score=self._calculate_learning_importance(learning_data),
            tags=["learning", learning_data.learning_type.value, learning_data.source]
        )
        
        await self.memory_engine.store_memory(memory)
    
    def _calculate_learning_importance(self, learning_data: LearningData) -> float:
        """è¨ˆç®—å­¸ç¿’é‡è¦æ€§"""
        base_importance = 0.5
        
        # æˆåŠŸç‡å½±éŸ¿
        if learning_data.success:
            base_importance *= 1.2
        else:
            base_importance *= 0.8
        
        # å­¸ç¿’é¡å‹æ¬Šé‡
        type_weight = self.adaptation_rules.get(learning_data.learning_type, {}).get("weight", 1.0)
        base_importance *= type_weight
        
        # æ€§èƒ½æŒ‡æ¨™å½±éŸ¿
        performance_avg = np.mean(list(learning_data.performance_metrics.values())) if learning_data.performance_metrics else 0.5
        base_importance *= (0.5 + performance_avg * 0.5)
        
        return min(2.0, max(0.1, base_importance))
    
    async def _update_performance_tracker(self, learning_data: LearningData):
        """æ›´æ–°æ€§èƒ½è¿½è¹¤å™¨"""
        tracker = self.performance_tracker[learning_data.learning_type]
        
        # æ·»åŠ æ€§èƒ½æ•¸æ“š
        tracker.append({
            "timestamp": learning_data.timestamp,
            "success": learning_data.success,
            "metrics": learning_data.performance_metrics,
            "importance": self._calculate_learning_importance(learning_data)
        })
        
        # ä¿æŒæœ€è¿‘çš„æ€§èƒ½æ•¸æ“š
        if len(tracker) > 100:
            self.performance_tracker[learning_data.learning_type] = tracker[-100:]
    
    async def get_best_practices(self, query: str, domain: str = "general") -> List[Dict[str, Any]]:
        """ç²å–æœ€ä½³å¯¦è¸"""
        try:
            # æœç´¢ç›¸é—œçš„å­¸ç¿’è¨˜æ†¶
            learning_memories = await self.memory_engine.search_memories(
                query=query,
                memory_type=self.memory_engine.MemoryType.PROCEDURAL,
                tags=["learning"],
                limit=10
            )
            
            best_practices = []
            
            for memory in learning_memories:
                try:
                    learning_data = json.loads(memory.content)
                    
                    # éæ¿¾æˆåŠŸçš„å­¸ç¿’æ•¸æ“š
                    if learning_data.get("success", False):
                        performance_metrics = learning_data.get("performance_metrics", {})
                        
                        # è¨ˆç®—å¯¦è·µè³ªé‡
                        quality_score = np.mean(list(performance_metrics.values())) if performance_metrics else 0.5
                        
                        if quality_score > 0.6:
                            best_practices.append({
                                "id": memory.id,
                                "content": learning_data.get("data", {}).get("interaction", {}).get("claude_response", "")[:200],
                                "quality_score": quality_score,
                                "domain": domain,
                                "tags": memory.tags,
                                "timestamp": memory.created_at
                            })
                            
                except Exception as e:
                    logger.warning(f"è§£æå­¸ç¿’æ•¸æ“šå¤±æ•—: {e}")
                    continue
            
            # æŒ‰è³ªé‡æ’åº
            best_practices.sort(key=lambda x: x["quality_score"], reverse=True)
            
            return best_practices[:5]
            
        except Exception as e:
            logger.error(f"âŒ ç²å–æœ€ä½³å¯¦è¸å¤±æ•—: {e}")
            return []
    
    async def get_learning_statistics(self) -> Dict[str, Any]:
        """ç²å–å­¸ç¿’çµ±è¨ˆ"""
        try:
            stats = {
                "total_learning_records": len(self.learning_history),
                "success_rate": 0.0,
                "avg_response_time": 0.0,
                "context_enhancement_rate": 0.0,
                "avg_user_satisfaction": 0.0,
                "learning_type_distribution": {},
                "performance_trends": {}
            }
            
            if self.learning_history:
                # æˆåŠŸç‡
                successful_records = [ld for ld in self.learning_history if ld.success]
                stats["success_rate"] = len(successful_records) / len(self.learning_history)
                
                # å¹³å‡éŸ¿æ‡‰æ™‚é–“
                response_times = [ld.performance_metrics.get("response_time", 0) for ld in self.learning_history]
                stats["avg_response_time"] = np.mean(response_times) if response_times else 0.0
                
                # å¹³å‡ç”¨æˆ¶æ»¿æ„åº¦
                satisfactions = [ld.performance_metrics.get("user_satisfaction", 0) for ld in self.learning_history]
                stats["avg_user_satisfaction"] = np.mean(satisfactions) if satisfactions else 0.0
                
                # å­¸ç¿’é¡å‹åˆ†ä½ˆ
                for learning_data in self.learning_history:
                    type_name = learning_data.learning_type.value
                    stats["learning_type_distribution"][type_name] = stats["learning_type_distribution"].get(type_name, 0) + 1
                
                # ä¸Šä¸‹æ–‡å¢å¼·ç‡
                enhanced_count = sum(1 for ld in self.learning_history 
                                   if ld.data.get("interaction", {}).get("context_enhanced", False))
                stats["context_enhancement_rate"] = enhanced_count / len(self.learning_history)
            
            # æ€§èƒ½è¶¨å‹¢
            for learning_type, tracker in self.performance_tracker.items():
                if tracker:
                    recent_performance = tracker[-10:]  # æœ€è¿‘10å€‹è¨˜éŒ„
                    stats["performance_trends"][learning_type.value] = {
                        "recent_success_rate": np.mean([p["success"] for p in recent_performance]),
                        "trend_direction": "up" if len(recent_performance) > 5 else "stable"
                    }
            
            return stats
            
        except Exception as e:
            logger.error(f"âŒ ç²å–å­¸ç¿’çµ±è¨ˆå¤±æ•—: {e}")
            return {}
    
    async def optimize_learning_parameters(self):
        """å„ªåŒ–å­¸ç¿’åƒæ•¸"""
        try:
            logger.info("ğŸ”§ å„ªåŒ–å­¸ç¿’åƒæ•¸...")
            
            # åˆ†æå­¸ç¿’æ¨¡å¼
            for learning_type, patterns in self.learning_patterns.items():
                if not patterns:
                    continue
                
                # ç²å–é©é…è¦å‰‡
                rules = self.adaptation_rules.get(learning_type, {})
                
                # è¨ˆç®—å¹³å‡æ€§èƒ½
                avg_quality = np.mean([pattern["avg_quality"] for pattern in patterns.values()])
                
                # èª¿æ•´é©é…ç‡
                if avg_quality > rules.get("success_threshold", 0.7):
                    # æ€§èƒ½è‰¯å¥½ï¼Œé™ä½é©é…ç‡
                    rules["adaptation_rate"] = max(0.01, rules["adaptation_rate"] * 0.95)
                else:
                    # æ€§èƒ½ä¸ä½³ï¼Œæé«˜é©é…ç‡
                    rules["adaptation_rate"] = min(0.5, rules["adaptation_rate"] * 1.05)
                
                logger.debug(f"ğŸ“Š èª¿æ•´ {learning_type.value} é©é…ç‡: {rules['adaptation_rate']:.4f}")
            
            logger.info("âœ… å­¸ç¿’åƒæ•¸å„ªåŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ å„ªåŒ–å­¸ç¿’åƒæ•¸å¤±æ•—: {e}")
    
    async def cleanup(self):
        """æ¸…ç†è³‡æº"""
        self.learning_history.clear()
        self.performance_tracker.clear()
        self.learning_patterns.clear()
        logger.info("ğŸ§¹ Learning Adapter æ¸…ç†å®Œæˆ")

# æ¸¬è©¦å‡½æ•¸
async def main():
    """æ¸¬è©¦å­¸ç¿’é©é…å™¨"""
    print("ğŸ§ª æ¸¬è©¦ Learning Adapter...")
    
    # æ¨¡æ“¬ä¾è³´
    class MockMemoryEngine:
        class MemoryType:
            CLAUDE_INTERACTION = "claude_interaction"
            PROCEDURAL = "procedural"
        
        class Memory:
            def __init__(self, **kwargs):
                for k, v in kwargs.items():
                    setattr(self, k, v)
        
        async def get_similar_memories(self, content, memory_type, limit):
            return []
        
        async def store_memory(self, memory):
            return True
        
        async def search_memories(self, query, memory_type, tags, limit):
            return []
    
    class MockContextManager:
        async def get_context(self, context_id):
            return None
    
    # å‰µå»ºæ¸¬è©¦å¯¦ä¾‹
    memory_engine = MockMemoryEngine()
    context_manager = MockContextManager()
    
    adapter = LearningAdapter(memory_engine, context_manager)
    await adapter.initialize()
    
    # æ¸¬è©¦äº¤äº’è™•ç†
    test_interaction = {
        "user_input": "å¦‚ä½•ä½¿ç”¨ Python é€²è¡Œæ•¸æ“šåˆ†æï¼Ÿ",
        "claude_response": "Python æ•¸æ“šåˆ†æå¯ä»¥ä½¿ç”¨ pandasã€numpy ç­‰åº«...",
        "response_time": 2500,
        "user_satisfaction": 0.85,
        "context_id": "test_context"
    }
    
    await adapter.process_interaction(test_interaction)
    
    # æ¸¬è©¦çµ±è¨ˆ
    stats = await adapter.get_learning_statistics()
    print(f"ğŸ“Š å­¸ç¿’çµ±è¨ˆ: {stats}")
    
    await adapter.cleanup()
    print("âœ… æ¸¬è©¦å®Œæˆ")

if __name__ == "__main__":
    asyncio.run(main())
        self.adaptation_rules = {
            LearningType.CLAUDE_INTERACTION: {
                "weight": 1.0,
                "adaptation_rate": 0.1,
                "success_threshold": 0.7,
                "features": ["user_satisfaction", "response_time", "context_relevance"]
            },
            LearningType.USER_BEHAVIOR: {
                "weight": 0.8,
                "adaptation_rate": 0.15,
                "success_threshold": 0.6,
                "features": ["interaction_frequency", "preference_consistency", "workflow_efficiency"]
            },
            LearningType.PERFORMANCE_OPTIMIZATION: {
                "weight": 0.9,
                "adaptation_rate": 0.05,
                "success_threshold": 0.8,
                "features": ["response_time", "accuracy", "resource_usage"]
            },
            LearningType.ERROR_CORRECTION: {
                "weight": 1.2,
                "adaptation_rate": 0.2,
                "success_threshold": 0.9,
                "features": ["error_rate", "correction_accuracy", "learning_speed"]
            },
            LearningType.CONTEXT_ENHANCEMENT: {
                "weight": 0.7,
                "adaptation_rate": 0.12,
                "success_threshold": 0.65,
                "features": ["context_relevance", "enhancement_quality", "user_acceptance"]
            }
        }
    
    async def _initialize_performance_tracker(self):
        """åˆå§‹åŒ–æ€§èƒ½è¿½è¹¤å™¨"""
        for learning_type in LearningType:
            self.performance_tracker[learning_type] = []
    
    async def process_interaction(self, interaction_data: Dict[str, Any], context: QueryContext):
        """è™•ç†äº¤äº’æ•¸æ“š - æ”¯æŒæ¨¡å¼æ„ŸçŸ¥"""
        try:
            # æ£€æµ‹äº¤äº’æ¨¡å¼
            interaction_mode = self.detect_interaction_mode(context)
            
            # æå–å­¸ç¿’ç‰¹å¾µ
            features = await self._extract_learning_features(interaction_data)
            
            # è©•ä¼°äº¤äº’è³ªé‡
            quality_score = await self._evaluate_interaction_quality(interaction_data, features)
            
            # æ›´æ–°å­¸ç¿’æ¨¡å¼
            await self._update_learning_patterns(interaction_data, features, quality_score, interaction_mode)
            
            # å­˜å„²å­¸ç¿’æ•¸æ“š
            learning_data = LearningData(
                id=f"learning_{int(time.time())}_{hash(str(interaction_data)) % 10000}",
                source="claude_interaction",
                learning_type=LearningType.CLAUDE_INTERACTION,
                interaction_mode=interaction_mode,
                data={
                    "interaction": interaction_data,
                    "features": features,
                    "quality_score": quality_score,
                    "context": context.to_dict() if hasattr(context, 'to_dict') else {}
                },
                performance_metrics={
                    "response_time": interaction_data.get("response_time", 0),
                    "user_satisfaction": interaction_data.get("user_satisfaction", 0),
                    "context_relevance": features.get("context_relevance", 0)
                },
                timestamp=time.time(),
                success=quality_score > 0.5
            )
            
            await self._store_learning_data(learning_data)
            
            logger.debug(f"âœ… è™•ç†äº¤äº’å­¸ç¿’: {learning_data.id} (è³ªé‡: {quality_score:.3f}, æ¨¡å¼: {interaction_mode.value})")
            
        except Exception as e:
            logger.error(f"âŒ è™•ç†äº¤äº’å­¸ç¿’å¤±æ•—: {e}")
    
    async def _extract_learning_features(self, interaction_data: Dict[str, Any]) -> Dict[str, float]:
        """æå–å­¸ç¿’ç‰¹å¾µ"""
        features = {}
        
        # åŸºæœ¬ç‰¹å¾µ
        features["response_time"] = min(1.0, 5000.0 / max(1.0, interaction_data.get("response_time", 5000)))
        features["user_satisfaction"] = interaction_data.get("user_satisfaction", 0.5)
        features["input_length"] = min(1.0, len(interaction_data.get("user_input", "")) / 1000.0)
        features["output_length"] = min(1.0, len(interaction_data.get("claude_response", "")) / 2000.0)
        
        # ä¸Šä¸‹æ–‡ç‰¹å¾µ
        context_id = interaction_data.get("context_id")
        if context_id and hasattr(self.context_manager, 'get_context'):
            try:
                context = await self.context_manager.get_context(context_id)
                if context:
                    features["context_relevance"] = getattr(context, 'relevance_score', 0.5)
                    features["context_age"] = min(1.0, (time.time() - getattr(context, 'created_at', time.time())) / 3600.0)
            except:
                features["context_relevance"] = 0.5
                features["context_age"] = 0.5
        else:
            features["context_relevance"] = 0.5
            features["context_age"] = 0.5
        
        # æ­·å²ç‰¹å¾µ
        user_input = interaction_data.get("user_input", "")
        if user_input and hasattr(self.memory_engine, 'search_memories'):
            try:
                similar_interactions = await self.memory_engine.search_memories(
                    query=user_input[:100],
                    limit=3
                )
                
                if similar_interactions:
                    features["similarity_score"] = np.mean([getattr(mem, 'importance_score', 0.5) for mem in similar_interactions])
                    features["repetition_factor"] = len(similar_interactions) / 10.0
                else:
                    features["similarity_score"] = 0.0
                    features["repetition_factor"] = 0.0
            except:
                features["similarity_score"] = 0.0
                features["repetition_factor"] = 0.0
        else:
            features["similarity_score"] = 0.0
            features["repetition_factor"] = 0.0
        
        return features
    
    async def _evaluate_interaction_quality(self, 
                                          interaction_data: Dict[str, Any], 
                                          features: Dict[str, float]) -> float:
        """è©•ä¼°äº¤äº’è³ªé‡"""
        quality_components = []
        
        # ç”¨æˆ¶æ»¿æ„åº¦ (40%)
        user_satisfaction = interaction_data.get("user_satisfaction", 0.5)
        quality_components.append(user_satisfaction * 0.4)
        
        # éŸ¿æ‡‰æ•ˆç‡ (25%)
        response_efficiency = features.get("response_time", 0.5)
        quality_components.append(response_efficiency * 0.25)
        
        # å…§å®¹ç›¸é—œæ€§ (20%)
        content_relevance = features.get("context_relevance", 0.5)
        quality_components.append(content_relevance * 0.2)
        
        # è¼¸å‡ºè³ªé‡ (15%)
        output_quality = min(1.0, features.get("output_length", 0.5) * 2.0)
        quality_components.append(output_quality * 0.15)
        
        return sum(quality_components)
    
    async def _update_learning_patterns(self, interaction_data: Dict[str, Any], 
                                      features: Dict[str, float], 
                                      quality_score: float,
                                      interaction_mode: InteractionMode):
        """æ›´æ–°å­¸ç¿’æ¨¡å¼ - æ”¯æŒæ¨¡å¼æ„ŸçŸ¥"""
        try:
            # æŒ‰æ¨¡å¼åˆ†åˆ«æ›´æ–°å­¦ä¹ æ¨¡å¼
            mode_key = interaction_mode.value
            
            if mode_key not in self.learning_patterns:
                self.learning_patterns[mode_key] = {
                    "feature_weights": defaultdict(float),
                    "quality_history": deque(maxlen=100),
                    "adaptation_count": 0,
                    "success_rate": 0.0
                }
            
            pattern = self.learning_patterns[mode_key]
            
            # æ›´æ–°ç‰¹å¾µæ¬Šé‡
            for feature, value in features.items():
                current_weight = pattern["feature_weights"][feature]
                adaptation_rate = self.adaptation_rules[LearningType.CLAUDE_INTERACTION]["adaptation_rate"]
                
                # æ ¹æ“šè³ªé‡åˆ†æ•¸èª¿æ•´æ¬Šé‡
                if quality_score > 0.7:
                    pattern["feature_weights"][feature] = current_weight + adaptation_rate * value
                elif quality_score < 0.3:
                    pattern["feature_weights"][feature] = current_weight - adaptation_rate * value * 0.5
            
            # æ›´æ–°è³ªé‡æ­·å²
            pattern["quality_history"].append(quality_score)
            pattern["adaptation_count"] += 1
            
            # è¨ˆç®—æˆåŠŸç‡
            if len(pattern["quality_history"]) > 0:
                pattern["success_rate"] = sum(1 for q in pattern["quality_history"] if q > 0.5) / len(pattern["quality_history"])
            
            logger.debug(f"âœ… æ›´æ–°å­¸ç¿’æ¨¡å¼: {mode_key} (æˆåŠŸç‡: {pattern['success_rate']:.3f})")
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°å­¸ç¿’æ¨¡å¼å¤±æ•—: {e}")
    
    async def _store_learning_data(self, learning_data: LearningData):
        """å­˜å„²å­¸ç¿’æ•¸æ“š"""
        try:
            # æ·»åŠ åˆ°æ­·å²è¨˜éŒ„
            self.learning_history.append(learning_data)
            
            # æ›´æ–°æ€§èƒ½è¿½è¹¤å™¨
            self.performance_tracker[learning_data.learning_type].append({
                "timestamp": learning_data.timestamp,
                "quality_score": learning_data.performance_metrics.get("user_satisfaction", 0),
                "success": learning_data.success,
                "interaction_mode": learning_data.interaction_mode.value
            })
            
            # å­˜å„²åˆ°è¨˜æ†¶å¼•æ“
            if hasattr(self.memory_engine, 'store_memory'):
                from .memory_engine import Memory, MemoryType
                
                memory = Memory(
                    id=learning_data.id,
                    memory_type=MemoryType.SYSTEM_STATE,
                    content=f"å­¸ç¿’æ•¸æ“š: {learning_data.learning_type.value}",
                    metadata=learning_data.to_dict(),
                    created_at=learning_data.timestamp,
                    accessed_at=learning_data.timestamp,
                    access_count=0,
                    importance_score=0.6,
                    tags=["learning", "adaptation", learning_data.interaction_mode.value]
                )
                
                await self.memory_engine.store_memory(memory)
            
        except Exception as e:
            logger.error(f"âŒ å­˜å„²å­¸ç¿’æ•¸æ“šå¤±æ•—: {e}")
    
    async def get_learning_statistics(self) -> Dict[str, Any]:
        """ç²å–å­¸ç¿’çµ±è¨ˆä¿¡æ¯"""
        stats = {
            "total_interactions": len(self.learning_history),
            "learning_patterns": {},
            "performance_trends": {},
            "mode_statistics": defaultdict(int),
            "success_rates": {}
        }
        
        # çµ±è¨ˆæ¨¡å¼åˆ†å¸ƒ
        for learning_data in self.learning_history:
            stats["mode_statistics"][learning_data.interaction_mode.value] += 1
        
        # çµ±è¨ˆå­¸ç¿’æ¨¡å¼
        for mode, pattern in self.learning_patterns.items():
            stats["learning_patterns"][mode] = {
                "adaptation_count": pattern["adaptation_count"],
                "success_rate": pattern["success_rate"],
                "top_features": dict(sorted(
                    pattern["feature_weights"].items(), 
                    key=lambda x: x[1], 
                    reverse=True
                )[:5])
            }
        
        # çµ±è¨ˆæ€§èƒ½è¶¨å‹¢
        for learning_type, records in self.performance_tracker.items():
            if records:
                recent_records = records[-20:]  # æœ€è¿‘20æ¢è¨˜éŒ„
                stats["performance_trends"][learning_type.value] = {
                    "avg_quality": np.mean([r["quality_score"] for r in recent_records]),
                    "success_rate": sum(1 for r in recent_records if r["success"]) / len(recent_records),
                    "total_records": len(records)
                }
        
        # å€‹æ€§åŒ–çµ±è¨ˆ
        personalization_stats = await self.get_personalization_statistics()
        stats.update(personalization_stats)
        
        return stats

# å…¨å±€å®ä¾‹ç®¡ç†
learning_adapter = None

def get_learning_adapter(memory_engine=None, context_manager=None):
    """è·å–å­¦ä¹ é€‚é…å™¨å®ä¾‹"""
    global learning_adapter
    if learning_adapter is None and memory_engine and context_manager:
        learning_adapter = LearningAdapter(memory_engine, context_manager)
    return learning_adapter

async def main():
    """æµ‹è¯•å­¦ä¹ é€‚é…å™¨"""
    print("ğŸ§ª æµ‹è¯• LearningAdapter...")
    
    # æ¨¡æ‹Ÿä¾èµ–
    class MockMemoryEngine:
        async def search_memories(self, query, limit=3):
            return []
        
        async def store_memory(self, memory):
            pass
    
    class MockContextManager:
        async def get_context(self, context_id):
            return None
    
    # åˆ›å»ºé€‚é…å™¨
    adapter = LearningAdapter(MockMemoryEngine(), MockContextManager())
    await adapter.initialize()
    
    # æµ‹è¯•æ¨¡å¼æ£€æµ‹
    context = QueryContext(
        current_tool="claude_code_tool",
        current_model="claude",
        user_id="test_user"
    )
    
    mode = adapter.detect_interaction_mode(context)
    print(f"âœ… æ¨¡å¼æ£€æµ‹: {mode.value}")
    
    # æµ‹è¯•ä¸ªæ€§åŒ–å¤„ç†
    response = "è¿™æ˜¯ä¸€ä¸ªPythonå‡½æ•°ç¤ºä¾‹"
    personalized = await adapter.personalize_response(response, context)
    print(f"âœ… ä¸ªæ€§åŒ–å¤„ç†å®Œæˆ")
    
    # æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯
    stats = await adapter.get_learning_statistics()
    print(f"âœ… ç»Ÿè®¡ä¿¡æ¯: {len(stats)} ä¸ªæŒ‡æ ‡")
    
    print("âœ… LearningAdapter æµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    asyncio.run(main())

