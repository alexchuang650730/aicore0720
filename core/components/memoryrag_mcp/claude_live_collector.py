#!/usr/bin/env python3
"""
Claude å¯¦æ™‚å°è©±æ•¸æ“šæ”¶é›†å™¨
åœ¨ç•¶å‰å°è©±ä¸­å³æ™‚æ”¶é›†è¨“ç·´æ•¸æ“š
"""

import json
import asyncio
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
import os

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class ConversationTurn:
    """å°è©±å›åˆ"""
    role: str  # user or assistant
    content: str
    timestamp: str
    metadata: Dict[str, Any] = None
    tools_used: List[str] = None
    thinking_process: str = None

@dataclass
class ConversationSession:
    """å°è©±æœƒè©±"""
    session_id: str
    start_time: str
    end_time: str = None
    turns: List[ConversationTurn] = None
    context: Dict[str, Any] = None
    summary: str = None
    quality_score: float = None

class ClaudeLiveCollector:
    """Claude å¯¦æ™‚æ•¸æ“šæ”¶é›†å™¨"""
    
    def __init__(self):
        # ä½¿ç”¨çµ•å°è·¯å¾‘
        base_dir = Path(__file__).parent.parent.parent.parent
        self.data_dir = base_dir / "data/claude_conversations"
        self.data_dir.mkdir(parents=True, exist_ok=True)
        self.current_session = None
        self.sessions = []
        
        # è¼‰å…¥å·²æœ‰æ•¸æ“š
        self.load_existing_data()
        
        # å•Ÿå‹•ç•¶å‰æœƒè©±
        self.start_new_session()
        
    def load_existing_data(self):
        """è¼‰å…¥å·²æœ‰çš„è¨“ç·´æ•¸æ“š"""
        try:
            data_file = self.data_dir / "claude_conversations.json"
            if data_file.exists():
                with open(data_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.sessions = [
                        ConversationSession(**session) for session in data.get("sessions", [])
                    ]
                logger.info(f"è¼‰å…¥äº† {len(self.sessions)} å€‹æ­·å²æœƒè©±")
        except Exception as e:
            logger.error(f"è¼‰å…¥æ•¸æ“šå¤±æ•—: {str(e)}")
    
    def start_session(self, context: Dict[str, Any] = None) -> str:
        """é–‹å§‹æ–°çš„æ”¶é›†æœƒè©±"""
        session_id = f"claude_session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.current_session = ConversationSession(
            session_id=session_id,
            start_time=datetime.now().isoformat(),
            turns=[],
            context=context or {
                "platform": "ClaudeEditor",
                "version": "4.74",
                "purpose": "training_data_collection"
            }
        )
        
        logger.info(f"é–‹å§‹æ–°æœƒè©±: {session_id}")
        return session_id
    
    def add_turn(self, role: str, content: str, metadata: Dict[str, Any] = None):
        """æ·»åŠ å°è©±å›åˆ"""
        if not self.current_session:
            self.start_session()
        
        turn = ConversationTurn(
            role=role,
            content=content,
            timestamp=datetime.now().isoformat(),
            metadata=metadata or {},
            tools_used=self._extract_tools_from_content(content),
            thinking_process=self._extract_thinking_from_content(content)
        )
        
        self.current_session.turns.append(turn)
        logger.info(f"æ·»åŠ  {role} å›åˆï¼Œé•·åº¦: {len(content)} å­—ç¬¦")
        
        # è‡ªå‹•ä¿å­˜
        self.save_current_session()
    
    def _extract_tools_from_content(self, content: str) -> List[str]:
        """å¾å…§å®¹ä¸­æå–ä½¿ç”¨çš„å·¥å…·"""
        tools = []
        tool_keywords = {
            "Read": ["è®€å–", "æŸ¥çœ‹", "æª¢æŸ¥æ–‡ä»¶"],
            "Write": ["å‰µå»º", "å¯«å…¥", "ç”Ÿæˆæ–‡ä»¶"],
            "Edit": ["ä¿®æ”¹", "ç·¨è¼¯", "æ›´æ–°"],
            "Bash": ["åŸ·è¡Œ", "é‹è¡Œå‘½ä»¤", "bash"],
            "WebFetch": ["ç²å–ç¶²é ", "æŠ“å–"],
            "Task": ["ä»»å‹™", "æœç´¢"],
            "TodoWrite": ["å¾…è¾¦", "ä»»å‹™åˆ—è¡¨"]
        }
        
        for tool, keywords in tool_keywords.items():
            if any(keyword in content for keyword in keywords):
                tools.append(tool)
        
        return tools
    
    def _extract_thinking_from_content(self, content: str) -> Optional[str]:
        """æå–æ€è€ƒéç¨‹"""
        thinking_patterns = [
            "æˆ‘éœ€è¦", "æˆ‘æœƒ", "é¦–å…ˆ", "ç„¶å¾Œ", "æ¥ä¸‹ä¾†",
            "è®“æˆ‘", "æˆ‘ä¾†", "åˆ†æ", "ç†è§£", "è€ƒæ…®"
        ]
        
        for pattern in thinking_patterns:
            if pattern in content:
                # æå–åŒ…å«æ€è€ƒæ¨¡å¼çš„å¥å­
                sentences = content.split('ã€‚')
                for sentence in sentences:
                    if pattern in sentence:
                        return sentence.strip()
        
        return None
    
    def end_session(self, summary: str = None, quality_score: float = None):
        """çµæŸç•¶å‰æœƒè©±"""
        if not self.current_session:
            logger.warning("æ²’æœ‰æ´»å‹•çš„æœƒè©±")
            return
        
        self.current_session.end_time = datetime.now().isoformat()
        self.current_session.summary = summary
        self.current_session.quality_score = quality_score
        
        # æ·»åŠ åˆ°æœƒè©±åˆ—è¡¨
        self.sessions.append(self.current_session)
        
        # ä¿å­˜æ‰€æœ‰æ•¸æ“š
        self.save_all_data()
        
        logger.info(f"çµæŸæœƒè©±: {self.current_session.session_id}")
        self.current_session = None
    
    def save_current_session(self):
        """ä¿å­˜ç•¶å‰æœƒè©±ï¼ˆå¢é‡ä¿å­˜ï¼‰"""
        if not self.current_session:
            return
        
        session_file = self.data_dir / f"{self.current_session.session_id}.json"
        with open(session_file, 'w', encoding='utf-8') as f:
            json.dump(asdict(self.current_session), f, ensure_ascii=False, indent=2)
    
    def save_all_data(self):
        """ä¿å­˜æ‰€æœ‰æ•¸æ“š"""
        data_file = self.data_dir / "claude_conversations.json"
        
        data = {
            "metadata": {
                "total_sessions": len(self.sessions),
                "last_updated": datetime.now().isoformat(),
                "version": "1.0"
            },
            "sessions": [asdict(session) for session in self.sessions]
        }
        
        with open(data_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ä¿å­˜äº† {len(self.sessions)} å€‹æœƒè©±æ•¸æ“š")
    
    def get_statistics(self) -> Dict[str, Any]:
        """ç²å–çµ±è¨ˆä¿¡æ¯"""
        total_turns = sum(len(session.turns) for session in self.sessions)
        total_user_turns = sum(
            len([t for t in session.turns if t.role == "user"]) 
            for session in self.sessions
        )
        total_assistant_turns = sum(
            len([t for t in session.turns if t.role == "assistant"]) 
            for session in self.sessions
        )
        
        # å·¥å…·ä½¿ç”¨çµ±è¨ˆ
        tool_usage = {}
        for session in self.sessions:
            for turn in session.turns:
                if turn.tools_used:
                    for tool in turn.tools_used:
                        tool_usage[tool] = tool_usage.get(tool, 0) + 1
        
        return {
            "total_sessions": len(self.sessions),
            "total_turns": total_turns,
            "user_turns": total_user_turns,
            "assistant_turns": total_assistant_turns,
            "avg_turns_per_session": total_turns / len(self.sessions) if self.sessions else 0,
            "tool_usage": tool_usage,
            "last_session": self.sessions[-1].session_id if self.sessions else None
        }
    
    def export_for_training(self, output_format: str = "jsonl") -> Path:
        """å°å‡ºè¨“ç·´æ•¸æ“š"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        if output_format == "jsonl":
            # å°å‡ºç‚º JSONL æ ¼å¼ï¼ˆç”¨æ–¼å¾®èª¿ï¼‰
            output_file = self.data_dir / f"claude_training_{timestamp}.jsonl"
            
            with open(output_file, 'w', encoding='utf-8') as f:
                for session in self.sessions:
                    for i in range(0, len(session.turns) - 1, 2):
                        if (i + 1 < len(session.turns) and 
                            session.turns[i].role == "user" and 
                            session.turns[i + 1].role == "assistant"):
                            
                            conversation = {
                                "messages": [
                                    {
                                        "role": "user",
                                        "content": session.turns[i].content
                                    },
                                    {
                                        "role": "assistant",
                                        "content": session.turns[i + 1].content
                                    }
                                ],
                                "metadata": {
                                    "session_id": session.session_id,
                                    "timestamp": session.turns[i].timestamp,
                                    "tools_used": session.turns[i + 1].tools_used
                                }
                            }
                            f.write(json.dumps(conversation, ensure_ascii=False) + '\n')
        
        elif output_format == "json":
            # å°å‡ºç‚ºçµæ§‹åŒ– JSON
            output_file = self.data_dir / f"claude_training_{timestamp}.json"
            
            training_data = {
                "metadata": self.get_statistics(),
                "conversations": []
            }
            
            for session in self.sessions:
                for i in range(0, len(session.turns) - 1, 2):
                    if (i + 1 < len(session.turns) and 
                        session.turns[i].role == "user" and 
                        session.turns[i + 1].role == "assistant"):
                        
                        training_data["conversations"].append({
                            "input": session.turns[i].content,
                            "output": session.turns[i + 1].content,
                            "context": session.context,
                            "tools": session.turns[i + 1].tools_used,
                            "thinking": session.turns[i + 1].thinking_process
                        })
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(training_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"å°å‡ºè¨“ç·´æ•¸æ“š: {output_file}")
        return output_file


# å…¨å±€æ”¶é›†å™¨å¯¦ä¾‹
collector = ClaudeLiveCollector()

def start_collection(context: Dict[str, Any] = None):
    """é–‹å§‹æ”¶é›†"""
    return collector.start_session(context)

def collect_user_input(content: str, metadata: Dict[str, Any] = None):
    """æ”¶é›†ç”¨æˆ¶è¼¸å…¥"""
    collector.add_turn("user", content, metadata)

def collect_assistant_response(content: str, metadata: Dict[str, Any] = None):
    """æ”¶é›†åŠ©æ‰‹å›æ‡‰"""
    collector.add_turn("assistant", content, metadata)

def end_collection(summary: str = None, quality_score: float = None):
    """çµæŸæ”¶é›†"""
    collector.end_session(summary, quality_score)

def get_collection_stats():
    """ç²å–æ”¶é›†çµ±è¨ˆ"""
    return collector.get_statistics()

def export_training_data(format: str = "jsonl"):
    """å°å‡ºè¨“ç·´æ•¸æ“š"""
    return collector.export_for_training(format)


# å‘½ä»¤è¡Œæ¥å£
if __name__ == "__main__":
    print("ğŸš€ Claude å¯¦æ™‚å°è©±æ•¸æ“šæ”¶é›†å™¨")
    print("="*50)
    
    # é¡¯ç¤ºçµ±è¨ˆ
    stats = get_collection_stats()
    print(f"å·²æ”¶é›†æœƒè©±: {stats['total_sessions']}")
    print(f"ç¸½å°è©±å›åˆ: {stats['total_turns']}")
    print(f"å·¥å…·ä½¿ç”¨çµ±è¨ˆ: {stats['tool_usage']}")
    
    # é¸é …
    print("\né¸é …:")
    print("1. é–‹å§‹æ–°çš„æ”¶é›†æœƒè©±")
    print("2. å°å‡ºè¨“ç·´æ•¸æ“š (JSONL)")
    print("3. å°å‡ºè¨“ç·´æ•¸æ“š (JSON)")
    print("4. æŸ¥çœ‹è©³ç´°çµ±è¨ˆ")
    
    choice = input("\nè«‹é¸æ“‡ (1-4): ")
    
    if choice == "1":
        session_id = start_collection()
        print(f"âœ… å·²é–‹å§‹æ–°æœƒè©±: {session_id}")
        print("ç¾åœ¨å¯ä»¥é–‹å§‹æ”¶é›†å°è©±æ•¸æ“šäº†ï¼")
    
    elif choice == "2":
        file_path = export_training_data("jsonl")
        print(f"âœ… å·²å°å‡º JSONL è¨“ç·´æ•¸æ“š: {file_path}")
    
    elif choice == "3":
        file_path = export_training_data("json")
        print(f"âœ… å·²å°å‡º JSON è¨“ç·´æ•¸æ“š: {file_path}")
    
    elif choice == "4":
        print("\nè©³ç´°çµ±è¨ˆ:")
        print(json.dumps(stats, ensure_ascii=False, indent=2))