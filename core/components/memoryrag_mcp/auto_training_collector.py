#!/usr/bin/env python3
"""
è‡ªå‹•è¨“ç·´æ•¸æ“šæ”¶é›†å™¨
æ¯æ¬¡ Claude Code ä½¿ç”¨éƒ½è‡ªå‹•æ”¶é›†ä¸¦åŠ å…¥è¨“ç·´æ•¸æ“š
"""

import json
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AutoTrainingCollector:
    """è‡ªå‹•è¨“ç·´æ•¸æ“šæ”¶é›†å™¨"""
    
    def __init__(self):
        # ç²å–é …ç›®æ ¹ç›®éŒ„
        self.base_dir = Path(__file__).parent.parent.parent.parent
        self.data_dir = self.base_dir / "data/claude_conversations"
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # ä»Šæ—¥æ•¸æ“šæ–‡ä»¶
        today = datetime.now().strftime("%Y%m%d")
        self.daily_file = self.data_dir / f"training_data_{today}.jsonl"
        
        # æœƒè©±æ•¸æ“š
        self.current_session = {
            'session_id': f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            'start_time': datetime.now().isoformat(),
            'interactions': []
        }
        
    def collect_interaction(self, user_input: str, assistant_response: str, tools_used: List[str] = None, context: Dict = None):
        """æ”¶é›†ä¸€æ¬¡äº¤äº’æ•¸æ“š"""
        interaction = {
            'timestamp': datetime.now().isoformat(),
            'user_input': user_input[:1000],  # é™åˆ¶é•·åº¦
            'assistant_response': assistant_response[:2000],  # é™åˆ¶é•·åº¦
            'tools_used': tools_used or [],
            'context': context or {},
            'session_id': self.current_session['session_id']
        }
        
        # åˆ†æäº¤äº’é¡å‹
        interaction_type = self._classify_interaction(user_input, assistant_response, tools_used)
        interaction['interaction_type'] = interaction_type
        
        # æå–ä»»å‹™å’Œè§£æ±ºæ–¹æ¡ˆ
        task = self._extract_task(user_input)
        solution = self._extract_solution(assistant_response, tools_used)
        
        # ç”Ÿæˆè¨“ç·´æ¨£æœ¬
        training_sample = {
            'instruction': "åˆ†æä¸¦åŸ·è¡Œä»»å‹™",
            'input': task,
            'output': solution,
            'category': interaction_type,
            'tools_used': tools_used or [],
            'confidence': self._calculate_confidence(interaction),
            'source': 'claude_code_auto',
            'metadata': {
                'session_id': self.current_session['session_id'],
                'timestamp': interaction['timestamp'],
                'user_input_length': len(user_input),
                'response_length': len(assistant_response)
            }
        }
        
        # ä¿å­˜æ•¸æ“š
        self._save_training_sample(training_sample)
        self.current_session['interactions'].append(interaction)
        
        logger.info(f"âœ… æ”¶é›†è¨“ç·´æ•¸æ“š: {interaction_type} - {len(tools_used or [])} å€‹å·¥å…·")
        
        return training_sample
    
    def _classify_interaction(self, user_input: str, assistant_response: str, tools_used: List[str]) -> str:
        """åˆ†é¡äº¤äº’é¡å‹"""
        user_lower = user_input.lower()
        response_lower = assistant_response.lower()
        
        # å‹•ä½œé¡ï¼šä½¿ç”¨äº†å·¥å…·æˆ–åŸ·è¡Œäº†å‘½ä»¤
        if tools_used or any(keyword in response_lower for keyword in [
            'åŸ·è¡Œ', 'é‹è¡Œ', 'å‰µå»º', 'ä¿®æ”¹', 'åˆªé™¤', 'éƒ¨ç½²', 'å®‰è£', 'é…ç½®'
        ]):
            return 'action'
        
        # è§€å¯Ÿé¡ï¼šæª¢æŸ¥çµæœæˆ–ç‹€æ…‹
        if any(keyword in user_lower for keyword in [
            'æª¢æŸ¥', 'æŸ¥çœ‹', 'ç‹€æ…‹', 'çµæœ', 'æ˜¯å¦', 'æœ‰æ²’æœ‰'
        ]):
            return 'observation'
        
        # æ€è€ƒé¡ï¼šåˆ†ææˆ–è¦åŠƒ
        return 'thinking'
    
    def _extract_task(self, user_input: str) -> str:
        """æå–ä»»å‹™æè¿°"""
        # ç§»é™¤å¤šé¤˜çš„ç©ºç™½å’Œæ›è¡Œ
        task = " ".join(user_input.split())
        
        # å¦‚æœå¤ªé•·ï¼Œæˆªå–é—œéµéƒ¨åˆ†
        if len(task) > 200:
            # å°‹æ‰¾é—œéµå‹•è©
            key_verbs = ['å¯¦ç¾', 'å‰µå»º', 'ä¿®å¾©', 'å„ªåŒ–', 'éƒ¨ç½²', 'åˆ†æ', 'æª¢æŸ¥', 'ä¿®æ”¹']
            for verb in key_verbs:
                if verb in task:
                    # å¾å‹•è©é–‹å§‹æˆªå–
                    verb_pos = task.find(verb)
                    task = task[max(0, verb_pos-20):verb_pos+180]
                    break
            else:
                task = task[:200]
        
        return task
    
    def _extract_solution(self, assistant_response: str, tools_used: List[str]) -> str:
        """æå–è§£æ±ºæ–¹æ¡ˆ"""
        solution_parts = []
        
        # æ·»åŠ å·¥å…·ä½¿ç”¨ä¿¡æ¯
        if tools_used:
            solution_parts.append(f"ä½¿ç”¨å·¥å…·: {', '.join(tools_used)}")
        
        # æå–é—œéµåŸ·è¡Œæ­¥é©Ÿ
        response_lines = assistant_response.split('\n')
        key_lines = []
        
        for line in response_lines:
            line = line.strip()
            if not line:
                continue
                
            # ä¿ç•™é‡è¦çš„è¡Œ
            if any(keyword in line for keyword in [
                'åŸ·è¡Œ', 'å‰µå»º', 'ä¿®æ”¹', 'æª¢æŸ¥', 'éƒ¨ç½²', 'é…ç½®', 'å®‰è£',
                '```', 'bash', 'python', 'npm', 'git'
            ]):
                key_lines.append(line)
            
            # é™åˆ¶é•·åº¦
            if len('\n'.join(key_lines)) > 500:
                break
        
        if key_lines:
            solution_parts.extend(key_lines[:5])  # æœ€å¤š5è¡Œ
        else:
            # å¦‚æœæ²’æœ‰æ‰¾åˆ°é—œéµè¡Œï¼Œå–å‰é¢éƒ¨åˆ†
            solution_parts.append(assistant_response[:300])
        
        return '\n'.join(solution_parts)
    
    def _calculate_confidence(self, interaction: Dict) -> float:
        """è¨ˆç®—ç½®ä¿¡åº¦"""
        confidence = 0.5  # åŸºç¤ç½®ä¿¡åº¦
        
        # åŸºæ–¼å·¥å…·ä½¿ç”¨
        tools_count = len(interaction.get('tools_used', []))
        if tools_count > 0:
            confidence += min(tools_count * 0.1, 0.3)
        
        # åŸºæ–¼éŸ¿æ‡‰é•·åº¦
        response_length = len(interaction.get('assistant_response', ''))
        if response_length > 200:
            confidence += 0.1
        if response_length > 500:
            confidence += 0.1
        
        # åŸºæ–¼ç”¨æˆ¶è¼¸å…¥æ¸…æ™°åº¦
        user_input = interaction.get('user_input', '')
        if len(user_input) > 50:
            confidence += 0.1
        
        return min(confidence, 1.0)
    
    def _save_training_sample(self, sample: Dict):
        """ä¿å­˜è¨“ç·´æ¨£æœ¬"""
        try:
            with open(self.daily_file, 'a', encoding='utf-8') as f:
                f.write(json.dumps(sample, ensure_ascii=False) + '\n')
        except Exception as e:
            logger.error(f"ä¿å­˜è¨“ç·´æ¨£æœ¬å¤±æ•—: {e}")
    
    def get_session_summary(self) -> Dict:
        """ç²å–æœƒè©±æ‘˜è¦"""
        interactions = self.current_session['interactions']
        
        if not interactions:
            return {'message': 'ç•¶å‰æœƒè©±æš«ç„¡äº¤äº’æ•¸æ“š'}
        
        # çµ±è¨ˆä¿¡æ¯
        total_interactions = len(interactions)
        tools_used = set()
        interaction_types = {}
        
        for interaction in interactions:
            # çµ±è¨ˆå·¥å…·ä½¿ç”¨
            tools_used.update(interaction.get('tools_used', []))
            
            # çµ±è¨ˆäº¤äº’é¡å‹
            itype = interaction.get('interaction_type', 'unknown')
            interaction_types[itype] = interaction_types.get(itype, 0) + 1
        
        summary = {
            'session_id': self.current_session['session_id'],
            'start_time': self.current_session['start_time'],
            'total_interactions': total_interactions,
            'tools_used': list(tools_used),
            'interaction_types': interaction_types,
            'data_file': str(self.daily_file),
            'estimated_training_samples': total_interactions
        }
        
        return summary
    
    def end_session(self):
        """çµæŸç•¶å‰æœƒè©±"""
        if self.current_session:
            self.current_session['end_time'] = datetime.now().isoformat()
            
            # ä¿å­˜æœƒè©±æ‘˜è¦
            summary_file = self.data_dir / f"session_summary_{self.current_session['session_id']}.json"
            try:
                with open(summary_file, 'w', encoding='utf-8') as f:
                    json.dump(self.current_session, f, ensure_ascii=False, indent=2)
                logger.info(f"æœƒè©±æ‘˜è¦å·²ä¿å­˜: {summary_file}")
            except Exception as e:
                logger.error(f"ä¿å­˜æœƒè©±æ‘˜è¦å¤±æ•—: {e}")

# å…¨å±€æ”¶é›†å™¨å¯¦ä¾‹
_global_collector = None

def get_collector():
    """ç²å–å…¨å±€æ”¶é›†å™¨å¯¦ä¾‹"""
    global _global_collector
    if _global_collector is None:
        _global_collector = AutoTrainingCollector()
    return _global_collector

def collect_claude_interaction(user_input: str, assistant_response: str, tools_used: List[str] = None, context: Dict = None):
    """ä¾¿æ·å‡½æ•¸ï¼šæ”¶é›† Claude äº¤äº’æ•¸æ“š"""
    collector = get_collector()
    return collector.collect_interaction(user_input, assistant_response, tools_used, context)

def get_current_session_summary():
    """ä¾¿æ·å‡½æ•¸ï¼šç²å–ç•¶å‰æœƒè©±æ‘˜è¦"""
    collector = get_collector()
    return collector.get_session_summary()

# åœ¨æ¨¡å¡Šå°å…¥æ™‚è‡ªå‹•å•Ÿå‹•æ”¶é›†å™¨ï¼ˆå¦‚æœåœ¨ Claude Code ç’°å¢ƒä¸­ï¼‰
if __name__ != "__main__":
    try:
        # æª¢æŸ¥æ˜¯å¦åœ¨ Claude Code ç’°å¢ƒä¸­
        if os.environ.get('CLAUDE_CODE_SESSION') or 'claude' in sys.executable.lower():
            logger.info("ğŸ¤– è‡ªå‹•è¨“ç·´æ•¸æ“šæ”¶é›†å™¨å·²å•Ÿå‹•")
            get_collector()
    except Exception as e:
        logger.warning(f"è‡ªå‹•å•Ÿå‹•æ”¶é›†å™¨å¤±æ•—: {e}")

if __name__ == "__main__":
    # æ¸¬è©¦æ”¶é›†å™¨
    collector = AutoTrainingCollector()
    
    # æ¨¡æ“¬ä¸€äº›äº¤äº’
    collector.collect_interaction(
        user_input="å¹«æˆ‘å‰µå»ºä¸€å€‹Pythonè…³æœ¬ä¾†è™•ç†JSONæ•¸æ“š",
        assistant_response="æˆ‘å°‡å‰µå»ºä¸€å€‹Pythonè…³æœ¬ä¾†è™•ç†JSONæ•¸æ“šã€‚\n\n```python\nimport json\ndef process_json(file_path):\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n    return data\n```",
        tools_used=["Write", "Edit"],
        context={"task_type": "development"}
    )
    
    # é¡¯ç¤ºæ‘˜è¦
    summary = collector.get_session_summary()
    print(f"\næœƒè©±æ‘˜è¦:")
    print(json.dumps(summary, ensure_ascii=False, indent=2))