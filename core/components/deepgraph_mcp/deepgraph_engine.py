#!/usr/bin/env python3
"""
DeepGraph MCP - æ·±åº¦åœ–å½¢åˆ†ææ¡†æ¶
é›†æˆåˆ°PowerAutomation v4.6.2çš„æ ¸å¿ƒåœ–åˆ†æå¼•æ“
"""

import asyncio
import logging
import json
import networkx as nx
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
import ast
import os
from pathlib import Path

logger = logging.getLogger(__name__)

class GraphType(Enum):
    """åœ–é¡å‹æšèˆ‰"""
    CODE_DEPENDENCY = "code_dependency"
    WORKFLOW = "workflow"
    UI_COMPONENT = "ui_component"
    TEST_DEPENDENCY = "test_dependency"
    DATA_FLOW = "data_flow"
    EXECUTION_PATH = "execution_path"

class NodeType(Enum):
    """ç¯€é»é¡å‹æšèˆ‰"""
    FUNCTION = "function"
    CLASS = "class"
    MODULE = "module"
    COMPONENT = "component"
    WORKFLOW_STEP = "workflow_step"
    TEST_CASE = "test_case"
    UI_ELEMENT = "ui_element"

@dataclass
class GraphNode:
    """åœ–ç¯€é»æ•¸æ“šçµæ§‹"""
    id: str
    type: NodeType
    name: str
    properties: Dict[str, Any]
    metadata: Dict[str, Any]
    coordinates: Optional[Tuple[float, float]] = None

@dataclass
class GraphEdge:
    """åœ–é‚Šæ•¸æ“šçµæ§‹"""
    source: str
    target: str
    relationship: str
    weight: float = 1.0
    properties: Dict[str, Any] = None

@dataclass
class GraphAnalysisResult:
    """åœ–åˆ†æçµæœ"""
    graph_id: str
    graph_type: GraphType
    nodes_count: int
    edges_count: int
    metrics: Dict[str, float]
    insights: List[str]
    recommendations: List[str]
    optimization_opportunities: List[Dict[str, Any]]

class DeepGraphEngine:
    """æ·±åº¦åœ–åˆ†æå¼•æ“"""
    
    def __init__(self):
        self.graphs: Dict[str, nx.DiGraph] = {}
        self.analysis_cache: Dict[str, GraphAnalysisResult] = {}
        self.node_embeddings: Dict[str, np.ndarray] = {}
        
    async def create_graph(self, graph_id: str, graph_type: GraphType) -> nx.DiGraph:
        """å‰µå»ºæ–°åœ–"""
        graph = nx.DiGraph()
        graph.graph['type'] = graph_type
        graph.graph['created_at'] = asyncio.get_event_loop().time()
        self.graphs[graph_id] = graph
        
        logger.info(f"å‰µå»ºåœ–: {graph_id}, é¡å‹: {graph_type.value}")
        return graph
    
    async def add_node(self, graph_id: str, node: GraphNode) -> None:
        """æ·»åŠ ç¯€é»åˆ°åœ–"""
        if graph_id not in self.graphs:
            raise ValueError(f"åœ– {graph_id} ä¸å­˜åœ¨")
        
        graph = self.graphs[graph_id]
        graph.add_node(
            node.id,
            type=node.type.value,
            name=node.name,
            properties=node.properties,
            metadata=node.metadata,
            coordinates=node.coordinates
        )
        
        # ç”Ÿæˆç¯€é»åµŒå…¥
        embedding = await self._generate_node_embedding(node)
        self.node_embeddings[f"{graph_id}:{node.id}"] = embedding
    
    async def add_edge(self, graph_id: str, edge: GraphEdge) -> None:
        """æ·»åŠ é‚Šåˆ°åœ–"""
        if graph_id not in self.graphs:
            raise ValueError(f"åœ– {graph_id} ä¸å­˜åœ¨")
        
        graph = self.graphs[graph_id]
        graph.add_edge(
            edge.source,
            edge.target,
            relationship=edge.relationship,
            weight=edge.weight,
            properties=edge.properties or {}
        )
    
    async def analyze_graph(self, graph_id: str) -> GraphAnalysisResult:
        """æ·±åº¦åˆ†æåœ–çµæ§‹"""
        if graph_id not in self.graphs:
            raise ValueError(f"åœ– {graph_id} ä¸å­˜åœ¨")
        
        graph = self.graphs[graph_id]
        graph_type = GraphType(graph.graph['type'])
        
        # åŸºç¤åº¦é‡
        metrics = await self._calculate_graph_metrics(graph)
        
        # æ·±åº¦åˆ†æ
        insights = await self._generate_insights(graph, metrics)
        
        # å„ªåŒ–å»ºè­°
        recommendations = await self._generate_recommendations(graph, metrics)
        
        # å„ªåŒ–æ©Ÿæœƒ
        optimization_opportunities = await self._find_optimization_opportunities(graph)
        
        result = GraphAnalysisResult(
            graph_id=graph_id,
            graph_type=graph_type,
            nodes_count=graph.number_of_nodes(),
            edges_count=graph.number_of_edges(),
            metrics=metrics,
            insights=insights,
            recommendations=recommendations,
            optimization_opportunities=optimization_opportunities
        )
        
        self.analysis_cache[graph_id] = result
        return result
    
    async def _calculate_graph_metrics(self, graph: nx.DiGraph) -> Dict[str, float]:
        """è¨ˆç®—åœ–åº¦é‡æŒ‡æ¨™"""
        metrics = {}
        
        try:
            # åŸºç¤åº¦é‡
            metrics['density'] = nx.density(graph)
            metrics['average_clustering'] = nx.average_clustering(graph.to_undirected())
            
            # ä¸­å¿ƒæ€§åº¦é‡
            betweenness = nx.betweenness_centrality(graph)
            closeness = nx.closeness_centrality(graph)
            pagerank = nx.pagerank(graph)
            
            metrics['max_betweenness'] = max(betweenness.values()) if betweenness else 0
            metrics['avg_betweenness'] = np.mean(list(betweenness.values())) if betweenness else 0
            metrics['max_closeness'] = max(closeness.values()) if closeness else 0
            metrics['avg_closeness'] = np.mean(list(closeness.values())) if closeness else 0
            metrics['max_pagerank'] = max(pagerank.values()) if pagerank else 0
            
            # é€£é€šæ€§åº¦é‡
            if graph.number_of_nodes() > 0:
                metrics['is_connected'] = float(nx.is_weakly_connected(graph))
                components = list(nx.weakly_connected_components(graph))
                metrics['connected_components'] = len(components)
                metrics['largest_component_size'] = len(max(components, key=len)) if components else 0
            
            # è·¯å¾‘åº¦é‡
            if nx.is_weakly_connected(graph):
                try:
                    metrics['average_shortest_path'] = nx.average_shortest_path_length(graph.to_undirected())
                    metrics['diameter'] = nx.diameter(graph.to_undirected())
                except:
                    metrics['average_shortest_path'] = 0
                    metrics['diameter'] = 0
            
            # åº¦åˆ†ä½ˆ
            degrees = [d for n, d in graph.degree()]
            if degrees:
                metrics['max_degree'] = max(degrees)
                metrics['avg_degree'] = np.mean(degrees)
                metrics['degree_variance'] = np.var(degrees)
            
        except Exception as e:
            logger.warning(f"è¨ˆç®—åœ–åº¦é‡æ™‚å‡ºéŒ¯: {e}")
            
        return metrics
    
    async def _generate_insights(self, graph: nx.DiGraph, metrics: Dict[str, float]) -> List[str]:
        """ç”Ÿæˆåœ–æ´å¯Ÿ"""
        insights = []
        
        # è¤‡é›œåº¦åˆ†æ
        if metrics.get('density', 0) > 0.3:
            insights.append("åœ–çµæ§‹å¯†åº¦è¼ƒé«˜ï¼Œå­˜åœ¨è¼ƒå¤šäº¤äº’é—œä¿‚ï¼Œå¯èƒ½éœ€è¦æ¨¡å¡ŠåŒ–é‡æ§‹")
        
        # ä¸­å¿ƒç¯€é»åˆ†æ
        if metrics.get('max_betweenness', 0) > 0.5:
            insights.append("å­˜åœ¨é—œéµä¸­å¿ƒç¯€é»ï¼Œé€™äº›ç¯€é»æ•…éšœæœƒåš´é‡å½±éŸ¿æ•´é«”åŠŸèƒ½")
        
        # é€£é€šæ€§åˆ†æ
        if metrics.get('connected_components', 0) > 1:
            insights.append(f"åœ–åŒ…å« {int(metrics['connected_components'])} å€‹ç¨ç«‹çµ„ä»¶ï¼Œå¯èƒ½å­˜åœ¨å­¤ç«‹æ¨¡å¡Š")
        
        # åº¦ä¸­å¿ƒæ€§åˆ†æ
        if metrics.get('degree_variance', 0) > metrics.get('avg_degree', 0) * 2:
            insights.append("ç¯€é»åº¦åˆ†ä½ˆä¸å‡ï¼Œå­˜åœ¨æ˜é¡¯çš„æ ¸å¿ƒç¯€é»å’Œé‚Šç·£ç¯€é»")
        
        return insights
    
    async def _generate_recommendations(self, graph: nx.DiGraph, metrics: Dict[str, float]) -> List[str]:
        """ç”Ÿæˆå„ªåŒ–å»ºè­°"""
        recommendations = []
        
        # é‡æ§‹å»ºè­°
        if metrics.get('density', 0) > 0.4:
            recommendations.append("å»ºè­°é€²è¡Œæ¨¡å¡ŠåŒ–é‡æ§‹ï¼Œæ¸›å°‘æ¨¡å¡Šé–“è€¦åˆ")
        
        # æ€§èƒ½å„ªåŒ–å»ºè­°
        if metrics.get('max_degree', 0) > 20:
            recommendations.append("å»ºè­°å°é«˜åº¦ç¯€é»é€²è¡Œè² è¼‰åˆ†æ•£ï¼Œé¿å…å–®é»ç“¶é ¸")
        
        # æ¸¬è©¦å»ºè­°
        betweenness = nx.betweenness_centrality(graph)
        critical_nodes = [node for node, centrality in betweenness.items() if centrality > 0.3]
        if critical_nodes:
            recommendations.append(f"å»ºè­°åŠ å¼·å°é—œéµç¯€é» {critical_nodes[:3]} çš„æ¸¬è©¦è¦†è“‹")
        
        # æ¶æ§‹å»ºè­°
        if metrics.get('connected_components', 0) > 5:
            recommendations.append("å»ºè­°æª¢æŸ¥æ¨¡å¡Šé–“çš„ä¾è³´é—œä¿‚ï¼Œå¯èƒ½å­˜åœ¨éåº¦åˆ†æ•£çš„å•é¡Œ")
        
        return recommendations
    
    async def _find_optimization_opportunities(self, graph: nx.DiGraph) -> List[Dict[str, Any]]:
        """ç™¼ç¾å„ªåŒ–æ©Ÿæœƒ"""
        opportunities = []
        
        # æ‰¾å‡ºå¯ä»¥åˆä½µçš„ç¯€é»
        nodes_to_merge = await self._find_mergeable_nodes(graph)
        if nodes_to_merge:
            opportunities.append({
                "type": "merge_nodes",
                "description": "ç™¼ç¾å¯ä»¥åˆä½µçš„ç›¸ä¼¼ç¯€é»",
                "nodes": nodes_to_merge,
                "impact": "æ¸›å°‘è¤‡é›œåº¦ï¼Œæé«˜ç¶­è­·æ€§"
            })
        
        # æ‰¾å‡ºå¯ä»¥åˆ†è§£çš„å¤§ç¯€é»
        large_nodes = await self._find_oversized_nodes(graph)
        if large_nodes:
            opportunities.append({
                "type": "decompose_nodes",
                "description": "ç™¼ç¾éœ€è¦åˆ†è§£çš„å¤§å‹ç¯€é»",
                "nodes": large_nodes,
                "impact": "æé«˜æ¨¡å¡Šæ€§ï¼Œé™ä½è€¦åˆ"
            })
        
        # æ‰¾å‡ºç¼ºå¤±çš„é€£æ¥
        missing_connections = await self._find_missing_connections(graph)
        if missing_connections:
            opportunities.append({
                "type": "add_connections",
                "description": "ç™¼ç¾å¯èƒ½ç¼ºå¤±çš„é‚è¼¯é€£æ¥",
                "connections": missing_connections,
                "impact": "å®Œå–„ä¾è³´é—œä¿‚ï¼Œæé«˜ç³»çµ±å®Œæ•´æ€§"
            })
        
        return opportunities
    
    async def _find_mergeable_nodes(self, graph: nx.DiGraph) -> List[List[str]]:
        """æ‰¾å‡ºå¯ä»¥åˆä½µçš„ç¯€é»"""
        # åŸºæ–¼çµæ§‹ç›¸ä¼¼æ€§æ‰¾å‡ºå¯åˆä½µç¯€é»
        similar_groups = []
        nodes = list(graph.nodes())
        
        for i, node1 in enumerate(nodes):
            for node2 in nodes[i+1:]:
                similarity = await self._calculate_node_similarity(graph, node1, node2)
                if similarity > 0.8:  # é«˜ç›¸ä¼¼åº¦é–¾å€¼
                    # æª¢æŸ¥æ˜¯å¦å·²åœ¨æŸå€‹çµ„ä¸­
                    added = False
                    for group in similar_groups:
                        if node1 in group or node2 in group:
                            if node1 not in group:
                                group.append(node1)
                            if node2 not in group:
                                group.append(node2)
                            added = True
                            break
                    
                    if not added:
                        similar_groups.append([node1, node2])
        
        return [group for group in similar_groups if len(group) > 1]
    
    async def _find_oversized_nodes(self, graph: nx.DiGraph) -> List[str]:
        """æ‰¾å‡ºéå¤§çš„ç¯€é»"""
        large_nodes = []
        
        for node in graph.nodes():
            degree = graph.degree(node)
            properties = graph.nodes[node].get('properties', {})
            
            # åŸºæ–¼åº¦æ•¸å’Œå±¬æ€§åˆ¤æ–·ç¯€é»å¤§å°
            if degree > 15:  # é€£æ¥éå¤š
                large_nodes.append(node)
            elif properties.get('complexity', 0) > 10:  # è¤‡é›œåº¦éé«˜
                large_nodes.append(node)
        
        return large_nodes
    
    async def _find_missing_connections(self, graph: nx.DiGraph) -> List[Tuple[str, str]]:
        """æ‰¾å‡ºå¯èƒ½ç¼ºå¤±çš„é€£æ¥"""
        missing = []
        
        # åŸºæ–¼å‚³éæ€§ç™¼ç¾ç¼ºå¤±é€£æ¥
        for node1 in graph.nodes():
            for node2 in graph.nodes():
                if node1 != node2 and not graph.has_edge(node1, node2):
                    # æª¢æŸ¥æ˜¯å¦å­˜åœ¨é–“æ¥è·¯å¾‘
                    try:
                        path = nx.shortest_path(graph, node1, node2)
                        if len(path) == 3:  # å­˜åœ¨ä¸­é–“ç¯€é»çš„çŸ­è·¯å¾‘
                            missing.append((node1, node2))
                    except nx.NetworkXNoPath:
                        continue
        
        return missing[:10]  # é™åˆ¶è¿”å›æ•¸é‡
    
    async def _calculate_node_similarity(self, graph: nx.DiGraph, node1: str, node2: str) -> float:
        """è¨ˆç®—ç¯€é»ç›¸ä¼¼åº¦"""
        # åŸºæ–¼é„°å±…ç¯€é»ç›¸ä¼¼åº¦
        neighbors1 = set(graph.neighbors(node1))
        neighbors2 = set(graph.neighbors(node2))
        
        if not neighbors1 and not neighbors2:
            return 0.0
        
        intersection = neighbors1.intersection(neighbors2)
        union = neighbors1.union(neighbors2)
        
        jaccard_similarity = len(intersection) / len(union) if union else 0
        
        # åŸºæ–¼ç¯€é»å±¬æ€§ç›¸ä¼¼åº¦
        props1 = graph.nodes[node1].get('properties', {})
        props2 = graph.nodes[node2].get('properties', {})
        
        attr_similarity = 0.0
        if props1.get('type') == props2.get('type'):
            attr_similarity += 0.3
        
        return (jaccard_similarity * 0.7 + attr_similarity * 0.3)
    
    async def _generate_node_embedding(self, node: GraphNode) -> np.ndarray:
        """ç”Ÿæˆç¯€é»åµŒå…¥å‘é‡"""
        # ç°¡åŒ–çš„ç¯€é»åµŒå…¥ç”Ÿæˆ
        embedding_dim = 64
        
        # åŸºæ–¼ç¯€é»é¡å‹å’Œå±¬æ€§ç”ŸæˆåµŒå…¥
        type_vector = np.random.normal(0, 1, embedding_dim // 2)
        prop_vector = np.random.normal(0, 1, embedding_dim // 2)
        
        # æ ¹æ“šç¯€é»é¡å‹èª¿æ•´å‘é‡
        type_multiplier = {
            NodeType.FUNCTION: 1.0,
            NodeType.CLASS: 1.2,
            NodeType.MODULE: 1.5,
            NodeType.COMPONENT: 1.1,
            NodeType.WORKFLOW_STEP: 0.9,
            NodeType.TEST_CASE: 0.8,
            NodeType.UI_ELEMENT: 1.3
        }.get(node.type, 1.0)
        
        type_vector *= type_multiplier
        
        embedding = np.concatenate([type_vector, prop_vector])
        return embedding / np.linalg.norm(embedding)  # æ­£è¦åŒ–

class CodeGraphBuilder:
    """ä»£ç¢¼åœ–æ§‹å»ºå™¨"""
    
    def __init__(self, deep_graph_engine: DeepGraphEngine):
        self.engine = deep_graph_engine
    
    async def build_from_directory(self, directory_path: str, graph_id: str) -> GraphAnalysisResult:
        """å¾ç›®éŒ„æ§‹å»ºä»£ç¢¼ä¾è³´åœ–"""
        print(f"ğŸ” é–‹å§‹åˆ†æä»£ç¢¼ç›®éŒ„: {directory_path}")
        
        # å‰µå»ºåœ–
        await self.engine.create_graph(graph_id, GraphType.CODE_DEPENDENCY)
        
        # åˆ†æPythonæ–‡ä»¶
        python_files = list(Path(directory_path).rglob("*.py"))
        print(f"ğŸ“ ç™¼ç¾ {len(python_files)} å€‹Pythonæ–‡ä»¶")
        
        # æ§‹å»ºç¯€é»
        for file_path in python_files:
            await self._analyze_python_file(graph_id, file_path)
        
        # æ§‹å»ºä¾è³´é‚Š
        await self._build_dependencies(graph_id, python_files)
        
        # åˆ†æåœ–
        result = await self.engine.analyze_graph(graph_id)
        print(f"âœ… ä»£ç¢¼åœ–åˆ†æå®Œæˆ: {result.nodes_count} ç¯€é», {result.edges_count} é‚Š")
        
        return result
    
    async def _analyze_python_file(self, graph_id: str, file_path: Path) -> None:
        """åˆ†æPythonæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            tree = ast.parse(content)
            
            # åˆ†ææ¨¡å¡Š
            module_node = GraphNode(
                id=str(file_path),
                type=NodeType.MODULE,
                name=file_path.name,
                properties={
                    'path': str(file_path),
                    'lines': len(content.split('\n')),
                    'size': len(content)
                },
                metadata={'file_type': 'python'}
            )
            await self.engine.add_node(graph_id, module_node)
            
            # åˆ†æé¡å’Œå‡½æ•¸
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    func_node = GraphNode(
                        id=f"{file_path}:{node.name}",
                        type=NodeType.FUNCTION,
                        name=node.name,
                        properties={
                            'lineno': node.lineno,
                            'args_count': len(node.args.args),
                            'is_async': isinstance(node, ast.AsyncFunctionDef)
                        },
                        metadata={'parent_module': str(file_path)}
                    )
                    await self.engine.add_node(graph_id, func_node)
                    
                    # æ·»åŠ æ¨¡å¡Šåˆ°å‡½æ•¸çš„é‚Š
                    edge = GraphEdge(
                        source=str(file_path),
                        target=f"{file_path}:{node.name}",
                        relationship="contains"
                    )
                    await self.engine.add_edge(graph_id, edge)
                
                elif isinstance(node, ast.ClassDef):
                    class_node = GraphNode(
                        id=f"{file_path}:{node.name}",
                        type=NodeType.CLASS,
                        name=node.name,
                        properties={
                            'lineno': node.lineno,
                            'methods_count': len([n for n in node.body if isinstance(n, ast.FunctionDef)])
                        },
                        metadata={'parent_module': str(file_path)}
                    )
                    await self.engine.add_node(graph_id, class_node)
                    
                    # æ·»åŠ æ¨¡å¡Šåˆ°é¡çš„é‚Š
                    edge = GraphEdge(
                        source=str(file_path),
                        target=f"{file_path}:{node.name}",
                        relationship="contains"
                    )
                    await self.engine.add_edge(graph_id, edge)
        
        except Exception as e:
            logger.warning(f"åˆ†ææ–‡ä»¶ {file_path} æ™‚å‡ºéŒ¯: {e}")
    
    async def _build_dependencies(self, graph_id: str, python_files: List[Path]) -> None:
        """æ§‹å»ºä¾è³´é—œä¿‚"""
        for file_path in python_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                tree = ast.parse(content)
                
                # åˆ†æimportèªå¥
                for node in ast.walk(tree):
                    if isinstance(node, ast.Import):
                        for alias in node.names:
                            await self._add_import_edge(graph_id, str(file_path), alias.name)
                    elif isinstance(node, ast.ImportFrom):
                        if node.module:
                            await self._add_import_edge(graph_id, str(file_path), node.module)
            
            except Exception as e:
                logger.warning(f"åˆ†æä¾è³´ {file_path} æ™‚å‡ºéŒ¯: {e}")
    
    async def _add_import_edge(self, graph_id: str, source_file: str, imported_module: str) -> None:
        """æ·»åŠ importä¾è³´é‚Š"""
        # ç°¡åŒ–çš„ä¾è³´é‚Šæ·»åŠ é‚è¼¯
        if imported_module.startswith('.'):  # ç›¸å°å°å…¥
            return
        
        # æª¢æŸ¥æ˜¯å¦æ˜¯é …ç›®å…§æ¨¡å¡Š
        graph = self.engine.graphs[graph_id]
        for node_id in graph.nodes():
            if imported_module in node_id:
                edge = GraphEdge(
                    source=source_file,
                    target=node_id,
                    relationship="imports"
                )
                await self.engine.add_edge(graph_id, edge)
                break

class WorkflowGraphBuilder:
    """å·¥ä½œæµåœ–æ§‹å»ºå™¨"""
    
    def __init__(self, deep_graph_engine: DeepGraphEngine):
        self.engine = deep_graph_engine
    
    async def build_codeflow_graph(self, graph_id: str, workflow_config: Dict[str, Any]) -> GraphAnalysisResult:
        """æ§‹å»ºCodeFlowå·¥ä½œæµåœ–"""
        print("ğŸ”„ é–‹å§‹æ§‹å»ºCodeFlowå·¥ä½œæµåœ–")
        
        # å‰µå»ºåœ–
        await self.engine.create_graph(graph_id, GraphType.WORKFLOW)
        
        # æ·»åŠ å…­å¤§å·¥ä½œæµç¯€é»
        workflows = [
            "Code Generation",
            "UI Design", 
            "API Development",
            "Database Design",
            "Testing Automation",
            "Deployment Pipeline"
        ]
        
        for i, workflow in enumerate(workflows):
            node = GraphNode(
                id=f"workflow_{i}",
                type=NodeType.WORKFLOW_STEP,
                name=workflow,
                properties={
                    "workflow_type": workflow.lower().replace(" ", "_"),
                    "stage_count": 7,  # ä¼æ¥­ç‰ˆ7éšæ®µ
                    "mcp_components": await self._get_workflow_mcps(workflow)
                },
                metadata={"index": i}
            )
            await self.engine.add_node(graph_id, node)
        
        # æ·»åŠ MCPçµ„ä»¶ç¯€é»
        mcp_components = [
            "MermaidFlow MCP",
            "ag-ui MCP", 
            "stagewise MCP",
            "test MCP",
            "SmartUI MCP",
            "DeepGraph MCP"  # æ–°å¢
        ]
        
        for mcp in mcp_components:
            node = GraphNode(
                id=f"mcp_{mcp.lower().replace(' ', '_')}",
                type=NodeType.COMPONENT,
                name=mcp,
                properties={
                    "component_type": "mcp",
                    "capabilities": await self._get_mcp_capabilities(mcp)
                },
                metadata={"category": "mcp"}
            )
            await self.engine.add_node(graph_id, node)
        
        # æ§‹å»ºé€£æ¥é—œä¿‚
        await self._build_workflow_connections(graph_id)
        
        # åˆ†æåœ–
        result = await self.engine.analyze_graph(graph_id)
        print(f"âœ… å·¥ä½œæµåœ–æ§‹å»ºå®Œæˆ: {result.nodes_count} ç¯€é», {result.edges_count} é‚Š")
        
        return result
    
    async def _get_workflow_mcps(self, workflow: str) -> List[str]:
        """ç²å–å·¥ä½œæµç›¸é—œçš„MCPçµ„ä»¶"""
        mapping = {
            "Code Generation": ["MermaidFlow MCP", "DeepGraph MCP"],
            "UI Design": ["ag-ui MCP", "SmartUI MCP", "DeepGraph MCP"],
            "API Development": ["stagewise MCP", "test MCP", "DeepGraph MCP"],
            "Database Design": ["MermaidFlow MCP", "DeepGraph MCP"],
            "Testing Automation": ["test MCP", "stagewise MCP", "DeepGraph MCP"],
            "Deployment Pipeline": ["DeepGraph MCP"]
        }
        return mapping.get(workflow, ["DeepGraph MCP"])
    
    async def _get_mcp_capabilities(self, mcp: str) -> List[str]:
        """ç²å–MCPçµ„ä»¶èƒ½åŠ›"""
        capabilities = {
            "MermaidFlow MCP": ["æµç¨‹è¨­è¨ˆ", "æ¥­å‹™å»ºæ¨¡", "å¯è¦–åŒ–"],
            "ag-ui MCP": ["UIçµ„ä»¶ç”Ÿæˆ", "æ‹–æ‹½è¨­è¨ˆ", "éŸ¿æ‡‰å¼ä½ˆå±€"],
            "stagewise MCP": ["æ“ä½œéŒ„è£½", "å›æ”¾æ¸¬è©¦", "éšæ®µç®¡ç†"],
            "test MCP": ["æ¸¬è©¦ç®¡ç†", "è‡ªå‹•åŒ–åŸ·è¡Œ", "å ±å‘Šç”Ÿæˆ"],
            "SmartUI MCP": ["AI UIç”Ÿæˆ", "æ™ºèƒ½å„ªåŒ–", "ç„¡éšœç¤™å¢å¼·"],
            "DeepGraph MCP": ["åœ–åˆ†æ", "ä¾è³´æ´å¯Ÿ", "å„ªåŒ–å»ºè­°"]
        }
        return capabilities.get(mcp, [])
    
    async def _build_workflow_connections(self, graph_id: str) -> None:
        """æ§‹å»ºå·¥ä½œæµé€£æ¥"""
        # å·¥ä½œæµä¹‹é–“çš„ä¾è³´é—œä¿‚
        workflow_deps = [
            ("workflow_0", "workflow_1", "feeds_into"),  # Code Gen -> UI Design
            ("workflow_1", "workflow_2", "feeds_into"),  # UI Design -> API Dev
            ("workflow_2", "workflow_3", "feeds_into"),  # API Dev -> DB Design
            ("workflow_0", "workflow_4", "tested_by"),   # Code Gen -> Testing
            ("workflow_1", "workflow_4", "tested_by"),   # UI Design -> Testing
            ("workflow_4", "workflow_5", "feeds_into"),  # Testing -> Deployment
        ]
        
        for source, target, relationship in workflow_deps:
            edge = GraphEdge(source=source, target=target, relationship=relationship)
            await self.engine.add_edge(graph_id, edge)
        
        # MCPèˆ‡å·¥ä½œæµçš„é€£æ¥
        mcp_workflow_connections = [
            ("mcp_mermaidflow_mcp", "workflow_0", "supports"),
            ("mcp_ag-ui_mcp", "workflow_1", "supports"),
            ("mcp_smartui_mcp", "workflow_1", "supports"),
            ("mcp_stagewise_mcp", "workflow_2", "supports"),
            ("mcp_test_mcp", "workflow_4", "supports"),
            ("mcp_deepgraph_mcp", "workflow_0", "supports"),
            ("mcp_deepgraph_mcp", "workflow_1", "supports"),
            ("mcp_deepgraph_mcp", "workflow_2", "supports"),
            ("mcp_deepgraph_mcp", "workflow_4", "supports"),
        ]
        
        for source, target, relationship in mcp_workflow_connections:
            edge = GraphEdge(source=source, target=target, relationship=relationship)
            await self.engine.add_edge(graph_id, edge)

# å°å‡ºä¸»é¡
__all__ = [
    'DeepGraphEngine',
    'CodeGraphBuilder', 
    'WorkflowGraphBuilder',
    'GraphNode',
    'GraphEdge',
    'GraphAnalysisResult',
    'GraphType',
    'NodeType'
]

if __name__ == "__main__":
    async def demo():
        """æ¼”ç¤ºDeepGraph MCP"""
        print("ğŸš€ DeepGraph MCP æ¼”ç¤ºé–‹å§‹")
        
        # åˆå§‹åŒ–å¼•æ“
        engine = DeepGraphEngine()
        code_builder = CodeGraphBuilder(engine)
        workflow_builder = WorkflowGraphBuilder(engine)
        
        # æ§‹å»ºä»£ç¢¼åœ–
        current_dir = os.path.dirname(os.path.abspath(__file__))
        code_result = await code_builder.build_from_directory(current_dir, "code_graph")
        
        print(f"\nğŸ“Š ä»£ç¢¼åœ–åˆ†æçµæœ:")
        print(f"ç¯€é»æ•¸: {code_result.nodes_count}")
        print(f"é‚Šæ•¸: {code_result.edges_count}")
        print(f"æ´å¯Ÿ: {code_result.insights}")
        print(f"å»ºè­°: {code_result.recommendations}")
        
        # æ§‹å»ºå·¥ä½œæµåœ–
        workflow_result = await workflow_builder.build_codeflow_graph("workflow_graph", {})
        
        print(f"\nğŸ”„ å·¥ä½œæµåœ–åˆ†æçµæœ:")
        print(f"ç¯€é»æ•¸: {workflow_result.nodes_count}")
        print(f"é‚Šæ•¸: {workflow_result.edges_count}")
        print(f"æ´å¯Ÿ: {workflow_result.insights}")
        print(f"å»ºè­°: {workflow_result.recommendations}")
        
        print("\nâœ… DeepGraph MCP æ¼”ç¤ºå®Œæˆ")
    
    # é‹è¡Œæ¼”ç¤º
    asyncio.run(demo())