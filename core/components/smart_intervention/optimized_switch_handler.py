#!/usr/bin/env python3
"""
Smart Intervention å„ªåŒ–åˆ‡æ›è™•ç†å™¨
ç›®æ¨™: å°‡åˆ‡æ›å»¶é²å¾ 147ms é™ä½åˆ° 100ms ä»¥ä¸‹
"""

import asyncio
import time
from typing import Dict, Any, Optional
from dataclasses import dataclass
from enum import Enum
import threading
import queue
import logging

logger = logging.getLogger(__name__)

class SwitchMode(Enum):
    CLAUDE_TO_EDITOR = "claude_to_editor"
    EDITOR_TO_CLAUDE = "editor_to_claude"
    STAY_CURRENT = "stay_current"

@dataclass
class SwitchMetrics:
    """åˆ‡æ›æ€§èƒ½æŒ‡æ¨™"""
    detection_time: float  # æª¢æ¸¬æ™‚é–“
    decision_time: float   # æ±ºç­–æ™‚é–“
    execution_time: float  # åŸ·è¡Œæ™‚é–“
    total_time: float      # ç¸½æ™‚é–“
    cache_hit: bool        # ç·©å­˜å‘½ä¸­
    
class OptimizedSwitchHandler:
    """å„ªåŒ–çš„åˆ‡æ›è™•ç†å™¨"""
    
    def __init__(self):
        # æ€§èƒ½å„ªåŒ–é…ç½®
        self.target_latency = 100.0  # ç›®æ¨™å»¶é² 100ms
        self.cache_size = 1000
        self.pre_compute_enabled = True
        self.batch_processing = True
        
        # ç·©å­˜ç³»çµ±
        self.keyword_cache = {}
        self.decision_cache = {}
        self.precomputed_decisions = {}
        
        # ç•°æ­¥è™•ç†
        self.switch_queue = queue.Queue(maxsize=10)
        self.worker_thread = None
        self.is_running = False
        
        # æ€§èƒ½æŒ‡æ¨™
        self.metrics_history = []
        self.last_switch_time = 0
        
        # é ç·¨è­¯çš„æ­£å‰‡è¡¨é”å¼å’Œé—œéµè©
        self._precompile_patterns()
        
    def _precompile_patterns(self):
        """é ç·¨è­¯å¸¸ç”¨æ¨¡å¼ä»¥æé«˜æ€§èƒ½"""
        import re
        
        # é«˜å„ªå…ˆç´šåˆ‡æ›è§¸ç™¼è© (ç›´æ¥åˆ‡æ›ï¼Œä¸éœ€è¤‡é›œåˆ†æ)
        self.instant_switch_patterns = [
            re.compile(r'(å•Ÿå‹•|æ‰“é–‹|launch|start)\s*(claudeditor|editor)', re.IGNORECASE),
            re.compile(r'(åˆ‡æ›åˆ°|switch\s*to)\s*(claudeditor|editor)', re.IGNORECASE),
            re.compile(r'(å‰µå»º|create)\s*(react|vue|angular)\s*(çµ„ä»¶|component)', re.IGNORECASE),
            re.compile(r'(ç”Ÿæˆ|generate)\s*(ui|interface|ç•Œé¢)', re.IGNORECASE),
        ]
        
        # å¿«é€Ÿé—œéµè©æ˜ å°„ (O(1) æŸ¥æ‰¾)
        self.fast_keywords = {
            # ç›´æ¥è§¸ç™¼é—œéµè©
            'claudeditor': SwitchMode.CLAUDE_TO_EDITOR,
            'editor': SwitchMode.CLAUDE_TO_EDITOR,
            'ce': SwitchMode.CLAUDE_TO_EDITOR,
            'ç¼–è¾‘å™¨': SwitchMode.CLAUDE_TO_EDITOR,
            
            # UI/ä»£ç¢¼ç›¸é—œ
            'react': SwitchMode.CLAUDE_TO_EDITOR,
            'vue': SwitchMode.CLAUDE_TO_EDITOR,
            'component': SwitchMode.CLAUDE_TO_EDITOR,
            'ç»„ä»¶': SwitchMode.CLAUDE_TO_EDITOR,
            'ui': SwitchMode.CLAUDE_TO_EDITOR,
            'interface': SwitchMode.CLAUDE_TO_EDITOR,
            'ç•Œé¢': SwitchMode.CLAUDE_TO_EDITOR,
            
            # é–‹ç™¼ç›¸é—œ
            'code': SwitchMode.CLAUDE_TO_EDITOR,
            'develop': SwitchMode.CLAUDE_TO_EDITOR,
            'build': SwitchMode.CLAUDE_TO_EDITOR,
            'å¼€å‘': SwitchMode.CLAUDE_TO_EDITOR,
            'ç¼–ç¨‹': SwitchMode.CLAUDE_TO_EDITOR,
        }
        
    async def analyze_and_switch(self, message: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†ææ¶ˆæ¯ä¸¦åŸ·è¡Œåˆ‡æ› - ä¸»è¦æ€§èƒ½å„ªåŒ–å…¥å£"""
        start_time = time.perf_counter()
        
        # éšæ®µ1: å¿«é€Ÿæª¢æ¸¬ (ç›®æ¨™: <20ms)
        detection_start = time.perf_counter()
        quick_decision = self._quick_detection(message)
        detection_time = (time.perf_counter() - detection_start) * 1000
        
        if quick_decision:
            # å¿«é€Ÿè·¯å¾‘: ç›´æ¥åŸ·è¡Œåˆ‡æ›
            execution_start = time.perf_counter()
            result = await self._execute_switch(quick_decision, context)
            execution_time = (time.perf_counter() - execution_start) * 1000
            
            total_time = (time.perf_counter() - start_time) * 1000
            
            # è¨˜éŒ„æŒ‡æ¨™
            metrics = SwitchMetrics(
                detection_time=detection_time,
                decision_time=0,  # å¿«é€Ÿè·¯å¾‘è·³éæ±ºç­–éšæ®µ
                execution_time=execution_time,
                total_time=total_time,
                cache_hit=True
            )
            
            self._record_metrics(metrics)
            
            return {
                'switched': True,
                'mode': quick_decision,
                'latency_ms': total_time,
                'path': 'fast',
                'metrics': metrics
            }
        
        # éšæ®µ2: æ·±åº¦åˆ†æ (ç›®æ¨™: <30ms)
        decision_start = time.perf_counter()
        decision = await self._deep_analysis(message, context)
        decision_time = (time.perf_counter() - decision_start) * 1000
        
        if decision != SwitchMode.STAY_CURRENT:
            # åŸ·è¡Œåˆ‡æ›
            execution_start = time.perf_counter()
            result = await self._execute_switch(decision, context)
            execution_time = (time.perf_counter() - execution_start) * 1000
            
            total_time = (time.perf_counter() - start_time) * 1000
            
            metrics = SwitchMetrics(
                detection_time=detection_time,
                decision_time=decision_time,
                execution_time=execution_time,
                total_time=total_time,
                cache_hit=False
            )
            
            self._record_metrics(metrics)
            
            return {
                'switched': True,
                'mode': decision,
                'latency_ms': total_time,
                'path': 'deep',
                'metrics': metrics
            }
        
        # ä¸éœ€è¦åˆ‡æ›
        total_time = (time.perf_counter() - start_time) * 1000
        return {
            'switched': False,
            'latency_ms': total_time,
            'path': 'no_switch'
        }
    
    def _quick_detection(self, message: str) -> Optional[SwitchMode]:
        """å¿«é€Ÿæª¢æ¸¬ - ä½¿ç”¨é ç·¨è­¯æ¨¡å¼å’Œç·©å­˜"""
        
        # ç·©å­˜æŸ¥æ‰¾ (O(1))
        if message in self.keyword_cache:
            return self.keyword_cache[message]
        
        message_lower = message.lower()
        
        # å¿«é€Ÿé—œéµè©æŸ¥æ‰¾ (O(1))
        words = message_lower.split()
        for word in words:
            if word in self.fast_keywords:
                decision = self.fast_keywords[word]
                # ç·©å­˜çµæœ
                if len(self.keyword_cache) < self.cache_size:
                    self.keyword_cache[message] = decision
                return decision
        
        # é ç·¨è­¯æ­£å‰‡è¡¨é”å¼æª¢æŸ¥
        for pattern in self.instant_switch_patterns:
            if pattern.search(message):
                decision = SwitchMode.CLAUDE_TO_EDITOR
                # ç·©å­˜çµæœ
                if len(self.keyword_cache) < self.cache_size:
                    self.keyword_cache[message] = decision
                return decision
        
        return None
    
    async def _deep_analysis(self, message: str, context: Dict[str, Any]) -> SwitchMode:
        """æ·±åº¦åˆ†æ - ç•°æ­¥ä¸¦ç™¼è™•ç†"""
        
        # æª¢æŸ¥æ±ºç­–ç·©å­˜
        cache_key = self._generate_cache_key(message, context)
        if cache_key in self.decision_cache:
            return self.decision_cache[cache_key]
        
        # ä¸¦ç™¼åˆ†æå¤šå€‹ç¶­åº¦
        tasks = [
            self._analyze_intent(message),
            self._analyze_complexity(message),
            self._analyze_context_switch_need(context),
        ]
        
        results = await asyncio.gather(*tasks)
        intent_score, complexity_score, context_score = results
        
        # å¿«é€Ÿæ±ºç­–ç®—æ³•
        total_score = intent_score + complexity_score + context_score
        
        if total_score > 0.7:
            decision = SwitchMode.CLAUDE_TO_EDITOR
        elif total_score < -0.3:
            decision = SwitchMode.EDITOR_TO_CLAUDE
        else:
            decision = SwitchMode.STAY_CURRENT
        
        # ç·©å­˜æ±ºç­–
        if len(self.decision_cache) < self.cache_size:
            self.decision_cache[cache_key] = decision
        
        return decision
    
    async def _analyze_intent(self, message: str) -> float:
        """æ„åœ–åˆ†æ - å„ªåŒ–ç‰ˆæœ¬"""
        
        # ä½¿ç”¨é è¨ˆç®—çš„æ¬Šé‡
        intent_keywords = {
            # é«˜æ¬Šé‡ - æ˜ç¢ºéœ€è¦ç·¨è¼¯å™¨
            'å‰µå»º': 0.8, 'create': 0.8, 'ç”Ÿæˆ': 0.8, 'generate': 0.8,
            'ç·¨å¯«': 0.7, 'write': 0.7, 'é–‹ç™¼': 0.7, 'develop': 0.7,
            'è¨­è¨ˆ': 0.6, 'design': 0.6, 'ä¿®æ”¹': 0.6, 'modify': 0.6,
            
            # ä¸­æ¬Šé‡ - å¯èƒ½éœ€è¦ç·¨è¼¯å™¨
            'æ¸¬è©¦': 0.4, 'test': 0.4, 'èª¿è©¦': 0.4, 'debug': 0.4,
            'éƒ¨ç½²': 0.3, 'deploy': 0.3, 'é‹è¡Œ': 0.3, 'run': 0.3,
            
            # è² æ¬Šé‡ - æ›´é©åˆå°è©±
            'è§£é‡‹': -0.3, 'explain': -0.3, 'ä»€éº¼': -0.3, 'what': -0.3,
            'ç‚ºä»€éº¼': -0.4, 'why': -0.4, 'å¦‚ä½•': -0.2, 'how': -0.2,
        }
        
        score = 0.0
        message_lower = message.lower()
        
        for keyword, weight in intent_keywords.items():
            if keyword in message_lower:
                score += weight
        
        return min(max(score, -1.0), 1.0)  # é™åˆ¶åœ¨ [-1, 1] ç¯„åœ
    
    async def _analyze_complexity(self, message: str) -> float:
        """è¤‡é›œåº¦åˆ†æ - ç°¡åŒ–ç‰ˆæœ¬"""
        
        # è¤‡é›œåº¦æŒ‡æ¨™
        complexity_indicators = {
            'react': 0.8, 'vue': 0.8, 'angular': 0.8,
            'javascript': 0.6, 'python': 0.6, 'typescript': 0.6,
            'api': 0.5, 'database': 0.5, 'server': 0.5,
            'component': 0.7, 'çµ„ä»¶': 0.7,
            'function': 0.4, 'å‡½æ•¸': 0.4,
        }
        
        score = 0.0
        message_lower = message.lower()
        
        for indicator, weight in complexity_indicators.items():
            if indicator in message_lower:
                score += weight
        
        return min(score, 1.0)
    
    async def _analyze_context_switch_need(self, context: Dict[str, Any]) -> float:
        """ä¸Šä¸‹æ–‡åˆ‡æ›éœ€æ±‚åˆ†æ"""
        
        current_mode = context.get('current_mode', 'claude')
        last_action = context.get('last_action', '')
        user_preference = context.get('user_preference', 0.5)
        
        # åŸºæ–¼ç•¶å‰æ¨¡å¼çš„åˆ‡æ›å‚¾å‘
        if current_mode == 'claude':
            return 0.2  # è¼•å¾®å‚¾å‘åˆ‡æ›åˆ°ç·¨è¼¯å™¨
        else:
            return -0.2  # è¼•å¾®å‚¾å‘ç•™åœ¨ç·¨è¼¯å™¨
    
    async def _execute_switch(self, mode: SwitchMode, context: Dict[str, Any]) -> bool:
        """åŸ·è¡Œåˆ‡æ› - å„ªåŒ–ç‰ˆæœ¬"""
        
        try:
            if mode == SwitchMode.CLAUDE_TO_EDITOR:
                # ç•°æ­¥å•Ÿå‹•ç·¨è¼¯å™¨
                await self._launch_editor_optimized(context)
                return True
            elif mode == SwitchMode.EDITOR_TO_CLAUDE:
                # ç•°æ­¥åˆ‡æ›åˆ°å°è©±æ¨¡å¼
                await self._switch_to_chat_optimized(context)
                return True
            
        except Exception as e:
            logger.error(f"åˆ‡æ›åŸ·è¡Œå¤±æ•—: {e}")
            return False
        
        return False
    
    async def _launch_editor_optimized(self, context: Dict[str, Any]):
        """å„ªåŒ–çš„ç·¨è¼¯å™¨å•Ÿå‹•"""
        
        # ä¸¦ç™¼åŸ·è¡Œå¤šå€‹å•Ÿå‹•ä»»å‹™
        tasks = [
            self._preload_editor_assets(),
            self._setup_editor_context(context),
            self._notify_switch_event('claude_to_editor')
        ]
        
        await asyncio.gather(*tasks)
    
    async def _switch_to_chat_optimized(self, context: Dict[str, Any]):
        """å„ªåŒ–çš„èŠå¤©æ¨¡å¼åˆ‡æ›"""
        
        tasks = [
            self._prepare_chat_context(context),
            self._notify_switch_event('editor_to_claude')
        ]
        
        await asyncio.gather(*tasks)
    
    async def _preload_editor_assets(self):
        """é è¼‰å…¥ç·¨è¼¯å™¨è³‡æº"""
        # æ¨¡æ“¬é è¼‰å…¥ - åœ¨å¯¦éš›å¯¦ç¾ä¸­æœƒè¼‰å…¥çœŸå¯¦è³‡æº
        await asyncio.sleep(0.01)  # 10ms æ¨¡æ“¬è¼‰å…¥æ™‚é–“
    
    async def _setup_editor_context(self, context: Dict[str, Any]):
        """è¨­ç½®ç·¨è¼¯å™¨ä¸Šä¸‹æ–‡"""
        await asyncio.sleep(0.005)  # 5ms æ¨¡æ“¬è¨­ç½®æ™‚é–“
    
    async def _prepare_chat_context(self, context: Dict[str, Any]):
        """æº–å‚™èŠå¤©ä¸Šä¸‹æ–‡"""
        await asyncio.sleep(0.005)  # 5ms æ¨¡æ“¬æº–å‚™æ™‚é–“
    
    async def _notify_switch_event(self, event_type: str):
        """é€šçŸ¥åˆ‡æ›äº‹ä»¶"""
        # ç•°æ­¥äº‹ä»¶é€šçŸ¥
        await asyncio.sleep(0.001)  # 1ms æ¨¡æ“¬é€šçŸ¥æ™‚é–“
    
    def _generate_cache_key(self, message: str, context: Dict[str, Any]) -> str:
        """ç”Ÿæˆç·©å­˜éµ"""
        return f"{hash(message)}_{context.get('current_mode', 'claude')}"
    
    def _record_metrics(self, metrics: SwitchMetrics):
        """è¨˜éŒ„æ€§èƒ½æŒ‡æ¨™"""
        self.metrics_history.append(metrics)
        
        # ä¿æŒæœ€è¿‘ 100 æ¬¡è¨˜éŒ„
        if len(self.metrics_history) > 100:
            self.metrics_history = self.metrics_history[-100:]
        
        # è¨˜éŒ„æ—¥èªŒ
        if metrics.total_time > self.target_latency:
            logger.warning(
                f"åˆ‡æ›å»¶é²è¶…æ¨™: {metrics.total_time:.1f}ms > {self.target_latency}ms"
            )
        else:
            logger.info(
                f"åˆ‡æ›æˆåŠŸ: {metrics.total_time:.1f}ms (ç›®æ¨™: {self.target_latency}ms)"
            )
    
    def get_performance_report(self) -> Dict[str, Any]:
        """ç²å–æ€§èƒ½å ±å‘Š"""
        if not self.metrics_history:
            return {"status": "no_data"}
        
        recent_metrics = self.metrics_history[-20:]  # æœ€è¿‘20æ¬¡
        
        avg_total = sum(m.total_time for m in recent_metrics) / len(recent_metrics)
        avg_detection = sum(m.detection_time for m in recent_metrics) / len(recent_metrics)
        avg_decision = sum(m.decision_time for m in recent_metrics) / len(recent_metrics)
        avg_execution = sum(m.execution_time for m in recent_metrics) / len(recent_metrics)
        
        cache_hit_rate = sum(1 for m in recent_metrics if m.cache_hit) / len(recent_metrics)
        
        under_target_rate = sum(1 for m in recent_metrics if m.total_time <= self.target_latency) / len(recent_metrics)
        
        return {
            "average_latency_ms": round(avg_total, 1),
            "target_latency_ms": self.target_latency,
            "under_target_rate": round(under_target_rate * 100, 1),
            "cache_hit_rate": round(cache_hit_rate * 100, 1),
            "breakdown": {
                "detection_ms": round(avg_detection, 1),
                "decision_ms": round(avg_decision, 1),
                "execution_ms": round(avg_execution, 1)
            },
            "status": "excellent" if avg_total <= self.target_latency else "needs_optimization",
            "sample_size": len(recent_metrics)
        }
    
    def clear_cache(self):
        """æ¸…ç†ç·©å­˜"""
        self.keyword_cache.clear()
        self.decision_cache.clear()
        logger.info("ç·©å­˜å·²æ¸…ç†")

# å‰µå»ºå…¨å±€å„ªåŒ–è™•ç†å™¨å¯¦ä¾‹
optimized_handler = OptimizedSwitchHandler()

# æ€§èƒ½æ¸¬è©¦å‡½æ•¸
async def performance_test():
    """æ€§èƒ½æ¸¬è©¦"""
    
    test_messages = [
        "å‰µå»ºä¸€å€‹Reactçµ„ä»¶",
        "ç”Ÿæˆç”¨æˆ¶ç•Œé¢",
        "å•Ÿå‹•ClaudeEditor",
        "å¯«ä¸€å€‹Pythonå‡½æ•¸",
        "è¨­è¨ˆç™»éŒ„é é¢",
        "ä»€éº¼æ˜¯React?",  # ä¸æ‡‰è©²åˆ‡æ›
        "è§£é‡‹é€™æ®µä»£ç¢¼",   # ä¸æ‡‰è©²åˆ‡æ›
        "ce",  # å¿«æ·æŒ‡ä»¤
        "é–‹ç™¼Webæ‡‰ç”¨",
        "æ¸¬è©¦APIæ¥å£"
    ]
    
    context = {
        'current_mode': 'claude',
        'user_preference': 0.5
    }
    
    print("ğŸš€ Smart Intervention æ€§èƒ½æ¸¬è©¦")
    print("=" * 50)
    
    results = []
    
    for i, message in enumerate(test_messages, 1):
        print(f"\næ¸¬è©¦ {i}: {message}")
        
        result = await optimized_handler.analyze_and_switch(message, context)
        results.append(result)
        
        print(f"  åˆ‡æ›: {'æ˜¯' if result['switched'] else 'å¦'}")
        print(f"  å»¶é²: {result['latency_ms']:.1f}ms")
        print(f"  è·¯å¾‘: {result.get('path', 'unknown')}")
        
        if result['latency_ms'] <= 100:
            print(f"  âœ… é”æ¨™ (â‰¤100ms)")
        else:
            print(f"  âŒ è¶…æ¨™ (>100ms)")
    
    # ç¸½é«”å ±å‘Š
    print(f"\nğŸ“Š æ¸¬è©¦ç¸½çµ")
    print("=" * 30)
    
    avg_latency = sum(r['latency_ms'] for r in results) / len(results)
    under_target = sum(1 for r in results if r['latency_ms'] <= 100)
    
    print(f"å¹³å‡å»¶é²: {avg_latency:.1f}ms")
    print(f"é”æ¨™ç‡: {under_target}/{len(results)} ({under_target/len(results)*100:.1f}%)")
    
    # è©³ç´°æ€§èƒ½å ±å‘Š
    report = optimized_handler.get_performance_report()
    print(f"\nè©³ç´°å ±å‘Š: {report}")

if __name__ == "__main__":
    asyncio.run(performance_test())