#!/usr/bin/env python3
"""
RAG Service - PowerAutomation v4.8

ä¼ä¸šçº§ RAG åŠŸèƒ½å®ç°ï¼ŒåŒ…æ‹¬:
- å‘é‡æ•°æ®åº“ç®¡ç†
- æ–‡æ¡£ç´¢å¼•å’Œæ£€ç´¢
- ä¸ Kimi K2 çš„é›†æˆ
- MemoryOS é¡¹ç›®ä¸Šä¸‹æ–‡ç®¡ç†
"""

import json
import logging
import hashlib
import numpy as np
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
import asyncio
import aiohttp
import time

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class Document:
    """æ–‡æ¡£æ•°æ®ç»“æ„"""
    id: str
    content: str
    metadata: Dict[str, Any]
    embedding: Optional[np.ndarray] = None
    timestamp: datetime = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now()

@dataclass
class RAGQuery:
    """RAG æŸ¥è¯¢æ•°æ®ç»“æ„"""
    query: str
    top_k: int = 5
    filters: Optional[Dict[str, Any]] = None
    include_metadata: bool = True

@dataclass
class RAGResult:
    """RAG æŸ¥è¯¢ç»“æœ"""
    query: str
    documents: List[Document]
    scores: List[float]
    total_time_ms: float
    enhanced_prompt: str

class RAGService:
    """RAG æœåŠ¡æ ¸å¿ƒç±»"""
    
    def __init__(self, config: Dict[str, Any] = None):
        """åˆå§‹åŒ– RAG æœåŠ¡"""
        self.config = config or {}
        
        # é…ç½®å‚æ•°
        self.embedding_model_name = self.config.get("embedding_model", "all-MiniLM-L6-v2")
        self.max_context_length = self.config.get("max_context_length", 32000)
        self.top_k_default = self.config.get("top_k_default", 5)
        self.kimi_k2_endpoint = self.config.get("kimi_k2_endpoint", "https://api.moonshot.cn/v1")
        self.kimi_k2_api_key = self.config.get("kimi_k2_api_key", "")
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.logger = logging.getLogger(__name__)
        self.embedding_model = None
        self.vector_index = None
        self.document_store = {}
        
        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            "total_queries": 0,
            "total_documents": 0,
            "avg_response_time": 0.0,
            "cache_hits": 0,
            "last_updated": datetime.now()
        }
    
    async def initialize(self) -> Dict[str, Any]:
        """åˆå§‹åŒ– RAG æœåŠ¡"""
        try:
            # åŠ è½½åµŒå…¥æ¨¡å‹
            await self._load_embedding_model()
            
            # åˆå§‹åŒ–å‘é‡ç´¢å¼•
            await self._initialize_vector_index()
            
            # éªŒè¯ Kimi K2 è¿æ¥
            await self._verify_kimi_k2_connection()
            
            logger.info("âœ… RAG æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
            return {"status": "success", "message": "RAG æœåŠ¡åˆå§‹åŒ–å®Œæˆ"}
            
        except Exception as e:
            logger.error(f"âŒ RAG æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
            return {"status": "error", "error": str(e)}
    
    async def _load_embedding_model(self):
        """åŠ è½½åµŒå…¥æ¨¡å‹"""
        try:
            from sentence_transformers import SentenceTransformer
            self.embedding_model = SentenceTransformer(self.embedding_model_name)
            logger.info(f"âœ… åµŒå…¥æ¨¡å‹åŠ è½½å®Œæˆ: {self.embedding_model_name}")
        except Exception as e:
            logger.error(f"âŒ åµŒå…¥æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    async def _initialize_vector_index(self):
        """åˆå§‹åŒ–å‘é‡ç´¢å¼•"""
        try:
            import faiss
            # ä½¿ç”¨å†…ç§¯ç›¸ä¼¼åº¦ç´¢å¼•
            dimension = 384  # all-MiniLM-L6-v2 çš„å‘é‡ç»´åº¦
            self.vector_index = faiss.IndexFlatIP(dimension)
            logger.info("âœ… å‘é‡ç´¢å¼•åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            logger.error(f"âŒ å‘é‡ç´¢å¼•åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    async def _verify_kimi_k2_connection(self):
        """éªŒè¯ Kimi K2 API è¿æ¥"""
        if not self.kimi_k2_api_key:
            logger.warning("âš ï¸ Kimi K2 API å¯†é’¥æœªé…ç½®")
            return
        
        try:
            # ç®€å•çš„è¿æ¥æµ‹è¯•
            async with aiohttp.ClientSession() as session:
                headers = {
                    "Authorization": f"Bearer {self.kimi_k2_api_key}",
                    "Content-Type": "application/json"
                }
                
                test_data = {
                    "model": "moonshot-v1-8k",
                    "messages": [{"role": "user", "content": "Hello"}],
                    "max_tokens": 10
                }
                
                async with session.post(
                    f"{self.kimi_k2_endpoint}/chat/completions",
                    headers=headers,
                    json=test_data,
                    timeout=10
                ) as response:
                    if response.status == 200:
                        logger.info("âœ… Kimi K2 API è¿æ¥éªŒè¯æˆåŠŸ")
                    else:
                        logger.warning(f"âš ï¸ Kimi K2 API è¿æ¥å¼‚å¸¸: {response.status}")
                        
        except Exception as e:
            logger.warning(f"âš ï¸ Kimi K2 API è¿æ¥éªŒè¯å¤±è´¥: {e}")
    
    async def add_documents(self, documents: List[Dict[str, Any]], kb_id: str = "default") -> Dict[str, Any]:
        """æ·»åŠ æ–‡æ¡£åˆ° RAG ç³»ç»Ÿ"""
        try:
            logger.info(f"æ·»åŠ  {len(documents)} ä¸ªæ–‡æ¡£åˆ°çŸ¥è¯†åº“ {kb_id}")
            
            # å¤„ç†æ–‡æ¡£
            processed_docs = []
            for i, doc in enumerate(documents):
                content = doc.get("content", "")
                if not content.strip():
                    continue
                
                # ç”Ÿæˆæ–‡æ¡£ ID
                doc_id = doc.get("id") or f"{kb_id}_{i}_{hashlib.md5(content.encode()).hexdigest()[:8]}"
                
                # ç”ŸæˆåµŒå…¥å‘é‡
                embedding = self.embedding_model.encode([content])[0]
                
                # åˆ›å»ºæ–‡æ¡£å¯¹è±¡
                document = Document(
                    id=doc_id,
                    content=content,
                    metadata=doc.get("metadata", {}),
                    embedding=embedding
                )
                
                processed_docs.append(document)
                
                # æ·»åŠ åˆ°å‘é‡ç´¢å¼•
                self.vector_index.add(np.array([embedding]).astype('float32'))
                
                # å­˜å‚¨æ–‡æ¡£
                self.document_store[doc_id] = document
            
            # æ›´æ–°ç»Ÿè®¡
            self.stats["total_documents"] += len(processed_docs)
            self.stats["last_updated"] = datetime.now()
            
            logger.info(f"âœ… æˆåŠŸæ·»åŠ  {len(processed_docs)} ä¸ªæ–‡æ¡£")
            
            return {
                "status": "success",
                "added_count": len(processed_docs),
                "total_documents": len(self.document_store)
            }
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ æ–‡æ¡£å¤±è´¥: {e}")
            return {
                "status": "error",
                "error": str(e)
            }
    
    async def retrieve_documents(self, query: str, kb_id: str = "default", top_k: int = 5) -> Dict[str, Any]:
        """æ£€ç´¢ç›¸å…³æ–‡æ¡£"""
        try:
            start_time = time.time()
            
            # ç”ŸæˆæŸ¥è¯¢åµŒå…¥
            query_embedding = self.embedding_model.encode([query])[0]
            
            # å‘é‡æ£€ç´¢
            if self.vector_index.ntotal == 0:
                return {
                    "status": "success",
                    "documents": [],
                    "scores": [],
                    "total_time_ms": (time.time() - start_time) * 1000
                }
            
            # æœç´¢æœ€ç›¸ä¼¼çš„æ–‡æ¡£
            scores, indices = self.vector_index.search(
                np.array([query_embedding]).astype('float32'), 
                min(top_k, self.vector_index.ntotal)
            )
            
            # è·å–æ–‡æ¡£
            retrieved_docs = []
            retrieved_scores = []
            
            for score, idx in zip(scores[0], indices[0]):
                if idx == -1:
                    continue
                
                # æ ¹æ®ç´¢å¼•æŸ¥æ‰¾æ–‡æ¡£
                doc_found = False
                for doc_id, doc in self.document_store.items():
                    # ç®€å•çš„ç´¢å¼•åŒ¹é…ï¼ˆå®é™…åº”ç”¨ä¸­éœ€è¦æ›´ç²¾ç¡®çš„æ˜ å°„ï¼‰
                    if len(retrieved_docs) == len([d for d in self.document_store.values() if d == doc]):
                        retrieved_docs.append(doc)
                        retrieved_scores.append(float(score))
                        doc_found = True
                        break
                
                if not doc_found and self.document_store:
                    # é™çº§å¤„ç†ï¼šè¿”å›ç¬¬ä¸€ä¸ªæ–‡æ¡£
                    first_doc = next(iter(self.document_store.values()))
                    retrieved_docs.append(first_doc)
                    retrieved_scores.append(float(score))
            
            # æ›´æ–°ç»Ÿè®¡
            self.stats["total_queries"] += 1
            query_time = (time.time() - start_time) * 1000
            self.stats["avg_response_time"] = (
                (self.stats["avg_response_time"] * (self.stats["total_queries"] - 1) + query_time) 
                / self.stats["total_queries"]
            )
            
            return {
                "status": "success",
                "documents": [
                    {
                        "id": doc.id,
                        "content": doc.content,
                        "metadata": doc.metadata,
                        "score": score
                    }
                    for doc, score in zip(retrieved_docs, retrieved_scores)
                ],
                "scores": retrieved_scores,
                "total_time_ms": query_time
            }
            
        except Exception as e:
            logger.error(f"âŒ æ–‡æ¡£æ£€ç´¢å¤±è´¥: {e}")
            return {
                "status": "error",
                "error": str(e)
            }
    
    async def query_with_kimi_k2(self, query: str, kb_id: str = "default", top_k: int = None) -> Dict[str, Any]:
        """ä½¿ç”¨ Kimi K2 è¿›è¡Œ RAG æŸ¥è¯¢"""
        try:
            start_time = datetime.now()
            
            # æ‰§è¡Œ RAG æŸ¥è¯¢
            rag_result = await self.retrieve_documents(query, kb_id, top_k or self.top_k_default)
            
            if rag_result["status"] != "success":
                return rag_result
            
            # æ„å»ºå¢å¼ºæç¤º
            context_docs = rag_result["documents"]
            if context_docs:
                context_text = "\n\n".join([
                    f"æ–‡æ¡£ {i+1}:\n{doc['content']}"
                    for i, doc in enumerate(context_docs)
                ])
                
                enhanced_prompt = f"""åŸºäºä»¥ä¸‹ç›¸å…³æ–‡æ¡£å›ç­”é—®é¢˜ï¼š

{context_text}

é—®é¢˜: {query}

è¯·åŸºäºä¸Šè¿°æ–‡æ¡£å†…å®¹æä¾›å‡†ç¡®ã€è¯¦ç»†çš„å›ç­”ã€‚å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜ã€‚"""
            else:
                enhanced_prompt = query
            
            # è°ƒç”¨ Kimi K2 API
            kimi_response = await self._call_kimi_k2_api(enhanced_prompt)
            
            # è®¡ç®—æ€»æ—¶é—´
            total_time = (datetime.now() - start_time).total_seconds() * 1000
            
            return {
                "status": "success",
                "query": query,
                "answer": kimi_response.get("content", ""),
                "context_documents": context_docs,
                "total_time_ms": total_time,
                "enhanced_prompt": enhanced_prompt
            }
            
        except Exception as e:
            logger.error(f"âŒ Kimi K2 RAG æŸ¥è¯¢å¤±è´¥: {e}")
            return {
                "status": "error",
                "error": str(e)
            }
    
    async def _call_kimi_k2_api(self, prompt: str) -> Dict[str, Any]:
        """è°ƒç”¨ Kimi K2 API"""
        if not self.kimi_k2_api_key:
            return {"content": "Kimi K2 API æœªé…ç½®ï¼Œè¿”å›æ¨¡æ‹Ÿå›ç­”"}
        
        try:
            async with aiohttp.ClientSession() as session:
                headers = {
                    "Authorization": f"Bearer {self.kimi_k2_api_key}",
                    "Content-Type": "application/json"
                }
                
                data = {
                    "model": "moonshot-v1-8k",
                    "messages": [{"role": "user", "content": prompt}],
                    "max_tokens": 2000,
                    "temperature": 0.7
                }
                
                async with session.post(
                    f"{self.kimi_k2_endpoint}/chat/completions",
                    headers=headers,
                    json=data,
                    timeout=30
                ) as response:
                    if response.status == 200:
                        result = await response.json()
                        return {
                            "content": result["choices"][0]["message"]["content"],
                            "usage": result.get("usage", {})
                        }
                    else:
                        error_text = await response.text()
                        logger.error(f"Kimi K2 API é”™è¯¯: {response.status} - {error_text}")
                        return {"content": f"API è°ƒç”¨å¤±è´¥: {response.status}"}
                        
        except Exception as e:
            logger.error(f"âŒ Kimi K2 API è°ƒç”¨å¼‚å¸¸: {e}")
            return {"content": f"API è°ƒç”¨å¼‚å¸¸: {str(e)}"}
    
    async def get_statistics(self) -> Dict[str, Any]:
        """è·å– RAG æœåŠ¡ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "total_documents": len(self.document_store),
            "vector_index_size": self.vector_index.ntotal if self.vector_index else 0,
            "embedding_model": self.embedding_model_name,
            "stats": self.stats,
            "timestamp": datetime.now().isoformat()
        }
    
    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        try:
            # æ£€æŸ¥æ ¸å¿ƒç»„ä»¶
            checks = {
                "embedding_model": self.embedding_model is not None,
                "vector_index": self.vector_index is not None,
                "document_store": len(self.document_store) >= 0,
                "kimi_k2_configured": bool(self.kimi_k2_api_key)
            }
            
            return {
                "status": "healthy" if all(checks.values()) else "degraded",
                "checks": checks,
                "timestamp": datetime.now().isoformat(),
                "document_count": len(self.document_store),
                "vector_index_size": self.vector_index.ntotal if self.vector_index else 0
            }
            
        except Exception as e:
            return {
                "status": "unhealthy",
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }

# å…¨å±€å®ä¾‹ç®¡ç†
rag_service = None

def get_rag_service(**kwargs) -> RAGService:
    """è·å– RAG æœåŠ¡å®ä¾‹"""
    global rag_service
    if rag_service is None:
        rag_service = RAGService(**kwargs)
    return rag_service

async def main():
    """æµ‹è¯• RAG æœåŠ¡"""
    print("ğŸ§ª æµ‹è¯• RAG æœåŠ¡...")
    
    service = get_rag_service()
    await service.initialize()
    
    # æµ‹è¯•å¥åº·æ£€æŸ¥
    health = await service.health_check()
    print(f"âœ… å¥åº·æ£€æŸ¥: {health['status']}")
    
    # æµ‹è¯•æ·»åŠ æ–‡æ¡£
    test_docs = [
        {
            "content": "Python æ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œå…·æœ‰ç®€æ´çš„è¯­æ³•å’Œå¼ºå¤§çš„åŠŸèƒ½ã€‚",
            "metadata": {"type": "programming", "language": "python"}
        }
    ]
    
    add_result = await service.add_documents(test_docs)
    print(f"âœ… æ–‡æ¡£æ·»åŠ : {add_result['status']}")
    
    # æµ‹è¯•æ£€ç´¢
    retrieve_result = await service.retrieve_documents("Python ç¼–ç¨‹")
    print(f"âœ… æ–‡æ¡£æ£€ç´¢: {retrieve_result['status']}, æ‰¾åˆ° {len(retrieve_result.get('documents', []))} ä¸ªæ–‡æ¡£")
    
    print("âœ… RAG æœåŠ¡æµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    asyncio.run(main())

