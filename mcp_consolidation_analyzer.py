#!/usr/bin/env python3
"""
MCP åˆä½µåˆ†æå·¥å…·
åˆ†æé …ç›®ä¸­æ‰€æœ‰ MCP çš„åŠŸèƒ½é‡è¤‡æƒ…æ³ä¸¦æä¾›åˆä½µå»ºè­°
"""

import os
import re
from pathlib import Path
from typing import Dict, List, Set, Tuple
import json
from datetime import datetime

class MCPConsolidationAnalyzer:
    def __init__(self):
        self.mcp_info = {}
        self.duplicate_functions = {}
        self.consolidation_suggestions = []
        
    def analyze_project(self, project_root: str = "."):
        """åˆ†ææ•´å€‹é …ç›®çš„ MCP"""
        print("ğŸ” é–‹å§‹åˆ†æ MCP åŠŸèƒ½é‡è¤‡æƒ…æ³...")
        
        # æŸ¥æ‰¾æ‰€æœ‰ MCP ç›¸é—œæ–‡ä»¶
        mcp_files = self._find_mcp_files(project_root)
        print(f"æ‰¾åˆ° {len(mcp_files)} å€‹ MCP ç›¸é—œæ–‡ä»¶")
        
        # åˆ†ææ¯å€‹ MCP
        for file_path in mcp_files:
            self._analyze_mcp_file(file_path)
        
        # æŸ¥æ‰¾é‡è¤‡åŠŸèƒ½
        self._find_duplicates()
        
        # ç”Ÿæˆåˆä½µå»ºè­°
        self._generate_consolidation_suggestions()
        
        # ç”Ÿæˆå ±å‘Š
        return self._generate_report()
    
    def _find_mcp_files(self, root: str) -> List[Path]:
        """æŸ¥æ‰¾æ‰€æœ‰ MCP ç›¸é—œæ–‡ä»¶"""
        mcp_files = []
        patterns = [
            '*_mcp.py',
            '*_manager.py',
            '*_server.py',
            'mcp_*.py'
        ]
        
        for pattern in patterns:
            mcp_files.extend(Path(root).rglob(pattern))
        
        # éæ¿¾æ‰ venv å’Œ __pycache__
        mcp_files = [f for f in mcp_files if 'venv' not in str(f) and '__pycache__' not in str(f)]
        
        return sorted(set(mcp_files))
    
    def _analyze_mcp_file(self, file_path: Path):
        """åˆ†æå–®å€‹ MCP æ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æå– MCP åç¨±
            mcp_name = self._extract_mcp_name(file_path, content)
            if not mcp_name:
                return
            
            # æå–åŠŸèƒ½ä¿¡æ¯
            tools = self._extract_tools(content)
            resources = self._extract_resources(content)
            description = self._extract_description(content)
            
            self.mcp_info[mcp_name] = {
                'file': str(file_path),
                'tools': tools,
                'resources': resources,
                'description': description,
                'category': self._categorize_mcp(mcp_name, tools, description)
            }
            
        except Exception as e:
            print(f"åˆ†ææ–‡ä»¶ {file_path} æ™‚å‡ºéŒ¯: {e}")
    
    def _extract_mcp_name(self, file_path: Path, content: str) -> str:
        """æå– MCP åç¨±"""
        # å¾æ–‡ä»¶åæå–
        file_name = file_path.stem
        
        # å˜—è©¦å¾é¡åæå–
        class_match = re.search(r'class\s+(\w+MCP|\w+Manager|\w+Server)', content)
        if class_match:
            return class_match.group(1)
        
        # ä½¿ç”¨æ–‡ä»¶å
        if '_mcp' in file_name:
            return file_name.replace('_mcp', '').title() + 'MCP'
        elif '_manager' in file_name:
            return file_name.replace('_manager', '').title() + 'Manager'
        
        return file_name
    
    def _extract_tools(self, content: str) -> List[Dict]:
        """æå–å·¥å…·å®šç¾©"""
        tools = []
        
        # æŸ¥æ‰¾ @mcp.tool è£é£¾å™¨
        tool_pattern = r'@(?:mcp\.)?tool(?:\([^)]*\))?\s*(?:async\s+)?def\s+(\w+)'
        for match in re.finditer(tool_pattern, content):
            tool_name = match.group(1)
            
            # å˜—è©¦æå–æè¿°
            desc_pattern = rf'def\s+{tool_name}.*?"""(.*?)"""'
            desc_match = re.search(desc_pattern, content, re.DOTALL)
            description = desc_match.group(1).strip() if desc_match else ""
            
            tools.append({
                'name': tool_name,
                'description': description
            })
        
        # æŸ¥æ‰¾å·¥å…·å­—å…¸å®šç¾©
        tools_dict_pattern = r'tools\s*=\s*\{([^}]+)\}'
        tools_match = re.search(tools_dict_pattern, content, re.DOTALL)
        if tools_match:
            tools_content = tools_match.group(1)
            tool_names = re.findall(r'["\'](\w+)["\']', tools_content)
            for name in tool_names:
                if not any(t['name'] == name for t in tools):
                    tools.append({'name': name, 'description': ''})
        
        return tools
    
    def _extract_resources(self, content: str) -> List[str]:
        """æå–è³‡æºå®šç¾©"""
        resources = []
        
        # æŸ¥æ‰¾ @mcp.resource è£é£¾å™¨
        resource_pattern = r'@(?:mcp\.)?resource\s*(?:\([^)]*\))?\s*(?:async\s+)?def\s+(\w+)'
        for match in re.finditer(resource_pattern, content):
            resources.append(match.group(1))
        
        return resources
    
    def _extract_description(self, content: str) -> str:
        """æå–æè¿°"""
        # æŸ¥æ‰¾æ–‡ä»¶é–‹é ­çš„æ–‡æª”å­—ç¬¦ä¸²
        doc_match = re.match(r'(?:.*?)?"""(.*?)"""', content, re.DOTALL)
        if doc_match:
            return doc_match.group(1).strip().split('\n')[0]
        
        return ""
    
    def _categorize_mcp(self, name: str, tools: List[Dict], description: str) -> str:
        """åˆ†é¡ MCP"""
        name_lower = name.lower()
        desc_lower = description.lower()
        tool_names = [t['name'].lower() for t in tools]
        
        # åŸºæ–¼åç¨±å’Œå·¥å…·åˆ¤æ–·é¡åˆ¥
        if any(word in name_lower for word in ['command', 'cmd', 'exec']):
            return 'command_execution'
        elif any(word in name_lower for word in ['code', 'flow', 'spec']):
            return 'code_generation'
        elif any(word in name_lower for word in ['ui', 'ag', 'interface']):
            return 'ui_generation'
        elif any(word in name_lower for word in ['route', 'router', 'proxy']):
            return 'routing'
        elif any(word in name_lower for word in ['memory', 'rag', 'store']):
            return 'memory_storage'
        elif any(word in name_lower for word in ['test', 'debug']):
            return 'testing'
        elif any(word in name_lower for word in ['coordinate', 'manage']):
            return 'coordination'
        else:
            return 'other'
    
    def _find_duplicates(self):
        """æŸ¥æ‰¾é‡è¤‡åŠŸèƒ½"""
        # æŒ‰é¡åˆ¥åˆ†çµ„
        categories = {}
        for mcp_name, info in self.mcp_info.items():
            category = info['category']
            if category not in categories:
                categories[category] = []
            categories[category].append(mcp_name)
        
        # æŸ¥æ‰¾æ¯å€‹é¡åˆ¥ä¸­çš„é‡è¤‡
        for category, mcps in categories.items():
            if len(mcps) > 1:
                self.duplicate_functions[category] = mcps
        
        # æŸ¥æ‰¾ç›¸åŒå·¥å…·åçš„ MCP
        tool_map = {}
        for mcp_name, info in self.mcp_info.items():
            for tool in info['tools']:
                tool_name = tool['name']
                if tool_name not in tool_map:
                    tool_map[tool_name] = []
                tool_map[tool_name].append(mcp_name)
        
        # è¨˜éŒ„æœ‰ç›¸åŒå·¥å…·çš„ MCP
        for tool_name, mcps in tool_map.items():
            if len(mcps) > 1:
                self.duplicate_functions[f'tool_{tool_name}'] = mcps
    
    def _generate_consolidation_suggestions(self):
        """ç”Ÿæˆåˆä½µå»ºè­°"""
        # åŸºæ–¼é¡åˆ¥çš„åˆä½µå»ºè­°
        for category, mcps in self.duplicate_functions.items():
            if category.startswith('tool_'):
                continue
                
            if len(mcps) > 1:
                self.consolidation_suggestions.append({
                    'type': 'category_merge',
                    'category': category,
                    'mcps': mcps,
                    'suggestion': f"åˆä½µ {category} é¡åˆ¥çš„ {len(mcps)} å€‹ MCP",
                    'new_name': f"{category}_unified_mcp",
                    'benefit': 'æ¸›å°‘åŠŸèƒ½é‡è¤‡ï¼Œæé«˜ç¶­è­·æ€§'
                })
        
        # ç‰¹å®šçš„åˆä½µå»ºè­°
        specific_merges = [
            {
                'mcps': ['command_manager', 'command_mcp'],
                'new_name': 'unified_command_mcp',
                'reason': 'å‘½ä»¤åŸ·è¡ŒåŠŸèƒ½é‡è¤‡'
            },
            {
                'mcps': ['codeflow_manager', 'codeflow_mcp', 'spec_generator'],
                'new_name': 'unified_codeflow_mcp',
                'reason': 'ä»£ç¢¼ç”ŸæˆåŠŸèƒ½é‡è¤‡'
            },
            {
                'mcps': ['claude_router_mcp', 'smart_routing_mcp'],
                'new_name': 'unified_routing_mcp',
                'reason': 'è·¯ç”±åŠŸèƒ½é‡è¤‡'
            }
        ]
        
        for merge in specific_merges:
            existing_mcps = [m for m in merge['mcps'] if any(m in name.lower() for name in self.mcp_info.keys())]
            if len(existing_mcps) > 1:
                self.consolidation_suggestions.append({
                    'type': 'specific_merge',
                    'mcps': existing_mcps,
                    'new_name': merge['new_name'],
                    'reason': merge['reason'],
                    'benefit': 'çµ±ä¸€åŠŸèƒ½æ¥å£ï¼Œé¿å…æ··æ·†'
                })
    
    def _generate_report(self) -> str:
        """ç”Ÿæˆåˆ†æå ±å‘Š"""
        report = []
        report.append("=" * 80)
        report.append("MCP åŠŸèƒ½é‡è¤‡åˆ†æå ±å‘Š")
        report.append("=" * 80)
        report.append(f"\nç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        
        # æ¦‚è¦½
        report.append("## ğŸ“Š æ¦‚è¦½")
        report.append(f"- ç¸½å…±ç™¼ç¾ {len(self.mcp_info)} å€‹ MCP")
        report.append(f"- ç™¼ç¾ {len(self.duplicate_functions)} çµ„åŠŸèƒ½é‡è¤‡")
        report.append(f"- æå‡º {len(self.consolidation_suggestions)} å€‹åˆä½µå»ºè­°\n")
        
        # MCP åˆ—è¡¨
        report.append("## ğŸ“‹ MCP åˆ—è¡¨")
        categories = {}
        for name, info in self.mcp_info.items():
            cat = info['category']
            if cat not in categories:
                categories[cat] = []
            categories[cat].append((name, info))
        
        for cat, mcps in sorted(categories.items()):
            report.append(f"\n### {cat.replace('_', ' ').title()}")
            for name, info in mcps:
                report.append(f"- **{name}**")
                report.append(f"  - æ–‡ä»¶: {info['file']}")
                report.append(f"  - å·¥å…·æ•¸: {len(info['tools'])}")
                if info['description']:
                    report.append(f"  - æè¿°: {info['description'][:80]}...")
        
        # åŠŸèƒ½é‡è¤‡
        report.append("\n## ğŸ”„ åŠŸèƒ½é‡è¤‡æª¢æ¸¬")
        for category, mcps in self.duplicate_functions.items():
            if not category.startswith('tool_'):
                report.append(f"\n### {category.replace('_', ' ').title()}")
                report.append(f"ç™¼ç¾ {len(mcps)} å€‹ MCP æœ‰ç›¸ä¼¼åŠŸèƒ½:")
                for mcp in mcps:
                    report.append(f"- {mcp}")
        
        # åˆä½µå»ºè­°
        report.append("\n## ğŸ’¡ åˆä½µå»ºè­°")
        for i, suggestion in enumerate(self.consolidation_suggestions, 1):
            report.append(f"\n### å»ºè­° {i}: {suggestion.get('suggestion', suggestion.get('reason', ''))}")
            report.append(f"- æ¶‰åŠ MCP: {', '.join(suggestion['mcps'])}")
            report.append(f"- å»ºè­°æ–°åç¨±: {suggestion.get('new_name', 'N/A')}")
            report.append(f"- é æœŸæ”¶ç›Š: {suggestion.get('benefit', 'N/A')}")
        
        # å¯¦æ–½è¨ˆåŠƒ
        report.append("\n## ğŸš€ å¯¦æ–½è¨ˆåŠƒ")
        report.append("\n### ç¬¬ä¸€éšæ®µï¼šåˆä½µå‘½ä»¤åŸ·è¡Œé¡ MCP")
        report.append("1. åˆä½µæ‰€æœ‰å‘½ä»¤åŸ·è¡Œç›¸é—œçš„ MCP")
        report.append("2. çµ±ä¸€æ¥å£å’ŒéŒ¯èª¤è™•ç†")
        report.append("3. æ›´æ–°æ‰€æœ‰ä¾è³´")
        
        report.append("\n### ç¬¬äºŒéšæ®µï¼šåˆä½µä»£ç¢¼ç”Ÿæˆé¡ MCP")
        report.append("1. æ•´åˆ codeflow å’Œ spec ç”ŸæˆåŠŸèƒ½")
        report.append("2. å»ºç«‹çµ±ä¸€çš„ä»£ç¢¼ç”Ÿæˆç®¡é“")
        
        report.append("\n### ç¬¬ä¸‰éšæ®µï¼šåˆä½µè·¯ç”±é¡ MCP")
        report.append("1. çµ±ä¸€è·¯ç”±é‚è¼¯")
        report.append("2. å„ªåŒ–æ€§èƒ½å’ŒéŒ¯èª¤è™•ç†")
        
        # ä¿å­˜è©³ç´°æ•¸æ“š
        data = {
            'mcp_info': self.mcp_info,
            'duplicates': self.duplicate_functions,
            'suggestions': self.consolidation_suggestions,
            'timestamp': datetime.now().isoformat()
        }
        
        with open('mcp_consolidation_data.json', 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        report.append(f"\n\nğŸ’¾ è©³ç´°æ•¸æ“šå·²ä¿å­˜åˆ°: mcp_consolidation_data.json")
        
        return "\n".join(report)

def main():
    """ä¸»å‡½æ•¸"""
    analyzer = MCPConsolidationAnalyzer()
    report = analyzer.analyze_project()
    
    # ä¿å­˜å ±å‘Š
    with open('mcp_consolidation_report.txt', 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(report)
    print("\nâœ… åˆ†æå®Œæˆï¼å ±å‘Šå·²ä¿å­˜åˆ°: mcp_consolidation_report.txt")

if __name__ == "__main__":
    main()