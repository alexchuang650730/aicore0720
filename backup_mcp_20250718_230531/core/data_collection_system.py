#!/usr/bin/env python3
"""
PowerAutomation Core æ•¸æ“šæ”¶é›†å’Œåé¥‹ç³»çµ±
v4.6.9.4 - å…¨é¢çš„æ•¸æ“šæ”¶é›†ã€åˆ†æå’Œåé¥‹æ©Ÿåˆ¶
"""

import asyncio
import json
import logging
import time
import uuid
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass, asdict
from enum import Enum
from pathlib import Path
import sqlite3
from datetime import datetime, timedelta
import numpy as np
from collections import defaultdict, deque
import threading
import queue

logger = logging.getLogger(__name__)

class DataType(Enum):
    """æ•¸æ“šé¡å‹"""
    USER_INTERACTION = "user_interaction"
    SYSTEM_PERFORMANCE = "system_performance"
    ERROR_EVENT = "error_event"
    LEARNING_PROGRESS = "learning_progress"
    CONTEXT_USAGE = "context_usage"
    CLAUDE_INTERACTION = "claude_interaction"
    COMPONENT_METRICS = "component_metrics"
    WORKFLOW_EXECUTION = "workflow_execution"
    OPTIMIZATION_RESULT = "optimization_result"
    FEEDBACK_RESPONSE = "feedback_response"

class DataPriority(Enum):
    """æ•¸æ“šå„ªå…ˆç´š"""
    CRITICAL = "critical"
    HIGH = "high"
    NORMAL = "normal"
    LOW = "low"

@dataclass
class DataPoint:
    """æ•¸æ“šé»"""
    id: str
    data_type: DataType
    priority: DataPriority
    timestamp: float
    source: str
    data: Dict[str, Any]
    metadata: Dict[str, Any]
    processed: bool = False
    
    def to_dict(self) -> Dict[str, Any]:
        """è½‰æ›ç‚ºå­—å…¸"""
        return asdict(self)

@dataclass
class FeedbackLoop:
    """åé¥‹å¾ªç’°"""
    id: str
    name: str
    input_data_types: List[DataType]
    output_actions: List[str]
    processing_function: Callable
    enabled: bool = True
    last_execution: float = 0.0
    execution_count: int = 0
    success_rate: float = 0.0

@dataclass
class CollectionRule:
    """æ”¶é›†è¦å‰‡"""
    id: str
    name: str
    data_type: DataType
    conditions: Dict[str, Any]
    sampling_rate: float = 1.0
    enabled: bool = True
    created_at: float = 0.0

class DataCollectionSystem:
    """æ•¸æ“šæ”¶é›†ç³»çµ±"""
    
    def __init__(self, db_path: str = "data_collection.db"):
        self.db_path = Path(db_path)
        self.connection = None
        
        # æ•¸æ“šæ”¶é›†
        self.data_queue = queue.Queue(maxsize=10000)
        self.collection_rules: Dict[str, CollectionRule] = {}
        self.data_processors: Dict[DataType, List[Callable]] = defaultdict(list)
        
        # åé¥‹å¾ªç’°
        self.feedback_loops: Dict[str, FeedbackLoop] = {}
        self.feedback_results = deque(maxlen=1000)
        
        # å¯¦æ™‚ç›£æ§
        self.real_time_metrics = defaultdict(deque)
        self.metric_thresholds = {}
        self.alert_callbacks = []
        
        # çµ±è¨ˆä¿¡æ¯
        self.collection_stats = {
            "total_data_points": 0,
            "data_by_type": defaultdict(int),
            "data_by_priority": defaultdict(int),
            "processing_errors": 0,
            "feedback_executions": 0,
            "alerts_triggered": 0
        }
        
        # ä»»å‹™ç®¡ç†
        self.collection_tasks = []
        self.processing_tasks = []
        self.feedback_tasks = []
        self.is_running = False
        
    async def initialize(self):
        """åˆå§‹åŒ–æ•¸æ“šæ”¶é›†ç³»çµ±"""
        logger.info("ğŸ“Š åˆå§‹åŒ–æ•¸æ“šæ”¶é›†ç³»çµ±...")
        
        try:
            # å‰µå»ºæ•¸æ“šåº«
            await self._create_database()
            
            # è¼‰å…¥æ”¶é›†è¦å‰‡
            await self._load_collection_rules()
            
            # è¨­ç½®é»˜èªåé¥‹å¾ªç’°
            await self._setup_default_feedback_loops()
            
            # å•Ÿå‹•æ”¶é›†ä»»å‹™
            await self._start_collection_tasks()
            
            self.is_running = True
            logger.info("âœ… æ•¸æ“šæ”¶é›†ç³»çµ±åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ æ•¸æ“šæ”¶é›†ç³»çµ±åˆå§‹åŒ–å¤±æ•—: {e}")
            raise
    
    async def _create_database(self):
        """å‰µå»ºæ•¸æ“šåº«"""
        self.connection = sqlite3.connect(str(self.db_path), check_same_thread=False)
        
        create_sql = """
        CREATE TABLE IF NOT EXISTS data_points (
            id TEXT PRIMARY KEY,
            data_type TEXT NOT NULL,
            priority TEXT NOT NULL,
            timestamp REAL NOT NULL,
            source TEXT NOT NULL,
            data TEXT NOT NULL,
            metadata TEXT,
            processed BOOLEAN DEFAULT 0,
            created_at REAL DEFAULT (strftime('%s', 'now'))
        );
        
        CREATE TABLE IF NOT EXISTS feedback_results (
            id TEXT PRIMARY KEY,
            feedback_loop_id TEXT NOT NULL,
            input_data TEXT NOT NULL,
            output_actions TEXT NOT NULL,
            execution_time REAL NOT NULL,
            success BOOLEAN NOT NULL,
            timestamp REAL NOT NULL,
            error_message TEXT
        );
        
        CREATE TABLE IF NOT EXISTS collection_rules (
            id TEXT PRIMARY KEY,
            name TEXT NOT NULL,
            data_type TEXT NOT NULL,
            conditions TEXT NOT NULL,
            sampling_rate REAL DEFAULT 1.0,
            enabled BOOLEAN DEFAULT 1,
            created_at REAL DEFAULT (strftime('%s', 'now'))
        );
        
        CREATE INDEX IF NOT EXISTS idx_data_type ON data_points(data_type);
        CREATE INDEX IF NOT EXISTS idx_timestamp ON data_points(timestamp);
        CREATE INDEX IF NOT EXISTS idx_priority ON data_points(priority);
        CREATE INDEX IF NOT EXISTS idx_processed ON data_points(processed);
        """
        
        self.connection.executescript(create_sql)
        self.connection.commit()
    
    async def _load_collection_rules(self):
        """è¼‰å…¥æ”¶é›†è¦å‰‡"""
        try:
            cursor = self.connection.cursor()
            cursor.execute("SELECT * FROM collection_rules WHERE enabled = 1")
            
            for row in cursor.fetchall():
                rule = CollectionRule(
                    id=row[0],
                    name=row[1],
                    data_type=DataType(row[2]),
                    conditions=json.loads(row[3]),
                    sampling_rate=row[4],
                    enabled=bool(row[5]),
                    created_at=row[6]
                )
                self.collection_rules[rule.id] = rule
            
            # å¦‚æœæ²’æœ‰è¦å‰‡ï¼Œå‰µå»ºé»˜èªè¦å‰‡
            if not self.collection_rules:
                await self._create_default_rules()
            
            logger.info(f"ğŸ“‹ è¼‰å…¥ {len(self.collection_rules)} å€‹æ”¶é›†è¦å‰‡")
            
        except Exception as e:
            logger.error(f"âŒ è¼‰å…¥æ”¶é›†è¦å‰‡å¤±æ•—: {e}")
            await self._create_default_rules()
    
    async def _create_default_rules(self):
        """å‰µå»ºé»˜èªæ”¶é›†è¦å‰‡"""
        default_rules = [
            CollectionRule(
                id="user_interaction_high",
                name="ç”¨æˆ¶äº¤äº’é«˜å„ªå…ˆç´š",
                data_type=DataType.USER_INTERACTION,
                conditions={"min_response_time": 0, "max_response_time": 10000},
                sampling_rate=1.0,
                enabled=True,
                created_at=time.time()
            ),
            CollectionRule(
                id="claude_interaction_all",
                name="Claude äº¤äº’å…¨è¨˜éŒ„",
                data_type=DataType.CLAUDE_INTERACTION,
                conditions={"min_satisfaction": 0.0},
                sampling_rate=1.0,
                enabled=True,
                created_at=time.time()
            ),
            CollectionRule(
                id="error_critical",
                name="é—œéµéŒ¯èª¤äº‹ä»¶",
                data_type=DataType.ERROR_EVENT,
                conditions={"severity": ["critical", "high"]},
                sampling_rate=1.0,
                enabled=True,
                created_at=time.time()
            ),
            CollectionRule(
                id="performance_monitoring",
                name="æ€§èƒ½ç›£æ§",
                data_type=DataType.SYSTEM_PERFORMANCE,
                conditions={"cpu_threshold": 80, "memory_threshold": 80},
                sampling_rate=0.1,
                enabled=True,
                created_at=time.time()
            ),
            CollectionRule(
                id="learning_progress",
                name="å­¸ç¿’é€²åº¦è·Ÿè¹¤",
                data_type=DataType.LEARNING_PROGRESS,
                conditions={"success_rate_threshold": 0.7},
                sampling_rate=1.0,
                enabled=True,
                created_at=time.time()
            )
        ]
        
        cursor = self.connection.cursor()
        
        for rule in default_rules:
            cursor.execute("""
                INSERT OR REPLACE INTO collection_rules
                (id, name, data_type, conditions, sampling_rate, enabled, created_at)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (
                rule.id,
                rule.name,
                rule.data_type.value,
                json.dumps(rule.conditions),
                rule.sampling_rate,
                rule.enabled,
                rule.created_at
            ))
            
            self.collection_rules[rule.id] = rule
        
        self.connection.commit()
        logger.info(f"âœ… å‰µå»º {len(default_rules)} å€‹é»˜èªæ”¶é›†è¦å‰‡")
    
    async def _setup_default_feedback_loops(self):
        """è¨­ç½®é»˜èªåé¥‹å¾ªç’°"""
        # æ€§èƒ½å„ªåŒ–åé¥‹å¾ªç’°
        self.feedback_loops["performance_optimization"] = FeedbackLoop(
            id="performance_optimization",
            name="æ€§èƒ½å„ªåŒ–åé¥‹",
            input_data_types=[DataType.SYSTEM_PERFORMANCE, DataType.COMPONENT_METRICS],
            output_actions=["optimize_memory", "adjust_thresholds", "scale_resources"],
            processing_function=self._process_performance_feedback,
            enabled=True
        )
        
        # å­¸ç¿’æ”¹é€²åé¥‹å¾ªç’°
        self.feedback_loops["learning_improvement"] = FeedbackLoop(
            id="learning_improvement",
            name="å­¸ç¿’æ”¹é€²åé¥‹",
            input_data_types=[DataType.LEARNING_PROGRESS, DataType.CLAUDE_INTERACTION],
            output_actions=["adjust_learning_rate", "update_models", "optimize_context"],
            processing_function=self._process_learning_feedback,
            enabled=True
        )
        
        # éŒ¯èª¤é é˜²åé¥‹å¾ªç’°
        self.feedback_loops["error_prevention"] = FeedbackLoop(
            id="error_prevention",
            name="éŒ¯èª¤é é˜²åé¥‹",
            input_data_types=[DataType.ERROR_EVENT, DataType.COMPONENT_METRICS],
            output_actions=["update_error_patterns", "adjust_monitoring", "preventive_fixes"],
            processing_function=self._process_error_feedback,
            enabled=True
        )
        
        # ç”¨æˆ¶é«”é©—å„ªåŒ–åé¥‹å¾ªç’°
        self.feedback_loops["user_experience"] = FeedbackLoop(
            id="user_experience",
            name="ç”¨æˆ¶é«”é©—å„ªåŒ–",
            input_data_types=[DataType.USER_INTERACTION, DataType.FEEDBACK_RESPONSE],
            output_actions=["personalize_interface", "adjust_responses", "improve_workflow"],
            processing_function=self._process_user_feedback,
            enabled=True
        )
        
        logger.info(f"ğŸ”„ è¨­ç½® {len(self.feedback_loops)} å€‹åé¥‹å¾ªç’°")
    
    async def _start_collection_tasks(self):
        """å•Ÿå‹•æ”¶é›†ä»»å‹™"""
        # æ•¸æ“šè™•ç†ä»»å‹™
        processing_task = asyncio.create_task(self._process_data_queue())
        self.processing_tasks.append(processing_task)
        
        # åé¥‹å¾ªç’°ä»»å‹™
        feedback_task = asyncio.create_task(self._execute_feedback_loops())
        self.feedback_tasks.append(feedback_task)
        
        # å¯¦æ™‚ç›£æ§ä»»å‹™
        monitoring_task = asyncio.create_task(self._monitor_real_time_metrics())
        self.collection_tasks.append(monitoring_task)
        
        # æ•¸æ“šæ¸…ç†ä»»å‹™
        cleanup_task = asyncio.create_task(self._cleanup_old_data())
        self.collection_tasks.append(cleanup_task)
        
        logger.info("ğŸš€ æ•¸æ“šæ”¶é›†ä»»å‹™å•Ÿå‹•å®Œæˆ")
    
    async def collect_data(self, 
                         data_type: DataType,
                         source: str,
                         data: Dict[str, Any],
                         priority: DataPriority = DataPriority.NORMAL,
                         metadata: Dict[str, Any] = None):
        """æ”¶é›†æ•¸æ“š"""
        try:
            # æª¢æŸ¥æ”¶é›†è¦å‰‡
            if not self._should_collect_data(data_type, data):
                return
            
            # å‰µå»ºæ•¸æ“šé»
            data_point = DataPoint(
                id=str(uuid.uuid4()),
                data_type=data_type,
                priority=priority,
                timestamp=time.time(),
                source=source,
                data=data,
                metadata=metadata or {},
                processed=False
            )
            
            # æ·»åŠ åˆ°éšŠåˆ—
            if not self.data_queue.full():
                self.data_queue.put(data_point)
                
                # æ›´æ–°çµ±è¨ˆ
                self.collection_stats["total_data_points"] += 1
                self.collection_stats["data_by_type"][data_type.value] += 1
                self.collection_stats["data_by_priority"][priority.value] += 1
                
                # æ›´æ–°å¯¦æ™‚æŒ‡æ¨™
                self._update_real_time_metrics(data_type, data)
                
                logger.debug(f"ğŸ“Š æ”¶é›†æ•¸æ“š: {data_type.value} from {source}")
            else:
                logger.warning("âš ï¸ æ•¸æ“šéšŠåˆ—å·²æ»¿ï¼Œä¸Ÿæ£„æ•¸æ“šé»")
                
        except Exception as e:
            logger.error(f"âŒ æ”¶é›†æ•¸æ“šå¤±æ•—: {e}")
    
    def _should_collect_data(self, data_type: DataType, data: Dict[str, Any]) -> bool:
        """æª¢æŸ¥æ˜¯å¦æ‡‰è©²æ”¶é›†æ•¸æ“š"""
        for rule in self.collection_rules.values():
            if rule.data_type == data_type and rule.enabled:
                # æª¢æŸ¥æ¡æ¨£ç‡
                if np.random.random() > rule.sampling_rate:
                    return False
                
                # æª¢æŸ¥æ¢ä»¶
                if self._check_rule_conditions(rule, data):
                    return True
        
        return False
    
    def _check_rule_conditions(self, rule: CollectionRule, data: Dict[str, Any]) -> bool:
        """æª¢æŸ¥è¦å‰‡æ¢ä»¶"""
        try:
            conditions = rule.conditions
            
            # æª¢æŸ¥éŸ¿æ‡‰æ™‚é–“æ¢ä»¶
            if "min_response_time" in conditions:
                response_time = data.get("response_time", 0)
                if response_time < conditions["min_response_time"]:
                    return False
            
            if "max_response_time" in conditions:
                response_time = data.get("response_time", float('inf'))
                if response_time > conditions["max_response_time"]:
                    return False
            
            # æª¢æŸ¥æ»¿æ„åº¦æ¢ä»¶
            if "min_satisfaction" in conditions:
                satisfaction = data.get("user_satisfaction", 0)
                if satisfaction < conditions["min_satisfaction"]:
                    return False
            
            # æª¢æŸ¥åš´é‡ç¨‹åº¦æ¢ä»¶
            if "severity" in conditions:
                severity = data.get("severity", "")
                if severity not in conditions["severity"]:
                    return False
            
            # æª¢æŸ¥é–¾å€¼æ¢ä»¶
            if "cpu_threshold" in conditions:
                cpu_usage = data.get("cpu_usage", 0)
                if cpu_usage < conditions["cpu_threshold"]:
                    return False
            
            if "memory_threshold" in conditions:
                memory_usage = data.get("memory_usage", 0)
                if memory_usage < conditions["memory_threshold"]:
                    return False
            
            # æª¢æŸ¥æˆåŠŸç‡æ¢ä»¶
            if "success_rate_threshold" in conditions:
                success_rate = data.get("success_rate", 0)
                if success_rate < conditions["success_rate_threshold"]:
                    return False
            
            return True
            
        except Exception as e:
            logger.warning(f"æª¢æŸ¥è¦å‰‡æ¢ä»¶å¤±æ•—: {e}")
            return True  # é»˜èªæ”¶é›†
    
    def _update_real_time_metrics(self, data_type: DataType, data: Dict[str, Any]):
        """æ›´æ–°å¯¦æ™‚æŒ‡æ¨™"""
        try:
            # æ›´æ–°é€šç”¨æŒ‡æ¨™
            self.real_time_metrics["data_rate"].append(time.time())
            
            # æ›´æ–°ç‰¹å®šé¡å‹æŒ‡æ¨™
            if data_type == DataType.SYSTEM_PERFORMANCE:
                if "cpu_usage" in data:
                    self.real_time_metrics["cpu_usage"].append(data["cpu_usage"])
                if "memory_usage" in data:
                    self.real_time_metrics["memory_usage"].append(data["memory_usage"])
            
            elif data_type == DataType.CLAUDE_INTERACTION:
                if "response_time" in data:
                    self.real_time_metrics["response_time"].append(data["response_time"])
                if "user_satisfaction" in data:
                    self.real_time_metrics["user_satisfaction"].append(data["user_satisfaction"])
            
            elif data_type == DataType.ERROR_EVENT:
                self.real_time_metrics["error_rate"].append(time.time())
            
            elif data_type == DataType.LEARNING_PROGRESS:
                if "success_rate" in data:
                    self.real_time_metrics["learning_success_rate"].append(data["success_rate"])
            
            # ä¿æŒæŒ‡æ¨™éšŠåˆ—å¤§å°
            for metric_name, metric_queue in self.real_time_metrics.items():
                if len(metric_queue) > 100:
                    # ç§»é™¤æœ€èˆŠçš„æ•¸æ“š
                    for _ in range(len(metric_queue) - 100):
                        metric_queue.popleft()
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°å¯¦æ™‚æŒ‡æ¨™å¤±æ•—: {e}")
    
    async def _process_data_queue(self):
        """è™•ç†æ•¸æ“šéšŠåˆ—"""
        while self.is_running:
            try:
                # æ‰¹é‡è™•ç†æ•¸æ“š
                batch = []
                batch_size = 50
                
                for _ in range(batch_size):
                    try:
                        data_point = self.data_queue.get(timeout=1.0)
                        batch.append(data_point)
                    except queue.Empty:
                        break
                
                if batch:
                    await self._process_data_batch(batch)
                
                # çŸ­æš«ä¼‘æ¯
                await asyncio.sleep(0.1)
                
            except Exception as e:
                logger.error(f"âŒ è™•ç†æ•¸æ“šéšŠåˆ—å¤±æ•—: {e}")
                await asyncio.sleep(1)
    
    async def _process_data_batch(self, batch: List[DataPoint]):
        """è™•ç†æ•¸æ“šæ‰¹æ¬¡"""
        try:
            # ä¿å­˜åˆ°æ•¸æ“šåº«
            cursor = self.connection.cursor()
            
            for data_point in batch:
                cursor.execute("""
                    INSERT INTO data_points
                    (id, data_type, priority, timestamp, source, data, metadata, processed)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    data_point.id,
                    data_point.data_type.value,
                    data_point.priority.value,
                    data_point.timestamp,
                    data_point.source,
                    json.dumps(data_point.data),
                    json.dumps(data_point.metadata),
                    data_point.processed
                ))
            
            self.connection.commit()
            
            # èª¿ç”¨æ•¸æ“šè™•ç†å™¨
            await self._call_data_processors(batch)
            
            logger.debug(f"ğŸ“Š è™•ç†æ•¸æ“šæ‰¹æ¬¡: {len(batch)} å€‹æ•¸æ“šé»")
            
        except Exception as e:
            logger.error(f"âŒ è™•ç†æ•¸æ“šæ‰¹æ¬¡å¤±æ•—: {e}")
            self.collection_stats["processing_errors"] += 1
    
    async def _call_data_processors(self, batch: List[DataPoint]):
        """èª¿ç”¨æ•¸æ“šè™•ç†å™¨"""
        try:
            # æŒ‰æ•¸æ“šé¡å‹åˆ†çµ„
            grouped_data = defaultdict(list)
            for data_point in batch:
                grouped_data[data_point.data_type].append(data_point)
            
            # èª¿ç”¨å°æ‡‰çš„è™•ç†å™¨
            for data_type, data_points in grouped_data.items():
                if data_type in self.data_processors:
                    for processor in self.data_processors[data_type]:
                        try:
                            await processor(data_points)
                        except Exception as e:
                            logger.error(f"âŒ æ•¸æ“šè™•ç†å™¨å¤±æ•— ({data_type.value}): {e}")
            
        except Exception as e:
            logger.error(f"âŒ èª¿ç”¨æ•¸æ“šè™•ç†å™¨å¤±æ•—: {e}")
    
    async def _execute_feedback_loops(self):
        """åŸ·è¡Œåé¥‹å¾ªç’°"""
        while self.is_running:
            try:
                for loop_id, feedback_loop in self.feedback_loops.items():
                    if feedback_loop.enabled:
                        # æª¢æŸ¥æ˜¯å¦åˆ°äº†åŸ·è¡Œæ™‚é–“
                        current_time = time.time()
                        if current_time - feedback_loop.last_execution >= 60:  # 1åˆ†é˜é–“éš”
                            await self._execute_single_feedback_loop(feedback_loop)
                
                # ç­‰å¾…ä¸‹ä¸€æ¬¡æª¢æŸ¥
                await asyncio.sleep(30)  # 30ç§’æª¢æŸ¥ä¸€æ¬¡
                
            except Exception as e:
                logger.error(f"âŒ åŸ·è¡Œåé¥‹å¾ªç’°å¤±æ•—: {e}")
                await asyncio.sleep(60)
    
    async def _execute_single_feedback_loop(self, feedback_loop: FeedbackLoop):
        """åŸ·è¡Œå–®å€‹åé¥‹å¾ªç’°"""
        try:
            start_time = time.time()
            
            # æ”¶é›†è¼¸å…¥æ•¸æ“š
            input_data = await self._collect_feedback_input_data(feedback_loop)
            
            if not input_data:
                return
            
            # åŸ·è¡Œè™•ç†å‡½æ•¸
            output_actions = await feedback_loop.processing_function(input_data)
            
            # è¨˜éŒ„çµæœ
            execution_time = time.time() - start_time
            success = bool(output_actions)
            
            # æ›´æ–°åé¥‹å¾ªç’°çµ±è¨ˆ
            feedback_loop.last_execution = time.time()
            feedback_loop.execution_count += 1
            
            # æ›´æ–°æˆåŠŸç‡
            if success:
                feedback_loop.success_rate = (
                    feedback_loop.success_rate * 0.9 + 0.1
                )
            else:
                feedback_loop.success_rate = (
                    feedback_loop.success_rate * 0.9
                )
            
            # ä¿å­˜çµæœ
            await self._save_feedback_result(
                feedback_loop.id,
                input_data,
                output_actions,
                execution_time,
                success
            )
            
            self.collection_stats["feedback_executions"] += 1
            
            logger.debug(f"ğŸ”„ åŸ·è¡Œåé¥‹å¾ªç’°: {feedback_loop.name}")
            
        except Exception as e:
            logger.error(f"âŒ åŸ·è¡Œåé¥‹å¾ªç’°å¤±æ•— ({feedback_loop.name}): {e}")
            
            # ä¿å­˜å¤±æ•—çµæœ
            await self._save_feedback_result(
                feedback_loop.id,
                {},
                [],
                time.time() - start_time,
                False,
                str(e)
            )
    
    async def _collect_feedback_input_data(self, feedback_loop: FeedbackLoop) -> Dict[str, Any]:
        """æ”¶é›†åé¥‹è¼¸å…¥æ•¸æ“š"""
        try:
            input_data = {}
            
            # å¾æ•¸æ“šåº«æŸ¥è©¢ç›¸é—œæ•¸æ“š
            cursor = self.connection.cursor()
            
            for data_type in feedback_loop.input_data_types:
                cursor.execute("""
                    SELECT data FROM data_points
                    WHERE data_type = ? AND timestamp > ?
                    ORDER BY timestamp DESC
                    LIMIT 50
                """, (data_type.value, time.time() - 3600))  # æœ€è¿‘1å°æ™‚
                
                rows = cursor.fetchall()
                data_points = []
                
                for row in rows:
                    try:
                        data_points.append(json.loads(row[0]))
                    except json.JSONDecodeError:
                        continue
                
                input_data[data_type.value] = data_points
            
            return input_data
            
        except Exception as e:
            logger.error(f"âŒ æ”¶é›†åé¥‹è¼¸å…¥æ•¸æ“šå¤±æ•—: {e}")
            return {}
    
    async def _save_feedback_result(self,
                                  feedback_loop_id: str,
                                  input_data: Dict[str, Any],
                                  output_actions: List[str],
                                  execution_time: float,
                                  success: bool,
                                  error_message: str = None):
        """ä¿å­˜åé¥‹çµæœ"""
        try:
            result_id = str(uuid.uuid4())
            
            cursor = self.connection.cursor()
            cursor.execute("""
                INSERT INTO feedback_results
                (id, feedback_loop_id, input_data, output_actions, execution_time, success, timestamp, error_message)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                result_id,
                feedback_loop_id,
                json.dumps(input_data),
                json.dumps(output_actions),
                execution_time,
                success,
                time.time(),
                error_message
            ))
            
            self.connection.commit()
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜åé¥‹çµæœå¤±æ•—: {e}")
    
    async def _monitor_real_time_metrics(self):
        """ç›£æ§å¯¦æ™‚æŒ‡æ¨™"""
        while self.is_running:
            try:
                # æª¢æŸ¥é–¾å€¼
                await self._check_metric_thresholds()
                
                # ç­‰å¾…ä¸‹ä¸€æ¬¡æª¢æŸ¥
                await asyncio.sleep(30)  # 30ç§’æª¢æŸ¥ä¸€æ¬¡
                
            except Exception as e:
                logger.error(f"âŒ ç›£æ§å¯¦æ™‚æŒ‡æ¨™å¤±æ•—: {e}")
                await asyncio.sleep(60)
    
    async def _check_metric_thresholds(self):
        """æª¢æŸ¥æŒ‡æ¨™é–¾å€¼"""
        try:
            current_time = time.time()
            
            # æª¢æŸ¥å„ç¨®æŒ‡æ¨™
            metrics_to_check = {
                "cpu_usage": {"threshold": 90, "duration": 300},
                "memory_usage": {"threshold": 85, "duration": 300},
                "error_rate": {"threshold": 10, "duration": 300},  # æ¯5åˆ†é˜10å€‹éŒ¯èª¤
                "response_time": {"threshold": 5000, "duration": 300}
            }
            
            for metric_name, config in metrics_to_check.items():
                if metric_name in self.real_time_metrics:
                    await self._check_single_metric_threshold(
                        metric_name,
                        config["threshold"],
                        config["duration"],
                        current_time
                    )
            
        except Exception as e:
            logger.error(f"âŒ æª¢æŸ¥æŒ‡æ¨™é–¾å€¼å¤±æ•—: {e}")
    
    async def _check_single_metric_threshold(self,
                                           metric_name: str,
                                           threshold: float,
                                           duration: float,
                                           current_time: float):
        """æª¢æŸ¥å–®å€‹æŒ‡æ¨™é–¾å€¼"""
        try:
            metric_queue = self.real_time_metrics[metric_name]
            
            if not metric_queue:
                return
            
            # éæ¿¾æŒ‡å®šæ™‚é–“å…§çš„æ•¸æ“š
            if metric_name == "error_rate":
                # éŒ¯èª¤ç‡è¨ˆç®—
                recent_errors = [
                    timestamp for timestamp in metric_queue
                    if current_time - timestamp <= duration
                ]
                current_value = len(recent_errors)
            else:
                # å…¶ä»–æŒ‡æ¨™çš„å¹³å‡å€¼
                recent_values = [
                    value for value in metric_queue
                    if isinstance(value, (int, float))
                ]
                current_value = np.mean(recent_values) if recent_values else 0
            
            # æª¢æŸ¥æ˜¯å¦è¶…éé–¾å€¼
            if current_value > threshold:
                await self._trigger_alert(metric_name, current_value, threshold)
            
        except Exception as e:
            logger.error(f"âŒ æª¢æŸ¥å–®å€‹æŒ‡æ¨™é–¾å€¼å¤±æ•— ({metric_name}): {e}")
    
    async def _trigger_alert(self, metric_name: str, current_value: float, threshold: float):
        """è§¸ç™¼è­¦å ±"""
        try:
            alert_data = {
                "metric_name": metric_name,
                "current_value": current_value,
                "threshold": threshold,
                "timestamp": time.time(),
                "severity": "high" if current_value > threshold * 1.5 else "medium"
            }
            
            # èª¿ç”¨è­¦å ±å›èª¿
            for callback in self.alert_callbacks:
                try:
                    await callback(alert_data)
                except Exception as e:
                    logger.error(f"âŒ è­¦å ±å›èª¿å¤±æ•—: {e}")
            
            # æ”¶é›†è­¦å ±æ•¸æ“š
            await self.collect_data(
                data_type=DataType.SYSTEM_PERFORMANCE,
                source="alert_system",
                data=alert_data,
                priority=DataPriority.HIGH
            )
            
            self.collection_stats["alerts_triggered"] += 1
            
            logger.warning(f"ğŸš¨ è§¸ç™¼è­¦å ±: {metric_name} = {current_value:.2f} (é–¾å€¼: {threshold})")
            
        except Exception as e:
            logger.error(f"âŒ è§¸ç™¼è­¦å ±å¤±æ•—: {e}")
    
    async def _cleanup_old_data(self):
        """æ¸…ç†èˆŠæ•¸æ“š"""
        while self.is_running:
            try:
                # æ¸…ç†30å¤©å‰çš„æ•¸æ“š
                cutoff_time = time.time() - (30 * 24 * 3600)
                
                cursor = self.connection.cursor()
                
                # æ¸…ç†æ•¸æ“šé»
                cursor.execute("""
                    DELETE FROM data_points
                    WHERE timestamp < ?
                """, (cutoff_time,))
                
                # æ¸…ç†åé¥‹çµæœ
                cursor.execute("""
                    DELETE FROM feedback_results
                    WHERE timestamp < ?
                """, (cutoff_time,))
                
                self.connection.commit()
                
                logger.info("ğŸ§¹ æ¸…ç†èˆŠæ•¸æ“šå®Œæˆ")
                
                # ç­‰å¾…ä¸‹ä¸€æ¬¡æ¸…ç†ï¼ˆæ¯å¤©æ¸…ç†ä¸€æ¬¡ï¼‰
                await asyncio.sleep(86400)
                
            except Exception as e:
                logger.error(f"âŒ æ¸…ç†èˆŠæ•¸æ“šå¤±æ•—: {e}")
                await asyncio.sleep(3600)  # éŒ¯èª¤æ™‚1å°æ™‚å¾Œé‡è©¦
    
    # åé¥‹å¾ªç’°è™•ç†å‡½æ•¸
    async def _process_performance_feedback(self, input_data: Dict[str, Any]) -> List[str]:
        """è™•ç†æ€§èƒ½åé¥‹"""
        actions = []
        
        # åˆ†æç³»çµ±æ€§èƒ½æ•¸æ“š
        performance_data = input_data.get("system_performance", [])
        
        if performance_data:
            # è¨ˆç®—å¹³å‡ CPU å’Œå…§å­˜ä½¿ç”¨ç‡
            cpu_usage = [d.get("cpu_usage", 0) for d in performance_data if "cpu_usage" in d]
            memory_usage = [d.get("memory_usage", 0) for d in performance_data if "memory_usage" in d]
            
            if cpu_usage:
                avg_cpu = np.mean(cpu_usage)
                if avg_cpu > 80:
                    actions.append("optimize_cpu_usage")
            
            if memory_usage:
                avg_memory = np.mean(memory_usage)
                if avg_memory > 80:
                    actions.append("optimize_memory_usage")
        
        return actions
    
    async def _process_learning_feedback(self, input_data: Dict[str, Any]) -> List[str]:
        """è™•ç†å­¸ç¿’åé¥‹"""
        actions = []
        
        # åˆ†æå­¸ç¿’é€²åº¦æ•¸æ“š
        learning_data = input_data.get("learning_progress", [])
        claude_data = input_data.get("claude_interaction", [])
        
        if learning_data:
            success_rates = [d.get("success_rate", 0) for d in learning_data if "success_rate" in d]
            if success_rates:
                avg_success_rate = np.mean(success_rates)
                if avg_success_rate < 0.7:
                    actions.append("adjust_learning_parameters")
        
        if claude_data:
            satisfactions = [d.get("user_satisfaction", 0) for d in claude_data if "user_satisfaction" in d]
            if satisfactions:
                avg_satisfaction = np.mean(satisfactions)
                if avg_satisfaction < 0.6:
                    actions.append("improve_response_quality")
        
        return actions
    
    async def _process_error_feedback(self, input_data: Dict[str, Any]) -> List[str]:
        """è™•ç†éŒ¯èª¤åé¥‹"""
        actions = []
        
        # åˆ†æéŒ¯èª¤äº‹ä»¶æ•¸æ“š
        error_data = input_data.get("error_event", [])
        
        if error_data:
            # çµ±è¨ˆéŒ¯èª¤é¡å‹
            error_types = defaultdict(int)
            for error in error_data:
                error_type = error.get("error_type", "unknown")
                error_types[error_type] += 1
            
            # å¦‚æœæŸç¨®éŒ¯èª¤é »ç¹å‡ºç¾ï¼Œæ¡å–è¡Œå‹•
            for error_type, count in error_types.items():
                if count > 5:  # è¶…é5æ¬¡
                    actions.append(f"prevent_{error_type}_errors")
        
        return actions
    
    async def _process_user_feedback(self, input_data: Dict[str, Any]) -> List[str]:
        """è™•ç†ç”¨æˆ¶åé¥‹"""
        actions = []
        
        # åˆ†æç”¨æˆ¶äº¤äº’æ•¸æ“š
        user_data = input_data.get("user_interaction", [])
        feedback_data = input_data.get("feedback_response", [])
        
        if user_data:
            response_times = [d.get("response_time", 0) for d in user_data if "response_time" in d]
            if response_times:
                avg_response_time = np.mean(response_times)
                if avg_response_time > 3000:  # è¶…é3ç§’
                    actions.append("optimize_response_time")
        
        if feedback_data:
            ratings = [d.get("rating", 0) for d in feedback_data if "rating" in d]
            if ratings:
                avg_rating = np.mean(ratings)
                if avg_rating < 0.7:
                    actions.append("improve_user_experience")
        
        return actions
    
    # å…¬å…± API æ–¹æ³•
    def add_data_processor(self, data_type: DataType, processor: Callable):
        """æ·»åŠ æ•¸æ“šè™•ç†å™¨"""
        self.data_processors[data_type].append(processor)
        logger.info(f"â• æ·»åŠ æ•¸æ“šè™•ç†å™¨: {data_type.value}")
    
    def add_alert_callback(self, callback: Callable):
        """æ·»åŠ è­¦å ±å›èª¿"""
        self.alert_callbacks.append(callback)
        logger.info("ğŸš¨ æ·»åŠ è­¦å ±å›èª¿")
    
    def remove_alert_callback(self, callback: Callable):
        """ç§»é™¤è­¦å ±å›èª¿"""
        if callback in self.alert_callbacks:
            self.alert_callbacks.remove(callback)
            logger.info("ğŸ—‘ï¸ ç§»é™¤è­¦å ±å›èª¿")
    
    async def get_collection_statistics(self) -> Dict[str, Any]:
        """ç²å–æ”¶é›†çµ±è¨ˆ"""
        try:
            # è¨ˆç®—å¯¦æ™‚æŒ‡æ¨™çµ±è¨ˆ
            real_time_stats = {}
            for metric_name, metric_queue in self.real_time_metrics.items():
                if metric_queue:
                    if metric_name in ["error_rate", "data_rate"]:
                        # è¨ˆç®—é »ç‡
                        recent_count = len([
                            timestamp for timestamp in metric_queue
                            if time.time() - timestamp <= 300  # æœ€è¿‘5åˆ†é˜
                        ])
                        real_time_stats[metric_name] = recent_count
                    else:
                        # è¨ˆç®—å¹³å‡å€¼
                        values = [v for v in metric_queue if isinstance(v, (int, float))]
                        real_time_stats[metric_name] = np.mean(values) if values else 0
            
            # ç²å–æ•¸æ“šåº«çµ±è¨ˆ
            cursor = self.connection.cursor()
            
            # æ•¸æ“šé»çµ±è¨ˆ
            cursor.execute("SELECT COUNT(*) FROM data_points")
            total_data_points = cursor.fetchone()[0]
            
            # åé¥‹çµæœçµ±è¨ˆ
            cursor.execute("SELECT COUNT(*) FROM feedback_results")
            total_feedback_results = cursor.fetchone()[0]
            
            # åé¥‹å¾ªç’°çµ±è¨ˆ
            feedback_loop_stats = {}
            for loop_id, loop in self.feedback_loops.items():
                feedback_loop_stats[loop_id] = {
                    "name": loop.name,
                    "enabled": loop.enabled,
                    "execution_count": loop.execution_count,
                    "success_rate": loop.success_rate,
                    "last_execution": loop.last_execution
                }
            
            return {
                "collection_stats": self.collection_stats,
                "real_time_metrics": real_time_stats,
                "database_stats": {
                    "total_data_points": total_data_points,
                    "total_feedback_results": total_feedback_results
                },
                "feedback_loops": feedback_loop_stats,
                "collection_rules": len(self.collection_rules),
                "is_running": self.is_running
            }
            
        except Exception as e:
            logger.error(f"âŒ ç²å–æ”¶é›†çµ±è¨ˆå¤±æ•—: {e}")
            return {}
    
    async def cleanup(self):
        """æ¸…ç†è³‡æº"""
        logger.info("ğŸ§¹ æ¸…ç†æ•¸æ“šæ”¶é›†ç³»çµ±...")
        
        # åœæ­¢é‹è¡Œ
        self.is_running = False
        
        # å–æ¶ˆæ‰€æœ‰ä»»å‹™
        all_tasks = self.collection_tasks + self.processing_tasks + self.feedback_tasks
        for task in all_tasks:
            task.cancel()
            try:
                await task
            except asyncio.CancelledError:
                pass
        
        # è™•ç†å‰©é¤˜çš„æ•¸æ“šéšŠåˆ—
        remaining_data = []
        while not self.data_queue.empty():
            try:
                data_point = self.data_queue.get_nowait()
                remaining_data.append(data_point)
            except queue.Empty:
                break
        
        if remaining_data:
            await self._process_data_batch(remaining_data)
        
        # é—œé–‰æ•¸æ“šåº«é€£æ¥
        if self.connection:
            self.connection.close()
        
        logger.info("âœ… æ•¸æ“šæ”¶é›†ç³»çµ±æ¸…ç†å®Œæˆ")

# å‰µå»ºå…¨å±€æ•¸æ“šæ”¶é›†ç³»çµ±å¯¦ä¾‹
data_collection_system = None

async def initialize_data_collection_system():
    """åˆå§‹åŒ–æ•¸æ“šæ”¶é›†ç³»çµ±"""
    global data_collection_system
    
    if data_collection_system is None:
        data_collection_system = DataCollectionSystem()
        await data_collection_system.initialize()
    
    return data_collection_system

async def get_data_collection_system():
    """ç²å–æ•¸æ“šæ”¶é›†ç³»çµ±å¯¦ä¾‹"""
    global data_collection_system
    
    if data_collection_system is None:
        data_collection_system = await initialize_data_collection_system()
    
    return data_collection_system

# æ¸¬è©¦å‡½æ•¸
async def main():
    """æ¸¬è©¦æ•¸æ“šæ”¶é›†ç³»çµ±"""
    print("ğŸ§ª æ¸¬è©¦æ•¸æ“šæ”¶é›†ç³»çµ±...")
    
    # åˆå§‹åŒ–ç³»çµ±
    system = await initialize_data_collection_system()
    
    # æ¸¬è©¦æ•¸æ“šæ”¶é›†
    await system.collect_data(
        data_type=DataType.CLAUDE_INTERACTION,
        source="test_system",
        data={
            "user_input": "å¦‚ä½•ä½¿ç”¨ Python é€²è¡Œæ•¸æ“šåˆ†æï¼Ÿ",
            "claude_response": "Python æ•¸æ“šåˆ†æå¯ä»¥ä½¿ç”¨ pandasã€numpy ç­‰åº«...",
            "response_time": 2500,
            "user_satisfaction": 0.85
        },
        priority=DataPriority.HIGH
    )
    
    # æ¸¬è©¦æ€§èƒ½æ•¸æ“šæ”¶é›†
    await system.collect_data(
        data_type=DataType.SYSTEM_PERFORMANCE,
        source="system_monitor",
        data={
            "cpu_usage": 75.5,
            "memory_usage": 68.2,
            "disk_usage": 45.8
        },
        priority=DataPriority.NORMAL
    )
    
    # ç­‰å¾…è™•ç†
    await asyncio.sleep(2)
    
    # ç²å–çµ±è¨ˆ
    stats = await system.get_collection_statistics()
    print(f"ğŸ“Š æ”¶é›†çµ±è¨ˆ: {stats}")
    
    # æ¸…ç†
    await system.cleanup()
    print("âœ… æ¸¬è©¦å®Œæˆ")

if __name__ == "__main__":
    asyncio.run(main())